<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>APISIX</title>
    <url>/article/gateway/apisix/</url>
    <content><![CDATA[<h2 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h2><p><a href="https://github.com/apache/apisix">APISIX</a> 是基于 <a href="https://links.jianshu.com/go?to=https://github.com/openresty/">OpenResty</a> + <a href="https://links.jianshu.com/go?to=https://github.com/etcd-io/etcd">etcd</a> 实现的云原生、高性能、可扩展的微服务 API 网关。它是国人开源，目前已经进入 Apache 进行孵化。</p>
<ul>
<li>OpenResty：通过 Lua 扩展 Nginx 实现的可伸缩的 Web 平台。</li>
<li>etcd：Key&#x2F;Value 存储系统。</li>
</ul>
<p>Apache APISIX 是一个动态、实时、高性能的 API 网关，提供负载均衡、动态上游、灰度发布、服务熔断、身份认证、可观测性等丰富的流量管理功能。Apache APISIX 不仅拥有众多实用的插件，而且支持插件动态变更和热插拔。APISIX 通过<a href="https://links.jianshu.com/go?to=https://github.com/apache/incubator-apisix/blob/master/doc/README_CN.md%23%25E6%258F%2592%25E4%25BB%25B6">插件机制</a>，提供了动态负载平衡、身份验证、限流限速等等功能，当然我们也可以自己开发插件进行拓展。<br><a href="https://nacos.io/zh-cn/blog/apisix.html">https://nacos.io/zh-cn/blog/apisix.html</a></p>
<h2 id="2、应用场景"><a href="#2、应用场景" class="headerlink" title="2、应用场景"></a>2、应用场景</h2><p>Apache APISIX + Nacos 可以将各个微服务节点中与业务无关的各项控制，集中在 Apache APISIX 中进行统一管理，即通过 Apache APISIX 实现接口服务的代理和路由转发的能力。各个微服务在 Nacos 上注册后，Apache APISIX 可以通过 Nacos 的服务发现功能获取服务列表，查找对应的服务地址从而实现动态代理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647155726611-f9cab74d-4ad9-4d47-9d05-6fcc1a719707.png#clientId=u1b21c1b5-5289-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=371&id=u340fb91b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=913&originWidth=1280&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=119938&status=done&style=none&taskId=u81026da1-86c3-4b1a-b7fd-014fcc40863&title=&width=520" alt="image.png"></p>
<h2 id="3、服务发现"><a href="#3、服务发现" class="headerlink" title="3、服务发现"></a>3、服务发现</h2><p>Apache APISIX 基于 Nacos 实现服务返现</p>
<h3 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h3><p>本文操作基于以下环境进行。</p>
<ul>
<li>操作系统 Centos 7.9。</li>
<li>已安装 Apache APISIX 12.1.0，详情请参考：<a href="https://apisix.apache.org/zh/docs/apisix/how-to-buildhttps://apisix.apache.org/zh/docs/apisix/how-to-build">Apache APISIX how-to-bulid</a>。</li>
<li>已安装 Nacos 2.0.4 及以上版本，详情请参考：<a href="https://nacos.io/zh-cn/docs/quick-start.html">quick start</a>。</li>
<li>已安装 Node.js，详情请参考：<a href="https://github.com/nodejs/help/wiki/Installation">node.js Installation</a>。</li>
</ul>
<h3 id="步骤一：服务注册"><a href="#步骤一：服务注册" class="headerlink" title="步骤一：服务注册"></a>步骤一：服务注册</h3><p>1、使用 Node.js 的 Koa 框架在 3005 端口启动一个简单的测试服务作为<a href="https://apisix.apache.org/zh/docs/apisix/admin-api#upstream">上游（Upstream）</a>。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">const Koa &#x3D; require(&#39;koa&#39;);
const app &#x3D; new Koa();

app.use(async ctx &#x3D;&gt; &#123;
  ctx.body &#x3D; &#39;Hello World&#39;;
&#125;);

app.listen(3005);</code></pre>

<p>2、在命令行中通过请求 Nacos Open API 的方式进行服务注册。<br><code>curl -X POST &#39;http://127.0.0.1:8848/nacos/v1/ns/instance?serviceName=APISIX-NACOS&amp;ip=127.0.0.1&amp;port=3005&amp;ephemeral=false&#39; </code><br>3、执行服务注册后使用以下命令查询当前服务情况。<br><code>curl -X GET &#39;http://127.0.0.1:8848/nacos/v1/ns/instance/list?serviceName=APISIX-NACOS&#39; </code><br>正确返回结果示例如下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">&#123;
  &quot;name&quot;: &quot;DEFAULT_GROUP@@APISIX-NACOS&quot;,
  &quot;groupName&quot;: &quot;DEFAULT_GROUP&quot;,
  &quot;clusters&quot;: &quot;&quot;,
  &quot;cacheMillis&quot;: 10000,
  &quot;hosts&quot;: [
    &#123;
      &quot;instanceId&quot;: &quot;127.0.0.1#3005#DEFAULT#DEFAULT_GROUP@@APISIX-NACOS&quot;,
      &quot;ip&quot;: &quot;127.0.0.1&quot;,
      &quot;port&quot;: 3005,
      &quot;weight&quot;: 1.0,
      &quot;healthy&quot;: true,
      &quot;enabled&quot;: true,
      &quot;ephemeral&quot;: true,
      &quot;clusterName&quot;: &quot;DEFAULT&quot;,
      &quot;serviceName&quot;: &quot;DEFAULT_GROUP@@APISIX-NACOS&quot;,
      &quot;metadata&quot;: &#123;&#125;,
      &quot;instanceHeartBeatInterval&quot;: 5000,
      &quot;instanceHeartBeatTimeOut&quot;: 15000,
      &quot;ipDeleteTimeout&quot;: 30000,
      &quot;instanceIdGenerator&quot;: &quot;simple&quot;
    &#125;
  ],
  &quot;lastRefTime&quot;: 1643191399694,
  &quot;checksum&quot;: &quot;&quot;,
  &quot;allIPs&quot;: false,
  &quot;reachProtectionThreshold&quot;: false,
  &quot;valid&quot;: true
&#125;</code></pre>

<h3 id="步骤二：新增-Nacos-路由"><a href="#步骤二：新增-Nacos-路由" class="headerlink" title="步骤二：新增 Nacos 路由"></a>步骤二：新增 Nacos 路由</h3><p>使用 Apache APISIX 提供的 Admin API 创建一个新的<a href="https://apisix.apache.org/zh/docs/apisix/admin-api#route">路由（Route）</a>，APISIX 通过 upstream.discovery_type 字段选择使用的服务发现类型，upstream.service_name 需要与注册中心的对应服务名进行关联，因此创建路由时指定服务发现类型为 nacos 。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">curl http:&#x2F;&#x2F;127.0.0.1:9080&#x2F;apisix&#x2F;admin&#x2F;routes&#x2F;1 -H &#39;X-API-KEY: edd1c9f034335f136f87ad84b625c8f1&#39; -X PUT -i -d &#39;
&#123;
    &quot;uri&quot;: &quot;&#x2F;nacos&#x2F;*&quot;,
    &quot;upstream&quot;: &#123;
        &quot;service_name&quot;: &quot;APISIX-NACOS&quot;,
        &quot;type&quot;: &quot;roundrobin&quot;,
        &quot;discovery_type&quot;: &quot;nacos&quot;
    &#125;
&#125;&#39;</code></pre>

<p>在上述命令中，请求头 X-API-KEY 是 Admin API 的访问 token，可以在 conf&#x2F;config.yaml 文件中的 apisix.admin_key.key 查看。<br>添加成功后，正确返回结果示例如下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">&#123;
  &quot;action&quot;: &quot;set&quot;,
  &quot;node&quot;: &#123;
    &quot;key&quot;: &quot;\&#x2F;apisix\&#x2F;routes\&#x2F;1&quot;,
    &quot;value&quot;: &#123;
      &quot;update_time&quot;: 1643191044,
      &quot;create_time&quot;: 1643176603,
      &quot;priority&quot;: 0,
      &quot;uri&quot;: &quot;\&#x2F;nacos\&#x2F;*&quot;,
      &quot;upstream&quot;: &#123;
        &quot;hash_on&quot;: &quot;vars&quot;,
        &quot;discovery_type&quot;: &quot;nacos&quot;,
        &quot;scheme&quot;: &quot;http&quot;,
        &quot;pass_host&quot;: &quot;pass&quot;,
        &quot;type&quot;: &quot;roundrobin&quot;,
        &quot;service_name&quot;: &quot;APISIX-NACOS&quot;
      &#125;,
      &quot;id&quot;: &quot;1&quot;,
      &quot;status&quot;: 1
    &#125;
  &#125;
&#125;</code></pre>

<p>除此之外，您还可以在 upstream.discovery_args 中传递其他服务相关参数用于指定服务所在的命名空间或组别，具体内容可参考下表：</p>
<table><thead><tr>
<th>名字</th>
<th>类型</th>
<th>可选项</th>
<th>默认值</th>
<th>有效值</th>
<th>说明</th>
</tr>
</thead><tbody><tr>
<td>namespace_id</td>
<td>string</td>
<td>可选</td>
<td>public</td>
<td></td>
<td>服务所在的命名空间</td>
</tr>
<tr>
<td>group_name</td>
<td>string</td>
<td>可选</td>
<td>DEFAULT_GROUP</td>
<td></td>
<td>服务所在的组</td>
</tr>
</tbody></table><h3 id="步骤三：验证配置结果"><a href="#步骤三：验证配置结果" class="headerlink" title="步骤三：验证配置结果"></a>步骤三：验证配置结果</h3><p>使用以下命令发送请求至需要配置的路由。<br><code>curl -i http://127.0.0.1:9080/nacos/ </code><br>正常返回结果示例如下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">HTTP&#x2F;1.1 200 OK
Content-Type: text&#x2F;plain; charset&#x3D;utf-8
Content-Length: 11
Connection: keep-alive
Date: Thu, 27 Jan 2022 00:48:26 GMT
Server: APISIX&#x2F;2.12.0

Hello World</code></pre>

<p>通过示例看到，Apache APISIX 中新增的路由已经可以通过 Nacos 服务发现找到正确的服务地址，并正常响应。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文为大家介绍了注册中心的概念以及 Apache APISIX 如何配合 Nacos 实现基于服务发现的路由代理。实际场景中如何进行 Apache APISIX 与 Nacos 的配合使用，您需要看具体的业务需求和过往技术架构。关于 nacos 插件的更多说明和完整配置信息，可参考官网文档：<a href="https://apisix.apache.org/zh/docs/apisix/discovery/nacos">nacos</a>。</p>
]]></content>
      <categories>
        <category>gateway</category>
      </categories>
      <tags>
        <tag>Gateway</tag>
      </tags>
  </entry>
  <entry>
    <title>Arthas获取Spring Context</title>
    <url>/article/arthas/arthas-context/</url>
    <content><![CDATA[<blockquote>
<p>Arthas 是 Alibaba 开源的 Java 诊断工具，深受开发者喜爱。<br><a href="https://github.com/alibaba/arthas">https://github.com/alibaba/arthas</a></p>
</blockquote>
<p>Arthas 提供了非常丰富的关于调用拦截的命令，比如 trace&#x2F;watch&#x2F;monitor&#x2F;tt 。但是很多时候我们在排查问题时，需要更多的线索，并不只是函数的参数和返回值。<br>比如在一个 spring 应用里，想获取到 spring context 里的其它 bean。如果能随意获取到 spring bean，那就可以“为所欲为”了，下面介绍如何利用 Arthas 获取到 spring context。</p>
<blockquote>
<p>搜索类 sc -d com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory<br>找不到对应类，可参考 <a href="http://www.zyiz.net/tech/detail-138429.html">http://www.zyiz.net/tech/detail-138429.html</a></p>
</blockquote>
<p>获取数据库密码步骤</p>
<h2 id="1、获取-classLoder-的-hash-值"><a href="#1、获取-classLoder-的-hash-值" class="headerlink" title="1、获取 classLoder 的 hash 值"></a>1、获取 classLoder 的 hash 值</h2><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">sc -d com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory
class-info com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory
code-source    &#x2F;data&#x2F;project&#x2F;aladdin&#x2F;second&#x2F;dubbo-3.2.18-RELEASE.jar
name  com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory
super-class    +-java.lang.Object
class-loader   +-com.youzan.aladdin.container.loader.AladdinClassLoader@ae13544
       +-sun.misc.Launcher$AppClassLoader@18b4aac2
       +-sun.misc.Launcher$ExtClassLoader@7bb52275
classLoaderHash  ae13544</code></pre>

<h2 id="2、获取对应实例数据"><a href="#2、获取对应实例数据" class="headerlink" title="2、获取对应实例数据"></a>2、获取对应实例数据</h2><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">ognl -c ae13544 &#39;#context&#x3D;@com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory@contexts.iterator.next, #context.getBean(&quot;dataSource&quot;).getPassword()&#39;</code></pre>

<h2 id="3、可调用任务任意的方法"><a href="#3、可调用任务任意的方法" class="headerlink" title="3、可调用任务任意的方法"></a>3、可调用任务任意的方法</h2><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">ognl -c ae13544 &#39;#context&#x3D;@com.alibaba.dubbo.config.spring.extension.SpringExtensionFactory@contexts.iterator.next, #obj&#x3D;new com.youzan.ebiz.video.channels.item.api.param.wechat.ItemListGetReq(),#obj.kdtId&#x3D;42163374,#obj.itemIds&#x3D;&#123;1562453283&#125;,#context.getBean(&quot;wechatChannelConsoleServiceImpl&quot;).listAuditStatus(#obj)&#39;</code></pre>
]]></content>
      <categories>
        <category>arthas</category>
      </categories>
      <tags>
        <tag>Arthas</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（一）核心概念</title>
    <url>/article/ddd/core-concept/</url>
    <content><![CDATA[<blockquote>
<p>原文：<a href="https://herbertograca.com/2017/09/07/domain-driven-design/">https://herbertograca.com/2017/09/07/domain-driven-design/</a><br>转载：<a href="https://www.jianshu.com/p/812636d55677">https://www.jianshu.com/p/812636d55677</a></p>
</blockquote>
<p>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>)的一部分，这部编年史由<a href="https://herbertograca.com/category/development/series/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。</p>
<blockquote>
<p>Eric Evans 于 2003 年出版了精采绝伦的《领域驱动设计：软件核心复杂性应对之道》，在书中他创造了领域驱动设计方法。Eric Evans 的这本著作十分重要，现今许多我们认为理所当然的软件开发概念都是在本书中被正式提出的。</p>
</blockquote>
<p>我不可能在一篇博客中全面地回顾 DDD。和 DDD 相关的重要概念实在是太多了。幸好，这篇文章志不在此。而我要做的就是列出一些 DDD 概念，我认为这些概念对我喜欢的代码组织方式和我对架构的看法而言更有意义：系统范围内构成特性开发基础的那些概念。</p>
<p>在这篇文章里，我将着重探讨：</p>
<ul>
<li>统一语言</li>
<li>分层</li>
<li>限界上下文</li>
<li>防腐层</li>
<li>共享内核</li>
<li>通用子域</li>
</ul>
<h2 id="统一语言"><a href="#统一语言" class="headerlink" title="统一语言"></a>统一语言</h2><p>在软件开发中，围绕着代码的理解始终有一些问题，代码是什么，它们干了什么，它们如何做到的，它们为什么要这么做…如果代码中使用的术语和领域专家使用的术语不一样的话就更复杂了，例如，领域专家说的是<em>老用户（elder user）</em>而代码说的却是<em>管理者（supervisor）</em>，在讨论应用时这可能带来很多的困扰。但是，绝大多数的混淆都可以通过类和方法的正确命名来解决，正确的命名能让它们表达对象在领域上下文中是什么以及方法在领域上下文中干了什么。</p>
<p>统一语言的主要思想是让应用能和业务相匹配。这是通过在业务与代码中的技术之间采用共同的语言达成。这门语言起源于公司的业务侧-他们拥有需要实现的概念，语言中的术语由他们和公司的技术侧通过<strong>协商</strong>来定义(意味着业务侧也不能总是选到最好的命名)，目标是创造<strong>可以被业务、技术和代码自身无歧义使用的共同术语</strong>，即统一语言。代码、类、方法、属性和模块的命名必须和统一语言相匹配。必要的时候需要对代码进行重构！</p>
<h2 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h2><p>之前的文章中我已经谈到过分层，但我觉得这里关键的是记住通过 DDD 识别的层次：</p>
<ol>
<li>用户界面<br>负责绘制用户用来和应用交互的屏幕界面并将用户的输入翻译成应用的命令。值得注意的是“用户”可以是人类也可以是连接我们 API 的其他应用，它们和<a href="https://herbertograca.com/2017/08/24/ebi-architecture/">EBI 架构</a>中的边界对象完全对应。</li>
<li>应用层<br>协调领域对象完成用户要求的任务：用例。它不包含业务逻辑。应用层和<a href="https://herbertograca.com/2017/08/24/ebi-architecture/">EBI 架构</a>中的交互器相对应，只有一点不同，交互器是和界面或实体无关的任意对象，而这里应用层只包含和用例相关的对象。应用服务属于这一层，它们是用例对资源库、领域模型、实体、值对象或是任何其它领域对象进行编配的容器。</li>
<li>领域层<br>这个层次包含了所有的业务逻辑，如领域服务、实体、事件和其他包含业务逻辑的任意对象类型。显然它和 EBI 架构中的实体对象类型对应。这是系统的心脏。领域服务摆包含的领域逻辑不太适合放到某个实体中，通常是为了完成某个领域操作而对多个实体进行的编配。</li>
<li>基础设施<br>支持上述三个层次的技术能力，例如，持久化或者消息机制。</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607003874-d0257027-6088-42bb-b7ff-ac6c97bb09d5.png#clientId=u8d788150-40a7-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=434&id=u72f39e12&margin=%5Bobject%20Object%5D&name=image.png&originHeight=578&originWidth=604&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=75513&status=done&style=none&taskId=ufb0501db-e40d-47b8-9bbc-a25ee34437c&title=&width=453" alt="image.png"></p>
<h2 id="限界上下文"><a href="#限界上下文" class="headerlink" title="限界上下文"></a>限界上下文</h2><p>在企业应用中，模型的规模和在代码仓库上工作的团队规模都增长得很快。这会给我们带来两个问题：</p>
<ol>
<li>开发者工作的代码仓库越大，认知超载就越严重，代码就越难理解，这会导致 BUG 的产生和错误的判断；</li>
<li>在同一个代码仓库上工作的开发者越多，就越难协作并达成共同的应用领域和技术愿景。</li>
</ol>
<p>换句话说，我们面临的问题太大了。<br>通常的解决方法就是把大问题切分成较小的问题，“限界上下文”就是这样干的。<br>一般来说，两个子系统一定服务于迥然不同的用户群体。——Eric Evans 2014, Domain-Driven Design Reference<br>限界上下文定义了模型中隔离出来的部分可以应用的上下文。这种隔离可以通过解耦技术逻辑，分割代码仓库，分割数据库 Schema 来达成，在团队组织方面也是一样。和往常一样，限界上下文将拆分到何种程度取决于实际情况：我们的需求和可能性。<br>有趣的是，这不是一个全新的概念。早在 1992 年，Ivar Jacobson 在他的<a href="https://www.amazon.com/Object-Oriented-Software-Engineering-Driven-Approach/dp/0201403471">书</a>中就有子系统的描述，比 Eric Evans 早了十一年！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607197513-8b0db624-30e0-44ab-a3f9-96d407c9f637.png#clientId=u9fa9c79e-ee82-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=432&id=u2c77ca81&margin=%5Bobject%20Object%5D&name=image.png&originHeight=576&originWidth=702&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=331782&status=done&style=none&taskId=ufdce38fb-a628-453a-9428-f6586725155&title=&width=527" alt="image.png"><br>那时他就提出了一些关于这个主题的具体想法：</p>
<ul>
<li>系统由若干子系统组成，而它们各自又有各自的子系统。这个层级结构的最底层就是分析对象。于是子系统就成为了进一步开发和维护系统的结构方式。</li>
<li>子系统的任务就是把对象组合成包，达到降低复杂度的目的。</li>
<li>和功能的特定部分相关的全部对象都将被放在同一个子系统中。</li>
<li>目标是子系统内的强功能性耦合和子系统间的弱耦合(现在被称为高内聚低耦合)</li>
<li>[一个子系统]最好应该只和一个角色耦合，因为变化通常由一个角色引发。</li>
<li>首先把控制对象放入子系统，然后将强耦合的实体对象和界面对象放到同一个子系统中</li>
<li>拥有强相关功能耦合的所有对象都将被放入同一个子系统之中<ul>
<li>一个对象中的变化会导致其它对象中的变化吗？(现在被称作共同封闭原则——一起变化的类应该放在同一个包中——由 Robert C. Martin 在他 1996 年的论文“<a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en">Granularity</a>”中发布，比 Ivar Jacobson 的书晚了四年)</li>
<li>它们是和同一个角色通信吗？</li>
<li>这两个对象都依赖第三个对象吗？例如同一个界面对象或实体对象？</li>
<li>这个对象会执行多个其它对象上的操作吗？(现在被称作共同重用原则——一起被使用的类应该放在同一个包中——由 Robert C. Martin 在他 1996 年的论文“<a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en">Granularity</a>”中发布，比 Ivar Jacobson 的书晚了四年)</li>
</ul>
</li>
<li>子系统划分的另一个标准是不同子系统之间的通信应该尽可能少(低耦合)</li>
<li>对大型项目来做，还有其它一些子系统划分的标准，例如：<ul>
<li>不同的开发小组拥有不同的能力或者资源，针对性地分配开发任务也许是值得的(这些小组还可能分布在不同的地点)</li>
<li>在分布式环境中，每个逻辑节点需要的可能就是一个子系统(SOA、Web 服务以及微服务)。</li>
<li>如果现存的产品可以在系统中使用，它可以被认为是一个子系统(我们的系统所依赖的库，例如 ORM)</li>
</ul>
</li>
</ul>
<h2 id="防腐层"><a href="#防腐层" class="headerlink" title="防腐层"></a>防腐层</h2><p>防腐层基本就是两个系统之间的中间件。它用来隔离两个子系统，让它们都依赖防腐层而不是直接互相依赖。这样，如果我们重构或者完全替换掉其中一个子系统时，只需要更新防腐层，而不需要动其它的子系统。<br>在将一个新系统和遗留系统进行集成时防腐层特别有用。为了不让遗留的结构限制我们设计新系统的想像力，我们会创建一个防腐层，将遗留子系统的 API 按照新的子系统的需要进行适配。<br>它有三个主要关注点：</p>
<ol>
<li>按照客户端子系统的需要对其它子系统 API 进行适配；</li>
<li>对系统间传递的数据和命令进行转换；</li>
<li>根据需要建立单向或多向的通信。</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607222269-0448d9cc-c5a6-437e-91f5-956ebc8e5e79.png#clientId=u9fa9c79e-ee82-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=309&id=ub9475928&margin=%5Bobject%20Object%5D&name=image.png&originHeight=412&originWidth=1087&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=154043&status=done&style=none&taskId=u2672926b-8dea-4414-8d29-99970525aa3&title=&width=815" alt="image.png"><br>当我们无法控制全部子系统或某个子系统时，使用这项技术的理由更加充分。但在我们能控制所有涉及的子系统时，这项技术也有意义，尽管这些子系统设计良好只是拥有大相径庭的模型，但是我们想要阻止一个模型对另一个模型的侵蚀(为了满足一个子系统的需要而修改另一个子系统)。</p>
<h2 id="共享内核"><a href="#共享内核" class="headerlink" title="共享内核"></a>共享内核</h2><p>在某些情况下，我们除了渴望完全隔离和解耦的组件之外，在多个组件之间共享一些领域代码也很有意义。<br>这会让组件之间保持解耦，尽管他们会和同一份代码——共享内核——耦合在一起。<br>例如，由一个组件触发并由另外一个或多个组件监听的事件就是这样的例子。但服务接口和事件实体也可能是这样。<br>不过，我们应该限制共享内核的大小，对它进行修改时要小心翼翼，才不会毫不知情地破坏使用它的代码。共享内核中的代码修改必须经过其它使用它的团队的同意，这一点非常重要。</p>
<h2 id="通用子域"><a href="#通用子域" class="headerlink" title="通用子域"></a>通用子域</h2><p>子域是领域中非常独立的一部分。通用子域不是特定于某个应用的子域，它可以在任何类似的应用中使用。<br>例如，如果我们的应用中有一部分是关于财务的，也许我们可以在应用中使用现有的财务相关的库。但是，无论以哪种方式实现，哪怕我们没有现成的库可用而要自己构建，如果这部分是通用子域，那么它就不是我们的核心业务，它应该被当作必要的而不是决定性的因素。它不是我们应用中最重要的部分，所以不是我们最好的专家重点关注的地方，毫无疑问它甚至不应该在主要的源代码之中出现，它可能是通过依赖管理工具安装的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>再一次声明，这里我选择探讨多是关于单一职责、低耦合、高内聚、逻辑隔离的 DDD 概念，这样我们的应用才能更一致、更简单、更快地响应变化并适应业务的需要。</p>
<h2 id="引用来源"><a href="#引用来源" class="headerlink" title="引用来源"></a>引用来源</h2><blockquote>
<p>1992 – Ivar Jacobson – <a href="https://www.amazon.com/Object-Oriented-Software-Engineering-Driven-Approach/dp/0201403471">Object-Oriented Software Engineering: A use case driven approach</a><br>1996 – Robert C. Martin – <a href="http://docs.google.com/a/cleancoder.com/viewer?a=v&pid=explorer&chrome=true&srcid=0BwhCYaYDn8EgOGM2ZGFhNmYtNmE4ZS00OGY5LWFkZTYtMjE0ZGNjODQ0MjEx&hl=en">Granularity</a><br>2003 – Eric Evans – <a href="https://www.amazon.com/dp/0321125215/ref=wl_it_dp_o_pC_nS_ttl?_encoding=UTF8&colid=CG11VVP0H8Y8&coliid=I1X0NXLUHTFGE4">Domain-Driven Design: Tackling Complexity in the Heart of Software</a><br>2014 – Eric Evans – <a href="https://www.amazon.com/Domain-Driven-Design-Reference-Definitions-Summaries/dp/1457501198">Domain-Driven Design Reference</a><br><a href="https://www.cnblogs.com/Zachary-Fan/p/5991674.html">领域驱动设计核心概念</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（三）洋葱架构</title>
    <url>/article/ddd/onion-architecture/</url>
    <content><![CDATA[<blockquote>
<p>原文：<a href="https://herbertograca.com/2017/09/21/onion-architecture/">https://herbertograca.com/2017/09/21/onion-architecture/</a> &gt; <a href="https://www.jianshu.com/p/d87d5389c92a">https://www.jianshu.com/p/d87d5389c92a</a></p>
</blockquote>
<p>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>)的一部分，这部编年史由<a href="https://herbertograca.com/category/development/series/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。<br><a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-1/">2008 年 Jeffrey Palermo 提出了洋葱架构</a>。在我看来，它在端口和适配器架构的基础上贯彻了将领域放在应用中心，将传达机制(UI)和系统使用的基础设施(ORM、搜索引擎、第三方 API…)放在外围的思路。但是它前进了一步，在其中加入了内部层次。</p>
<p>我们从通常拥有四个层次(<strong>表现层、应用层、领域层、持久化层</strong>)的分层架构发展到了端口和适配器架构，它只是含蓄地提到了两个同心圆层次：</p>
<ol>
<li>代表传达机制和基础设施的外层；</li>
<li>代表业务逻辑的内层。</li>
</ol>
<p>端口和适配器架构与洋葱架构有着相同的思路，它们都通过编写适配器代码将应用核心从对基础设施的关注中解放出来，避免基础设施代码渗透到应用核心之中。这样应用使用的工具和传达机制都可以轻松地替换，可以一定程度地避免技术、工具或者供应商锁定。<br>另外，它还有着脱离真实基础设施和传达机制应用仍然可以运行的便利，这样可以使用 mock 代替它们方便测试。<br>然而，洋葱架构还告诉我们，企业应用中存在着不止两个层次，它在业务逻辑中加入了一些在领域驱动设计的过程中被识别出来的层次：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608119083-5309ddc4-278c-4f09-a764-26b5310736ad.png#clientId=udd11f49d-b9ae-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=289&id=u8b611542&margin=%5Bobject%20Object%5D&name=image.png&originHeight=577&originWidth=828&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=403435&status=done&style=none&taskId=u696a16fc-1738-4c2e-b42e-fa75a013357&title=&width=414" alt="image.png"><br>此外，它明确了端口和适配器架构中关于依赖方向的暗示：</p>
<ul>
<li>外层依赖内层；</li>
<li>内层对外层无感知。</li>
</ul>
<p>也就是说耦合的方向是从外层指向中心，它提供了一个完全独立的对象模型(领域模型)，该模型位于架构的核心，不依赖其它任何层次。我们拥有了在不影响内层的情况下改变外层的灵活性。它在架构层面运用了<strong>依赖倒置原则</strong>。</p>
<blockquote>
<p>洋葱架构的关键原则：</p>
<ul>
<li><p>围绕独立的对象模型构建应用</p>
</li>
<li><p>内层定义接口，外层实现接口</p>
</li>
<li><p>依赖的方向指向圆心</p>
</li>
<li><p>所有的应用代码可以独立于基础设施编译和运行</p>
<p>—— Jeffrey Palermo 2008, <a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-3/">The Onion Architecture: part 3</a></p>
</li>
</ul>
</blockquote>
<p>还有，任何一个外部层次都可以直接调用任何一个内部层次，这样既不会破坏耦合的方向，也避免了仅仅为了追求分层模式而创建一些没有任何业务逻辑的代理方法甚至代理类。这和 Martin Flowler 表达的偏好一致。</p>
<blockquote>
<p>上层可以使用它们下面的任意层次，而不仅仅是它们直接的下层。——Jeffrey Palermo 2008, <a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-3/">The Onion Architecture: part 3</a></p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>洋葱架构在端口和适配器架构的基础之上增加了一些的应用业务逻辑的内部组织，这些组织基于领域驱动设计的概念划分的。<br>这又是一次职责分离的更深入的演化，带来了高内聚低耦合，反过来也带来了更好的可测试性和可维护性。</p>
<h2 id="引用来源"><a href="#引用来源" class="headerlink" title="引用来源"></a>引用来源</h2><blockquote>
<p>2002 – Martin Fowler – <a href="https://www.amazon.com/dp/0321127420/ref=wl_it_dp_o_pC_nS_ttl?_encoding=UTF8&colid=CG11VVP0H8Y8&coliid=I1QPWUPW6G7YF5">Patterns of Enterprise Application Architecture</a><br>2008 – Jeffrey Palermo – <a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-1/">The Onion Architecture: part 1</a><br>2008 – Jeffrey Palermo – <a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-2/">The Onion Architecture: part 2</a><br>2008 – Jeffrey Palermo – <a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-3/">The Onion Architecture: part 3</a><br>2013 – Jeffrey Palermo – <a href="http://jeffreypalermo.com/blog/onion-architecture-part-4-after-four-years/">The Onion Architecture: part 4 – After Four Years</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（二）端口和适配器架构</title>
    <url>/article/ddd/ports-adapters-architecture/</url>
    <content><![CDATA[<blockquote>
<p>原文链接：<a href="https://herbertograca.com/2017/09/14/ports-adapters-architecture/">https://herbertograca.com/2017/09/14/ports-adapters-architecture/</a><br>转载：<a href="https://www.jianshu.com/p/f39f4537857e">https://www.jianshu.com/p/f39f4537857e</a></p>
</blockquote>
<p>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>)的一部分，这部编年史由<a href="https://herbertograca.com/category/development/series/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。<br>2005 年，Alistair Cockburn 构思了<a href="http://alistair.cockburn.us/Hexagonal+architecture">端口和适配器架构</a> (又称<a href="http://alistair.cockburn.us/Hexagonal+architecture">六边形架构</a>)并记录在他的博客中。下面这句话就是他对该架构的目标的定义：</p>
<blockquote>
<p>让用户、程序、自动化测试和批处理脚本可以平等地驱动应用，让应用的开发和测试可以独立于其最终运行的设备和数据库。——Alistair Cockburn 2005，<a href="http://alistair.cockburn.us/Hexagonal+architecture">端口和适配器</a></p>
</blockquote>
<p>但是，Alistair Cockburn 意识到 <strong>顶部和底部的层次从另一方面来说，就是应用的入口&#x2F;出口</strong>。尽管实际中它们不一样，却有着十分相似的目标，在设计上也是对称的。而且，如果我们想要隔离出应用中间的层次，这些入口和出口能以另一种相似的方式使用。<br>有许多文章在谈及端口和适配器架构时会花很多篇幅在分层上。然而， 我并没有在 Alistair Cockburn 的原文中找到关于分层的只言片语。<br>其思想是将我们的应用看作是一个系统的中心交付物，输入和输出都是通过端口出入应用，这些端口将应用和外部工具、技术以及传达机制隔离开来。应用不应该关心是谁在发送输入或接收输出。这就是为了保护产品免受技术和业务需求演进的影响。由于技术&#x2F;供应商锁定，这些演进可能导致产品刚开发没多久就被废弃。我将在本文中剖析以下主题：</p>
<ul>
<li>传统架构方式的问题</li>
<li>分层架构的演化<ul>
<li>什么是端口</li>
<li>什么是适配器</li>
<li>适配器的两种不同类型</li>
</ul>
</li>
<li>端口和适配器架构优势<ul>
<li>实现隔离和技术隔离</li>
<li>传达机制的隔离</li>
<li>测试</li>
</ul>
</li>
</ul>
<h2 id="传统架构方式的问题"><a href="#传统架构方式的问题" class="headerlink" title="传统架构方式的问题"></a>传统架构方式的问题</h2><p>传统的架构方式在前端和后端都可能给我们带来问题。<br>在前端，业务逻辑最终可能会渗透到 UI(例如，我们把用例的逻辑放到控制器或视图里，导致这些逻辑不能在其它 UI 界面中重用)， 甚至 UI 会反过来渗透到业务逻辑中(例如，我们会为了模板中需要的业务逻辑在实体中创建对应的方法)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649603355048-a90a05bb-1922-455a-9f43-20ff9bcf1d85.png#clientId=u3394d0a2-5ada-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u01b2defd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=452&originWidth=600&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=191413&status=done&style=none&taskId=uc1fa4e29-b3c3-4bc0-a7e3-3192bc0d39b&title=" alt="image.png"><br>而在后端，我们可能会在自己的业务逻辑里使用外部类的类型提示、继承或者实例化它们，这会导致对这些外部的库和技术直接引用，最后任由它们渗透到业务逻辑中。</p>
<h2 id="分层架构的演化"><a href="#分层架构的演化" class="headerlink" title="分层架构的演化"></a>分层架构的演化</h2><p>托<a href="https://herbertograca.com/2017/08/24/ebi-architecture/">EBI</a> (<a href="https://www.jianshu.com/p/395814410cf5">译</a>)和<a href="https://herbertograca.com/2017/09/07/domain-driven-design/">DDD</a>(<a href="https://www.jianshu.com/p/812636d55677">译</a>)的福, 2005 年我们已经知道了“系统中真正重要的是位于中间的层次”。业务逻辑(应该)存在于这些层次之中，它们才是我们和竞品的真正区别。这才是真正的“应用”。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649603384744-dc10c804-2807-4dd4-a46a-07f3484efcb3.png#clientId=u3394d0a2-5ada-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9ba73af9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=262&originWidth=575&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=87576&status=done&style=none&taskId=ua76c3ff7-1602-43b5-9abb-2d8a7d3bd1c&title=" alt="image.png"><br>但是，Alistair Cockburn 意识到 <strong>顶部和底部的层次从另一方面来说，就是应用的入口&#x2F;出口</strong>。尽管实际中它们不一样，却有着十分相似的目标，在设计上也是对称的。而且，如果我们想要隔离出应用中间的层次，这些入口和出口能以另一种相似的方式使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649603507253-bd3ab953-4263-4c3d-b22e-cb3d56e922a7.png#clientId=u3394d0a2-5ada-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u01344caa&margin=%5Bobject%20Object%5D&name=image.png&originHeight=400&originWidth=496&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=161482&status=done&style=none&taskId=ua77e3432-e278-4a2e-83eb-0017d0e144b&title=" alt="image.png"><br>区别于典型的分层架构图，我们将它们画在系统的左右两侧，而不是上下两边。<br>虽然我们识别出了系统中对称的两侧，但<strong>两侧都可能有若干入口&#x2F;出口</strong>。例如， API 和 UI 就是位于应用左侧的两个不同的入口&#x2F;出口。为了表示应用有若干个入口&#x2F;出口，我们把应用的形状改成了多边形。<strong>应用的形状可以是有多条边的任意多边形</strong>，但最终六边形获得了青睐。这也是“六边形架构”的由来。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607918007-5c1b4d23-cfdd-4d31-a381-de0f579c715d.png#clientId=udbfe8f8e-02a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud33f6313&margin=%5Bobject%20Object%5D&name=image.png&originHeight=513&originWidth=562&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=203122&status=done&style=none&taskId=u6dc2bbd3-85d0-427e-b368-73878baad76&title=" alt="image.png"></p>
<p><a href="http://alistair.cockburn.us/Hexagonal+architecture">端口和适配器架构</a>使用了实现为端口和适配器的抽象层次，解决了传统架构方式带来的问题。</p>
<h3 id="什么端口"><a href="#什么端口" class="headerlink" title="什么端口"></a>什么端口</h3><p>端口是对其消费者无感知的进入&#x2F;离开应用的入口和出口。在许多编程语言里，端口就是接口。例如，在搜索引擎里它可能是执行搜索的接口。在应用中，我们把这个接口当成入口&#x2F;出口使用，而不用去关心它的具体实现，实际上在所有将接口定义为类型提示的地方，这些实现会被注入。</p>
<h3 id="什么是适配器"><a href="#什么是适配器" class="headerlink" title="什么是适配器"></a>什么是适配器</h3><p>适配器是将一个接口转换(适配)成另一个接口的类。<br>例如，一个适配器实现了接口 A 并被注入了接口 B。当这个适配器被实例化时，一个实现了接口 B 的对象将从构造方法注入进来。实现了接口 A 的 对象会被注入到需要接口 A 的地方，然后接收方法请求，将其转换并代理给那个实现了接口 B 的内部对象。<br>如果我说的不够明白，别慌，后面我会给出一个更具体的例子。</p>
<h3 id="适配器的两种不同类型"><a href="#适配器的两种不同类型" class="headerlink" title="适配器的两种不同类型"></a>适配器的两种不同类型</h3><p>左侧代表 UI 的适配器被称为<strong>主适配器</strong>或者<strong>主动适配器</strong>，因为是它们发起了对应用的一些操作。而右侧表示和后端工具链接的适配器，被称为<strong>从适配器</strong>或者<strong>被动适配器</strong>，因为它们只会对主适配器的操作作出响应。<br>端口&#x2F;适配器的用法也有一点区别：</p>
<ul>
<li>在<strong>左侧</strong>，适配器依赖端口，该端口的具体实现会被注入到适配器，这个实现包含了用例。换句话说，<strong>端口和它的具体实现(用例)都在应用内部</strong>。</li>
<li>在<strong>右侧</strong>，适配器<strong>就是</strong>端口的具体实现，它自己将被注入到我们的业务逻辑中，尽管业务逻辑只知道接口。换句话说，<strong>端口在应用内部，而它的具体实现在应用之外</strong>并包装了某个外部工具。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607675100-6acb67d1-cee5-4470-8a60-a265c6e8b256.png#clientId=udbfe8f8e-02a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u929c69dc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=513&originWidth=708&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=99467&status=done&style=none&taskId=uf6a0a72b-a5ba-4f52-b2ac-05b9ddb7ebd&title=" alt="image.png"></p>
<h2 id="端口和适配器架构优势"><a href="#端口和适配器架构优势" class="headerlink" title="端口和适配器架构优势"></a>端口和适配器架构优势</h2><p>使用这种应用位于系统中心的端口&#x2F;适配器设计，让我们可以保持应用和实现细节之间的隔离，这些实现细节包括昙花一现的技术、工具和传达机制。它还让可重用的概念更容易更快速地得到验证并被创建出来。</p>
<h3 id="实现隔离和技术隔离"><a href="#实现隔离和技术隔离" class="headerlink" title="实现隔离和技术隔离"></a>实现隔离和技术隔离</h3><h4 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h4><p>我们的应用使用 SOLR 作为搜索引擎，并使用一个开源库连接它并执行搜索。</p>
<h4 id="传统架构方式"><a href="#传统架构方式" class="headerlink" title="传统架构方式"></a>传统架构方式</h4><p>传统架构方式下，我们会直接在我们的代码中使用库(SOLR)里的类，作为类型提示，或者实例化和&#x2F;或作为我们实现的基类。</p>
<h4 id="端口和适配器架构方式"><a href="#端口和适配器架构方式" class="headerlink" title="端口和适配器架构方式"></a>端口和适配器架构方式</h4><p>如果采用端口和适配器架构的话，我们会创建一个接口，比如叫做 UserSearchInterface，在代码中用这个接口作为类型提示。我们还会为 SOLR 创建一个实现该接口的适配器，比如叫做 UserSearchSolrAdapter。这个实现是 SOLR 的包装，SOLR 会被注入其中并用来实现接口指定的方法。</p>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>不久之后，我们想用 Elasticsearch 换掉 SOLR。甚至，对于同样的搜索行为，我们希望有些时候使用 SOLR，有些时候使用 Elasticsearch，在运行时决定就好。<br>如果我们采用传统架构，我们需要查找所有使用 SOLR 的代码并替换成 Elasticsearch。然而，这可不是简单的查找替换：两个引擎的用法不同，方法、输入、输出也不尽相同，替换并不是一件轻松的任务。而在运行时在决定使用那个引擎甚至是不可能的。<br>然而，假设我们使用了端口和适配器架构，我们只需要创建一个新的适配器，比如就叫 UserSearchElasticsearchAdapter，在注入时使用它换掉 SOLR 的适配器，也许改一下 DCI 中的配置就可以做到。我们完全可以使用工厂来决定注入那个适配器，实现在运行时注入不同的实现。</p>
<h3 id="传达机制的隔离"><a href="#传达机制的隔离" class="headerlink" title="传达机制的隔离"></a>传达机制的隔离</h3><p>和上面这个例子类似，假设我们的应用需要 Web GUI，CLI 和 Web API。我们想在全部三种 UI 中提供某个功能，比如叫做<em>UserProfileUpdate</em>的功能。<br>使用端口和适配器架构的话，我们会在一个应用服务的方法中实现这个功能并将其作为一个用例。服务会实现一个接口，该接口说明了方法、输入以及输出。<br>每个版本的 UI 都有各自的控制器(或控制台命令)来通过这个接口触发期望的逻辑，应用服务接口的具体实现会被注入到 UI 中。这种情况下，适配器实际上就是控制器(或 CLI 命令)。<br>之后我们可以修改 UI，因为我们知道这些修改不会影响业务逻辑。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>上面两个例子中，使用端口和适配器架构会让测试更加容易。第一个例子中，我们用接口(端口)的 Mock 就可以测试应用，而不需要使用 SOLR 或 Elasticsearch 。<br>第二个例子中，所有的 UI 都可以独立于应用进行测试。我们的用例也可以独立于 UI 进行测试，传给服务一些输入再断言结果就好。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在我看来，端口和适配器架构只有一个<strong>目标：将业务逻辑和系统使用的传达机制以及工具隔离</strong>。为此，它使用了常见的编程语言结构：<strong>接口</strong>。<br>在<strong>UI</strong>侧(主动适配器)，我们创建<strong>使用应用接口的适配器</strong>，比如控制器。<br>在<strong>基础设施</strong>侧(被动适配器)，我们创建<strong>实现应用接口的适配器</strong>，比如资源库。<br>这就是全部！<br>然而，我惊讶的发现<a href="https://herbertograca.com/2017/08/24/ebi-architecture/">早在十三年前同样的思想就已经公开发表了</a>(<a href="https://www.jianshu.com/p/395814410cf5">译</a>)，尽管它没有刻意地强调要将工具和传达机制从应用核心中隔离出来。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649607958490-46f69631-5bbf-4d68-985c-1f56ca2fee20.png#clientId=udbfe8f8e-02a1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf8b320f4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=633&originWidth=764&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=310444&status=done&style=none&taskId=u4816a965-975f-4b8c-b205-51bbd8bb8d8&title=" alt="image.png"><br>系统和角色的任何交互都要通过边界对象。按照 Jacobson 的描述，角色可以是客户或者管理员(操作员)这样的人类用户，也可以是定时器或者打印机这样的非人类“用户”，它们分别对应着端口和适配器架构中的主动适配器和被动适配器。</p>
<h2 id="引用来源"><a href="#引用来源" class="headerlink" title="引用来源"></a>引用来源</h2><blockquote>
<p>1992 – Ivar Jacobson – <a href="https://www.amazon.com/Object-Oriented-Software-Engineering-Driven-Approach/dp/0201403471">Object-Oriented Software Engineering: A use case driven approach</a><br>200? – Alistair Cockburn – <a href="http://wiki.c2.com/?HexagonalArchitecture">Hexagonal Architecture</a><br>2005 – Alistair Cockburn – <a href="http://alistair.cockburn.us/Hexagonal+architecture">Ports and Adapters</a><br>2012 – Benjamin Eberlei – <a href="https://beberlei.de/2012/08/13/oop_business_applications_entity_boundary_interactor.html">OOP Business Applications: Entity, Boundary, Interactor</a><br>2014 – Fideloper – <a href="http://fideloper.com/hexagonal-architecture">Hexagonal Architecture</a><br>2014 – Philip Brown – <a href="https://www.culttt.com/2014/12/31/hexagonal-architecture/">What is Hexagonal Architecture?</a><br>2014 – Jan Stenberg – <a href="https://www.infoq.com/news/2014/10/exploring-hexagonal-architecture">Exploring the Hexagonal Architecture</a><br>2017 – Grzegorz Ziemoński – <a href="https://dzone.com/articles/hexagonal-architecture-is-powerful">Hexagonal Architecture Is Powerful</a><br>2017 – Shamik Mitra – <a href="https://dzone.com/articles/hello-hexagonal-architecture-1">Hello, Hexagonal Architecture</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>Cloud Native定义</title>
    <url>/article/cncf/cloud-native/</url>
    <content><![CDATA[<h2 id="CNCF-定义"><a href="#CNCF-定义" class="headerlink" title="CNCF 定义"></a>CNCF 定义</h2><p>CNCF（Cloud Native Computing Foundation，云原生计算基金会），2016 年 6 月 11 日，CNCF 技术监督委员会经过几个月的讨论，终于投票通过了 Cloud Native 的定义，目前官方的翻译如下：</p>
<blockquote>
<p>Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.</p>
</blockquote>
<p>云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。</p>
<blockquote>
<p>These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.</p>
</blockquote>
<p>这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师们能够轻松地对系统作出频繁和可预测的重大变更。</p>
<blockquote>
<p>The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone.</p>
</blockquote>
<p>云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。我们通过把最前沿的模式民主化，让这些创新为大众所用。<br>从这个定义中，我们可以看到云原生应用除了要长在云上，还具备几个典型特征：</p>
<ul>
<li>弹性可扩展（scalable）</li>
<li>松耦合（loosely coupled）</li>
<li>容错性好（resilient）</li>
<li>易于管理（manageable）</li>
<li>便于观察（observable）</li>
<li>频繁变更（changes frequently）</li>
</ul>
<p>为了支持或实现这些特征，CNCF 列举了一些典型的技术手段</p>
<ul>
<li>容器：使用容器作为应用的部署和运行单元，让应用彼此隔离、也从环境中隔离出来，有助于上层资源隔离、组件重用，更易移植，便于观察，并且很容易进行标准化的生命周期管理；</li>
<li>服务网格：使得服务访问与服务提供者的拓扑结构（位置）解耦，从而减少系统变更的风险，便于观察跨组件的交互；</li>
<li>微服务架构：松耦合的微服务让细粒度的升级或弹性扩展成为可能，使得应用更加敏捷和易于维护、演进；</li>
<li>不可变基础设施：替换组件或资源的实例而不是去修补它们，这种新陈代谢的方式能防止配置出现失真，提升了系统的可重复性和可预测性，对大规模、高速运转的应用运维至关重要；</li>
<li>声明式 API：应用之间、应用的微服务之间以及应用与其依赖、环境之间都使用 API 作为 Contract，屏蔽实现，实现完全的松耦合。</li>
</ul>
<p>CNCF 在 2016 年 11 月还发布了 Cloud Native 参考架构， 具体见 <a href="https://www.cncf.io/blog/2017/05/15/developing-cloud-native-applications/">https://www.cncf.io/blog/2017/05/15/developing-cloud-native-applications/</a><br>并把诸多相关的开源项目和厂商产品映射到这个架构里，具体见 <a href="https://github.com/cncf/landscape">https://github.com/cncf/landscape</a><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649594783940-75df1b5e-39f5-4fa5-8e2a-f3cc39d514e3.png#clientId=ud1c53c6a-8e96-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf12d1fb0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=463&originWidth=975&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=135875&status=done&style=none&taskId=u18635326-7bae-4cc7-9143-39c133c65d3&title=" alt="image.png"></p>
]]></content>
      <categories>
        <category>cncf</category>
      </categories>
      <tags>
        <tag>CNCF</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（五）CQRS</title>
    <url>/article/ddd/cqrs-architecture/</url>
    <content><![CDATA[<blockquote>
<p>原文：<a href="https://herbertograca.com/2017/10/19/from-cqs-to-cqrs/">https://herbertograca.com/2017/10/19/from-cqs-to-cqrs/</a> &gt; <a href="https://www.jianshu.com/p/ab3843093903">https://www.jianshu.com/p/ab3843093903</a></p>
</blockquote>
<p>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>)的一部分，这部编年史由<a href="https://herbertograca.com/category/development/series/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。<br>如果我们的应用以数据为中心，比如，仅实现基本的 CRUD 操作而把业务流程(例如，哪些数据需要修改，应按什么顺序修改)留给用户；其优点是用户可以在无需改变应用的情况下改变业务流程。而另一方面，这意味着所有用户都需要了解所有使用应用可以执行的业务流程的全部细节，当我们的流程不那么简单并且需要许多人都去理解它们时，这是一个大问题。<br>以数据为中心的应用对业务流程一无所知，因此领域不能使用任何动词，除了修改原始数据以外不能做任何事。它变成了徒有其表的数据模型抽象。流程都在使用应用的用户脑袋里，甚至只能在他们屏幕周围贴着的便利贴上找到。<br>一个有效的能真正发挥作用的应用的目标应该是通过捕捉用户的意图将他们从“流程”的负担中解放，让应用可以处理行为，而不仅仅只是简单地存储数据。<br>CQRS 就是这样一些技术概念演化的结果，它们一起帮助应用更准确地反映领域，同时还要克服常见的技术限制。</p>
<h2 id="命令查询分离"><a href="#命令查询分离" class="headerlink" title="命令查询分离"></a>命令查询分离</h2><p>如 Martin Fowler 所述，“命令查询分离”这个术语由 Bertrand Meyer 在他的“<a href="https://www.amazon.com/gp/product/0136291554?ie=UTF8&tag=martinfowlerc-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=0136291554">Object Oriented Software Construction</a>” (1988)一书中提出。这本书据说是 OO 早期最有影响力的著作之一。<br>Meier 为这样一条原则辩护，<strong>我们不应该使用既能修改数据也能返回数据的方法</strong>。这样我们就有了两种类型的方法：</p>
<ol>
<li><strong>查询</strong>：返回数据但不修改数据，因此没有副作用；</li>
<li><strong>命令</strong>：修改数据但不返回数据。</li>
</ol>
<p>换句话说，_访问不应该改变答案而做事不应该给出答案_，这样也遵守了单一职责原则。<br>然而，有一些模式是这条规则的例外，Martin Fowler 又说，传统的队列和堆栈的实现在弹出一个元素时，即改变了队列&#x2F;堆栈也返回了移除的元素。</p>
<h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><p>命令模式的主要思想就是让我们远离数据为中心的应用，向具备领域知识和应用流程知识的以流程为中心的应用迈进。<br>事实上，这意味着用户不需要按顺序分别执行“CreateUser”、“ActivateUser”、“SendUserCreatedEmail”三个操作，只需要简单地执行一个“RegisterUser”命令，就可以将上面三个操作作为一个封装好的业务流程执行。</p>
<p>一个更有意思的例子是使用表单来修改一个客户的数据。假设我们可以使用表单来修改客户的名字、地址和电话号码，以及设置他是否是优先客户。我们还假设客户只有支付了账单才可以成为优先客户。在一个 CRUD 应用中，我们在收到数据之后，可以检查客户是否支付了账单，还可以接受或是拒绝数据修改请求。然而，这却是两个不同的业务流程：即便是客户没有支付账单，他也能成功地修改名字、地址和电话号码。使用命令模式之后，我们就能在代码中清晰地区别它们，创建两个代表不同业务流程的命令：一个用来改变客户数据，而另一个用来升级用户的优先状态，两个流程都由同一个 UI 界面触发。</p>
<blockquote>
<p>在修改数据时为我们提供正确的粒度和意图。这就是命令的全部。—— Udi Dahan 2009, <a href="http://udidahan.com/2009/12/09/clarified-cqrs/">Clarified CQRS</a></p>
</blockquote>
<p>可是，还是有一点要记得，并不是说不能有“CreateUser”这样的简单命令。CRUD 的用例可以和带着意图的代表着复杂业务流程的用例完美共存，重要的是别误用。</p>
<p>技术上来说，如<a href="https://www.amazon.com/Head-First-Design-Patterns-Brain-Friendly/dp/0596007124">Head First Design Patterns</a> 所述，命令模式会将执行一个动作或者一系列动作所需的所有信息都封装起来。当我们需要在同一个地方以同样的方式执行一些不同的业务流程(命令)时这特别有用，因此它们需要同样的接口。例如，所有命令都有同样的 execute()方法，这样在某个时刻，任何命令都可以被触发，不管到底是哪个命令。这也能让任何业务流程(命令)可以被放到队列中在合适的时候执行，同步或异步都行。<br><a href="https://www.amazon.com/Head-First-Design-Patterns-Brain-Friendly/dp/0596007124">Head First Design Patterns</a> 一书给出的例子是屋子里的灯的遥控器。接下来我也会使用同样的例子，尽管我会指出它的不足之处。<br>那么，假设我们有一个控制屋子里的灯的遥控器，上面有一个按钮可以打开厨房里的灯，还有一个按钮关掉它们。每个按钮都代表着一个我们可以发给房屋灯光系统的命令。<br>下图是这个系统一种可能的设计：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608812998-900bc66b-d55f-4ac7-b250-bb9cd08ccaf1.png#clientId=u730b459d-7447-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=173&id=ua9aee8a8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=346&originWidth=797&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=214730&status=done&style=none&taskId=u00227301-ca8c-4872-b7c8-438711e19a0&title=&width=398.5" alt="image.png"><br>这个一个朴素的设计，当然，它甚至不用考虑 DIC 我也完全用不到 UML。但我希望它能表达我的意思，所以我们来看看上面这幅图：作为对来自传达机制的输入的反映，LightController 会使用参数为 CommandInvoker 的构造方法实例化并触发一个特定的控制器动作 kitchenLightOnAction。这个动作将实例化正确的灯 KitchenLight，还会实例化正确的命令 KitchenLightOnCommand，把灯对象作为构造方法的参数传递它。然后命令会被交给 CommandInvoker 在某个时刻执行。要关灯的话，我们得创建另外的动作和命令，但设计基本是一样的。</p>
<p>这样我们就有了一个开灯的命令和一个关灯的命令。如果我们要将它们的功率设置为 50% 呢？我们再创建一条命令！如果我们要将它们的功率设置为 25% 和 75 % 呢？我们创建更多的命令！如果我们不用按钮而是用调光器将灯花设置成任意值呢？我们没办法创建无限多的命令！！！</p>
<p>这时的<strong>实现问题</strong>是：虽然命令中的逻辑一样，但是数据(功率的百分比)每次都不一样。所以我们应该创建一个命令，它的逻辑不变，仅仅是执行时的数据不同，但我们就会面临一个问题，接口 execute()方法不接受参数。如果让它接受参数，那么将破坏整个命令的最重要的技术思路(将执行业务流程所需的所有信息都封装起来，而不用知道将要执行的到底是哪一个流程)。<br>当然，我们可以将数据传递给命令的构造方法来绕过这个问题，但并不优雅。实际上这是一个非正常的手段，因为数据不是对象之所以存在的必要信息，数据是它执行某段逻辑是需要的信息。因此，这些数据是方法的依赖而非对象的依赖。<br>我们还可以使用原生的语言结构[译：？？]来绕过这个问题，但还是不够优雅。</p>
<h2 id="命令总线"><a href="#命令总线" class="headerlink" title="命令总线"></a>命令总线</h2><p>要解决命令模式的这个限制，我们能做的就是应用最古老的 OO 原则：<strong>将变化的部分和不变的部分分开</strong>。<br>这个例子中变化的数据不变的是命令中执行的逻辑，所以我们可以将它们分成两个类。一个是用来存放数据的简单 DTO(我们称之为<strong>命令</strong>)，另一个存放要执行的逻辑(我们称之为<strong>处理器</strong>)，它拥有一个用来触发逻辑执行的方法 execute(CommandInterface $command): void。CommandInvoker 也将演化，它将可以接收命令并找出能够处理该命令的处理器。我们称之为<strong>命令总线</strong>。<br>用户界面的模式还可以进一步修改，许多命令不需要立即处理，它们可以放到队列中异步地执行。这种方式有一些优点能让系统更健壮：</p>
<ul>
<li>响应可以更快地返回给用户，因为不用等着命令立即执行；</li>
<li>如果因为系统缺陷(如出现问题或者数据库下线) 导致命令失败，用户可能根本不会意识到。当问题解决后命令可以简单地进行重放。</li>
</ul>
<p>在一个集中的地方处理需要执行(触发处理器)的逻辑，还会带来一个好处：我们可以在一个地方为所有处理器增加执行前后的逻辑。例如，我们可以在命令数据传给处理器之前进行校验，或者我们可以用数据库事务包装处理器的执行逻辑，或者让命令总线支持复杂的队列操作和异步的命令&#x2F;处理器执行。<br>命令总线一般会使用包装着它的装饰器(或者已经包装了该装饰器的装饰器)来实现这个目标，类似俄罗斯套娃的结构.<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608850786-f1595cdd-2df6-4a55-b831-a23e0f5a537e.png#clientId=u730b459d-7447-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=259&id=u1f353b8f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=518&originWidth=744&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=555477&status=done&style=none&taskId=u926963fa-4f69-4a53-94f3-a91a40a68b4&title=&width=372" alt="image.png"><br>这样我们可以创建自己的装饰器，可以配置命令总线(可能是第三方的)由哪些装饰器按照何种顺序组成，在命令总线中加入我们的定制功能。如果我们需要队列，我们就增加一个管理命令队列的装饰器。如果我们没有使用支持事务的数据库，我们就不需要用装饰器将处理器的执行器包装在数据库事务中。以此类推。</p>
<h2 id="命令查询职责分离"><a href="#命令查询职责分离" class="headerlink" title="命令查询职责分离"></a>命令查询职责分离</h2><p>将 CQS、命令和命令总线的概念组合在一起，我们最终得到了 CQRS。CQRS 可以用不同的方式实现，也可以不同程度地实现，也许只用了命令端，也许不会使用命令总线。为了保持完整性，下面的图代表了我所认为的全套 CQRS 实现：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608860199-b92c6730-eacf-4b86-9885-7ae5526ba1d4.png#clientId=u730b459d-7447-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=337&id=ufc117a43&margin=%5Bobject%20Object%5D&name=image.png&originHeight=674&originWidth=951&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=306660&status=done&style=none&taskId=u79086d16-e1a7-41e2-a06e-d370f90b9f9&title=&width=475.5" alt="image.png"></p>
<h3 id="查询端"><a href="#查询端" class="headerlink" title="查询端"></a>查询端</h3><p>依照 CQS，查询端只返回数据，完全不会修改它。由于我们不会尝试在这些数据上执行业务逻辑，我们不需要业务对象(如实体)，所以我们不需要 ORM 来填充实体，也不需要获取填充实体所需的全部数据。我们只需要查询原始数据展现给用户，并且只用查询展现给用户的模板所需的数据！<br>这立即就可以提升性能：查询数据时无需穿过业务逻辑层，我们直接查询刚好够用的数据。<br>这种拆分还可能带来的优化是数据存储完全会被拆分成两个独立的数据存储：一个专为写优化，另一个专为读优化。例如，如果我们使用关系型数据库管理系统：</p>
<ul>
<li>读操作不需要任何数据完整性校验，也完全不需要外键约束，因为数据完整性的校验在写入数据存储是已经完成。所以<strong>我们可以去掉读库的数据完整性约束</strong>。</li>
<li>我们还能使用<strong>刚好包含每个模板需要的数据的数据库视图</strong>，让查询变得简单，变得更快(尽管我们要在模板变化时保持视图与之同步，而这会增加系统的复杂性) 。</li>
</ul>
<p>这一点上，如果每个模板我们都有专门的数据库视图与之对应来简化查询，为什么我们还需要使用关系型数据库管理系统来做读取呢？！也许我们可以<strong>使用文档存储来做读取</strong>，比如 Mongo DB 甚至 Redis，它们要更快一些。也许可行，也许不行，我只是觉得如果应用在读取端出现性能问题的话这值得考虑。<br>查询本身可以使用返回一组供模板使用的数据的查询对象来实现，或者我们可以使用更成熟的方案，例如查询总线，它接收一个模板名字，使用一个查询对象查询数据并返回该模板需要的 ViewModel 实例。<br>这种方法可以解决 <a href="https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf">Greg Young</a> 提出的一些问题：</p>
<ul>
<li>大量的存储库读方法常常还要包含分页和排序信息；</li>
<li>为了构造 DTO，Getter 暴露了领域对象的内部状态；</li>
<li>在读取用例上使用预取路径，因为它们需要更多由 ORM 加载的数据；</li>
<li>构建 DTO 需要加载多个聚合根，导致对数据模型的非最优查询。另外，DTO 的构建操作还会导致聚合边界变得模糊；</li>
<li>不过，最大的问题是查询的优化极度困难：因为查询是针对对象模型的操作然后被转换成数据模型，比如 ORM，这些查询的优化可能非常困难。</li>
</ul>
<h3 id="命令端"><a href="#命令端" class="headerlink" title="命令端"></a>命令端</h3><p>如前所述，使用命令之后，我们将应用由以数据为中心的设计变成了围绕行为的设计，这和 DDD 完全一致。<br>将读取操作从处理命令的代码和领域中去掉之后，Greg Young 提出的问题也就不复存在：</p>
<ul>
<li>领域对象突然不再需要暴露内部状态了；</li>
<li>除了 GetById 之外，资源库几乎没有任何查询方法；</li>
<li>聚合的边界将更聚焦于行为。</li>
</ul>
<p>实体间“一对多”和“多对多”的关系会严重的影响 ORM 的性能。好消息是我们在处理命令时很少会需要这些关系，它们大多数时候只会在查询中用到，而我们已经把查询从命令的处理中移走了，所以我们可以移除这些实体关系。这里我所说的并不是关系型数据库管理系统中表之间的关系，这些外键约束依然应该存在于写库中，我指的是在 ORM 级别配置的实体间的连接。</p>
<blockquote>
<p>我们真的需要在客户实体中保留订单集合吗？我们需要在哪条命令中浏览这个集合？实际上，到底有什么样的命令会需要一对多关系？如果一对多关系是这种情况，那么多对多关系绝对也是一样的。我的意思是，大多数命令都只包含一两个 ID。—— Udi Dahan 2009, <a href="http://udidahan.com/2009/12/09/clarified-cqrs/">Clarified CQRS</a></p>
</blockquote>
<p>按照和查询端的一样的思路，如果复杂查询用不上写入端，我们能用序列化实体的文档或键值存储来代替关系型数据库管理系统吗？也许可行，也许不行，我只是觉得如果应用在写入端出现性能问题的话这值得考虑。</p>
<h3 id="业务处理事件"><a href="#业务处理事件" class="headerlink" title="业务处理事件"></a>业务处理事件</h3><p>命令处理完之后，如果成功，处理器会触发一个事件将发生的事情通知到应用的其它部分。事件应该和按触发它的命令一样，只是应该以过去时态命名，这是它的命名规则。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>使用 CQRS 之后，我们就能够把读模型和写模型完全分开，让我们可以优化读操作和写操作。除了性能提升，它还让代码库更清晰简洁，更能体现出领域，更易维护。<br>同样，这全部都是封装、低耦合、高内聚和单一责任原则的体现。<br>然而，请记住，尽管 CQRS 提供了一种设计风格和一些技术解决方案，可以使应用非常健壮，但这并不意味着所有应用都应该以这种方式构建：我们应该在需要的时候使用我们需要的东西。</p>
<h1 id="引用来源"><a href="#引用来源" class="headerlink" title="引用来源"></a>引用来源</h1><blockquote>
<p>1994 – Gamma, Helm, Johnson, Vlissides – <a href="https://www.amazon.com/Design-Patterns-Elements-Reusable-Object-Oriented-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a><br>1999 – Bala Paranj – <a href="http://www.javaworld.com/article/2077569/core-java/java-tip-68--learn-how-to-implement-the-command-pattern-in-java.html">Java Tip 68: Learn how to implement the Command pattern in Java</a><br>2004 – Eric Freeman, Elisabeth Robson – <a href="https://www.amazon.com/Head-First-Design-Patterns-Brain-Friendly/dp/0596007124">Head First Design Patterns</a><br>2005 – Martin Fowler – <a href="https://martinfowler.com/bliki/CommandQuerySeparation.html">Command Query Separation</a><br>**2009 – Udi Dahan – **<a href="http://udidahan.com/2009/12/09/clarified-cqrs/">Clarified CQRS</a><br>2010 – Greg Young – <a href="http://codebetter.com/gregyoung/2010/02/16/cqrs-task-based-uis-event-sourcing-agh/">CQRS, Task Based UIs, Event Sourcing agh!</a><br>2010 – Greg Young – <a href="https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf">CQRS Documents</a><br>2010 – Udi Dahan – <a href="http://udidahan.com/2010/08/31/race-conditions-dont-exist/">Race Conditions Don’t Exist</a><br>2011 – Martin Fowler – <a href="https://martinfowler.com/bliki/CQRS.html">CQRS</a><br>2011 – Udi Dahan – <a href="http://udidahan.com/2011/04/22/when-to-avoid-cqrs/">When to avoid CQRS</a><br>**2014 – Greg Young – <em><em><a href="https://www.youtube.com/watch?v=JHGkaShoyNs">CQRS and Event Sourcing – Code on the Beach 2014</a><br>2015 – Matthias Noback – <a href="https://php-and-symfony.matthiasnoback.nl/2015/01/responsibilities-of-the-command-bus/">Responsibilities of the command bus</a><br>2017 – Martin Fowler – <a href="https://martinfowler.com/articles/201701-event-driven.html">What do you mean by “Event-Driven”?</a><br>2017</em> – Doug Gale – <a href="http://wiki.c2.com/?CommandPattern">Command Pattern</a><br>2017</em> – Wikipedia – <a href="https://en.wikipedia.org/wiki/Command_pattern">Command Pattern</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（六）清晰架构</title>
    <url>/article/ddd/explicit-architecture/</url>
    <content><![CDATA[<blockquote>
<p>原文：<a href="https://links.jianshu.com/go?to=https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/">https://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/</a> &gt; <a href="https://www.jianshu.com/p/4cf50cf3e127">https://www.jianshu.com/p/4cf50cf3e127</a><br>清晰架构（Explicit Architecture）： 融合 DDD、六边形架构、洋葱架构、整洁架构、CQRS</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647948589004-38220c98-fbff-4855-bd1c-eb426658333d.png#clientId=u4b25f31a-f046-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=1266&id=u39c1d37b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=2531&originWidth=4500&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=1577960&status=done&style=none&taskId=uc04a9f29-711f-43d9-86dd-77feecdce3d&title=&width=2250" alt="image.png"><br>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>) 的一部分，这部编年史由<a href="https://herbertograca.com/tag/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。<br>今天的文章内容是我如何将这些碎片融合成一种新的架构，看起来我得给它起个名字，就叫做<strong>清晰架构</strong>吧。而且，这些概念全都经历过“炮火的洗礼”，在高水准的平台生产代码中得到了应用。其中一个是拥有数千家遍布全球的网上商店的 SaaS 电子商务平台，另一个是已经在两个国家上线的市场，它拥有可以每月处理超过两千万条消息的消息总线。</p>
<h2 id="系统的基本构建块"><a href="#系统的基本构建块" class="headerlink" title="系统的基本构建块"></a>系统的基本构建块</h2><p>我们从 <a href="https://herbertograca.com/2017/08/24/ebi-architecture/">EBI 架构</a>以及<a href="https://www.jianshu.com/p/f39f4537857e">端口和适配器架构</a>(<a href="https://www.jianshu.com/p/f39f4537857e">译</a>)的回顾开始。它们都有清晰的代码划分，哪些代码在应用内部，哪些代码在外部，而哪些代码用来连接它们。<br>除此之外，<a href="https://www.jianshu.com/p/f39f4537857e">端口和适配器架构</a>还明确地识别出了一个系统中的三个基本代码构建块：</p>
<ul>
<li>运行<strong>用户界面</strong>所需的构建块，无论是哪种用户界面；</li>
<li>系统的<strong>业务逻辑</strong>，或者<strong>应用核心</strong>，用户界面要使用这个构建块达成目的；</li>
<li><strong>基础设施</strong>代码，这个构建块将我们的应用核心和诸如数据库、搜索引擎或第三方 API 这样的工具连接起来。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609050029-de556f79-835f-4439-885f-43d5f80d1a39.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=udc7c6dfd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=156075&status=done&style=none&taskId=u66080bf2-33e6-4da6-8ad3-aabb4a112fc&title=&width=600" alt="image.png"><br>我们真正关心的应该是应用核心。这部分代码才是我们编写代码的目的，它们才是我们的应用。它们可能使用一些不同的用户界面(渐进式 Web 应用，移动应用、命令行、接口…)，但完成实际工作的代码是一模一样的，它们就在应用核心内部，它们不用关心是哪种用户界面触发了它们。<br>你可以想像得到，典型的应用控制流开始于用户界面中的代码，经过应用核心到达基础设施代码，又返回应用核心，最后将响应传达给用户界面。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609059529-8ce232f9-6ddd-4a18-a449-673c62ec6540.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=ue9d6a47f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=261750&status=done&style=none&taskId=u36b3b868-dd8a-47fe-b30a-e7c4fb90054&title=&width=600" alt="image.png"></p>
<h2 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h2><p>在远离我们系统中最重要的代码-——应用核心-——的地方，还有一些应用会用到的工具，例如数据库引擎、搜索引擎、Web 服务器或者命令行控制台(虽然最后两种工具也是传达机制)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609084958-afe9af30-746e-499f-9250-a2deaa86d896.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=u4c2e06b2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=273718&status=done&style=none&taskId=udcec806e-3e5a-4f27-a626-7fbed3f9bb0&title=&width=600" alt="image.png"><br>把命令行控制台和数据库引擎放在同一个“篮子”中感觉有点奇怪，尽管它们有着不用的用途，但它们实际都是应用使用的工具。关键的区别在于，命令行控制台和 Web 服务器<em><strong>告诉我们的应用它要做什么</strong>，而数据库引擎是由我们的应用来</em><em>告诉它**做什么</em>。这是针锋相对的差别，强烈地暗示着我们应该如何构建连接这些工具和应用核心的代码。</p>
<h3 id="将传达机制和工具连接到应用核心"><a href="#将传达机制和工具连接到应用核心" class="headerlink" title="将传达机制和工具连接到应用核心"></a>将传达机制和工具连接到应用核心</h3><p>连接工具和应用核心的代码单元被称为适配器(<a href="https://www.jianshu.com/p/f39f4537857e">端口和适配器架构</a>)。适配器有效地实现了让业务逻辑和特定工具之间可以相互通信的代码。<br><strong>告知我们</strong>的应用应该做什么的适配器被称为<strong>主适配器</strong>或<strong>主动适配器</strong>，而那些由我们的应用<strong>告知它</strong>该做什么的适配器被称为<strong>从适配器</strong>或者<strong>被动适配器</strong>。</p>
<h3 id="端口"><a href="#端口" class="headerlink" title="端口"></a>端口</h3><p>而这些适配器并非是随意创建的。它们需要按照应用核心某个特定的入口的要求来创建，即<strong>端口</strong>。端口无外乎是一份工具如何使用应用核心或者如何被应用核心使用的<strong>说明书</strong>。这份说明书，即端口，在大多数语言里最简单的形式就是接口，但实际上也可能由多个接口和 DTO 组成。<br><strong>端口(接口)位于业务逻辑内部</strong>，而适配器位于其外部，这一点要特别注意。要让这种模式按照设想发挥作用，端口按照应用核心的需要来设计而不是简单地套用工具的 API，这一点再怎么强调都不为过。</p>
<h3 id="主适配器或主动适配器"><a href="#主适配器或主动适配器" class="headerlink" title="主适配器或主动适配器"></a>主适配器或主动适配器</h3><p><strong>主适配器</strong>或<strong>主动适配器包装端口</strong>并通过它告知应用核心应该做什么。<strong>它们将来自传达机制的信息转换成对应用核心的方法调用</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609123231-555111ed-871c-48c4-b5cc-e79860ea986f.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=ud3766365&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=519375&status=done&style=none&taskId=uc0240ded-55dc-4dae-9db2-fea16992196&title=&width=600" alt="image.png"><br>换句话说，我们的主动适配器就是 Controller 或者控制台命令，它们需要的接口(端口)由其他类实现，这些类的对象通过构造方法注入到 Controller 或者控制台命令。<br>再举一个更具体的例子，端口就是 Controller 需要的 Service 接口或者 Repository 接口。Service、Repository 或 Query 的具体实现被注入到 Controller 供 Controller 使用。<br>此外，端口还可以是命令总线接口或者查询总线接口。这种情况下，命令总线或者查询总线的具体实现将被注入到 Controller 中， Controller 将创建命令或查询并传递给相应的总线。</p>
<h3 id="从适配器或被动适配器"><a href="#从适配器或被动适配器" class="headerlink" title="从适配器或被动适配器"></a>从适配器或被动适配器</h3><p>和主动适配器包装端口不同，*<em>被动适配器***<strong>实现</strong>**<em>一个端口(接口)**并被注入到需要这个端口的应用核心里。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609133392-e3b84a5e-037a-4b55-a2ee-5eeedec00511.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=u6d63f0f4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=688279&status=done&style=none&taskId=u1feabb3f-431d-4a79-acaa-06e70830f64&title=&width=600" alt="image.png"><br>举个例子，假设有一个需要存储数据的简单应用。我们创建了一个符合应用要求的持久化接口，这个接口有一个</em>保存*数据数组的方法和一个根据 ID 从表中</em>删除*一行的方法。接口创建好之后，无论何时应用需要保存或删除数据，都应该使用实现了这个持久化接口的对象，而这个对象是通过构造方法注入的。<br>现在我们创建了一个专门针对 MySQL 实现了该接口的适配器。它拥有保存数组和删除表中一行数据的方法，然后在需要使用持久化接口的地方注入它。<br>如果未来我们决定更换数据库供应商，比如换成 PostgreSQL 或者 MongoDB，我们只用创建一个专门针对 PostgreSQL 实现了该接口的适配器，在注入时用新适配器代替旧适配器。</p>
<h3 id="控制反转"><a href="#控制反转" class="headerlink" title="控制反转"></a>控制反转</h3><p>这种模式有一个特征值得留意，适配器依赖特定的工具和特定的端口(它需要提供接口的特定实现)。但业务逻辑只依赖按照它的需求设计的端口(接口)，它并不依赖特定的适配器或工具。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609142710-934428ff-d24d-4764-a3dc-da2585e829b8.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=uae517187&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=740238&status=done&style=none&taskId=u425f920f-22b7-488c-a225-54ca08f13a3&title=&width=600" alt="image.png"><br>这意味着依赖的方向是由外向内的，这就是<strong>架构层面的控制反转原则</strong>。<br>再一次强调，<strong>端口按照应用核心的需要来设计而不是简单地套用工具的 API</strong>。</p>
<h2 id="组织应用核心的结构"><a href="#组织应用核心的结构" class="headerlink" title="组织应用核心的结构"></a>组织应用核心的结构</h2><p><a href="https://www.jianshu.com/p/d87d5389c92a">洋葱架构</a>采用了 DDD 的分层，将它们融合进了端口和适配器架构。这种分层想要为位于<a href="https://www.jianshu.com/p/f39f4537857e">端口和适配器架构</a>“六边形”内的业务逻辑带来一种结构组织，和<a href="https://www.jianshu.com/p/f39f4537857e">端口与适配器架构</a>一样，依赖的方向也是由外向内。</p>
<h3 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h3><p>在应用中，由一个或多个用户界面触发的应用核心中的过程就是用例。例如，在一个 CMS 系统中，我们可以提供普通用户使用的应用 UI、CMS 管理员使用的独立的 UI、命令行 UI 以及 Web API。这些 UI(应用)可以触发的用例可能是专门为它设计的，也可以是多个 UI 复用的。<br>用例定义在应用层中，这是 DDD 提供的第一个被<a href="https://www.jianshu.com/p/d87d5389c92a">洋葱架构</a>使用的层。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609153933-63b5b3c8-2f5e-41f9-b230-88e32886c587.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=uc6060559&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=807561&status=done&style=none&taskId=u0708475f-7dcc-43ba-b265-a2517b49193&title=&width=600" alt="image.png"><br>这个层包括了作为一等公民的应用服务(以及它们的接口)，也包括了<a href="https://www.jianshu.com/p/f39f4537857e">端口与适配器架构</a>中的接口，例如 ORM 接口、搜索引擎接口、消息接口等等。如果我们使用了命令总线和&#x2F;或查询总线，命令和查询分别对应的处理程序也属于这一层。<br>应用服务和&#x2F;或命令处理程序包含了展现一个用例，一个业务过程的逻辑。通常，它们的作用是：</p>
<ol>
<li>使用 Repostitory 查找一个或多个实体；</li>
<li>让这些实体执行一些领域逻辑；</li>
<li>再次使用 Repostitory 让这些实体持久化，有效地保存数据变化。</li>
</ol>
<p>命令处理程序有两种不同使用方式：</p>
<ol>
<li>它们可以包含执行用例的实际逻辑；</li>
<li>它们可以仅仅作为我们应用中的连接片段，接收命令然后简单地触发应用服务中的逻辑。</li>
</ol>
<p>使用哪种方式是由上下文决定的，例如：</p>
<ul>
<li>我们已经有了合适的应用服务，现在要做的是添加命令总线？</li>
<li>命令总线允许指定任意类&#x2F;方法作为处理程序吗？还是说它们需要扩展已有的类或者实现已有的接口？</li>
</ul>
<p>应用层还包括<strong>应用事件</strong>的触发，这也代表着某些用例的产出。这些事件触发的逻辑是用例的副作用，比如发送邮件、通知第三方 PAI、发送推送通知，或是发起属于其他应用组件的另一个用例。</p>
<h3 id="领域层"><a href="#领域层" class="headerlink" title="领域层"></a>领域层</h3><p>继续向内一层就是领域层。这一层中的对象包含了数据和操作数据的逻辑，它们只和领域本身有关，独立于调用这些逻辑的业务过程。它们完全独立，对应用层完全无感知。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609164934-124f4e36-fbc7-47a8-b604-d6cd9b92bc70.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=u63c9d1ab&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=838183&status=done&style=none&taskId=u4fec3b8a-3089-430b-b80a-adb16ecd200&title=&width=600" alt="image.png"></p>
<h4 id="领域服务"><a href="#领域服务" class="headerlink" title="领域服务"></a>领域服务</h4><p>如前所述，应用服务的作用是：</p>
<ol>
<li>使用 Repostitory 查找一个或多个实体；</li>
<li>让这些实体执行一些领域逻辑；</li>
<li>再次使用 Repostitory 让这些实体持久化，有效地保存数据变化。</li>
</ol>
<p>然而，有时我们还会碰到某种领域逻辑，它涉及不同的实体。这些实体也许是同一个类型，也许不是，而且我们觉得这种领域领域逻辑并不属于这些实体，这种逻辑不是这些实体的直接责任。<br>所以，我们的第一反应也许是把这些逻辑放到实体外的应用服务中。然而，这意味着这些领域逻辑就不能被其它的用例复用。领域逻辑应该放在应用层之外！<br>解决方法是创建领域服务，它的作用是接收一组实体并对它们执行某种业务逻辑。领域服务属于领域层，因此它并不了解应用层中的类，比如应用服务或者 Repository[译注：Repository 属于应用服务层？？]。另一方面，它可以使用其他领域服务，当然还可以使用领域模型对象。</p>
<h4 id="领域模型"><a href="#领域模型" class="headerlink" title="领域模型"></a>领域模型</h4><p>在架构的正中心，是完全不依赖外部任何层次的领域模型。它包含了那些表示领域中某个概念的业务对象。这些对象的例子首先就是实体，还有值对象、枚举以及其它领域模型种用到的任何对象。<br>领域事件也“活在”领域模型中。当一组特定的数据发生变化时就会触发这些事件，而这些时间会携带这些变化的信息。换句话说，当实体变化时，就会触发一个领域事件，它携带着发生变化的属性的新值。这些事件可以完美地应用于事件溯源。</p>
<h2 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h2><p>目前为止，我们都是使用层次来划分代码，但这是细粒度的代码隔离。根据 Robert C. Martin 在<a href="https://links.jianshu.com/go?to=https://8thlight.com/blog/uncle-bob/2011/09/30/Screaming-Architecture.html">尖叫架构</a>中表达的观点，按照子域和<a href="https://links.jianshu.com/go?to=http://ddd.fed.wiki.org/view/welcome-visitors/view/domain-driven-design/view/bounded-context">限界上下文</a>对代码进行划分这种粗粒度的代码隔离同样重要。这通常被叫做“按特性分包”或者“按组件分包”，和“按层次分包”相呼应。Simon Brown 的文章“<a href="https://links.jianshu.com/go?to=http://www.codingthearchitecture.com/2015/03/08/package_by_component_and_architecturally_aligned_testing.html">Package by component and architecturally-aligned testing</a>”很好地阐述了这种划分：</p>
<table><thead><tr>
<th><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609217169-1c217678-c03d-4500-9530-0ab5383bbadb.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=321&id=u0106679b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=642&originWidth=856&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=283344&status=done&style=none&taskId=u2ecff89a-12c3-455b-9be2-d79f2afae4b&title=&width=428" alt="image.png"></th>
<th><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609221969-5a16adc6-e42e-48e6-9040-62fadcbc6faf.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=321&id=u98946746&margin=%5Bobject%20Object%5D&name=image.png&originHeight=642&originWidth=856&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=274131&status=done&style=none&taskId=u05431945-8f19-4527-888c-8a82ab3dede&title=&width=428" alt="image.png"></th>
<th><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609227563-18c327d3-b1f6-4e7a-8c1c-1e042021bb3e.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=321&id=ued0141d4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=642&originWidth=856&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=298643&status=done&style=none&taskId=u4030fd91-986e-47d7-9b27-8da2df0b976&title=&width=428" alt="image.png"></th>
</tr>
</thead><tbody></tbody></table><p>我是“_按组件分包_”方式的坚定拥护者，在此我厚着脸皮将 Simon Brown <em>按组件分包</em>的示意图做了如下修改：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609234423-e1923097-e61a-4231-8f62-33009be38a58.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=360&id=ucacf6fc2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=959&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=402264&status=done&style=none&taskId=u83a84dae-f5f1-4e03-b5ac-2ec32b8e1fb&title=&width=479.5" alt="image.png"><br>这些代码块在前面描述的分层基础上再进行了“横切”，它们是应用的<a href="https://links.jianshu.com/go?to=https://herbertograca.com/2017/07/05/software-architecture-premises/">组件</a>(<a href="https://www.jianshu.com/p/df295f92fb52">译</a>)。组件的例子包括<del>认证</del>、<del>授权</del>、账单、用户、评论或帐号，而它们总是都和领域相关。像认证和&#x2F;或授权这样的限界上下文应该被看作外部工具，我们应该为它们创建适配器，把它们隐藏在某个端口之后。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609243111-aa84694b-8272-4faa-9f77-1336922a60f4.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=411&id=u61ee0d69&margin=%5Bobject%20Object%5D&name=image.png&originHeight=821&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=880283&status=done&style=none&taskId=u6a63347f-fece-4043-b726-15487651774&title=&width=600" alt="image.png"></p>
<h3 id="组件解耦"><a href="#组件解耦" class="headerlink" title="组件解耦"></a>组件解耦</h3><p>和细粒度的代码单元(类、接口、特质、混合等等)一样，粗粒度的代码单元(组件)也会从高内聚低耦合中受益。<br>我们使用了依赖注入，<strong>通过将依赖注入类而不是在类内部初始化依赖</strong>；以及依赖倒置；<strong>让类依赖抽象(接口和&#x2F;或抽象类)而不是具体类</strong>来解耦类。这意味着类不用知道它要使用的具体类的任何信息，不用引用所依赖的类的完全限定类名。<br>以同样的方式完全解耦的组件意味着组件不会直接了解其它任何组件的信息。换句话说，它不会引用任何来自其它组件的细粒度的代码单元，甚至都不会引用接口！这意味着依赖注入和依赖倒置对组件解耦是不够用的，我们还需要一些架构层级的结构。我们需要事件、共享内核、最终一致性甚至发现服务！<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609252532-3ed20f8b-55c8-45d0-a92e-15074d627266.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=270&id=uac853691&margin=%5Bobject%20Object%5D&name=image.png&originHeight=540&originWidth=960&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=593536&status=done&style=none&taskId=ucd2c55d8-3f11-4bb4-a7dc-946a28e9dd6&title=&width=480" alt="image.png"></p>
<h4 id="触发其它组件的逻辑"><a href="#触发其它组件的逻辑" class="headerlink" title="触发其它组件的逻辑"></a>触发其它组件的逻辑</h4><p>当一个组件(组件 A)中有事情发生需要另一个组件(组件 B)做些什么时，我们不能简单地从组件 A 直接调用组件 B 中的类&#x2F;方法，因为这样 A 就和 B 耦合在一起了。<br>但是我们可以让 A 使用事件派发器，派发一个领域事件，这个事件将会投递给任何监听它的组件，例如 B，然后 B 的事件监听器会触发期望的操作。这意味着组件 A 将依赖事件派发器，但和 B 解耦了。<br>然而，如果事件本身“活在” A 中，这将意味着 B 知道了 A 的存在，就和 A 存在耦合。要去掉这个依赖，我们可以创建一个包含应用核心功能的库，由所有组件共享，这就是<a href="https://links.jianshu.com/go?to=http://ddd.fed.wiki.org/view/welcome-visitors/view/domain-driven-design/view/shared-kernel">共享内核</a>。这意味着两个组件都依赖共享内核，而它们之间却没有耦合。共享内核包含了应用事件和领域事件这样的功能，而且还包含规格对象，以及其它任何有理由共享的东西。记住共享内核的范围应该尽可能的小，因为它的任何变化都会影响所有应用组件。而且，如果我们的系统是语言异构的，比如使用不同语言编写的微服务生态，共享内核需要做到与语言无关的，这样它才能被所有组件理解，无论它们是用哪种语言编写的。例如，共享内核应该包含像 JSON 这样无关语言的事件描述(例如，名称、属性，也许还有方法，尽管它们对规格对象来说更有意义)而不是事件类，这样所有组件&#x2F;微服务都可以解析它，还可以自动生成各自的具体实现。请在我的下一篇文章种了解更多内容：<a href="https://links.jianshu.com/go?to=https://herbertograca.com/2018/07/07/more-than-concentric-layers/">超越同心圆分层</a>(<a href="https://www.jianshu.com/p/fcf5bb27a60b">译</a>)<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609263428-b3fc8b83-c435-4e56-a3a5-3c4bb49d3595.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=412&id=ua7cbfbfd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=823&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=677060&status=done&style=none&taskId=uc7d470a0-ffd2-44bc-a75f-d11f0fd489d&title=&width=600" alt="image.png"><br>这种方法既适用于单体应用，也适用于像微服务生态系统这样的分布式应用。然而，这种方法只适用于事件异步投递的情况，在需要即时完成触发其它组件逻辑的上下文中并不适用！组件 A 将需要向组件 B 发起直接的 HTTP 调用。这种情况下，要解耦组件，我们需要一个发现服务，A 可以询问它得知请求应该发送到哪里才能触发期望的操作，又或是向发现服务发起请求并由发现服务将请求代理给相关服务并最终返回响应给请求方。这种方法会把组件和发现服务耦合在一起，但会让组件之间解耦。</p>
<h4 id="从其它组件获得数据"><a href="#从其它组件获得数据" class="headerlink" title="从其它组件获得数据"></a>从其它组件获得数据</h4><p>我的看法是，组件不允许修改不“属于”它的数据，但可以查询和使用任何数据。<br><strong>组件之间共享的数据存储</strong><br>当一个组件需要使用属于其它组件的数据时，比如说账单组件需要使用属于账户组件的客户名字，账单组件会包含一个查询对象，可以在数据存储中查询该数据。简单的说就是账单组件知道任何数据集，但它只能通过查询只读地使用不“属于”它的数据。<br><strong>按组件隔离的数据存储</strong><br>这种情况下，这种模式同样有效，但数据存储层面的复杂度更高。<br>组件拥有各自的数据存储意味着每个数据存储都包含：</p>
<ul>
<li>一组属于它的数据，并且只允许它自己修改这些数据，让它成为单一事实来源；</li>
<li>一组其它组件数据的副本，它自己不能修改这些数据，但组件的功能需要这些数据，而且一旦数据在其所属的组件中发生了变化，这些副本需要更新。</li>
</ul>
<p>每个组件都会创建其所需的其它组件数据的本地副本，在必要时使用。当数据在其所属的组件中发生了变化，该组件将触发一个携带数据变更的领域事件。拥有这些数据副本的组件将监听这个领域事件并相应地更新它们的本地副本。</p>
<h2 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h2><p>如前所述，控制流显然从用户出发，进入应用核心，抵达基础设施工具，再返回应用核心并最终返回给用户。但这些类到底是是如何配合的？哪些类依赖哪些类？我们怎样把它们组合在一起？<br>根据 Uncle Bob 在他关于整洁架构的文章中的说法，我来试着用 UML 图解释控制流…</p>
<h3 id="没有命令-x2F-查询总线"><a href="#没有命令-x2F-查询总线" class="headerlink" title="没有命令&#x2F;查询总线"></a>没有命令&#x2F;查询总线</h3><p>如果没有命令总线，控制器要么依赖应用服务，要么依赖查询对象。<br>[<strong>2017-11-18 编辑</strong>] 之前我完全忘记了查询返回数据中的 DTO，现在我把它加了回来。谢谢<a href="https://links.jianshu.com/go?to=https://www.reddit.com/r/PHP/comments/7dcz8k/ddd_hexagonal_onion_clean_cqrs_how_i_put_it_all/dpy6va4/">指出</a>我这处错误的<a href="https://links.jianshu.com/go?to=https://www.reddit.com/user/MorphineAdministered">MorphineAdministered</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609283011-6f274944-4ed8-4496-b461-fef9e614869c.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=301&id=u614b3333&margin=%5Bobject%20Object%5D&name=image.png&originHeight=602&originWidth=802&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=128675&status=done&style=none&taskId=u42312eaf-b1b7-433a-acde-4e11b70ba0f&title=&width=401" alt="image.png"><br>上图中我们使用了应用服务接口，尽管我们会质疑这并没有必要。因为应用服务是我们应用代码的一部分，而且我们不会想用另外一种实现来替换它，尽管我们可能会彻底地重构它。<br>查询对象包含优化过的查询，简单地返回一些给用户看的原始数据就好。这些数据将放在 DTO 中返回，并注入到 ViewModel。ViewModel 中可能有一些 View 逻辑，它被用来填充 View。<br>另一方面，应用服务还包含用例逻辑，不是浏览数据这么简单，我们需要在系统中做一些事情时触发这些逻辑。应用服务依赖 Repository 返回实体，这些实体中包含着需要触发的逻辑。它也可能依赖领域服务来整合多个实体来完成领域流程，但这种情况很少出现。<br>展开用例之后，应用服务可能想通知整个系统，这个用例已经发生了。这种情况下，它还要依赖事件派发器来触发事件。<br>很有意思的是我们在持久化引擎和资源库之上都放上了接口。尽管看起来有些多余，但它们服务于不用的目标：</p>
<ul>
<li>持久化接口是 ORM 之上的抽象层，这样我们可以切换使用的 ORM 而不用修改应用核心。</li>
<li>资源库接口是持久化引擎自身的抽象。比方说我们想要从 MySQL 切换为 MongoDB。如果我们想继续使用同样的 ORM，持久化接口可以保持不变，甚至持久化适配器也可以保持不变。然而，两者的查询语言完全不同，所以，我们可以创建使用同样持久化机制的新资源库，可以实现相同的资源库接口，但使用 MongoDB 查询语言而不是 SQL 来构建查询。</li>
</ul>
<h3 id="有命令-x2F-查询总线"><a href="#有命令-x2F-查询总线" class="headerlink" title="有命令&#x2F;查询总线"></a>有命令&#x2F;查询总线</h3><p>如果我们的应用使用了命令&#x2F;查询总线，UML 图基本没有变化，唯一的区别是控制器现在会依赖总线、命令或查询。它将实例化命令或查询，将它们传递给总线。总线会找到合适的处理程序接收并处理命令。<br>在下图中，命令处理程序接下来将使用应用服务。然而，这不总是必须的，实际上大多数情况下，处理程序将包含用例的所有逻辑。只有在其它处理程序需要重用同样的逻辑时，我们才需要把处理程序中的逻辑提取出来放到单独的应用服务中。<br>[<strong>2017-11-18 编辑</strong>] 之前我完全忘记了查询返回数据中的 DTO，现在我把它加了回来。谢谢<a href="https://links.jianshu.com/go?to=https://www.reddit.com/r/PHP/comments/7dcz8k/ddd_hexagonal_onion_clean_cqrs_how_i_put_it_all/dpy6va4/">指出</a>我这处错误的<a href="https://links.jianshu.com/go?to=https://www.reddit.com/user/MorphineAdministered">MorphineAdministered</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609293264-559b7401-9db6-488f-9fea-388e102919c8.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=298&id=u4d8c0c1f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=596&originWidth=794&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=174603&status=done&style=none&taskId=u32bc1257-5de2-41a9-9ce9-28c914a3650&title=&width=397" alt="image.png"><br>你可能注意到了，总线和命令查询，以及处理程序之间没有依赖。这是因为实际上它们之间应该互相无感知，才能提供足够的解耦。只有通过配置才能设置总线可以发现哪些命令，或者查询应该由哪个处理程序处理。<br>如你所见，两种情况下，所有跨越应用核心边界的箭头——依赖——都指向内部。如前所述，这是端口和适配器架构、洋葱架构以及整洁架构的基本规则。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609300765-081b1099-24e1-4010-bd7d-2e78bb4280dc.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=64&id=u97b63914&margin=%5Bobject%20Object%5D&name=image.png&originHeight=128&originWidth=913&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=77046&status=done&style=none&taskId=ub87c4650-51ec-4b07-8d1c-a0f831d2f70&title=&width=456.5" alt="image.png"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一如既往，这些架构的目标是得到高内聚低耦合的代码库，这样变化才会简单、快速和安全。</p>
<blockquote>
<p>计划不名一文，但制订计划的过程至关重要。——艾森豪威尔</p>
</blockquote>
<p>这份信息图是一份概念地图。了解并理解所有这些概念将帮助我们规划出健康的架构和应用。<br>不过：</p>
<blockquote>
<p>地图并非疆域。——阿尔弗雷德·柯日布斯基</p>
</blockquote>
<p>这只是一份指南！<strong>应用才是你的疆域，现实情况和具体用例才是运用这些知识的地方，它们才能勾勒出实际架构的轮廓！</strong><br><strong>我们需要理解所有这些模式，但我们还时常需要思考和理解我们的应用需要什么，我们应该在追求解耦和内聚的道路上走多远。</strong>这个决定可能受到许多因素的影响，包括项目的功能需求，也包括构建应用的时间期限，应用寿命，开发团队的体验等等因素。<br>就到这里，这是我对一切的理解。这就是我脑海中对这一切的梳理。<br>在下篇文章中我将更深入地展开这些话题: <a href="https://links.jianshu.com/go?to=https://herbertograca.com/2018/07/07/more-than-concentric-layers/">超越同心圆分层</a>(<a href="https://www.jianshu.com/p/fcf5bb27a60b">译</a>)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609322759-17736d9b-f927-4c06-a357-3b260c6c5f1a.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=221&id=u13f8c854&margin=%5Bobject%20Object%5D&name=image.png&originHeight=441&originWidth=600&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=281325&status=done&style=none&taskId=u4a61d459-4e84-4250-839f-c135bae6c57&title=&width=300" alt="image.png"><br>这种架构方式问题是实际上只适用于系统中的少数典型请求。此外，我倾向于看到这些架构严重拟合，严格遵守依赖关系管理规则。在实践中，我发现这些规则很少有用，并且你开始得到很多关于真正不应该被抽象的抽象（控制器必须与必须使用存储库的服务进行对话）。<br>相反，我想对我的系统采用量身定制的方法，我将每个请求视为如何处理其代码的独特用例。因为我的系统整齐地分解为“命令”请求和“查询”请求（HTTP-land 中的 GET 与 POST &#x2F; PUT &#x2F; DELETE），所以向垂直切片架构的移动使我使用了 CQRS。<br>什么是“垂直切片架构”？在这种风格中，我的架构是围绕不同的具体请求功能而构建的，通过这种方法，我们的每个垂直切片都可以自行决定如何最好地满足请求：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609329202-0086d13e-25bc-4464-859b-96d8ebadbb6d.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=140&id=u7d1ef354&margin=%5Bobject%20Object%5D&name=image.png&originHeight=280&originWidth=917&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=176143&status=done&style=none&taskId=u38fa88d0-38ad-4012-8395-358f8696549&title=&width=458.5" alt="image.png"><br>(banq 注：对于获取订单，直接使用 ORM 转换为 DTO，对于订单细节使用原生 SQL 转换为 DTO，对于发票，使用基于聚合根的<a href="https://links.jianshu.com/go?to=https://www.jdon.com/tags/17268">事件溯源</a>，取消订单使用存储过程，这是一种<a href="https://links.jianshu.com/go?to=https://www.jdon.com/tags/25407">微服务</a>风格)<br>在所谓正常的“n 层”或六边形或任何架构中，通过垂直切片移除这些层障碍，并沿着变化轴聚合在一起：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609338400-a7650183-7d95-435c-b141-aa5190cda3f4.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=190&id=u97952df0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=379&originWidth=581&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=71059&status=done&style=none&taskId=u21248bf5-6f8f-4a2c-abc8-4519905ddb3&title=&width=290.5" alt="image.png"><br>在应用程序中添加或更改功能时，通常会在应用程序中涉及到许多不同的“层”。现在改为沿着切片垂直将这些功能聚合在一起。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649609346344-25cd5ce3-0128-4281-ba42-bcae3af392de.png#clientId=ubff85c3b-7100-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=301&id=u3e0c3d77&margin=%5Bobject%20Object%5D&name=image.png&originHeight=602&originWidth=802&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=134840&status=done&style=none&taskId=uaf78b0ed-44bb-49e1-a993-acab577be3b&title=&width=401" alt="image.png"></p>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>DDD（四）整洁架构</title>
    <url>/article/ddd/clean-architecture/</url>
    <content><![CDATA[<blockquote>
<p>原文：<a href="https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/">https://herbertograca.com/2017/09/28/clean-architecture-standing-on-the-shoulders-of-giants/</a> &gt; <a href="https://www.jianshu.com/p/b565f0c00c0c">https://www.jianshu.com/p/b565f0c00c0c</a></p>
</blockquote>
<p>这篇文章是<a href="https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/">软件架构编年史</a>(<a href="https://www.jianshu.com/p/b477b2cc6cfa">译</a>)的一部分，这部编年史由<a href="https://herbertograca.com/category/development/series/software-architecture/">一系列关于软件架构的文章</a>组成。在这一系列文章中，我将写下我对软件架构的学习和思考，以及我是如何运用这些知识的。如果你阅读了这个系列中之前的文章，本篇文章的的内容将更有意义。<br>Robert C. Martin(大名鼎鼎的 Uncle Bob)于 2012 年在<a href="https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html">他的一篇博客</a>中发表了整洁架构的观点，并在一些会议上做了关于该架构的演讲。<br>整洁架构借助了许多或熟悉或陌生的概念、规则和模式，说明了如何将它们融会贯通产生出一种构建应用的标准套路。</p>
<h2 id="站在-EBI-架构、六边形架构和洋葱架构的肩膀上"><a href="#站在-EBI-架构、六边形架构和洋葱架构的肩膀上" class="headerlink" title="站在 EBI 架构、六边形架构和洋葱架构的肩膀上"></a>站在 EBI 架构、六边形架构和洋葱架构的肩膀上</h2><p>整洁架构的核心目标与端口和适配器(六边形)架构以及洋葱架构是一致的：</p>
<ul>
<li>工具无关</li>
<li>传达机制无关</li>
<li>独立的可测试性</li>
</ul>
<p>下面这张图发表在整洁架构的博客中，揭示了该架构的总体思路：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608398336-9a577acc-186f-403a-8690-645706753ebd.png#clientId=u0810918f-6dc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=284&id=udfe816b8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=567&originWidth=772&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=463984&status=done&style=none&taskId=ub1e28296-c043-409a-87e1-6404a90d2d7&title=&width=386" alt="image.png"><br>Robert C. Martin 2012, <a href="https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html">The Clean Architecture</a></p>
<p>正如 Uncle Bob 自己在博客中所说，上面这张图试图将最新的架构观点整合成一个可操作的思路。<br>我们来对比一下整洁架构和六边形架构以及洋葱架构的示意图，看看它们在哪些方面是一致的：</p>
<table><thead><tr>
<th><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608428873-c6a319c5-c039-4f6e-90d5-a6917d8088da.png#clientId=u0810918f-6dc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=161&id=uc137bb4f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=321&originWidth=490&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=127029&status=done&style=none&taskId=u74efedda-759a-47bb-be0f-764ef1b5264&title=&width=245" alt="image.png"></th>
<th><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608433866-107f20dd-f413-47a7-9cd9-69aff68eddbb.png#clientId=u0810918f-6dc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=130&id=u741aac26&margin=%5Bobject%20Object%5D&name=image.png&originHeight=259&originWidth=366&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=104824&status=done&style=none&taskId=u85f3cc37-69c3-452c-9dbd-8300d3d728c&title=&width=183" alt="image.png"></th>
</tr>
</thead><tbody></tbody></table><h3 id="外化工具和传达机制"><a href="#外化工具和传达机制" class="headerlink" title="外化工具和传达机制"></a>外化工具和传达机制</h3><p>六边形架构聚焦于使用接口和适配器将工具和传达机制从应用中外化出去。这也是洋葱架构的核心基石之一，就像图中呈现的那样，UI、基础设置和测试全部都在示意图的最外层。整洁架构也有完全一致的特征，UI、Web、DB 等等都在最外层。最终，所有的应用核心代码都是独立于框架&#x2F;库的。</p>
<h3 id="依赖方向"><a href="#依赖方向" class="headerlink" title="依赖方向"></a>依赖方向</h3><p>六边形架构中并没有明确地告知我们依赖的方向。然而，我们可以轻易地推测出来：应用拥有接口，它们必须由适配器实现或使用。所以适配器依赖接口，依赖位于圆心的应用。外部依赖内部，依赖的方向就指向圆心。在洋葱架构的示意图中，也没有发现关于依赖方向的表示，但是，Jeffrey Palermo 在他的第二篇博客中清楚地表明了所以依赖都指向圆心。整洁架构则非常明确的指出依赖的方向是指向圆心的。它们都在架构层级引入了依赖倒置原则。内圈不能知道外圈的任何信息。还有，当数据跨越界限进行传递时，数据总是以最方便内圈使用的格式提供。</p>
<h3 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h3><p>六边形架构示意图只展现了两个层次：应用内部和应用外部。而洋葱架构引入了 DDD 中定义的应用层次的混合：控制用例逻辑的应用服务；封装了领域逻辑的领域服务，这些逻辑既不属于实体也不属于值对象；还有实体、值对象等等…和洋葱架构相比，整洁架构保留了应用服务层(用例)和实体层，当好像漏掉了领域服务层。然而，读过 Uncle Bob 的博客后，我们会发现，他认为任何领域对象都是实体，而非只有 DDD 中的“实体”才是实体：“一个实体可以是一个拥有方法的对象，或者是一组数据结构和函数”。实际上，他为了简化示意图而将最中间的两层合并了。</p>
<h3 id="独立的可测试性"><a href="#独立的可测试性" class="headerlink" title="独立的可测试性"></a>独立的可测试性</h3><p>三种架构风格共同遵守的规则，让它们将应用和业务逻辑隔离了出来。这意味着任何情况下我们都可以简单地 mock 外部工具和传达机制，独立地对应用的代码进行测试，而不需要使用数据库或 HTTP 请求。<br>正如我们所见，整洁架构包含了六边形架构和洋葱架构的规则。截至目前，整洁架构好像没有加入什么新鲜的概念。但是，在整洁架构示意图的右下角，还有一张小图…</p>
<h2 id="站在-MVC-和-EBI-的肩膀上"><a href="#站在-MVC-和-EBI-的肩膀上" class="headerlink" title="站在 MVC 和 EBI 的肩膀上"></a>站在 MVC 和 EBI 的肩膀上</h2><p>整洁架构示意图的右下角的这张小图说明了控制流是如何工作的。这张小图并没还有提供太多信息，但博客中的说明和 Robert C. Martin 的会议演讲拓展了该话题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649608511165-12df652a-976a-45f0-a771-55b48137f02b.png#clientId=u0810918f-6dc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=218&id=ua9bdbccc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=436&originWidth=847&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=275211&status=done&style=none&taskId=ua6c270c1-da18-4ee0-bf06-4a21b28ba89&title=&width=423.5" alt="image.png"><br>我们在上图的左侧看到的是 MVC 中的视图和控制器。双实线另一层的所有形状都是 MVC 中的模型。这些模型也代表着 EBI 架构(我们可以清楚的看到边界、交互器和实体)，六边形架构中的“应用”、洋葱架构中的“应用核心”，以及前面整洁架构示意图中的“实体”层和“用例”层。</p>
<p>假设有一个 HTTP 请求按照控制流到达了控制器。控制器接下来会：</p>
<ol>
<li>拆解请求；</li>
<li>使用相关数据创建一个请求模型；</li>
<li>执行交互器(作为交互器接口的，即边界的，实例被注入到控制器中)中的方法并将请求模型传递给它；</li>
<li>交互器会：<br>4.1. 使用实体网关实现(作为实体网关接口的实例被注入到交互器中)查找相关实体；<br>4.2. 编排实体之间的交互；<br>4.3 用操作的数据结果创建响应模型；<br>4.4 将响应模型交给展示器进行填充；<br>4.5 将展示器返回给控制器；</li>
<li>使用展示器生成视图模型；</li>
<li>将视图模型绑定到视图；</li>
<li>将视图返回给客户端。</li>
</ol>
<p>这里只有“展示器”的用法我有些疑问，我在项目中的实际做法和这里不太一样。我会某种 DTO 类型的数据返回给交互器，而不是注入一个填充了数据的展示器对象。<br>我通常会采用实际上是一种 MVP 实现，控制器在其中负责从客户端接收数据并响应它。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我不认为整洁架构是革命性的，因为它实际上并没有带来突破性的概念或模式。<br>但是，我认为它是相当重要的成果：</p>
<ul>
<li>它发掘了某种程度上被遗忘了的概念、规则和模式；</li>
<li>它澄清了一些实用且重要的概念、规则和模式；</li>
<li>它告诉我们如何把所有的概念、规则和模式整合起来，形成一种构建复杂应用并保持可维护性的标准套路</li>
</ul>
<p>Uncle Bob 关于整洁架构的工作总会让我想起牛顿。引力始终是存在的，每个人都知道松手让苹果远离地面的高处落下，它会落向地面。牛顿做的事情“只不过”是写了一篇论文披露这个事实。这件事请很“简单”，但却让人们开始思考它并基于它创造更新的想法。<br>换句话说，我认为 Robert C. Martin 就是软件开发领域的牛顿！</p>
<h2 id="引用来源"><a href="#引用来源" class="headerlink" title="引用来源"></a>引用来源</h2><blockquote>
<p>2012 – Robert C. Martin – <a href="https://youtu.be/Nltqi7ODZTM">Clean Architecture (NDC 2012)</a><br>2012 – Robert C. Martin – <a href="https://blog.8thlight.com/uncle-bob/2012/08/13/the-clean-architecture.html">The Clean Architecture</a><br>2012 – Benjamin Eberlei – <a href="https://beberlei.de/2012/08/13/oop_business_applications_entity_boundary_interactor.html">OOP Business Applications: Entity, Boundary, Interactor</a><br>2017 – Lieven Doclo – <a href="https://www.insaneprogramming.be/article/2017/02/14/thoughts-on-clean-architecture/">A couple of thoughts on Clean Architecture</a><br>2017 – Grzegorz Ziemoński – <a href="https://dzone.com/articles/clean-architecture-is-screaming">Clean Architecture Is Screaming</a></p>
</blockquote>
]]></content>
      <categories>
        <category>ddd</category>
      </categories>
      <tags>
        <tag>DDD</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor（一）RingBuffer数据结构</title>
    <url>/article/disruptor/disruptor-ringbuffer/</url>
    <content><![CDATA[<blockquote>
<p>Disruptor 是 LMAX 公司开源的一个高效的内存无锁队列。</p>
</blockquote>
<h2 id="并发程序设计几个概念"><a href="#并发程序设计几个概念" class="headerlink" title="并发程序设计几个概念"></a>并发程序设计几个概念</h2><p>1、<strong>锁</strong>： 锁是用来做并发最简单的方式，当然其代价也是最高的。内核态的锁的时候需要操作系统进行一次上下文切换，等待锁的线程会被挂起直至锁释放。在上下文切换的时候，cpu 之前缓存的指令和数据都将失效，对性能有很大的损失。用户态的锁虽然避免了这些问题，但是其实它们只是在没有真实的竞争时才有效。<br>2、<strong>CAS</strong>： CAS 的涵义不多介绍了。使用 CAS 时不像上锁那样需要一次上下文切换，但是也需要处理器锁住它的指令流水线来保证原子性，并且还要加上 Memory Barrier 来保证其结果可见。<br>3、<strong>MemoryBarrier</strong>: 大家都知道现代 CPU 是乱序执行的，也就是程序顺序与实际的执行顺序很可能是不一致的。在单线程执行时这不是个问题，但是在多线程环境下这种乱序就可能会对执行结果产生很大的影响了。memory barrier 提供了一种控制程序执行顺序的手段, 关于其更多介绍，可以参考<a href="http://en.wikipedia.org/wiki/Memory_barrier">Memory_barrier</a><br>4、<strong>CacheLine</strong>： cacheLine 解释起来其实很简单，就是 CPU 在做缓存的时候有个最小缓存单元，在同一个单元内的数据被同时被加载到缓存中，充分利用 cacheLine 可以大大降低数据读写的延迟，错误利用 cache line 也会导致缓存不同替换，反复失效。</p>
<h2 id="并发内存队列考虑的问题"><a href="#并发内存队列考虑的问题" class="headerlink" title="并发内存队列考虑的问题"></a>并发内存队列考虑的问题</h2><p>1、<strong>数据结构问题</strong><br>是选用定长的数组还是可变的链表<br>2、<strong>并发控问题</strong><br>使用锁还是 CAS 操作，是使用粗粒度的一把锁，还是将队列的头、尾、和容量三个变量分开控制，即使分开，能不能避免它们落入同一个 Cache line 中。数据的入队和出队都是很耗时的，尤其在性能要求极高的场景中，这种消耗更显得奢侈。</p>
<h2 id="Disruptor-数据结构-RingBuffer"><a href="#Disruptor-数据结构-RingBuffer" class="headerlink" title="Disruptor 数据结构 RingBuffer"></a>Disruptor 数据结构 RingBuffer</h2><p>RingBuffer 是一个环（首尾相接的环），你可以把它用做在不同上下文（线程）间传递数据的 buffer。基本来说，RingBuffer 拥有一个序号，这个序号指向数组中下一个可用的元素。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648396576091-696e7ca7-d164-49cf-8128-695a46f29a30.png#clientId=u22fa69ef-54c0-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4592195d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=216&originWidth=305&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=9853&status=done&style=none&taskId=u0f595954-bb3d-45ef-8131-1c1ad0e5f26&title=" alt="image.png"><br>随着你不停地填充这个 buffer（可能也会有相应的读取），这个序号会一直增长，直到绕过这个环。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648396576094-091558b4-f73e-484b-b6ac-c8d51304e65f.png#clientId=u22fa69ef-54c0-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uda175c5a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=206&originWidth=306&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=9866&status=done&style=none&taskId=ub85662a4-fa5b-4120-9fb4-3c345f06af1&title=" alt="image.png"><br>要找到数组中当前序号指向的元素，可以通过 mod 操作<br>sequence mod array.length &#x3D; array.index<br>以上面的 RingBuffer 为例（java 的 mod 语法）：11 % 8 &#x3D; 3，RingBuffer 槽的个数是 2 的 N 次方，更有利于基于二进制的计算机进行计算，，这样计算余数只需要通过位操作 index &amp; ( size - 1 )就能够得到实际的 index。和维基百科里面的关于[<a href="https://en.wikipedia.org/wiki/Circular_buffer">环形 buffer</a>]的实现方式，与其最大的区别在于：没有尾指针。我们只维护了一个指向下一个可用位置的序号。</p>
<p>RingBuffer 本身并不控制是否需要重叠，对于如何避免 RingBuffer 产生重叠，以及如何对 RingBuffer 进行读写操作，移到了数据结构（RingBuffer）的外（队列通常注重维护队列的头尾元素，添加和删除元素等)，由于生产者和消费者是分开考虑和控制的，因此有可能能够通过一个核心的环形队列来表示全部的依赖关系，可以大大提高吞吐，降低延迟。</p>
<h2 id="RingBuffer-的优点"><a href="#RingBuffer-的优点" class="headerlink" title="RingBuffer 的优点"></a>RingBuffer 的优点</h2><p>1、<strong>在可靠消息传递方面有很好的性能</strong><br>不删除 buffer 中的数据（这些数据一直存放在 buffer 中，直到新的数据覆盖他们），这样当另外一个服务通过 nak (拒绝应答信号) 告诉我们没有成功收到消息时，我们能够重新发送给他们。<br>2、<strong>底层使用数组，访问比链表快</strong><br>数组内元素的内存地址的连续性存储的，而且有一个容易预测的访问模式，这是对 CPU 缓存友好的—也就是说，在硬件级别，数组中的元素是会被预加载的，因此在 RingBuffer 当中，cpu 无需时不时去主存加载数组中的下一个元素。（因为只要一个元素被加载到缓存行，其他相邻的几个元素也会被加载进同一个缓存行）。<br>3、<strong>避免 GC 问题</strong><br>可以为数组预先分配内存，使得数组对象一直存在（除非程序终止），这就意味着不需要花大量的时间用于垃圾回收。不像链表那样，需要为每一个添加到其上面的对象创造节点对象—对应的，当删除节点时，需要执行相应的内存清理操作。</p>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor（三）RingBuffer单生产者写入</title>
    <url>/article/disruptor/disruptor-ringbuffer-single-write/</url>
    <content><![CDATA[<p>上一章主要介绍了消费者从 RingBuffer 读取数据，本章主要介绍单个生产者如何向 RingBuffer 数据写入数据。在 RingBuffer 数据写入过程中如何不要让 Ring 重叠，写入后通知消费者，生产者一端的批处理，以及多个生产者如何协同工作。<br>在 RingBuffer 写入数据的过程涉及到两阶段提交(two-phasecommit)<br>1）生产者需要申请 buffer 里的下一个节点。<br>2）当生产者向节点写完数据，需要调用调用 publish 发布数据。</p>
<h2 id="1、单个生产者-SingleProducerSequencer-数据写入"><a href="#1、单个生产者-SingleProducerSequencer-数据写入" class="headerlink" title="1、单个生产者 SingleProducerSequencer 数据写入"></a>1、单个生产者 SingleProducerSequencer 数据写入</h2><p>在后台由 ProducerSequencer 负责所有的交互细节，来从 RingBuffer 中找到下一个节点，然后才允许生产者向它写入数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397299914-3ed84df9-6972-4100-91ef-73f24102ce5a.png#clientId=ufc0fe107-3dbe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6219745a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=644&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=31518&status=done&style=none&taskId=ud945e053-3c92-4edc-91fb-966dcbaff45&title=" alt="image.png"><br>在图中一个生产者写入 RingBuffer，SingleProducerSequencer 对象拥有所有正在访问 RingBuffer 的消费者 gatingSequences 列表（区别于队列需要追踪队列的头和尾，而且它们有时候会指向相同的位置），Disruptor 中由消费者负责通知它们处理到了哪个序列号，而不是 RingBuffer。<br>如果想确定我们没有让 RingBuffer 重叠，需要检查所有的消费者们都读到了哪里。在上图中有 2 个消费者，一个消费者顺利的读到了最大序号 13（用蓝色高亮），第二个消费者有点儿落后停在序号 6。因此消费者 2 在赶上消费者 1 之前要跑完整个 RingBuffer 一圈的距离。<br>现在生产者想要写入 RingBuffer 中序号 6 占据的节点，因为它是 RingBuffer 当前游标的下一个节点。但是 SingleProducerSequencer 明白现在不能写入，因为有一个消费者正在占用它。所以 SingleProducerSequencer 停下来自旋(spins)，等待，直到那个消费者离开。</p>
<h2 id="2、申请下一个节点"><a href="#2、申请下一个节点" class="headerlink" title="2、申请下一个节点"></a>2、申请下一个节点</h2><p>现在可以想像消费者 2 已经处理完了一批节点，并且向前移动了它的序号。可能它挪到了序号 9（因为消费端的批处理方式，现实中我会预计它到达 13）<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397299926-647bb596-72a8-4fd0-893c-ae97bbf0750e.png#clientId=ufc0fe107-3dbe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf1f8ca5f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=285&originWidth=646&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=31871&status=done&style=none&taskId=u40900888-32ec-44ca-a8ef-9cf680b0bf0&title=" alt="image.png"><br>上图显示了当消费者 2 挪动到序号 9 时发生的情况。SingleProducerSequencer 会看到下一个节点序号 6 那个已经可以用了。它会抢占这个节点上的 Entry（我还没有特别介绍 Entry 对象，基本上它是一个放写入到某个序号的 RingBuffer 数据的桶），把下一个序号（14）更新成 Entry 的序号，然后把 Entry 返回给生产者。生产者可以接着往 Entry 里写入数据。</p>
<h2 id="3、提交新的数据"><a href="#3、提交新的数据" class="headerlink" title="3、提交新的数据"></a>3、提交新的数据</h2><p>将生产的数据提交，通知消费之。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397299941-c11a08c3-60fa-4ada-b893-38ab8221f12a.png#clientId=ufc0fe107-3dbe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1b79e4c6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=964&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=52541&status=done&style=none&taskId=u05f1893c-4fae-4722-ba8c-917ef06c989&title=" alt="image.png"><br>绿色表示最近写入的 Entry，序号是 14，通过 publish 方法提交，设置 RingBuffer 的 cursor 为 14，通知消费者 14 被更新了，可以读取了（不同的 WaitStrategy 实现以不同的方式来实现提醒，取决于它是否采用阻塞模式）。现在消费者 2 可以读 Entry14 的数据进行消费了。<br>看完上面的原理后下面分析 SingleProducerSequencer 是如何获取序号和提交数据的。<strong>**</strong></p>
<h2 id="4、SingleProducerSequencer-生产者类图"><a href="#4、SingleProducerSequencer-生产者类图" class="headerlink" title="4、SingleProducerSequencer 生产者类图"></a>4、SingleProducerSequencer 生产者类图</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397300602-265d27ae-f95c-43ef-b703-f79eda237721.png#clientId=ufc0fe107-3dbe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub001cddc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1113&originWidth=1198&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=138853&status=done&style=none&taskId=ucd5ccad9-2b8a-4af1-8a15-f051d5c6473&title=" alt="image.png"><br>SingleProducerSequencer 继承 AbstractSequencer，实现了 Sequencer 接口。<br>Sequencer 提供增加删除消费者序列，创建 SequenceBarrier，获取最小序号，和最大发布的序号。<br>Cursored 获取当前的游标。<br>Sequenced 获取当前 ringbuffer 大小，获取想一个序号，以及提交数据接口。</p>
<h2 id="5、消费者和生产者直接的关联"><a href="#5、消费者和生产者直接的关联" class="headerlink" title="5、消费者和生产者直接的关联"></a>5、消费者和生产者直接的关联</h2><p>首先看下 AbstractSequencer 中定义</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 生产者的当前的游标位置
protected final Sequence cursor &#x3D; new Sequence(Sequencer.INITIAL_CURSOR_VALUE);
&#x2F;&#x2F; 消费者当前处理的序号集合
protected volatile Sequence[] gatingSequences &#x3D; new Sequence[0];</code></pre>

<p><strong>由于 volatile 只能保存可见性和禁止编译器优化，当时不能保证互斥性，多线程并发读写的话会有问题。</strong></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">private static final AtomicReferenceFieldUpdater&lt;AbstractSequencer, Sequence[]&gt; SEQUENCE_UPDATER &#x3D; AtomicReferenceFieldUpdater.newUpdater(AbstractSequencer.class, Sequence[].class, &quot;gatingSequences&quot;);</code></pre>

<p><strong>使用 AtomicReferenceFieldUpdater 原子字段更新解决多线程更新 gatingSequences 问题</strong><br>具体实现参照 SequenceGroups 中使用 CAS 进行更新。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public final void addGatingSequences(Sequence... gatingSequences) &#123;
    SequenceGroups.addSequences(this, SEQUENCE_UPDATER, this, gatingSequences);
&#125;
public boolean removeGatingSequence(Sequence sequence) &#123;
    return SequenceGroups.removeSequence(this, SEQUENCE_UPDATER, sequence);
&#125;</code></pre>

<h2 id="6、生产者使用-next-获取下一个可用的序号"><a href="#6、生产者使用-next-获取下一个可用的序号" class="headerlink" title="6、生产者使用 next 获取下一个可用的序号"></a>6、生产者使用 next 获取下一个可用的序号</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">public long next(int n) &#123;
    if (n &lt;1) &#123;
        throw new IllegalArgumentException(&quot;n must be &gt; 0&quot;);
    &#125;
    &#x2F;&#x2F; 当前的最小序号（单个生产者为生产者的游标）
    long nextValue &#x3D; this.nextValue;
    &#x2F;&#x2F; 下一个序号
    long nextSequence &#x3D; nextValue + n;
    &#x2F;&#x2F; 重叠点位置
    long wrapPoint &#x3D; nextSequence - bufferSize;
    &#x2F;&#x2F; 缓存的消费者处理的序号
    long cachedGatingSequence &#x3D; this.cachedValue;
    &#x2F;&#x2F; wrapPoint &gt; cachedGatingSequence,
    &#x2F;&#x2F; 重叠位置大于缓存的消费者处理的序号，说明有消费者没有处理完成，不能够防止数据
    &#x2F;&#x2F; cachedGatingSequence &gt; nextValue
    &#x2F;&#x2F; 只会在https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;issues&#x2F;76情况下存在
    if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; nextValue) &#123;
        long minSequence;
        &#x2F;&#x2F; 等待不重叠后退出循环
        while (wrapPoint &gt; (minSequence &#x3D; Util.getMinimumSequence(gatingSequences, nextValue))) &#123;
            &#x2F;&#x2F; 通知消费者处理事件
            waitStrategy.signalAllWhenBlocking();
            &#x2F;&#x2F; 生产者等待的时候后自旋，后续需要使用策略
            LockSupport.parkNanos(1L);
        &#125;
        &#x2F;&#x2F; 缓存消费者和生产者的最小序号
        this.cachedValue &#x3D; minSequence;
    &#125;
    &#x2F;&#x2F; 设置生产者下一个可用的的序号
    this.nextValue &#x3D; nextSequence;
    return nextSequence;
&#125;</code></pre>

<h2 id="7、生产者使用-publish-发布数据"><a href="#7、生产者使用-publish-发布数据" class="headerlink" title="7、生产者使用 publish 发布数据"></a>7、生产者使用 publish 发布数据</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void publish(long sequence) &#123; &#x2F;&#x2F; 设置生产者的游标序号
    cursor.set(sequence);
    &#x2F;&#x2F; 通知消费者处理事件
    waitStrategy.signalAllWhenBlocking();
&#125;</code></pre>

<p>当发布数据后，消费者 sequenceBarrier.waitFor(nextSequence)就能够获取 RingBuffer 最大可访问的 availableSequence 序号，处理数据了。</p>
<h2 id="8、消费者消费数据"><a href="#8、消费者消费数据" class="headerlink" title="8、消费者消费数据"></a>8、消费者消费数据</h2><p>再回忆下 ProcessingSequenceBarrier 的 waitFor 函数，其中调用到了 sequencer.getHighestPublishedSequence(sequence, availableSequence);</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public long waitFor(final long sequence)
        throws AlertException, InterruptedException, TimeoutException &#123;
    &#x2F;&#x2F; 检查clert异常
    checkAlert();
    &#x2F;&#x2F; 通过waitStrategy策略获取可用的序号,cursorSequence为当前的Sequence，dependentSequence为依赖的Sequence[]
    long availableSequence &#x3D; waitStrategy.waitFor(sequence, cursorSequence, dependentSequence, this);
    &#x2F;&#x2F; 产生比预期的sequence小,可能序号被重置回老的的oldSequence值
    &#x2F;&#x2F;可参考https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;issues&#x2F;76
    if (availableSequence &lt;sequence) &#123;
        return availableSequence;
    &#125;
    &#x2F;&#x2F; 获取最大的可用的已经发布的sequence，可能比sequence小
    &#x2F;&#x2F; 会在多生产者中出现，当生产者1获取到序号13，生产者2获取到14；生产者1没发布，生产者2发布，会导致获取的可用序号为12，而sequence为13
    return sequencer.getHighestPublishedSequence(sequence, availableSequence);
&#125;
public long getHighestPublishedSequence(long lowerBound, long availableSequence) &#123;
    return availableSequence;
&#125;</code></pre>

<p>在 SingleProducerSequencer 的 getHighestPublishedSequence 方法中直接返回可用的 availableSequence，通知消费者消费数据。通过以上步骤，生产者和消费者就协同起来了。</p>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor（二）RingBuffer读取</title>
    <url>/article/disruptor/disruptor-ringbuffer-read/</url>
    <content><![CDATA[<p>上一章主要介绍 Ring Buffer 的数据结构，本章主要讲解如何使用 Disruptor 从 Ring Buffer 中读取数据。</p>
<h2 id="1、消费者通过-ProcessingSequenceBarrier-读取数据"><a href="#1、消费者通过-ProcessingSequenceBarrier-读取数据" class="headerlink" title="1、消费者通过 ProcessingSequenceBarrier 读取数据"></a>1、消费者通过 ProcessingSequenceBarrier 读取数据</h2><p>能够读取数据的前提是数据已经写入到 Ring Buffer 中，关于数据的写入，后面一章节会详细讲解。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397116031-82c58b44-3caf-47c7-bb3b-1923c80bd4c0.png#clientId=ucd2ac4d2-f85d-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u326a8084&margin=%5Bobject%20Object%5D&name=image.png&originHeight=280&originWidth=704&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29588&status=done&style=none&taskId=u8a8a8a8c-b409-491e-8b5a-757f23d4e78&title=" alt="image.png"><br>RingBuffer 的元素的大小是 2 的 n 次方（上面 ringBufferSize 为 8，从序号 0 开始）。消费者(Consumer)是一个想从 RingBuffer 里读取数据的线程，它可以通过访问 ProcessingSequenceBarrier 对象和 RingBuffer 进行交互。消费者也需要知道它将要处理的序号，每个消费者都需要找到下一个它要访问的序号。在上面的例子中，消费者处理完了 RingBuffer 里序号 8 之前（包括 8）的所有数据，那么它期待访问的下一个序号是 9。</p>
<h2 id="2、消费者-BatchEventProcessor"><a href="#2、消费者-BatchEventProcessor" class="headerlink" title="2、消费者 BatchEventProcessor"></a>2、消费者 BatchEventProcessor</h2><p>关于消费者如何通过调用 SequenceBarrier 对象的 waitFor()方法，传递它所需要的下一个序号。本章节以 BatchEventProcessor 批量事件处理器为例进行讲解，首先查看类图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397116033-7c7deb37-2b47-48ba-9449-270ec1b3134a.png#clientId=ucd2ac4d2-f85d-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uec892130&margin=%5Bobject%20Object%5D&name=image.png&originHeight=668&originWidth=508&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=44819&status=done&style=none&taskId=u47f1190a-0a68-4a7c-94f2-7c4dae2a966&title=" alt="image.png"><br>主要继承 EventProcessor 接口和 Runnable 接口，本章主要介绍 run 方法，对于 BatchEventProcessor 的初始化暂时不做讲解。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void run() &#123;
    &#x2F;&#x2F; 线程是否运行
    if (!running.compareAndSet(false, true)) &#123;
        throw new IllegalStateException(&quot;Thread is already running&quot;);
    &#125;
    &#x2F;&#x2F; 将ProcessingSequenceBarrier的alerted设置成false
    sequenceBarrier.clearAlert();
    &#x2F;&#x2F; start事件处理
    notifyStart();

    T event &#x3D; null;
    &#x2F;&#x2F; 获取当前事件处理器的下一个sequence
    long nextSequence &#x3D; sequence.get() + 1L;
    try &#123;
        while (true) &#123;
            try &#123;
                &#x2F;&#x2F; 从ProcessingSequenceBarrier获取可用的availableSequence
                final long availableSequence &#x3D; sequenceBarrier.waitFor(nextSequence);
                &#x2F;&#x2F; 下一个nextSequence比可用的availableSequence小的时候，获取事件，并触发事件处理
                while (nextSequence &lt;&#x3D; availableSequence) &#123;
                    event &#x3D; dataProvider.get(nextSequence);
                    &#x2F;&#x2F; 消费者事件处理
                    eventHandler.onEvent(event, nextSequence, nextSequence &#x3D;&#x3D; availableSequence);
                    nextSequence++;
                &#125;
                &#x2F;&#x2F; 设置当前事件处理器已经处理的sequence
                sequence.set(availableSequence);
            &#125; catch (final TimeoutException e) &#123;
                &#x2F;&#x2F; 超时处理
                notifyTimeout(sequence.get());
            &#125; catch (final AlertException ex) &#123;
                if (!running.get()) &#123;
                    break;
                &#125;
            &#125; catch (final Throwable ex) &#123;
                &#x2F;&#x2F; 异常事件处理
                exceptionHandler.handleEventException(ex, nextSequence, event);
                sequence.set(nextSequence);
                nextSequence++;
            &#125;
        &#125;
    &#125; finally &#123;
        &#x2F;&#x2F; 关闭事件处理
        notifyShutdown();
        running.set(false);
    &#125;
&#125;</code></pre>

<p>拿到了数据后，消费者(Consumer)会更新自己的标识(cursor)，消费者(Consumer)现在只需要通过简单通过 ProcessingSequenceBarrier 拿到可用的 Ringbuffer 中的 Sequence 序号就可以可以读取数据了。因为这些新的节点的确已经写入了数据（RingBuffer 本身的序号已经更新），而且消费者对这些节点的唯一操作是读而不是写，因此访问不用加锁。不仅代码实现起来可以更加安全和简单，而且不用加锁使得速度更快。另一个好处是可以用多个消费者(Consumer)去读同一个 RingBuffer，不需要加锁，也不需要用另外的队列来协调不同的线程(消费者)。这样你可以在 Disruptor 的协调下实现真正的并发数据处理。</p>
<h2 id="3、ProcessingSequenceBarrier-获取可用序号"><a href="#3、ProcessingSequenceBarrier-获取可用序号" class="headerlink" title="3、ProcessingSequenceBarrier 获取可用序号"></a>3、ProcessingSequenceBarrier 获取可用序号</h2><p>在上面的 BatchEventProcessor 中的 run 方法中有如下调用</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">final long availableSequence &#x3D; sequenceBarrier.waitFor(nextSequence);</code></pre>

<p>获取 RingBuffer 最大可访问的 availableSequence 序号，在上面的例子中是 10。<br>首先看下 ProcessingSequenceBarrier 的类图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397115980-a1126197-6f1f-48eb-85c7-86399a9d6161.png#clientId=ucd2ac4d2-f85d-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u652bf873&margin=%5Bobject%20Object%5D&name=image.png&originHeight=542&originWidth=441&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=36301&status=done&style=none&taskId=u7d531f19-1748-4b73-b0e2-fcee70debc0&title=" alt="image.png"><br>其实现了 SequenceBarrier 接口，用于和 RingBuffer 之间进行交互，下面主要看下构造函数和 waitFor 函数。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public long waitFor(final long sequence)
        throws AlertException, InterruptedException, TimeoutException &#123;
    &#x2F;&#x2F; 检查clert异常
    checkAlert();
    &#x2F;&#x2F; 通过waitStrategy策略获取可用的序号,cursorSequence为当前的Sequence，dependentSequence为依赖的Sequence[]
    long availableSequence &#x3D; waitStrategy.waitFor(sequence, cursorSequence, dependentSequence, this);
    &#x2F;&#x2F; 产生比预期的sequence小,可能序号被重置回老的的oldSequence值
    &#x2F;&#x2F;可参考https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;issues&#x2F;76
    if (availableSequence &lt;sequence) &#123;
        return availableSequence;
    &#125;
    &#x2F;&#x2F; 获取最大的可用的已经发布的sequence，可能比sequence小
    &#x2F;&#x2F; 会在多生产者中出现，当生产者1获取到序号13，生产者2获取到14；生产者1没发布，生产者2发布，会导致获取的可用序号为12，而sequence为13
    return sequencer.getHighestPublishedSequence(sequence, availableSequence);
&#125;</code></pre>

<h2 id="4、WaitStrategy-策略"><a href="#4、WaitStrategy-策略" class="headerlink" title="4、WaitStrategy 策略"></a>4、WaitStrategy 策略</h2><p>waitFor 函数的主要功能为获取到可用的 sequence 并返回给事件处理器。SequenceBarrier 内部有一个 WaitStrategy 方法来决定它如何等待这个序号，我现在不会去描述它的细节，代码的注释里已经概括了每一种 WaitStrategy 的优点和缺点，目前的实现方式主要有以下几种，后续会做详细介绍。</p>
<ul>
<li>BlockingWaitStrategy</li>
<li>BusySpinWaitStrategy</li>
<li>LiteBlockingWaitStrategy</li>
<li>PhasedBackoffWaitStrategy</li>
<li>SleepingWaitStrategy</li>
<li>TimeoutBlockingWaitStrategy</li>
<li>YieldingWaitStrategy</li>
</ul>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor（四）RingBuffer多生产者写入</title>
    <url>/article/disruptor/disruptor-ringbuffer-muti-write/</url>
    <content><![CDATA[<p>上一章主要介绍了单个生产者如何向 RingBuffer 数据写入数据，如何不要让 Ring 重叠，写入后通知消费者，生产者一端的批处理，以及多个生产者如何协同工作，本章主要介绍多生产者向 RingBuffer 数据写入数据。</p>
<h2 id="1、多生产者-MultiProducerSequencer-申请下一个节点"><a href="#1、多生产者-MultiProducerSequencer-申请下一个节点" class="headerlink" title="1、多生产者 MultiProducerSequencer 申请下一个节点"></a>1、多生产者 MultiProducerSequencer 申请下一个节点</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397514503-95042b3d-3223-4a11-8b63-129201a857c1.png#clientId=u1a4fa253-2c3e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2a2de43c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=325&originWidth=678&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=43988&status=done&style=none&taskId=u8c23180a-f31c-4ca9-b827-e0afd2f50af&title=" alt="image.png"><br>和单生产者不同的是在 next 方法中会直接通过 cursor.compareAndSet(current, next)设置生产者的游标 cursor 的 sequence。大家很可能会问设置了生产者的游标后，没有提交数据之前，多生产者场景中消费者是否就能够获取到数据，答案是否定的，在 MultiProducerSequencer 实现的 getHighestPublishedSequence 的方法和单生产者有所区别，后面会详细讲解。</p>
<h2 id="2、多生产者-MultiProducerSequencer-提交数据"><a href="#2、多生产者-MultiProducerSequencer-提交数据" class="headerlink" title="2、多生产者 MultiProducerSequencer 提交数据"></a>2、多生产者 MultiProducerSequencer 提交数据</h2><p>和单生产者的区别是使用 setAvailable 将数据设置成可用状态。<br>在多个生产者的场景下，还需要其他东西来追踪序号。这个序号是指当前可写入的序号。注意这和“向 RingBuffer 的游标加 1”不一样，如果你有一个以上的生产者同时在向 RingBuffer 写入，就有可能出现某些 Entry 正在被生产者写入但还没有提交的情况。<br>生产者 1 拿到序号 14，生产者 2 拿到序号 15。现在假设生产者 1 因为某些原因没有来得及提交数据。<br>生产者 2 通过 setAvailable(15)请求完成提交数据，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397514762-36299bf0-a7b3-4385-bb2e-ec274a82912d.png#clientId=u1a4fa253-2c3e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u38506f47&margin=%5Bobject%20Object%5D&name=image.png&originHeight=374&originWidth=983&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=54199&status=done&style=none&taskId=u670184da-248e-4801-b74b-b0b3a888803&title=" alt="image.png"><br>当这个时候消费者通过 waitFor(14)，返回的结果会为 13，不错任何事件处理。<br>当生产者 1 通过 setAvailable(14)请求完成提交数据，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397514831-75b3af6a-f08b-4905-9c3d-dbecbffec22e.png#clientId=u1a4fa253-2c3e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u02f3d4b1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=371&originWidth=979&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=54879&status=done&style=none&taskId=u5c56fe60-3531-433e-aa86-2e6cb4e5a00&title=" alt="image.png"><br>以 BatchEventProcessor 的 run 实现会处理 14 和 15 位置上的数据，在下一次通过 waitFor(16)获取可用的数据。</p>
<h3 id="3、MutiProducerSequencer-生产者类图。"><a href="#3、MutiProducerSequencer-生产者类图。" class="headerlink" title="3、MutiProducerSequencer 生产者类图。"></a>3、MutiProducerSequencer 生产者类图。</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648397514845-7342f6ef-c79a-4654-ba17-f600028afef9.png#clientId=u1a4fa253-2c3e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua7e57fc7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1113&originWidth=1198&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=138853&status=done&style=none&taskId=ua3ae1fa6-21bd-44fa-9fc2-82e8254c611&title=" alt="image.png"><br>MutiProducerSequencer 继承 AbstractSequencer，实现了 Sequencer 接口。<br>Sequencer 提供增加删除消费者序列，创建 SequenceBarrier，获取最小序号，和最大发布的序号。<br>Cursored 获取当前的游标。<br>Sequenced 获取当前 ringbuffer 大小，获取想一个序号，以及提交数据接口。<br>消费者和生产者之间的关联和单生产者一样，不做重复介绍。</p>
<h4 id="4、多生产者通过-next-获取下一个可用的序号"><a href="#4、多生产者通过-next-获取下一个可用的序号" class="headerlink" title="4、多生产者通过 next 获取下一个可用的序号"></a>4、多生产者通过 next 获取下一个可用的序号</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">public long next(int n) &#123;
    if (n &lt;1) &#123;
        throw new IllegalArgumentException(&quot;n must be &gt; 0&quot;);
    &#125;
    long current;
    long next;
    do &#123;
        &#x2F;&#x2F; ringbuffer当前生产者cursor
        current &#x3D; cursor.get();
        &#x2F;&#x2F; 下一个可用的序号
        next &#x3D; current + n;
        &#x2F;&#x2F; 重叠点位置
        long wrapPoint &#x3D; next - bufferSize;
        &#x2F;&#x2F; 缓存的消费者处理的序号
        long cachedGatingSequence &#x3D; gatingSequenceCache.get();
        &#x2F;&#x2F; wrapPoint &gt; cachedGatingSequence,
        &#x2F;&#x2F; 重叠位置大于缓存的消费者处理的序号，说明有消费者没有处理完成，不能够防止数据
        &#x2F;&#x2F; cachedGatingSequence &gt; nextValue
        &#x2F;&#x2F; 只会在https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;issues&#x2F;76情况下存在
        if (wrapPoint &gt; cachedGatingSequence || cachedGatingSequence &gt; current) &#123;
            &#x2F;&#x2F; 获取消费者和生产者最小的序号
            long gatingSequence &#x3D; Util.getMinimumSequence(gatingSequences, current);
            &#x2F;&#x2F; 仍然重叠
            if (wrapPoint &gt; gatingSequence) &#123;
                &#x2F;&#x2F; 通知消费者处理事件
                waitStrategy.signalAllWhenBlocking();
                &#x2F;&#x2F; 生产者等待的时候后自旋，后续需要使用策略
                LockSupport.parkNanos(1);
                continue;
            &#125;
            &#x2F;&#x2F; 没有重叠的话，设置消费者缓存
            gatingSequenceCache.set(gatingSequence);
        &#125;
        &#x2F;&#x2F; 没有重叠，直接将RingBuffer的序号设置成next
        else if (cursor.compareAndSet(current, next)) &#123;
            break;
        &#125;
    &#125;
    while (true);
    &#x2F;&#x2F; 返回可用的序号
    return next;
&#125;</code></pre>

<h2 id="5、多生产者通过-publish-提交数据"><a href="#5、多生产者通过-publish-提交数据" class="headerlink" title="5、多生产者通过 publish 提交数据"></a>5、多生产者通过 publish 提交数据</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void publish(final long sequence) &#123;
    &#x2F;&#x2F; 将sequence设置为可用状态
    setAvailable(sequence);
    &#x2F;&#x2F; 通知消费者处理事件
    waitStrategy.signalAllWhenBlocking();
&#125;</code></pre>

<p>多生产者在获取序号 next 方法中就已经设置了 cusor，提交数据的时候是将该 sequence 设置成可用状态，才能够被消费者使用。</p>
<h2 id="6、消费者消费数据"><a href="#6、消费者消费数据" class="headerlink" title="6、消费者消费数据"></a>6、消费者消费数据</h2><p>再回忆下 ProcessingSequenceBarrier 的 waitFor 函数，其中调用到了 sequencer.getHighestPublishedSequence(sequence,availableSequence);</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public long waitFor(final long sequence)
        throws AlertException, InterruptedException, TimeoutException &#123;
    &#x2F;&#x2F; 检查clert异常
    checkAlert();
    &#x2F;&#x2F; 通过waitStrategy策略获取可用的序号,cursorSequence为当前的Sequence，dependentSequence为依赖的Sequence[]
    long availableSequence &#x3D; waitStrategy.waitFor(sequence, cursorSequence, dependentSequence, this);
    &#x2F;&#x2F; 产生比预期的sequence小,可能序号被重置回老的的oldSequence值
    &#x2F;&#x2F;可参考https:&#x2F;&#x2F;github.com&#x2F;LMAX-Exchange&#x2F;disruptor&#x2F;issues&#x2F;76
    if (availableSequence &lt;sequence) &#123;
        return availableSequence;
    &#125;
    &#x2F;&#x2F; 获取最大的可用的已经发布的sequence，可能比sequence小
    &#x2F;&#x2F; 会在多生产者中出现，当生产者1获取到序号13，生产者2获取到14；生产者1没发布，生产者2发布，会导致获取的可用序号为12，而sequence为13
    return sequencer.getHighestPublishedSequence(sequence, availableSequence);
&#125;</code></pre>

<p>获取最大的可用的已经发布的 sequence</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public long getHighestPublishedSequence(long lowerBound, long availableSequence) &#123;
    for (long sequence &#x3D; lowerBound; sequence &lt;&#x3D; availableSequence; sequence++) &#123;
        &#x2F;&#x2F; 判断是否可用
        if (!isAvailable(sequence)) &#123;
            return sequence - 1;
        &#125;
    &#125;
    return availableSequence;
&#125;</code></pre>

<p>其中判断 isAvailable 通过 availableBuffer 进行判断</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public boolean isAvailable(long sequence) &#123;
    &#x2F;&#x2F; 计算((int) sequence) &amp; indexMask的索引index
    int index &#x3D; calculateIndex(sequence);
    &#x2F;&#x2F; 计算(int) (sequence &gt;&gt;&gt; indexShift) ringbuffer的slot的设置次数
    int flag &#x3D; calculateAvailabilityFlag(sequence);
    &#x2F;&#x2F; index在数组中的偏移量
    long bufferAddress &#x3D; (index * SCALE) + BASE;
    &#x2F;&#x2F; 如果和flag相等，说明可用
    return UNSAFE.getIntVolatile(availableBuffer, bufferAddress) &#x3D;&#x3D; flag;
&#125;</code></pre>

<p>内部使用的变量如下。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; availableBuffer跟踪每个ringbuffer的slot槽的状态，是否可用
private final int[] availableBuffer &#x3D; new int[bufferSize]; &#x2F;&#x2F; 初始值为-1
private final int indexMask &#x3D; bufferSize - 1;
private final int indexShift &#x3D; Util.log2(bufferSize);</code></pre>

<p>通过以上方式就能够判断当前的 sequence 是否可用了。<br>通过在 MutiProducerSequencer 的 getHighestPublishedSequence 方法中直接返回可用的 availableSequence，通知消费者消费数据，生产者和消费者就协同起来了。</p>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker（二）使用Swarm Mode创建集群</title>
    <url>/article/docker/docker-warm-mode/</url>
    <content><![CDATA[<blockquote>
<p>能使用 Docker Machine 的前提是宿主机需要是物理机，云主机目前不支持 Docker Machine 的创建。</p>
</blockquote>
<h2 id="Virtualbox-安装"><a href="#Virtualbox-安装" class="headerlink" title="Virtualbox 安装"></a>Virtualbox 安装</h2><p>步骤<a href="https://www.virtualbox.org/wiki/Linux_Downloads">可参考</a></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">cd &#x2F;etc&#x2F;yum.repos.d
wget http:&#x2F;&#x2F;download.virtualbox.org&#x2F;virtualbox&#x2F;rpm&#x2F;rhel&#x2F;virtualbox.repo
yum install VirtualBox-5.2</code></pre>

<h2 id="Docker-Machine-安装"><a href="#Docker-Machine-安装" class="headerlink" title="Docker Machine 安装"></a>Docker Machine 安装</h2><h3 id="命令行安装-docker-machine"><a href="#命令行安装-docker-machine" class="headerlink" title="命令行安装 docker-machine"></a>命令行安装 docker-machine</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">base&#x3D;https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;machine&#x2F;releases&#x2F;download&#x2F;v0.15.0 &amp;&amp;
  curl -L $base&#x2F;docker-machine-$(uname -s)-$(uname -m) &gt;&#x2F;tmp&#x2F;docker-machine &amp;&amp;
  sudo ixunstall &#x2F;tmp&#x2F;docker-machine &#x2F;usr&#x2F;local&#x2F;bin&#x2F;docker-machine</code></pre>

<h3 id="创建-docker-machine"><a href="#创建-docker-machine" class="headerlink" title="创建 docker-machine"></a>创建 docker-machine</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-machine create --engine-registry-mirror&#x3D;https:&#x2F;&#x2F;xxx.mirror.aliyuncs.com -d virtualbox manager
docker-machine create --engine-registry-mirror&#x3D;https:&#x2F;&#x2F;xxx.mirror.aliyuncs.com -d virtualbox worker1
docker-machine create --engine-registry-mirror&#x3D;https:&#x2F;&#x2F;xxx.mirror.aliyuncs.com -d virtualbox worker2</code></pre>

<p>创建 3 台机器，manager 为 leader</p>
<h3 id="初始化-swarm-集群-manager"><a href="#初始化-swarm-集群-manager" class="headerlink" title="初始化 swarm 集群 manager"></a>初始化 swarm 集群 manager</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-machine ssh manager
docker swarm init
Swarm initialized: current node (bvz81updecsj6wjz393c09vti) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-0bfpg588koug4bricwcs7y4edh70984pnpfx3tj1tmpb83atmn-442mbo6pueqsjcedq8aey04v0 192.168.99.100:2377

To add a manager to this swarm, run &#39;docker swarm join-token manager&#39; and follow the instructions.</code></pre>

<h3 id="机器加入到-swarm-集群"><a href="#机器加入到-swarm-集群" class="headerlink" title="机器加入到 swarm 集群"></a>机器加入到 swarm 集群</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-machine ssh work1
docker swarm join --token SWMTKN-1-0bfpg588koug4bricwcs7y4edh70984pnpfx3tj1tmpb83atmn-442mbo6pueqsjcedq8aey04v0 192.168.99.100:2377</code></pre>

<h2 id="Swarm-Mode-集群部署"><a href="#Swarm-Mode-集群部署" class="headerlink" title="Swarm Mode 集群部署"></a>Swarm Mode 集群部署</h2><h3 id="创建-service-服务"><a href="#创建-service-服务" class="headerlink" title="创建 service 服务"></a>创建 service 服务</h3><p>详细命令<a href="https://docs.docker.com/engine/reference/commandline/service_create/">可参考</a>，部署 etcd <a href="https://github.com/appcelerator-archive/docker-etcd">可参考</a></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-machine ssh manager

docker network create --driver overlay db
docker service create --network db -e SERVICE_NAME&#x3D;etcd -e MIN_SEEDS_COUNT&#x3D;3 --replicas 3 --name etcd appcelerator&#x2F;etcd</code></pre>

<h3 id="查看-service-服务"><a href="#查看-service-服务" class="headerlink" title="查看 service 服务"></a>查看 service 服务</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker@manager:~$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION
i0o3eu86v8qhf9pjfgpseytxq *   manager             Ready               Active              Leader              18.06.0-ce
tafuebh4yfm7c6a753xuq7hu1     worker1             Down                Active                                  18.06.0-ce
no9dktvpeslqipt6suc6d7va0     worker2             Down                Active</code></pre>

<h3 id="其他-service-命令"><a href="#其他-service-命令" class="headerlink" title="其他 service 命令"></a>其他 service 命令</h3><p>其他详细的命令<a href="https://docs.docker.com/engine/swarm/#whats-next">可参考</a></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker service inspect
docker service ls
docker service rm
docker service scale
docker service ps
docker service update</code></pre>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Etcd Watch机制</title>
    <url>/article/etcd/etcd-watch/</url>
    <content><![CDATA[<p>watch 是 mvcc 包中的一个功能，之所以拿出来说，是因为它确实有很重的逻辑。watch 是监听一个或一组 key，key 的任何变化都会发出消息。某种意义上讲，这就是发布订阅模式。<a href="https://segmentfault.com/a/1190000021787055">https://segmentfault.com/a/1190000021787055</a></p>
<h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>既然 Watch 机制就是发布订阅模式，我们通过对比 Kafka，来更深入了解 Watch。<br>首先说明结论：<br>ETCD 没有消费者组的概念，所以不能代替 Kafka<br>对比其他方面呢：</p>
<table><thead><tr>
<th></th>
<th>ETCD</th>
<th>Kafka</th>
</tr>
</thead><tbody><tr>
<td>消费方式</td>
<td>监听一个 Key</td>
<td>订阅一个 Topic</td>
</tr>
<tr>
<td>生产方式</td>
<td>Put(Key, Value)</td>
<td>Produce(Topic, Message)</td>
</tr>
<tr>
<td>历史消息是否保留</td>
<td>保留</td>
<td>保留</td>
</tr>
<tr>
<td>能否从指定位置消费</td>
<td>可以从指定 Revision 消费</td>
<td>可以从指定 offset 消费</td>
</tr>
<tr>
<td>能否保证消息不重放</td>
<td>不能</td>
<td>消费者会主动上报 offset，kafka 会保存每个消费者的 offset，消费者重启会从当前进度消费</td>
</tr>
</tbody></table><p>对比 Kafka 不是试图用 ETCD 代替 Kafka，是想通过对比了解 Watch 的特性和局限性</p>
<h2 id="猜想"><a href="#猜想" class="headerlink" title="猜想"></a>猜想</h2><p>在讨论别人是怎么实现的时候，自己总要先猜想下。想的过程中就会发现难点在哪。<br>我的想法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">type watcher struct &#123;
    key string &#x2F;&#x2F; 要监听的key

    ch  chan struct&#123;&#125; &#x2F;&#x2F; 通过ch将消息发出来
&#125;

func loop() &#123;
    for _, w :&#x3D; range []watchers &#123;
        ch &lt;- message
    &#125;
&#125;</code></pre>

<p>解释下，我的想法中，每一个监听者都是一个 watcher，监听者会自己消费自己的 ch，实现消费功能。在服务端需要维护一个 loop，将消息不断的发送到每一个监听者的 ch 中。<br>我感觉大多数人的最直观想法应该就是这样。<br>这样做我实现了</p>
<ul>
<li>订阅发布功能</li>
</ul>
<p>但我没有做到</p>
<ul>
<li>同时监听一个范围的 key（比如：我可以监听 key&#x3D;foo，但不能监听 key&#x3D;foo ～ fox。这是 ETCD 一个重要的功能）</li>
<li>消费者消费速率不同（比如：按我的设想，有一个消费者出现阻塞，会导致 loop 阻塞）</li>
</ul>
<p>有了这些想法之后，我们来看看 ETCD 中 Watch 是怎么实现的。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>在 MVCC 文章中提到，KV 接口的具体实现是 store 结构体。Watch 的实现是在 store 上封装了一层,叫做：watchableStore，重写了 store 的 Write 方法。<br>通过 MVCC 中介绍，store 的任何写操作，都需要 Write 方法返回的 TxnWrite。所以这里重写 Write 方法意味这任何写操作都会经过 watchableStore。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">func (tw *watchableStoreTxnWrite) End() &#123;
   changes :&#x3D; tw.Changes()

   evs :&#x3D; make([]mvccpb.Event, len(changes))
   for i, change :&#x3D; range changes &#123;
      evs[i].Kv &#x3D; &amp;changes[i]
   &#125;

   tw.s.notify(rev, evs)
   tw.TxnWrite.End()
&#125;

type watchableStoreTxnWrite struct &#123;
   TxnWrite
   s *watchableStore
&#125;

func (s *watchableStore) Write(trace *traceutil.Trace) TxnWrite &#123;
   return &amp;watchableStoreTxnWrite&#123;s.store.Write(trace), s&#125;
&#125;</code></pre>

<p>以上代码只列出了核心的逻辑，不难看出，watchableStoreTxnWrite 在事务提交时，先将本次变更 changes 打包成 Event，然后调用 notify 来将变更通知出去。最后真正提交事务 TxnWrite.End()<br>现在待推送的消息（Event）已经通过 notify 方法进入到了 Watch 机制中，我们看看这个消息是如何流转的。<br>首先需要介绍几个对象：</p>
<ul>
<li>Event</li>
</ul>
<p>事件。变更的消息是以 Event 的形式发送出去的，Event 包括 KeyValue，同时包括操作类型（Put、Delete 等）</p>
<ul>
<li>watcher</li>
</ul>
<p>watcher 监听一个或一组 key，如果有变更，watcher 将变更内容通过 chan 发送出去。</p>
<ul>
<li>watcherGroup</li>
</ul>
<p>顾名思义，一组 watcher。watcherGroup 管理多个 watcher，能够根据 key 快速找到监听该 key 的一个或多个 watcher。</p>
<ul>
<li>watchableStore</li>
</ul>
<p>继承自 store，在 store 基础上实现了 watch 功能。watchableStore 管理着两个 watcherGroup：synced、unsynced，和一个用于缓存的 victims。victims 是缓存当前未发出去的 Event。</p>
<ul>
<li>watchStream</li>
</ul>
<p>watchStream 是对 watchableStore 的封装。因为 watchableStore 继承自 store，所以他实现了很多方法，但这些方法并不都是用于 Watch 功能。所以 watchStream 对 watchableStore 再次封装，暴露出与 Watch 有关的方法。<br>在知道这 5 个对象之后，我们是如何使用 Watch 呢？</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">func testWatch() &#123;
    s :&#x3D; newWatchableStore()

    w :&#x3D; s.NewWatchStream()

    w.Watch(start_key: foo, end_key: nil)

    w.Watch(start_key: bar, end_key: nil)

    for &#123;
        consume :&#x3D; &lt;- w.Chan()
    &#125;
&#125;</code></pre>

<p>解释下，我们先创建了 watchableStore，这是 ETCD 启动后就创建了的。当我们要使用 Watch 功能时，我们创建了一个 watchStream（s.NewWatchStream）。创建出来的 w 可以监听多个 key：foo、bar。之后我们就可以消费 w.Chan()返回的 chan。foo 或 bar 的任何变化，都会通过这个 chan 发送给消费端 consume。<br>于是我们便得到下面这幅图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333092046-903c1cad-93f9-4963-bbab-1a8dba9fbe54.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=732&id=ue640269b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=732&originWidth=586&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=55310&status=done&style=none&taskId=ud198c15a-c76d-4b46-83e3-0b5313b4522&title=&width=586" alt="image.png"><br>可以看到 watchStream 实现了在一大堆 kv 的变化中，过滤出监听的 key，将 key 的变化输出。<br>紧接着，我们将这幅图补充完整：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333110163-e8f57b54-1173-42f6-b70d-4adf39287517.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=634&id=uec73c1c9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=634&originWidth=732&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=77541&status=done&style=none&taskId=u2311c2b1-ed35-427e-b1ba-e50fa3083a0&title=&width=732" alt="image.png"><br>这幅图是什么意思呢？<br>watchableStore 收到了所有 key 的变更后，将这些 key 交给 synced（watchGroup），synced 能够快速地从所有 key 中找到监听的 key。将这些 key 发送给对应的 watcher，这些 watcher 再通过 chan 将变更信息发送出去。<br>synced 是怎么快速找到符合条件的 key 呢？<br>ETCD 中使用了 map 和 adt（红黑树）来实现。<br>不单独使用 map 是因为 watch 可以监听一个范围的 key。如果只监听一个 key<br><code>watch(start_key: foo, end_key: nil)</code><br>我们可以这样存储<br><code>map[key]*watcher</code><br>这样可以根据 key 快速找到对应的 watcher，ETCD 也是这样做的。<br>但对于一组 key 呢？<br><code>watch(start_key: foo, end_key: fop)</code><br>这里我监听了从 foo-&gt;fop 之间的所有 key，理论上这些 key 的数目是无限的，所以无法再使用 map。<br>比如：key&#x3D;fooac 也属于监听范围。<br>ETCD 用 adt 来存储这种 key。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333293445-d3b48322-b865-4d74-9b00-8e1982e2eee1.png#clientId=ub19f4876-2fdf-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=206&id=u4267a929&margin=%5Bobject%20Object%5D&name=image.png&originHeight=206&originWidth=732&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=89993&status=done&style=none&taskId=u97de705b-a4eb-4dca-b35d-3df35111040&title=&width=732" alt="image.png"><br>adt 的实现这里不做介绍，只用知道 adt 能够根据 key&#x3D;fooac 快速地找到所属范围 foo-&gt;fop。</p>
<blockquote>
<p>adt 的原理推荐这篇文章：<a href="https://link.segmentfault.com/?enc=tBF+NgCKCto5lgP5kXXmWA==.O67spWZrUmB6U9JCJg/j9XFxWIR0u60mv6ztjsgDS34DxqDkYQqkqsjEV+6T0iM1">https://www.jianshu.com/p/e13...</a><br>adt 的 go 实现：go.etcd.io&#x2F;etcd&#x2F;pkg&#x2F;ad</p>
</blockquote>
<p>在找到 watcher 后，调用 watcher 的 send()方法，将变更的 Event 发送出去。<br>这就是上述图的意思，也就是正常的 Watch 流程。</p>
<h3 id="各种场景"><a href="#各种场景" class="headerlink" title="各种场景"></a>各种场景</h3><p>上图所述是正常流程，但是会有很多不正常的情况发生。<br>上图可以看到，消息都是通过一个 Chan 发送出去，但如果消费者消费速度慢，Chan 就容易堆积。Chan 的空间不可能无限大，那就必然会有满的时候，满了后该怎么办呢？<br>接下来就要讨论上图 unsynced、victims 的作用了。<br>Chan 什么时候会满呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333319458-12eb50d2-a66b-4a45-baae-d30d91b43345.png#clientId=ub19f4876-2fdf-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=184&id=uaa0d8e6a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=388&originWidth=1576&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=176312&status=done&style=none&taskId=u9921ffac-f9aa-4795-9605-4e207b93f21&title=&width=746" alt="image.png"><br>代码中 Chan 的长度是 1024。不过这也是一个随机值，只是没有现在更好的选择。<br>一旦满了，会发生以下操作：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">func (s *watchableStore) notify() &#123;
    var victim watcherBatch
    ...
    w.minRev &#x3D; rev + 1           &#x2F;&#x2F; w是当前watcher
    if victim &#x3D;&#x3D; nil &#123;
       victim &#x3D; make(watcherBatch)
    &#125;
    w.victim &#x3D; true              &#x2F;&#x2F; w被标记为受损的
    victim[w] &#x3D; eb               &#x2F;&#x2F; eb是当前的变更消息EventBatch
    s.synced.delete(w)
    ...
    s.addVictim(victim)          &#x2F;&#x2F; 将victim添加到s的victims中
&#125;</code></pre>

<p>watcher 会记录当前的 Revision，并将自身标记为受损的。此次的变更操作会被保存到 watchableStore 的 victims 中。同时该 watcher 会被从 synced 踢出。<br>假设此时有一个写操作：foo&#x3D;f1。而正好 Chan 此时刚满，则监听 foo 的 watcher 将从 synced 中踢出，同时 foo&#x3D;f1 被保存到 victims 中<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333367096-914ce175-94f5-427b-86a4-0268ccd89e0f.png#clientId=ub19f4876-2fdf-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=572&id=ue2bb00f1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=677&originWidth=732&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=88626&status=done&style=none&taskId=u1c577aa6-a5be-4130-9323-c2c1d519829&title=&width=618" alt="image.png"><br>接下来对 foo 的任何变更，该 watcher 都不会记录。那这些消息就都丢掉了吗？当然不是，watcher 变成受损状态时记录下了当时的 Revision，这个很重要。<br>这时要说到两个工作协程了：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 我们在创建watchableStore时，会同时启动两个工作协程
go s.syncWatchersLoop()
go s.syncVictimsLoop()</code></pre>

<p>顾名思义，第一个协程用于将 unsynced 的 watcher 同步为 synced。<br>第二个协程用于循环清除 watchableStore 中的 victims。<br>在上面的场景中，我们知道，队列满时，当时变更的 Event 被放入了 victims 中。这个协程就会试图清除这个 Event。怎么清除呢？协程会不断尝试让 watcher 发送这个 Event，一旦队列不满，watcher 将这个 Event 发出后。该 watcher 就被划入了 unsycned 中，同时不再是受损状态。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647333411733-cae3e46b-9a77-4b2a-bdf9-0222d21f2b86.png#clientId=ub19f4876-2fdf-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=597&id=u2bb9d879&margin=%5Bobject%20Object%5D&name=image.png&originHeight=671&originWidth=732&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=106483&status=done&style=none&taskId=u5bb36fec-96e6-4680-ab95-eb5efbe46f3&title=&width=651" alt="image.png"><br>此时 syncWatchersLoop 协程就开始起作用。由于在受损状态下，这个 watcher 已经错过了很多消息。为了追回进度，协程会根据 watcher 保存的 Revision，找出受损之后所有的消息，将关于 foo 的消息全部给 watcher，当 watcher 将这些消息都发送出去后。watcher 就脱离了 unsynced，成为了 synced。<br>至此就解决了 Chan 满导致的问题。同时也阐明了 Watch 的设计实现。</p>
<p><a href="https://www.jianshu.com/p/0c1c462c19d0">https://www.jianshu.com/p/0c1c462c19d0</a></p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>查询是后台领域经常使用的一种数据同步方式。但是在一些场景，需求方需要针对一些数据变化做出响应。虽然定期轮询也可以满足部分的需求，但在以下场景中就不太合适了。</p>
<ul>
<li>存活检测：为了检测低于%1 异常。轮询会一直耗费查询资源。</li>
<li>实时响应：变化响应时间要尽可能小，但是轮询周期越小，消耗的资源也越多。</li>
</ul>
<p>因此数据层往往在“增删改查”这 4 种基本接口之外还会提供一个 watch 接口用来实时推送数据变化事件。</p>
<h1 id="Watch-机制设计"><a href="#Watch-机制设计" class="headerlink" title="Watch 机制设计"></a>Watch 机制设计</h1><p>watch 机制是一个典型的 CS 架构，其中数据需求方作为 client，数据提供方作为 server。由 client 向 server 发起请求，server 端推送数据给 client。</p>
<h2 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h2><p>带有 watch 机制的存储系统往往都是具有版本功能的。具备版本功能的系统可以实现以下两个功能：</p>
<ul>
<li>因为某些原因（崩溃、重启）client 可能错失部分历史事件。恢复之后 client 可以利用版本号重新接收这些事件。</li>
<li>client 可以在请求参数中附带版本号表示该版本号之前的历史数据已经接收。server 可以过滤掉过时事件只发送新的事件给 client。具体如下图所示。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647277142417-43c3a5be-779d-4870-bb85-499c03e0067e.png#clientId=u28b533e9-4247-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=435&id=u5ffdc645&margin=%5Bobject%20Object%5D&name=image.png&originHeight=521&originWidth=988&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=99714&status=done&style=none&taskId=uf3661f8c-dcb1-4d45-94b1-ff9b908e272&title=&width=825" alt="image.png"></p>
<h2 id="连接层"><a href="#连接层" class="headerlink" title="连接层"></a>连接层</h2><p>连接层讨论的是 client 和 server 之间通信的协议。相较于单机程序之间的 IPC 通信，分布式系统网络通信的 IO 成本是非常大的。下面就连接层实现方式、性能和开发成本展开具体分析。</p>
<h3 id="http-长轮询"><a href="#http-长轮询" class="headerlink" title="http 长轮询"></a>http 长轮询</h3><p>http 长轮询是一种非常容易实现的 watch 手段，因此也是使用最广泛的。比如 etcd v2、consul 等都使用了 http 长轮询技术来 watch 事件。具体实现原理如下图。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332451786-6b372b3d-ca74-4561-b162-5ec7ffed94e2.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=584&id=u95342c91&margin=%5Bobject%20Object%5D&name=image.png&originHeight=584&originWidth=570&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=71266&status=done&style=none&taskId=ufa1860ba-7a1b-4c0d-9abc-5cb11fb7e8e&title=&width=570" alt="image.png"><br>http 长轮询的优点是实现简单、兼容性好，不需要额外开发客户端程序。但是这样的实现意味每接收一个 event 都需要至少走完一个 http 请求应答流程。这对于 watch key 非常多的系统，负荷是相当大的。假设某个后台系统需要 watch 10W 个 key，每个 http 轮询超时时间为 100s。计算下来即使在空闲的时候系统需要承受并发 10W 个连接和 1K&#x2F;QSP 的请求量。</p>
<h3 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h3><p>长连接模式是对 http 长轮询的一种优化。不同于 http 长轮询每个连接都只能处理一个事件，长连接模式一个连接可以接收多个事件，通过减少了 tcp 三次握手的开销，提高了资源利用率。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332503352-f6b49e7a-6de3-4614-92f2-debfe3ff1cce.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=305&id=u297f15e5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=305&originWidth=708&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=32572&status=done&style=none&taskId=u9a81b0cf-5fb2-4741-ba7d-1000e72a92a&title=&width=708" alt="image.png"><br>但相对而言长连接模式开发成本要比 http 长轮询高，主要体现在：</p>
<ul>
<li>需要定义事件流的序列化和反序列化协议。目前没有公认的标准，只能私有定制应用于内部系统。</li>
<li>没有成熟的反向代理组件。需要考虑在大规模部署下的负载均衡问题。</li>
</ul>
<p>长连接模式虽然减少了 tcp 握手的开销，但每个 watch key 都需要一个连接。假设某个后台系统需要 watch 10w 个 key，就需要建立 10W 个连接，这很容易消耗光 server 的 socket 和内存资源。</p>
<h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>多路复用是通信工程上的概念，指的是将多个低速信道整合到一个高速信道进行传输，从而有效地利用了高速信道。通过使用多路复用，可以避免维护多条线路，从而有效地节约运营成本。<br>网络工程上有很多方面借鉴了多路复用的思想。比如 L4 层的 TCP、UDP 就是复用了 L3 层的 IP 层的通道。同理我们也可以在 tcp 上层定义更高层协议来复用 tcp 连接。如下图，虽然端到端之间只有一个 tcp 连接。但在逻辑层上可以抽象出多个双工的 session stream。每个 session stream 负责一个 watch 任务。假设一个客户端需要 watch 1k 个 key，原先按照需要 1k 个连接，但现在只需要一个连接即可。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332525229-0c0f5fc4-840b-4ddc-b733-b21e7492aeec.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=437&id=ucf1bb072&margin=%5Bobject%20Object%5D&name=image.png&originHeight=437&originWidth=552&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=69198&status=done&style=none&taskId=u82744d60-c170-4971-9638-12c5f178e31&title=&width=552" alt="image.png"><br>多路复用核心就是在 tcp 连接上构建一个逻辑层。该逻辑层负责处理一下内容：</p>
<ul>
<li>建立、关闭 stream 需要的控制帧。</li>
<li>接收时将 tcp 连接里的数据流，拆分为一个个 frame，再按照协议封装到对于的 stream 中。</li>
<li>发送时将 stream 里的数据流分割成 frame，再通过 tcp 层发送出去。</li>
<li>为了防止 stream 之间相互干扰抢占带宽资源，需要设计流控机制公平调度。</li>
<li>空闲 stream 保活通信，维持 session 会话心跳。</li>
<li>封装好类似 socket 的 Read 和 Write 的接口，方便业务调用。</li>
</ul>
<p>可以看出，多路复用技术是开发是比较复杂的。但值得庆幸的是，业内已经有了成熟可靠的工具和标准。HTTP&#x2F;2 定义了多路复用的协议，grpc 实现多语言版本的接口。我们完全可以秉着拿来主义的思想直接来用，比如 etcd v3 版本就是使用 grpc stream 模式来处理 watch 的。</p>
<blockquote>
<p>The etcd3 API multiplexes watches on a single connection. Instead of opening a new connection, a client registers a watcher on a bidirectional gRPC stream. The stream delivers events tagged with a watcher’s registered ID. Multiple watch streams can even share the same TCP connection. Multiplexing and stream connection sharing reduce etcd3’s memory footprint by at least an order of magnitude.</p>
</blockquote>
<p>consul 的 watch 也采用了多路复用技术。它自己实现了一个多路复用库<a href="https://links.jianshu.com/go?to=https://github.com/hashicorp/yamux">yamux</a>，虽然没有 http&#x2F;2 和 grpc 那么完备，但是还是可以供愿意自己练手的同学参考学习。</p>
<h3 id="watch-gateway"><a href="#watch-gateway" class="headerlink" title="watch gateway"></a>watch gateway</h3><p>对于一般的场合，多路复用已经有很好的性能表现了。但是 etd v3.2 版本提出一个进一步提高 watch 性能的优化方案 watch gateway。<br>考虑到 k8s 使用场合可能存在有上万个 watcher。一旦事件触发 etcd 需要广播给所有的 watcher，就会带来相当大的性能消耗，甚至会影响的读写性能。但在实际场景，这些 watcher 很有可能监听的资源是重复的，比如每个 api-server 监听的资源都是一样的。为了优化这种大量重复监听 watcher 的场景，etcd v3.2 版本设计了 gateway 组件。gateway 可以聚合 watch 相同范围 key 的 watcher。举例说明如下图，client1、client2、client3 都对事件 a 感兴趣，如果直接请求 server，server 需要负担 3 个 watcher。但如果通过 gateway 聚合，可以合并 3 个 watch 变成 1 个，这样可以降低 server 的压力<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332547975-19b4f78e-bf39-4532-b2c3-8ed393fe2f10.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=377&id=u5faab80d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=377&originWidth=933&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=56344&status=done&style=none&taskId=ua87eb265-3aaf-4ad1-a41f-a1e4f463c98&title=&width=933" alt="image.png"><br>本质上来说，gateway 只是将广播的压力从 server 转移到自己身上去了。但是 server 作为存储服务器，一般都是有状态的。无论是扩容还是迁移都是有一定成本的。但是 gateway 是一个无状态的服务，完全可以根据实际需求横向部署 gateway 服务器来降低存储层的压力。<br>下图是 etcd v3.2 使用 watch-gateway 性能提升的对比图。在不使用 gateway 时，随着 watcher 的增多，写和 watch 速率下降。但是使用了 gateway 之后，watch 数量增加对性能没有影响。详细文档见(<a href="https://links.jianshu.com/go?to=https://coreos.com/blog/etcd-3.2-announcement">https://coreos.com/blog/etcd-3.2-announcement</a>)<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332566970-d8ede7bb-955a-4c26-93d6-45b0abf54dfc.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=441&id=u985a830b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=441&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=122352&status=done&style=none&taskId=u3ad37cf0-5999-4b67-8ba9-b6a68bce6bd&title=&width=1200" alt="image.png">存储<br>watch 机制实现的另一个核心问题就是如何存储数据。按照存储类型来分，可以分为内存和硬盘里两大类。下面会根据具体场景来讨论这两种类型的数据格式的设计。</p>
<h3 id="历史数据存储"><a href="#历史数据存储" class="headerlink" title="历史数据存储"></a>历史数据存储</h3><p>watch 机制的特点决定了存储系统需要保存历史数据。举例说明，如下图一个数据同步场景。client 向 server watch 同步数据，历史同步数据已经达到 1G。某个时间点网络异常导致 client 和 server 之间通信中断，watch 被迫停止。在网络中断时间内，server 的数据发生了变更。当网络恢复的时候，client 重新发送 watch 请求，希望能够从 version&#x3D;10001 继续获取事件。但此时 server 端的 version&#x3D;10010，并且没有保存历史数据。客户端发现数据丢失，只好作废之前同步的数据，重新同步高达 1G 的数据，等追上之后再继续 watch。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332591799-b3c946a7-594a-4b5a-b740-bdd1d8b9192d.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=513&id=ueb2ff0a0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=513&originWidth=465&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=47473&status=done&style=none&taskId=u9532c88d-53e0-40bd-b450-3da472863f1&title=&width=465" alt="image.png"><br>保留历史数据可以简化客户端的工作，但是这也给存储方带来了极大的压力。</p>
<h4 id="滑动事件窗口"><a href="#滑动事件窗口" class="headerlink" title="滑动事件窗口"></a>滑动事件窗口</h4><p>内存型数据库一个缺点是容量相对有限。如果在数据更改频繁的情况下保留历史数据的话，有可能导致内存溢出。因此内存型数据库往往采用滑动事件窗口来作为妥协方案。<br>滑动事件窗口就是一个简单的回环数组。不断的插入新事件、淘汰掉超过大小的旧事件。因为窗口的大小是固定的，因此不会出现内存溢出。<br>如果 watch 的版本命中了滑动事件窗口里的事件版本，就可以返回给 client。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332610556-b7d63b91-99e8-4d23-a5d9-d15a7c632e7c.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=199&id=u35c4ca9c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=199&originWidth=503&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=11990&status=done&style=none&taskId=udc7b5f91-34ce-452c-a0ea-47f255421ca&title=&width=503" alt="image.png"><br>滑动事件窗口的缺点是显而易见的。对于修改频繁的系统，滑动事件窗口可以保存的事件时间非常短，很有可能丢失事件。这个是内存型存储系统的硬伤，没办法根本解决。目前 etcd v2、consul 和 k8s api server 都是采用这样的机制。</p>
<h4 id="多版本存储"><a href="#多版本存储" class="headerlink" title="多版本存储"></a>多版本存储</h4><p>相较于受限容量的内存型数据库，磁盘数据库的空间就大很多了。有能力存储足够旧的历史版本数据。比如<strong>etcd v3</strong>就是存储了多个版本的数据。<br>简单来说，<strong>etcd v3 在内存里维护一个 B 树</strong>，存储的是 Key 和这个 Key 所有的版本列表。磁盘里维护了一个 B+树，存储的是版本和 KV 的实际内容。磁盘 B+树是实际的数据，内存 B 数一个二级索引。查找某个 Key 某个版本的数据可以分为以下两步：</p>
<ul>
<li>通过内存 B 数查找到 Key 对应的版本列表。再从版本列表中找到里查询版本参数最近的一个版本号 Version。</li>
<li>再到磁盘 B+树中查找 Version 对应的数据信息。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332627222-1069364f-fad8-4a14-af9f-37310e26864a.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=341&id=ufefa5f31&margin=%5Bobject%20Object%5D&name=image.png&originHeight=341&originWidth=706&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=41411&status=done&style=none&taskId=u9bfeeb2a-bcc3-400e-8b8e-5481d04e835&title=&width=706" alt="image.png"><br>因为需要将 Key 存储在内存中，etcd 的实际存储量也是非常有限的。按照 etcd 文档，默认存储是 2G、最大可配置到 8G。当然这个比内存型的 consul 容量还是大的多了。</p>
<h3 id="事件触发"><a href="#事件触发" class="headerlink" title="事件触发"></a>事件触发</h3><p>和其他的存储系统不一样的是，watch 存储系统需要在某个 key 变更的时候通知到 client。这就需要设计对应的触发响应机制。watcher 往往不仅仅监听单个的 key，还可能是监听某个前缀或是范围 key，只要其中之一有变化，就需要触发事件。<br>事件触发最简单的实现方式就是采用遍历的方法：当某个 Key 发生变化时，逐个遍历 watcher，一旦发现满足条件的 watcher 就发送数据。这种 O(n)复杂度的处理方式固然简单，但随着 watcher 数量的增多，带来的性能损失也是越来越大的。下面介绍两种应用于工程的数据结构。</p>
<h4 id="radix-树"><a href="#radix-树" class="headerlink" title="radix 树"></a>radix 树</h4><p>说到前缀匹配，很容易想到和前缀匹配相关的数据结构 radix 树。在计算机科学中，基数树，或称 Patricia trie&#x2F;tree，或 crit bit tree，压缩前缀树，是一种更节省空间的 Trie（前缀树）。对于基数树的每个节点，如果该节点是唯一的子树的话，就和父节点合并。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332704592-0ddff3f7-8abf-4d1d-a895-369366f0af17.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=386&id=u19bc4e5e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=386&originWidth=1053&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=77353&status=done&style=none&taskId=u45e744bf-24f0-431b-8ef1-21e053fb9f3&title=&width=1053" alt="image.png"><br>radix.png<br>如图当前缀匹配 watch ro 的时候，可以通过 radix 树找到 om 节点。之后切割 o、m 节点并将 watcher 挂载在 o 节点上。如果 o 下面的节点有任何的变化，都会通过回调通知 watcher 触发事件。<br>consul 就是采用 radix 树来存储 KV 数据的。但是 radix 树只能解决前缀匹配的问题，无法解决范围 Key 的问题。因此 consul 是不支持范围 key watch 的。</p>
<h4 id="区间树"><a href="#区间树" class="headerlink" title="区间树"></a>区间树</h4><p>radix 作为一个树的问题在于它太长了，需要大量使用间接指针。对于内存型存储结构还算好，但对于磁盘数据结构而言，多次间接查找是非常消耗性能的。目前 B+树还是最适合查找的磁盘数据结构。但 B+树没法反向查找某个 Key 是否在某个 watcher 范围内。为了解决这个问题，etcd v3 采用了区间树。<br>区间树是在红黑树基础上进行扩展得到的支持以区间为元素的动态集合的操作，其中每个节点的关键值是区间的左端点。通过建立这种特定的结构，可是使区间的元素的查找和插入都可以在 O(lgn)的时间内完成。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332720273-bac1820d-f734-482b-98ed-6737d3f9510c.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=315&id=u15a55f4d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=315&originWidth=760&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=69990&status=done&style=none&taskId=u8a1821c8-6301-4c2b-a70d-458dd3a81d0&title=&width=760" alt="image.png"><br>区间树.png<br>关于区间树原理本文不再赘述，感兴趣的同学可以查阅算法导论。简而言之，每个 watcher 将自己的监听范围[start,end]封装成一个节点插入区间树。当某个 Key 发生变化需要查找对应 watcher 的时候，就可以利用区间树快速查找到重叠的 watcher。</p>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>之前说的是 watch 的实现机制。下面谈谈 watch 的应用场景。利用（list watch 机制）的方式解决以下场景的读性能瓶颈问题：</p>
<ul>
<li>读多写少</li>
<li>可以接受最终一致性</li>
<li>数据量不大，可以存储在内存中</li>
</ul>
<h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332879811-a20b7de6-a93d-4ea9-9c36-e99d768b5ee0.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=350&id=uff0d3c06&margin=%5Bobject%20Object%5D&name=image.png&originHeight=350&originWidth=431&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=24373&status=done&style=none&taskId=u13b3f945-5ca5-403c-9600-9c716ffc5be&title=&width=431" alt="image.png"><br>服务发现.png<br>服务发现场景恰好满足了上述的 3 个条件，因此非常适合采用 watch 同步机制来减缓服务发现服务器的读压力。每个客户端可以利用 list watch 缓存一份同步数据到本地，程序直接查询本地缓存，性能非常优异。</p>
<h2 id="k8s-api-server"><a href="#k8s-api-server" class="headerlink" title="k8s api-server"></a>k8s api-server</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332896374-af568760-e22e-4819-9d14-c6bba4cae298.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=475&id=u3a2a1052&margin=%5Bobject%20Object%5D&name=image.png&originHeight=475&originWidth=542&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=38689&status=done&style=none&taskId=u47d1c787-d261-463d-8278-cc4f005b05f&title=&width=542" alt="image.png"><br>k8s-server.png<br>k8s api 每个 server 利用 list watch 机制保留一份和 etcd 数据同步的缓存。当接收到查询请求时，直接读取缓存数据返回给客户端。对于新增、修改和删除请求直接透传给 etcd。<br>需要注意的是，在服务发现场景里客户端不会修改缓存数据，但 api-server 是可以修改数据的。一旦涉及数据修改，就会有数据一致性的问题。假设原先数据 a&#x3D;1,之后客户端写入 a&#x3D;2。写入成功后让客户端读取另外一个 server 的数据，有可能读取到 a&#x3D;1（watch 有时间差）。这就产生了读写不一致的问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332917866-7ad571c9-cd28-41f0-af3c-e368d2f543d5.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=542&id=u44435634&margin=%5Bobject%20Object%5D&name=image.png&originHeight=542&originWidth=625&originalType=binary%E2%88%B6=1&rotation=0&showTitle=true&size=57577&status=done&style=none&taskId=u0e40e03d-620f-423f-be18-d4b75407997&title=api-server%E8%AF%BB%E5%86%99%E4%B8%8D%E4%B8%80%E8%87%B4&width=625" alt="image.png" title="api-server读写不一致"><br>当然实际情况 k8s 是不会出现上述读写不一致的现象的。解决方法是 ResourceVersion 管理。k8s 里每个 Object 都有对应的 ResourceVersion，其实这个就是 etcd 的 revision，也就是 watch 的版本号。这个版本号是自增的，对于每个请求 k8s 都要求客户端在请求里带上特点的版本号。api-server 在收到客户端请求后会对比自身缓存里的版本信息，如果小于客户端的版本信息则需要阻塞等待新数据同步。只有缓存数据版本大于等于客户端请求的版本信息才可以返回数据给客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647332930990-4df6d8ac-91d0-4921-973c-2d5fe1a54478.png#clientId=u772060f5-114b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=454&id=u09529b6d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=454&originWidth=819&originalType=binary%E2%88%B6=1&rotation=0&showTitle=true&size=88670&status=done&style=none&taskId=u76b283a0-5015-4325-81d7-19eb17a5614&title=k8s-api-version&width=819" alt="image.png" title="k8s-api-version"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文主要讨论了 watch 机制的具体实现和一些应用场景。虽然要实现一个简易的 watch 机制很容易，但随着业务发展，数据量和请求量逐步上升，就不得不就各个环节进行优化。虽然 etcd 和 consul 都是基于 raft 的 KV 数据库，但两者发展的方向已经越来越不相同。etcd 是伴随着 k8s 不断成长，在性能优化上一步步改进。consul 则是向着服务发现场景不断进步。当从 watch 机制实现上来看，consul 做的确不如 etcd 做的好，但在实际应用上，很难找到一个像 k8s 一样对性能要求如此严苛的场景。可以说 k8s 采用了 etcd，也是 etcd 的幸运。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="https://links.jianshu.com/go?to=https://github.com/etcd-io/etcd">https://github.com/etcd-io/etcd</a></li>
<li><a href="https://links.jianshu.com/go?to=https://github.com/hashicorp/consul">https://github.com/hashicorp/consul</a></li>
<li><a href="https://links.jianshu.com/go?to=https://github.com/kubernetes/kubernetes">https://github.com/kubernetes/kubernetes</a></li>
<li><a href="https://links.jianshu.com/go?to=https://coreos.com/blog/etcd3-a-new-etcd.html">etcd3 | A New Version of etcd from CoreOS</a></li>
<li><a href="https://links.jianshu.com/go?to=https://coreos.com/blog/etcd-3.2-announcement">etcd 3.2 now with massive watch scaling and easy locks</a></li>
</ul>
<p>其他系统文章可参考<br><a href="https://zhuanlan.zhihu.com/p/369782579">https://zhuanlan.zhihu.com/p/369782579</a></p>
]]></content>
      <categories>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>Etcd</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker（一）基本命令</title>
    <url>/article/docker/docker-command/</url>
    <content><![CDATA[<h2 id="Docker-基本服务命令"><a href="#Docker-基本服务命令" class="headerlink" title="Docker 基本服务命令"></a>Docker 基本服务命令</h2><h3 id="启动-docker"><a href="#启动-docker" class="headerlink" title="启动 docker"></a>启动 docker</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ service docker start</code></pre>

<h3 id="重启-docker"><a href="#重启-docker" class="headerlink" title="重启 docker"></a>重启 docker</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ service docker restart</code></pre>

<h3 id="停止-docker"><a href="#停止-docker" class="headerlink" title="停止 docker"></a>停止 docker</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ service docker stop</code></pre>

<h3 id="docker-自启动"><a href="#docker-自启动" class="headerlink" title="docker 自启动"></a>docker 自启动</h3><p>让它随服务器的启动而自动运行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ update-rc.d docker defaults
$ systemctl enable docker</code></pre>

<h2 id="Docker-基础命令"><a href="#Docker-基础命令" class="headerlink" title="Docker 基础命令"></a>Docker 基础命令</h2><h3 id="启动-x2F-停止-x2F-重启-x2F-杀掉容器"><a href="#启动-x2F-停止-x2F-重启-x2F-杀掉容器" class="headerlink" title="启动&#x2F;停止&#x2F;重启&#x2F;杀掉容器"></a>启动&#x2F;停止&#x2F;重启&#x2F;杀掉容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker start&#x2F;stop&#x2F;restart&#x2F;kill

实例操作如下：
$ docker start myweb
$ docker stop myweb
$ docker restart myweb
$ docker kill -s kill myweb
参数 -s  #向容器发送信号</code></pre>

<h3 id="创建并启动一个新的容器"><a href="#创建并启动一个新的容器" class="headerlink" title="创建并启动一个新的容器"></a>创建并启动一个新的容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker run
常用参数如下：
-d #后台运行容器，并返回容器ID
-i #以交互式模式运行容器，常与-t参数同时使用
-t #给容器重新分配一个伪终端，常与-i参数同时使用
–name #给容器指定一个名称
-m #指定容器使用内存的最大值
–net #指定容器使用的网络类型
–link #链接到另一个容器

实例操作如下：
$ docker run -d --name nginx nginx:latest
#后台启动并运行一个名为nginx的容器，运行前它会自动去docker镜像站点下载最新的镜像文件
$ docker run -d -P 80:80 nginx:latest
#后台启动并运名为nginx的容器，然后将容器的80端口映射到物理机的80端口
$ docker run -d -v &#x2F;docker&#x2F;data:&#x2F;docker&#x2F;data -P 80:80 nginx:latest
#后台启动并运名为nginx的容器，然后将容器的80端口映射到物理机的80端口,并且将物理机的&#x2F;docker&#x2F;data目录映射到容器的&#x2F;docker&#x2F;data
$ docker run -it  nginx:latest &#x2F;bin&#x2F;bash
#以交互式模式运行容器，然后在容器内执行&#x2F;bin&#x2F;bash命令</code></pre>

<h3 id="删除容器"><a href="#删除容器" class="headerlink" title="删除容器"></a>删除容器</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker rm
常用参数如下：
-f #强制删除一个运行中的容器
-l #删除指定的链接
-v #删除与容器关联和卷

实例操作如下：
$ docker rm -f mydocker
强制删除容器mydocker
$ docker rm -f dockerA dockerB
强制删除容器dockerA，dockerB
$ docker rm -v mydocker****
删除容器，并删除容器挂载的数据卷</code></pre>

<h3 id="创建一个新的容器但不启动它"><a href="#创建一个新的容器但不启动它" class="headerlink" title="创建一个新的容器但不启动它"></a>创建一个新的容器但不启动它</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker create
$ docker create --name myserver nginx:latest
09b93464c2f75b7b69f83d56a9cfc23ceb50a48a9db7652ee4c27e3e2cb1961f
#创建一个名为myserver的容器</code></pre>

<h3 id="在运行的容器中执行命令"><a href="#在运行的容器中执行命令" class="headerlink" title="在运行的容器中执行命令"></a>在运行的容器中执行命令</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker exec
常用参数如下：
-d #在后台运行
-i #保持STDIN打开
-t #分配一个伪终端

实例操作如下：
$ docker exec -it mydocker &#x2F;bin&#x2F;sh &#x2F;server&#x2F;scripts&#x2F;docker.sh
hello world
以交互模式执行容器中的&#x2F;server&#x2F;scripts&#x2F;docker.sh脚本
$ docker exec -it mydocker &#x2F;bin&#x2F;sh
以交互模式给容器分配一个伪终端连接</code></pre>

<h3 id="列出容器（正在运行）"><a href="#列出容器（正在运行）" class="headerlink" title="列出容器（正在运行）"></a>列出容器（正在运行）</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker ps
常用参数如下：
-a #列出所有容器包括停止的
-f #根据条件过滤显示内容
-l #列出最近创建的容器
-n #列出最近创建的N个容器，N为数字
-q #只显示容器ID
-s #显示总文件大小

#列出最近创建的2个容器
$ docker ps -a -q
bd96d72ed9c7
665563143eb7
f2304dad5855
9921d2660307
显示所有容器的ID</code></pre>

<h3 id="获取容器的元数据"><a href="#获取容器的元数据" class="headerlink" title="获取容器的元数据"></a>获取容器的元数据</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker inspect
常用参数如下：
-f #指定返回值格式或模板文件
-s #显示总文件大小
–type #为指定类型返回JSON

$ docker inspect &lt;container id or name&gt;</code></pre>

<h3 id="获取-docker-容器-container-的-ip-地址"><a href="#获取-docker-容器-container-的-ip-地址" class="headerlink" title="获取 docker 容器(container)的 ip 地址"></a>获取 docker 容器(container)的 ip 地址</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker inspect -f &#39;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; $(docker ps -aq)</code></pre>

<h3 id="删除的镜像"><a href="#删除的镜像" class="headerlink" title="删除的镜像"></a>删除<none>的镜像</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker rmi $(docker images -f &quot;dangling&#x3D;true&quot; -q)</code></pre>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Disruptor（五）DSL相关实战</title>
    <url>/article/disruptor/disruptor-practise/</url>
    <content><![CDATA[<p>本文主要讲解使用 Disruptor 的 DSL 演示生产者和消费者的数据交换，和以往的线程间通信不同，disruptor 使用消息传递的方式，通过 RingBuffer 进行线程间的数据传递和通信，下面分别从一对一和多对一的模型进行讲解。<br>下面主要通过计算区间[0 , 100000000)中的所有数值相加为例子讲解 Disruptor 中的 dsl 使用。</p>
<h2 id="1、一对一"><a href="#1、一对一" class="headerlink" title="1、一对一"></a>1、一对一</h2><p>一个生产者和一个消费者之间进行数据传递，使用 disruptor 主要涉及到 RingBuffer 中的 ValueEvent 定义，ValueAdditionEventHandler 消费者处理，以及生产者发布。</p>
<h3 id="1-1-RingBuffer-中-ValueEvent-定义"><a href="#1-1-RingBuffer-中-ValueEvent-定义" class="headerlink" title="1.1 RingBuffer 中 ValueEvent 定义"></a>1.1 RingBuffer 中 ValueEvent 定义</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">package com.lmax.disruptor.charles;

import com.lmax.disruptor.EventFactory;

public final class ValueEvent &#123;

    private long value;
    public long getValue() &#123;
        return value;
    &#125;

    public void setValue(final long value) &#123;
        this.value &#x3D; value;
    &#125;

    public static final EventFactory&lt;ValueEvent&gt; EVENT_FACTORY &#x3D; new EventFactory&lt;ValueEvent&gt;() &#123;
        public ValueEvent newInstance() &#123;
            return new ValueEvent();
        &#125;
    &#125;;

&#125;</code></pre>

<h3 id="1-2-ValueAdditionEventHandler-消费者数据处理"><a href="#1-2-ValueAdditionEventHandler-消费者数据处理" class="headerlink" title="1.2 ValueAdditionEventHandler 消费者数据处理"></a>1.2 ValueAdditionEventHandler 消费者数据处理</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">package com.lmax.disruptor.charles;

import com.lmax.disruptor.EventHandler;
import com.lmax.disruptor.util.PaddedLong;

import java.util.concurrent.CountDownLatch;

public final class ValueAdditionEventHandler implements EventHandler&lt;ValueEvent&gt; &#123;

    private final PaddedLong value &#x3D; new PaddedLong();
    private long count;
    private CountDownLatch latch;

    public long getValue() &#123;
        return value.get();
    &#125;

    public void reset(final CountDownLatch latch, final long expectedCount) &#123;
        value.set(0L);
        this.latch &#x3D; latch;
        count &#x3D; expectedCount;
    &#125;

    @Override
    public void onEvent(final ValueEvent event, final long sequence, final boolean endOfBatch) throws Exception &#123;
        value.set(value.get() + event.getValue());

        if (count &#x3D;&#x3D; sequence) &#123;
            latch.countDown();
        &#125;
    &#125;

&#125;</code></pre>

<p>使用 CountDownLatch 保证在处理完消费者数据后在退出，保证结果的正确性，其中 ValueAdditionEventHandler.value 为计算结果，每次增加事件中的数值。</p>
<h3 id="1-3-数据发布"><a href="#1-3-数据发布" class="headerlink" title="1.3 数据发布"></a>1.3 数据发布</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 *
 * UniCast a series of items between 1 publisher and 1 event processor.
 *
 * +----+    +-----+
 * | P1 |---&gt;| EP1 |
 * +----+    +-----+
 *
 * Disruptor:
 * &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;
 *              track to prevent wrap
 *              +------------------+
 *              |                  |
 *              |                  v
 * +----+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +&#x3D;&#x3D;&#x3D;&#x3D;+   +-----+
 * | P1 |---&gt;| RB |&lt;---| SB |   | EP1 |
 * +----+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +&#x3D;&#x3D;&#x3D;&#x3D;+   +-----+
 *      claim      get    ^        |
 *                        |        |
 *                        +--------+
 *                          waitFor
 *
 * P1  - Publisher 1
 * RB  - RingBuffer
 * SB  - SequenceBarrier
 * EP1 - EventProcessor 1
 *
 *&#x2F;
public class OneToOneDisruptor &#123;

    private static int RING_BUFFER_SIZE &#x3D; 1024 * 16;
    private static long ITERATIONS      &#x3D; 1000L * 1000L * 100L;

    public static void main(String[] args) throws InterruptedException &#123;
        &#x2F;&#x2F; 单个生产者ProducerType.SINGLE，消费者的等待策略为YieldingWaitStrategy
        Disruptor&lt;ValueEvent&gt; disruptor &#x3D;
                new Disruptor&lt;ValueEvent&gt;(ValueEvent.EVENT_FACTORY,
                        RING_BUFFER_SIZE,
                        DaemonThreadFactory.INSTANCE,
                        ProducerType.SINGLE,
                        new YieldingWaitStrategy());

        ValueAdditionEventHandler handler &#x3D; new ValueAdditionEventHandler();
        &#x2F;&#x2F; 设置处理者
        disruptor.handleEventsWith(handler);
        &#x2F;&#x2F; 启动disruptor
        disruptor.start();

        &#x2F;&#x2F; CountDownLatch是为了保证发布的数据被处理完后，才输出结果
        CountDownLatch latch &#x3D; new CountDownLatch(1);
        long expectedCount &#x3D; ITERATIONS - 1;
        handler.reset(latch, expectedCount);

        &#x2F;&#x2F; 生产者生产消息，暂时不用translator
        for (int i &#x3D; 0; i &lt;ITERATIONS; i++) &#123;
            &#x2F;&#x2F; 生产者设置数据并发布
            long next &#x3D; disruptor.getRingBuffer().next();
            disruptor.getRingBuffer().get(next).setValue(i);
            disruptor.getRingBuffer().publish(next);
        &#125;

        &#x2F;&#x2F; 闭锁，等所有的发布的数据被处理完成后，向下执行
        latch.await();
        System.out.println(&quot;mutiProcess: &quot; + handler.getValue());
        disruptor.shutdown();
        &#x2F;&#x2F; 单个线程本地计算结果
        locoalCaculate();
    &#125;

    &#x2F;**
     * 单个线程本地计算
     *&#x2F;
    private static void locoalCaculate() &#123;
        long total &#x3D; 0l;
        for (int i &#x3D; 0; i &lt;ITERATIONS; i++) &#123;
            total +&#x3D; i;
        &#125;
        System.out.println(&quot;local: &quot; + total);
    &#125;

&#125;</code></pre>

<h2 id="2、多对一"><a href="#2、多对一" class="headerlink" title="2、多对一"></a>2、多对一</h2><p>多个生产者和一个消费者之间进行数据传递，和一对一不同的是，涉及到生产者 ValuePublisher 定义。和单生产者不同的时，需要让多个生产者同时工作，并且每个生产者处理其中的某个区间，在本例子中将分为 2 个区间，2 个生产者每个发布各自区间中的数据。首先看下 ValuePublisher 的定义</p>
<h3 id="2-1-生产者-ValuePublisher-定义"><a href="#2-1-生产者-ValuePublisher-定义" class="headerlink" title="2.1 生产者 ValuePublisher 定义"></a>2.1 生产者 ValuePublisher 定义</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">package com.lmax.disruptor.charles;

import java.util.concurrent.CyclicBarrier;

import com.lmax.disruptor.RingBuffer;

public final class ValuePublisher implements Runnable &#123;
    private final CyclicBarrier cyclicBarrier;
    private final RingBuffer&lt;ValueEvent&gt; ringBuffer;
    private final long start;
    private final long end;

    public ValuePublisher(
            final CyclicBarrier cyclicBarrier,
            final RingBuffer&lt;ValueEvent&gt; ringBuffer,
            final long start,
            final long end) &#123;
        this.cyclicBarrier &#x3D; cyclicBarrier;
        this.ringBuffer &#x3D; ringBuffer;
        this.start &#x3D; start;
        this.end &#x3D; end;
    &#125;

    @Override
    public void run() &#123;
        try &#123;
            cyclicBarrier.await();
            for (long i &#x3D; start; i &lt;end; i++) &#123;
                long sequence &#x3D; ringBuffer.next();
                ValueEvent event &#x3D; ringBuffer.get(sequence);
                event.setValue(i);
                ringBuffer.publish(sequence);
            &#125;
        &#125; catch (Exception ex) &#123;
            throw new RuntimeException(ex);
        &#125;
    &#125;

&#125;</code></pre>

<p>CyclicBarrier 确保两个生产者同时生产数据，每个生产者处理[start, end)中数据的发布。</p>
<h3 id="2-2-多生产者数据发布"><a href="#2-2-多生产者数据发布" class="headerlink" title="2.2 多生产者数据发布"></a>2.2 多生产者数据发布</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">package com.lmax.disruptor.charles;

import com.lmax.disruptor.YieldingWaitStrategy;
import com.lmax.disruptor.dsl.Disruptor;
import com.lmax.disruptor.dsl.ProducerType;
import com.lmax.disruptor.util.DaemonThreadFactory;

import java.util.concurrent.BrokenBarrierException;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.CyclicBarrier;

&#x2F;**
 *
 *
 * Sequence a series of events from multiple publishers going to one event processor.
 *
 * +----+
 * | P1 |------+
 * +----+      |
 *             v
 * +----+    +-----+
 * | P2 |---&gt;| EP1 |
 * +----+    +-----+
 *
 * Disruptor:
 * &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;
 *             track to prevent wrap
 *             +--------------------+
 *             |                    |
 *             |                    v
 * +----+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +-----+
 * | P1 |---&gt;| RB |&lt;---| SB |    | EP1 |
 * +----+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +&#x3D;&#x3D;&#x3D;&#x3D;+    +-----+
 *             ^   get    ^         |
 * +----+      |          |         |
 * | P2 |------+          +---------+
 * +----+                   waitFor
 *
 *
 * P1  - Publisher 1
 * P2  - Publisher 2
 * RB  - RingBuffer
 * SB  - SequenceBarrier
 * EP1 - EventProcessor 1
 *
 *
 *&#x2F;
public class ManyToOneDisruptor &#123;

    private static int RING_BUFFER_SIZE &#x3D; 1024 * 16;
    private static long ITERATIONS      &#x3D; 1000L * 1000L * 100L;

    public static void main(String[] args) throws InterruptedException, BrokenBarrierException &#123;

        &#x2F;&#x2F; 单个生产者ProducerType.MULTI，消费者的等待策略为YieldingWaitStrategy
        Disruptor&lt;ValueEvent&gt; disruptor &#x3D;
                new Disruptor&lt;ValueEvent&gt;(ValueEvent.EVENT_FACTORY,
                        RING_BUFFER_SIZE,
                        DaemonThreadFactory.INSTANCE,
                        ProducerType.MULTI,
                        new YieldingWaitStrategy());

        ValueAdditionEventHandler handler &#x3D; new ValueAdditionEventHandler();
        &#x2F;&#x2F; 设置处理者
        disruptor.handleEventsWith(handler);
        &#x2F;&#x2F; 启动disruptor
        disruptor.start();

        &#x2F;&#x2F; CountDownLatch是为了保证发布的数据被处理完后，才输出结果
        CountDownLatch latch &#x3D; new CountDownLatch(1);
        handler.reset(latch, ITERATIONS - 1);

        &#x2F;&#x2F; 保证2个生产者同时生产数据
        CyclicBarrier cyclicBarrier &#x3D; new CyclicBarrier(3);

        &#x2F;&#x2F; 定义生产者，以及生产的数据区间[start, end)
        ValuePublisher publisher1 &#x3D; new ValuePublisher(cyclicBarrier,
                disruptor.getRingBuffer(),
                0,
                ITERATIONS &#x2F; 2);
        new Thread(publisher1).start();

        ValuePublisher publisher2 &#x3D; new ValuePublisher(cyclicBarrier,
                disruptor.getRingBuffer(),
                ITERATIONS &#x2F; 2,
                ITERATIONS);
        new Thread(publisher2).start();

        &#x2F;&#x2F; 所有的生产者线程都同时运行
        cyclicBarrier.await();
        &#x2F;&#x2F; 等待计算完成
        latch.await();
        System.out.println(&quot;mutiProcess: &quot; + handler.getValue());
        disruptor.shutdown();
        &#x2F;&#x2F; 单个线程本地计算
        locoalCaculate();
    &#125;

    &#x2F;**
     * 单个线程本地计算
     *&#x2F;
    private static void locoalCaculate() &#123;
        long total &#x3D; 0l;
        for (int i &#x3D; 0; i &lt;ITERATIONS; i++) &#123;
            total +&#x3D; i;
        &#125;
        System.out.println(&quot;localProcess: &quot; + total);
    &#125;

&#125;</code></pre>

<p>上面主要演示了一对一和多对一的使用，关于其他的使用方式，可以访问 <a href="%5Bhttps://github.com/LMAX-Exchange/disruptor%5D(https://github.com/LMAX-Exchange/disruptor)">Disruptor</a> 进行查看其他的官方例子。</p>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 读优化</title>
    <url>/article/hbase/hbase-read-optimize/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://blog.csdn.net/weixin_40954192/article/details/106942029">https://blog.csdn.net/weixin_40954192&#x2F;article&#x2F;details&#x2F;106942029</a></p>
</blockquote>
<p>LSM 存储引擎是在 B+树的基础上衍生过来的，目的就是为了在读和写之间，提高写的性能。所以，LSM 树的弊端也由此可见，对读并不是很友好，所以，针对 LSM 树，有后续 compact，布隆过滤器，blockCache 等优化方式。来弥补对读的查询。<br>LSM 树的索引一般由 2 部分构成，一部分是内存部分，一部分是磁盘部分。内存部分采用跳跃表来维护一个有序的 KV 集合,也就是 memstore.随着内存不断数据写入，一旦内存占用超过一定的阈值，就把内存部分数据进行导出（这里的 flush 操作实则是通过两个跳跃表来完成的），形成一个有序的数据文件，存储在磁盘上，磁盘部分则是对应的 hFile。</p>
<h2 id="keyValue-存储格式"><a href="#keyValue-存储格式" class="headerlink" title="keyValue 存储格式"></a>keyValue 存储格式</h2><p>LSM 树中存储的是多个 keyValue 组成的集合。每一个 KeyValue 由一个字节数组来表示。如图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915437003-ca220200-1508-4b7f-9a2e-65f702f2d1e9.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=263&id=uf54582c0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=263&originWidth=1165&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=37515&status=done&style=none&taskId=ue4a68932-475c-49b0-9604-0ec8205fec1&title=&width=1165" alt="image.png"></p>
<h2 id="LSM-索引结构"><a href="#LSM-索引结构" class="headerlink" title="LSM 索引结构"></a>LSM 索引结构</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915452495-be03b890-a16f-4960-9043-b7a11fcf17ec.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=740&id=u1c1b950f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=740&originWidth=1006&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=90458&status=done&style=none&taskId=ueac0d2b5-5c06-43c2-af65-786d4db2922&title=&width=1006" alt="image.png">在 hbase 实现中，memstore 的数据达到某个级别的阈值之后，都会进行 flush 到 disk 中，形成一个 file。（前提为了怕 memstore 内存数据丢失，会先将数据写入到所属 regionServer 的 WAL 预写日志中）这个 file 的存储也就是一个小的 B+树，因为 hbase 一般是部署在 hdfs 上，hdfs 不支持对文件的 update 操作，而且最终随着磁盘文件越来越多，对读的影响很大。所以内存 flush 到磁盘上的小树，定期也会合并成一个大树。来增强读操作的性能，整体上 hbase 就是用了 lsm tree 的思路。</p>
<h2 id="多路归并"><a href="#多路归并" class="headerlink" title="多路归并"></a>多路归并</h2><p>为了优化读取操作的性能，hbase 会进行两种类型的 compact。<br><strong>一种是 major Compact，是将所有的 HFile 一次性多路归并成一个文件</strong>。这种方式的好处是，合并之后只有一个文件，这样读取的性能肯定是最高的。但它的问题是合并所有的文件可能需要很长的时间并消耗大量的 IO 贷款，所以 major Compact 不宜使用太频繁，适合周期性的跑。或者我们手动设置在闲时合并。<br><strong>另一种是 minor Compact，即选中少数几个 Hfile，将他们多路归并成一个文件</strong>。这种方式的有点是可以进行局部的 Compact，通过少量的 IO 减少文件个数，提高读取操作的性能。适合较高频率的跑。但它的缺点是只合并了局部的数据，对于那些全局删除操作，无法在合并过程中完全删除。</p>
<h2 id="多路归并原理"><a href="#多路归并原理" class="headerlink" title="多路归并原理"></a>多路归并原理</h2><p>比如现在我们有 K 个文件，其中第 i 个文件内存存储有 N 个正整数（这些整数在文件内按照从小到大的顺序排序）<br>多路归并的算法原理就是对每个文件设计一个指针，取出 K 个指针中数值最小的一个（对应的 K 个文件），然后把最小的那个指针后移，接着继续找 K 个指针中数值最小的一个，继续后移指针…直到文件全部读完为止。如图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915475324-aaf3a59d-f6fe-4944-9012-5e22fc9149da.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=791&id=u06632d08&margin=%5Bobject%20Object%5D&name=image.png&originHeight=791&originWidth=742&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=70335&status=done&style=none&taskId=u585d56ee-4dad-479e-b1dc-eb44883e88f&title=&width=742" alt="image.png"><br>针对读取操作，还涉及到了布隆过滤器。<br>布隆过滤器是由一个长度为 N 的 01 数组组成的。首先将数组 array 每个元素初始设为 0，对集合 A 中的每个元素 w，做 K 次哈希，第 i 次哈希值对 N 取模得到一个 index(i).即 index(i) &#x3D; Hash_i（w） % N,将 array 数组中的 array[index(i)] 置为 1.最终变为一个这些元素为 1 的 01 数组。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915498955-975c2bea-6ff2-4e5d-af75-1169d740f0ce.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=699&id=u7296dd92&margin=%5Bobject%20Object%5D&name=image.png&originHeight=699&originWidth=886&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=99911&status=done&style=none&taskId=u6465223c-5d78-4432-9628-51e703954a2&title=&width=886" alt="image.png">正是由于布隆过滤器只需占用极小的空间，便可给出 “可能存在” 和 “肯定不存在”的存在性判断。因此可以提前过滤掉很多不必要的数据块，从而节省了大量的磁盘 IO。hbase 的 get 操作就是通过运用低成本高效率的布隆过滤器来过滤大量无效数据块的，从而节省了大量磁盘 IO。</p>
<p>如果在表中设置了 Bloomfilter，那么 HBase 会在生成 StoreFile 时包含一份 bloomfilter 结构的数据，称其为 MetaBlock；MetaBlock 与 DataBlock（真实的 KeyValue 数据）一起由 LRUBlockCache 维护。所以，开启 bloomfilter 会有一定的存储及内存 cache 开销。</p>
<p>布隆过滤器的 3 中类型：</p>
<ul>
<li>none，关闭布隆过滤器功能</li>
<li>row，按照 rowkey 计算布隆过滤器的二进制串并存储。get 查询时，必须带 rowkey.</li>
<li>rowcol，按照 rowkey+family+qualifier 这 3 个字段拼出 byte[]来计算布隆过滤器值并存储。如果查询时，get 可以指定到这 3 个字段，则肯定可以通过布隆过滤器提高性能。</li>
</ul>
<p>任何类型的 get（基于 rowkey 或 row+col）Bloom Filter 的优化都能生效，关键是 get 的类型要匹配 Bloom Filter 的类型<br>基于 row 的 scan 是没办法走 Bloom Filter 的。因为<strong>Bloom Filter</strong>是需要事先知道过滤项的。对于顺序 scan 是没有事先办法知道 rowkey 的。而 get 是指明了 rowkey 所以可以用 Bloom Filter，scan 指明 column 同理。</p>
<p>一般意义上的 scan 操作，是没法使用布隆过滤器提升性能的，因为布隆过滤器的 key 不确定。但是 row+col+qualify 的 scan 可以借助布隆过滤器去掉不存在此 qualify 的 storefile，也算是不错的优化了，而且指明 qualify 也能减少流量，因此 scan 尽量指明 qualify<br>关于<strong>BlockCache</strong>的内容较多，在后续文章补充。</p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase （一）系统架构</title>
    <url>/article/hbase/hbase-architecture/</url>
    <content><![CDATA[<p>本文基本是对 MapR 的官网文章<a href="https://mapr.com/blog/in-depth-look-hbase-architecture/">An In-Depth Look at the HBase Architecture</a>的翻译</p>
<h2 id="HBase-存储架构"><a href="#HBase-存储架构" class="headerlink" title="HBase 存储架构"></a>HBase 存储架构</h2><p>HBase 采用 Master&#x2F;Slave 架构搭建集群，它隶属于 Hadoop 生态系统，由一下类型节点组成：HMaster 节点、HRegionServer 节点、ZooKeeper 集群，而在底层，它将数据存储于 HDFS 中，因而涉及到 HDFS 的 NameNode、DataNode 等，总体结构如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578858-a17a0bfb-0f8d-419b-885f-148ebbca588f.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u723b4673&margin=%5Bobject%20Object%5D&name=image.png&originHeight=411&originWidth=711&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=240958&status=done&style=none&taskId=u454e491c-809a-4e79-83c8-a5682ce06d5&title=" alt="image.png"></p>
<h3 id="HMaster-节点"><a href="#HMaster-节点" class="headerlink" title="HMaster 节点"></a>HMaster 节点</h3><ul>
<li>管理 HRegionServer，实现其负载均衡。</li>
<li>管理和分配 HRegion，比如在 HRegion split 时分配新的 HRegion；在 HRegionServer 退出时迁移其内的 HRegion 到其他 HRegionServer 上。</li>
<li>实现 DDL 操作（Data Definition Language，namespace 和 table 的增删改，column familiy 的增删改等）。</li>
<li>管理 namespace 和 table 的元数据（实际存储在 HDFS 上）。</li>
<li>权限控制（ACL）。</li>
</ul>
<h3 id="HRegionServer-节点"><a href="#HRegionServer-节点" class="headerlink" title="HRegionServer 节点"></a>HRegionServer 节点</h3><ul>
<li>存放和管理本地 HRegion。</li>
<li>读写 HDFS，管理 Table 中的数据。</li>
<li>Client 直接通过 HRegionServer 读写数据（从 HMaster 中获取元数据，找到 RowKey 所在的 HRegion&#x2F;HRegionServer 后）。</li>
</ul>
<h3 id="ZooKeeper-集群协调系统"><a href="#ZooKeeper-集群协调系统" class="headerlink" title="ZooKeeper 集群协调系统"></a>ZooKeeper 集群协调系统</h3><ul>
<li>存放整个 HBase 集群的元数据以及集群的状态信息。</li>
<li>实现 HMaster 主从节点的 failover。</li>
</ul>
<p>HBase Client 通过 RPC 方式和 HMaster、HRegionServer 通信；一个 HRegionServer 可以存放 1000 个 HRegion；底层 Table 数据存储于 HDFS 中，而 HRegion 所处理的数据尽量和数据所在的 DataNode 在一起，实现数据的本地化；数据本地化并不是总能实现，比如在 HRegion 移动(如因 Split)时，需要等下一次 Compact 才能继续回到本地化。<br>《An In-Depth Look At The HBase Architecture》的架构图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578621-e7f149be-14ec-4a2d-b62e-6fcbe2acacf7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8bc90172&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=632&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108396&status=done&style=none&taskId=u04136b8b-47ca-414a-99ef-8f070c7ddb5&title=" alt="image.png"><br>这个架构图比较清晰的表达了 HMaster 和 NameNode 都支持多个热备份，使用 ZooKeeper 来做协调；ZooKeeper 并不是云般神秘，它一般由三台机器组成一个集群，内部使用 PAXOS 算法支持三台 Server 中的一台宕机，也有使用五台机器的，此时则可以支持同时两台宕机，既少于半数的宕机，然而随着机器的增加，它的性能也会下降；RegionServer 和 DataNode 一般会放在相同的 Server 上实现数据的本地化。</p>
<h2 id="HRegion"><a href="#HRegion" class="headerlink" title="HRegion"></a>HRegion</h2><p>HBase 使用 RowKey 将表水平切割成多个 HRegion，从 HMaster 的角度，每个 HRegion 都纪录了它的 StartKey 和 EndKey（第一个 HRegion 的 StartKey 为空，最后一个 HRegion 的 EndKey 为空），由于 RowKey 是排序的，因而 Client 可以通过 HMaster 快速的定位每个 RowKey 在哪个 HRegion 中。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 负责 HRegion 的启动和管理，和 Client 的通信，负责数据的读(使用 HDFS)。每个 HRegionServer 可以同时管理 1000 个左右的 HRegion（这个数字怎么来的？没有从代码中看到限制，难道是出于经验？超过 1000 个会引起性能问题？来回答这个问题：感觉这个 1000 的数字是从 BigTable 的论文中来的（5 Implementation 节）：Each tablet server manages a set of tablets(typically we have somewhere between ten to a thousand tablets per tablet server)）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578679-bdc90194-2fa0-4548-9d6a-dc05c68b2b28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf01c9495&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108162&status=done&style=none&taskId=u6b6133cb-a01c-4ce1-9c25-07763a60d97&title=" alt="image.png"></p>
<h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2><p>HMaster 没有单点故障问题，可以启动多个 HMaster，通过 ZooKeeper 的 Master Election 机制保证同时只有一个 HMaster 出于 Active 状态，其他的 HMaster 则处于热备份状态。一般情况下会启动两个 HMaster，非 Active 的 HMaster 会定期的和 Active HMaster 通信以获取其最新状态，从而保证它是实时更新的，因而如果启动了多个 HMaster 反而增加了 Active HMaster 的负担。前文已经介绍过了 HMaster 的主要用于 HRegion 的分配和管理，DDL(Data Definition Language，既 Table 的新建、删除、修改等)的实现等，既它主要有两方面的职责：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578676-90123c3d-eef5-4a0f-9854-893368a11cb3.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u78a55d4e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=367&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=86163&status=done&style=none&taskId=u176d4cf8-2a32-44ce-89a5-46dfff7582d&title=" alt="image.png"></p>
<h3 id="协调-HRegionServer"><a href="#协调-HRegionServer" class="headerlink" title="协调 HRegionServer"></a>协调 HRegionServer</h3><ul>
<li>启动时 HRegion 的分配，以及负载均衡和修复时 HRegion 的重新分配。</li>
<li>监控集群中所有 HRegionServer 的状态(通过 Heartbeat 和监听 ZooKeeper 中的状态)。</li>
</ul>
<h3 id="Admin-职能"><a href="#Admin-职能" class="headerlink" title="Admin 职能"></a>Admin 职能</h3><ul>
<li>创建、删除、修改 Table 的定义。</li>
</ul>
<h2 id="ZooKeeper-协调者"><a href="#ZooKeeper-协调者" class="headerlink" title="ZooKeeper 协调者"></a>ZooKeeper 协调者</h2><p>ZooKeeper 为 HBase 集群提供协调服务，它管理着 HMaster 和 HRegionServer 的状态(available&#x2F;alive 等)，并且会在它们宕机时通知给 HMaster，从而 HMaster 可以实现 HMaster 之间的 failover，或对宕机的 HRegionServer 中的 HRegion 集合的修复(将它们分配给其他的 HRegionServer)。ZooKeeper 集群本身使用一致性协议(PAXOS 协议)保证每个节点状态的一致性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578733-c859758f-8f4f-4919-a401-76ece989c145.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u355c5a55&margin=%5Bobject%20Object%5D&name=image.png&originHeight=318&originWidth=703&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=100372&status=done&style=none&taskId=u8d5eb963-5e89-4827-87e6-99f933cf92d&title=" alt="image.png"></p>
<h2 id="How-The-Components-Work-Together"><a href="#How-The-Components-Work-Together" class="headerlink" title="How The Components Work Together"></a>How The Components Work Together</h2><p>ZooKeeper 协调集群所有节点的共享信息，在 HMaster 和 HRegionServer 连接到 ZooKeeper 后创建 Ephemeral 节点，并使用 Heartbeat 机制维持这个节点的存活状态，如果某个 Ephemeral 节点实效，则 HMaster 会收到通知，并做相应的处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580371-8380eb6c-c579-418b-be2b-48b0f83658b0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u09e4cba8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=116454&status=done&style=none&taskId=u3c9ac6e6-13d4-46c1-b3fa-95947b15824&title=" alt="image.png"><br>另外，HMaster 通过监听 ZooKeeper 中的 Ephemeral 节点(默认：&#x2F;hbase&#x2F;rs&#x2F;*)来监控 HRegionServer 的加入和宕机。在第一个 HMaster 连接到 ZooKeeper 时会创建 Ephemeral 节点(默认：&#x2F;hbasae&#x2F;master)来表示 Active 的 HMaster，其后加进来的 HMaster 则监听该 Ephemeral 节点，如果当前 Active 的 HMaster 宕机，则该节点消失，因而其他 HMaster 得到通知，而将自身转换成 Active 的 HMaster，在变为 Active 的 HMaster 之前，它会创建在&#x2F;hbase&#x2F;back-masters&#x2F;下创建自己的 Ephemeral 节点。</p>
<h3 id="HBase-的第一次读写"><a href="#HBase-的第一次读写" class="headerlink" title="HBase 的第一次读写"></a>HBase 的第一次读写</h3><p>在 HBase 0.96 以前，HBase 有两个特殊的 Table：-ROOT-和.META.（如<a href="http://research.google.com/archive/bigtable-osdi06.pdf">BigTable</a>中的设计），其中-ROOT- Table 的位置存储在 ZooKeeper，它存储了.META. Table 的 RegionInfo 信息，并且它只能存在一个 HRegion，而.META. Table 则存储了用户 Table 的 RegionInfo 信息，它可以被切分成多个 HRegion，因而对第一次访问用户 Table 时，首先从 ZooKeeper 中读取-ROOT- Table 所在 HRegionServer；然后从该 HRegionServer 中根据请求的 TableName，RowKey 读取.META. Table 所在 HRegionServer；最后从该 HRegionServer 中读取.META. Table 的内容而获取此次请求需要访问的 HRegion 所在的位置，然后访问该 HRegionSever 获取请求的数据，这需要三次请求才能找到用户 Table 所在的位置，然后第四次请求开始获取真正的数据。当然为了提升性能，客户端会缓存-ROOT- Table 位置以及-ROOT-&#x2F;.META. Table 的内容。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580326-61fe3d03-5e26-4113-a242-d514c6e314a2.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6618f3ca&margin=%5Bobject%20Object%5D&name=image.png&originHeight=228&originWidth=399&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=45988&status=done&style=none&taskId=uc4946914-9a62-4a41-aab7-e197f2ede54&title=" alt="image.png"><br>可是即使客户端有缓存，在初始阶段需要三次请求才能直到用户 Table 真正所在的位置也是性能低下的，而且真的有必要支持那么多的 HRegion 吗？或许对 Google 这样的公司来说是需要的，但是对一般的集群来说好像并没有这个必要。在 BigTable 的论文中说，每行 METADATA 存储 1KB 左右数据，中等大小的 Tablet(HRegion)在 128MB 左右，3 层位置的 Schema 设计可以支持 2^34 个 Tablet(HRegion)。即使去掉-ROOT- Table，也还可以支持 2^17(131072)个 HRegion， 如果每个 HRegion 还是 128MB，那就是 16TB，这个貌似不够大，但是现在的 HRegion 的最大大小都会设置的比较大，比如我们设置了 2GB，此时支持的大小则变成了 4PB，对一般的集群来说已经够了，因而在 HBase 0.96 以后去掉了-ROOT- Table，只剩下这个特殊的目录表叫做 Meta Table(hbase:meta)，它存储了集群中所有用户 HRegion 的位置信息，而 ZooKeeper 的节点中(&#x2F;hbase&#x2F;meta-region-server)存储的则直接是这个 Meta Table 的位置，并且这个 Meta Table 如以前的-ROOT- Table 一样是不可 split 的。这样，客户端在第一次访问用户 Table 的流程就变成了：</p>
<ul>
<li>从 ZooKeeper(&#x2F;hbase&#x2F;meta-region-server)中获取 hbase:meta 的位置（HRegionServer 的位置），缓存该位置信息。</li>
<li>从 HRegionServer 中查询用户 Table 对应请求的 RowKey 所在的 HRegionServer，缓存该位置信息。</li>
<li>从查询到 HRegionServer 中读取 Row。</li>
</ul>
<p>从这个过程中，我们发现客户会缓存这些位置信息，然而第二步它只是缓存当前 RowKey 对应的 HRegion 的位置，因而如果下一个要查的 RowKey 不在同一个 HRegion 中，则需要继续查询 hbase:meta 所在的 HRegion，然而随着时间的推移，客户端缓存的位置信息越来越多，以至于不需要再次查找 hbase:meta Table 的信息，除非某个 HRegion 因为宕机或 Split 被移动，此时需要重新查询并且更新缓存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580741-c98bab14-3341-4784-9af5-cbad496ba448.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2d56a83a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=356&originWidth=590&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=75992&status=done&style=none&taskId=u1bb7d5f9-92df-4a3c-a110-20319264562&title=" alt="image.png"></p>
<h3 id="hbase-meta-表"><a href="#hbase-meta-表" class="headerlink" title="hbase:meta 表"></a>hbase:meta 表</h3><p>hbase:meta 表存储了所有用户 HRegion 的位置信息，它的 RowKey 是：tableName,regionStartKey,regionId,replicaId 等，它只有 info 列族，这个列族包含三个列，他们分别是：info:regioninfo 列是 RegionInfo 的 proto 格式：regionId,tableName,startKey,endKey,offline,split,replicaId；info:server 格式：HRegionServer 对应的 server:port；info:serverstartcode 格式是 HRegionServer 的启动时间戳。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580891-6feb81e6-8d18-4d3c-9583-be28019444e0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9776aea4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=362&originWidth=736&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115586&status=done&style=none&taskId=u6aecdbed-2fa8-4c2d-9f07-d26905069e2&title=" alt="image.png"></p>
<h2 id="HRegionServer-详解"><a href="#HRegionServer-详解" class="headerlink" title="HRegionServer 详解"></a>HRegionServer 详解</h2><p>HRegionServer 一般和 DataNode 在同一台机器上运行，实现数据的本地性。HRegionServer 包含多个 HRegion，由 WAL(HLog)、BlockCache、MemStore、HFile 组成。</p>
<ol>
<li>WAL 即 Write Ahead Log，在早期版本中称为 HLog，它是 HDFS 上的一个文件，如其名字所表示的，所有写操作都会先保证将数据写入这个 Log 文件后，才会真正更新 MemStore，最后写入 HFile 中。采用这种模式，可以保证 HRegionServer 宕机后，我们依然可以从该 Log 文件中读取数据，Replay 所有的操作，而不至于数据丢失。这个 Log 文件会定期 Roll 出新的文件而删除旧的文件(那些已持久化到 HFile 中的 Log 可以删除)。WAL 文件存储在&#x2F;hbase&#x2F;WALs&#x2F;${HRegionServer_Name}的目录中(在 0.94 之前，存储在&#x2F;hbase&#x2F;.logs&#x2F;目录中)，一般一个 HRegionServer 只有一个 WAL 实例，也就是说一个 HRegionServer 的所有 WAL 写都是串行的(就像 log4j 的日志写也是串行的)，这当然会引起性能问题，因而在 HBase 1.0 之后，通过 <a href="https://issues.apache.org/jira/browse/HBASE-5699">HBASE-5699</a> 实现了多个 WAL 并行写(MultiWAL)，该实现采用 HDFS 的多个管道写，以单个 HRegion 为单位。关于 WAL 可以参考 Wikipedia 的 <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">Write-Ahead Logging</a> 。顺便吐槽一句，英文版的维基百科竟然能毫无压力的正常访问了，这是某个 GFW 的疏忽还是以后的常态？</li>
<li>BlockCache 是一个读缓存，即“引用局部性”原理（也应用于 CPU，<a href="http://baike.baidu.com/link?url=Dh2u9KvowXcl2PloHJFTB9vEOoVS3WxPhDCVvbQGL_piyKFQ2iTHYAYf5mLAsFrcBUig6NC7A4-Aki61qnGCTK#3_1">分空间局部性和时间局部性</a>，空间局部性是指 CPU 在某一时刻需要某个数据，那么有很大的概率在一下时刻它需要的数据在其附近；时间局部性是指某个数据在被访问过一次后，它有很大的概率在不久的将来会被再次的访问），将数据预读取到内存中，以提升读的性能。HBase 中提供两种 BlockCache 的实现：默认 on-heap LruBlockCache 和 BucketCache(通常是 off-heap)。通常 BucketCache 的性能要差于 LruBlockCache，然而由于 GC 的影响，LruBlockCache 的延迟会变的不稳定，而 BucketCache 由于是自己管理 BlockCache，而不需要 GC，因而它的延迟通常比较稳定，这也是有些时候需要选用 BucketCache 的原因。这篇文章 <a href="http://www.n10k.com/blog/blockcache-101/">BlockCache101</a> 对 on-heap 和 off-heap 的 BlockCache 做了详细的比较。</li>
<li>HRegion 是一个 Table 中的一个 Region 在一个 HRegionServer 中的表达。一个 Table 可以有一个或多个 Region，他们可以在一个相同的 HRegionServer 上，也可以分布在不同的 HRegionServer 上，一个 HRegionServer 可以有多个 HRegion，他们分别属于不同的 Table。HRegion 由多个 Store(HStore)构成，每个 HStore 对应了一个 Table 在这个 HRegion 中的一个 Column Family，即每个 Column Family 就是一个集中的存储单元，因而最好将具有相近 IO 特性的 Column 存储在一个 Column Family，以实现高效读取(数据局部性原理，可以提高缓存的命中率)。HStore 是 HBase 中存储的核心，它实现了读写 HDFS 功能，一个 HStore 由一个 MemStore 和 0 个或多个 StoreFile 组成。<ul>
<li>MemStore 是一个写缓存(In Memory Sorted Buffer)，所有数据的写在完成 WAL 日志写后，会 写入 MemStore 中，由 MemStore 根据一定的算法将数据 Flush 到地层 HDFS 文件中(HFile)，通常每个 HRegion 中的每个 Column Family 有一个自己的 MemStore。</li>
<li>HFile(StoreFile) 用于存储 HBase 的数据(Cell&#x2F;KeyValue)。在 HFile 中的数据是按 RowKey、Column Family、Column 排序，对相同的 Cell(即这三个值都一样)，则按 timestamp 倒序排列。</li>
</ul>
</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581299-289e4273-4207-453d-9a8f-664f4911c72c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u35254fb8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=366&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=95333&status=done&style=none&taskId=u12039456-1add-4c7c-958a-c13ce2debd8&title=" alt="image.png"><br>虽然上面这张图展现的是最新的 HRegionServer 的架构(但是并不是那么的精确)，但是我一直比较喜欢看以下这张图，即使它展现的应该是 0.94 以前的架构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581512-9c74e462-666b-434c-8a29-8d2dcc9afd98.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u71a1066c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=347&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=214681&status=done&style=none&taskId=u3a1655c4-b13b-4c95-a9d6-3fc382b506b&title=" alt="image.png"></p>
<h3 id="HRegionServer-中数据写流程图解"><a href="#HRegionServer-中数据写流程图解" class="headerlink" title="HRegionServer 中数据写流程图解"></a>HRegionServer 中数据写流程图解</h3><p>当客户端发起一个 Put 请求时，首先它从 hbase:meta 表中查出该 Put 数据最终需要去的 HRegionServer。然后客户端将 Put 请求发送给相应的 HRegionServer，在 HRegionServer 中它首先会将该 Put 操作写入 WAL 日志文件中(Flush 到磁盘中)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582098-1768ce69-621c-42ab-8e9f-c088e8777cca.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub4d83a95&margin=%5Bobject%20Object%5D&name=image.png&originHeight=363&originWidth=716&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=71683&status=done&style=none&taskId=u8836b841-21cd-45ad-ad75-2b5427b07bb&title=" alt="image.png"><br>写完 WAL 日志文件后，HRegionServer 根据 Put 中的 TableName 和 RowKey 找到对应的 HRegion，并根据 Column Family 找到对应的 HStore，并将 Put 写入到该 HStore 的 MemStore 中。此时写成功，并返回通知客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582636-fd38aaea-d523-4b11-b13c-1efdef987fd7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf32f92cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=298&originWidth=664&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=63155&status=done&style=none&taskId=u30b36f42-9271-4e99-b1dd-7ce3205c36d&title=" alt="image.png"></p>
<h3 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h3><p>MemStore 是一个 In Memory Sorted Buffer，在每个 HStore 中都有一个 MemStore，即它是一个 HRegion 的一个 Column Family 对应一个实例。它的排列顺序以 RowKey、Column Family、Column 的顺序以及 Timestamp 的倒序，如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582832-94bc8fd5-adc7-418c-9d39-f165199fa60e.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u512fd7af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=719&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=106803&status=done&style=none&taskId=u85f74483-7f18-4a00-a4e7-60cabcf63e6&title=" alt="image.png"><br>每一次 Put&#x2F;Delete 请求都是先写入到 MemStore 中，当 MemStore 满后会 Flush 成一个新的 StoreFile(底层实现是 HFile)，即一个 HStore(Column Family)可以有 0 个或多个 StoreFile(HFile)。有以下三种情况可以触发 MemStore 的 Flush 动作，需要注意的是 MemStore 的最小 Flush 单元是 HRegion 而不是单个 MemStore。据说这是 Column Family 有个数限制的其中一个原因，估计是因为太多的 Column Family 一起 Flush 会引起性能问题？具体原因有待考证。</p>
<ol>
<li>当一个 HRegion 中的所有 MemStore 的大小总和超过了 hbase.hregion.memstore.flush.size 的大小，默认 128MB。此时当前的 HRegion 中所有的 MemStore 会 Flush 到 HDFS 中。</li>
<li>当全局 MemStore 的大小超过了 hbase.regionserver.global.memstore.upperLimit 的大小，默认 40％的内存使用量。此时当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 顺序是 MemStore 大小的倒序（一个 HRegion 中所有 MemStore 总和作为该 HRegion 的 MemStore 的大小还是选取最大的 MemStore 作为参考？有待考证），直到总体的 MemStore 使用量低于 hbase.regionserver.global.memstore.lowerLimit，默认 38%的内存使用量。</li>
<li>当前 HRegionServer 中 WAL 的大小超过了 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs 的数量，当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 使用时间顺序，最早的 MemStore 先 Flush 直到 WAL 的数量少于 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs。<a href="http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/">这里</a>说这两个相乘的默认大小是 2GB，查代码，hbase.regionserver.max.logs 默认值是 32，而 hbase.regionserver.hlog.blocksize 是 HDFS 的默认 blocksize，32MB。但不管怎么样，因为这个大小超过限制引起的 Flush 不是一件好事，可能引起长时间的延迟，因而这篇文章给的建议：“Hint: keep hbase.regionserver.hlog.blocksize _ hbase.regionserver.maxlogs just a bit above hbase.regionserver.global.memstore.lowerLimit _ HBASE_HEAPSIZE.”。并且需要注意，<a href="http://hbase.apache.org/book.html#_memstore_flush">这里</a>给的描述是有错的(虽然它是官方的文档)。</li>
</ol>
<p>在 MemStore Flush 过程中，还会在尾部追加一些 meta 数据，其中就包括 Flush 时最大的 WAL sequence 值，以告诉 HBase 这个 StoreFile 写入的最新数据的序列，那么在 Recover 时就直到从哪里开始。在 HRegion 启动时，这个 sequence 会被读取，并取最大的作为下一次更新时的起始 sequence。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583046-e073a721-456c-4607-89f7-ec5a222e50f0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8e41b38a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=248&originWidth=622&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=64652&status=done&style=none&taskId=u01119a37-ba73-457e-89cf-4e03d0108f9&title=" alt="image.png"></p>
<h2 id="HFile-格式"><a href="#HFile-格式" class="headerlink" title="HFile 格式"></a>HFile 格式</h2><p>HBase 的数据以 KeyValue(Cell)的形式顺序的存储在 HFile 中，在 MemStore 的 Flush 过程中生成 HFile，由于 MemStore 中存储的 Cell 遵循相同的排列顺序，因而 Flush 过程是顺序写，我们直到磁盘的顺序写性能很高，因为不需要不停的移动磁盘指针。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583239-35f30a61-6003-4baa-b78e-d0406b53f458.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uec0329c3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=698&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115221&status=done&style=none&taskId=u3b84bd8d-8533-4733-9068-58f3d383a88&title=" alt="image.png"><br>HFile 参考 BigTable 的 SSTable 和 Hadoop 的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html">TFile</a>实现，从 HBase 开始到现在，HFile 经历了三个版本，其中 V2 在 0.92 引入，V3 在 0.98 引入。首先我们来看一下 V1 的格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583656-2174688c-da96-443f-a46f-d8e391ffc97b.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9844c88d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=160&originWidth=554&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=72628&status=done&style=none&taskId=u55f4c3b1-daf2-4893-935c-09a8dd5acb9&title=" alt="image.png"><br>V1 的 HFile 由多个 Data Block、Meta Block、FileInfo、Data Index、Meta Index、Trailer 组成，其中 Data Block 是 HBase 的最小存储单元，在前文中提到的 BlockCache 就是基于 Data Block 的缓存的。一个 Data Block 由一个魔数和一系列的 KeyValue(Cell)组成，魔数是一个随机的数字，用于表示这是一个 Data Block 类型，以快速监测这个 Data Block 的格式，防止数据的破坏。Data Block 的大小可以在创建 Column Family 时设置(HColumnDescriptor.setBlockSize())，默认值是 64KB，大号的 Block 有利于顺序 Scan，小号 Block 利于随机查询，因而需要权衡。Meta 块是可选的，FileInfo 是固定长度的块，它纪录了文件的一些 Meta 信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY 等。Data Index 和 Meta Index 纪录了每个 Data 块和 Meta 块的其实点、未压缩时大小、Key(起始 RowKey？)等。Trailer 纪录了 FileInfo、Data Index、Meta Index 块的起始位置，Data Index 和 Meta Index 索引的数量等。其中 FileInfo 和 Trailer 是固定长度的。<br>HFile 里面的每个 KeyValue 对就是一个简单的 byte 数组。但是这个 byte 数组里面包含了很多项，并且有固定的结构。我们来看看里面的具体结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583953-34c63a35-4c72-417a-bb89-8902777196ee.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ufac2071c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=93&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=68710&status=done&style=none&taskId=u99911b0c-045d-4a97-bbe0-73cbdafbed4&title=" alt="image.png"><br>开始是两个固定长度的数值，分别表示 Key 的长度和 Value 的长度。紧接着是 Key，开始是固定长度的数值，表示 RowKey 的长度，紧接着是 RowKey，然后是固定长度的数值，表示 Family 的长度，然后是 Family，接着是 Qualifier，然后是两个固定长度的数值，表示 Time Stamp 和 Key Type（Put&#x2F;Delete）。Value 部分没有这么复杂的结构，就是纯粹的二进制数据了。随着 HFile 版本迁移，KeyValue(Cell)的格式并未发生太多变化，只是在 V3 版本，尾部添加了一个可选的 Tag 数组。<br>HFileV1 版本的在实际使用过程中发现它占用内存多，并且 Bloom File 和 Block Index 会变的很大，而引起启动时间变长。其中每个 HFile 的 Bloom Filter 可以增长到 100MB，这在查询时会引起性能问题，因为每次查询时需要加载并查询 Bloom Filter，100MB 的 Bloom Filer 会引起很大的延迟；另一个，Block Index 在一个 HRegionServer 可能会增长到总共 6GB，HRegionServer 在启动时需要先加载所有这些 Block Index，因而增加了启动时间。为了解决这些问题，在 0.92 版本中引入 HFileV2 版本：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916584996-bbbb6bb6-fc78-4a2c-8547-8ec1dbf366a1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7e338f01&margin=%5Bobject%20Object%5D&name=image.png&originHeight=418&originWidth=566&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=59249&status=done&style=none&taskId=u3169ce73-eb5d-4b8b-8c12-fe22df00816&title=" alt="image.png"><br>在这个版本中，Block Index 和 Bloom Filter 添加到了 Data Block 中间，而这种设计同时也减少了写的内存使用量；另外，为了提升启动速度，在这个版本中还引入了延迟读的功能，即在 HFile 真正被使用时才对其进行解析。<br>FileV3 版本基本和 V2 版本相比，并没有太大的改变，它在 KeyValue(Cell)层面上添加了 Tag 数组的支持；并在 FileInfo 结构中添加了和 Tag 相关的两个字段。关于具体 HFile 格式演化介绍，可以参考<a href="http://hbase.apache.org/book.html#_hfile_format_2">这里</a>。<br>对 HFileV2 格式具体分析，它是一个多层的类 B+树索引，采用这种设计，可以实现查找不需要读取整个文件：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585756-2c38fca8-e68c-4d91-a8dd-7d557a9b30bc.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u667d00a9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=349&originWidth=688&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107524&status=done&style=none&taskId=u8dc1ef81-99a0-428d-b317-b7c86f91e80&title=" alt="image.png"><br>Data Block 中的 Cell 都是升序排列，每个 block 都有它自己的 Leaf-Index，每个 Block 的最后一个 Key 被放入 Intermediate-Index 中，Root-Index 指向 Intermediate-Index。在 HFile 的末尾还有 Bloom Filter 用于快速定位那么没有在某个 Data Block 中的 Row；TimeRange 信息用于给那些使用时间查询的参考。在 HFile 打开时，这些索引信息都被加载并保存在内存中，以增加以后的读取性能。</p>
<h2 id="HBase-读的实现"><a href="#HBase-读的实现" class="headerlink" title="HBase 读的实现"></a>HBase 读的实现</h2><p>通过前文的描述，我们知道在 HBase 写时，相同 Cell(RowKey&#x2F;ColumnFamily&#x2F;Column 相同)并不保证在一起，甚至删除一个 Cell 也只是写入一个新的 Cell，它含有 Delete 标记，而不一定将一个 Cell 真正删除了，因而这就引起了一个问题，如何实现读的问题？要解决这个问题，我们先来分析一下相同的 Cell 可能存在的位置：首先对新写入的 Cell，它会存在于 MemStore 中；然后对之前已经 Flush 到 HDFS 中的 Cell，它会存在于某个或某些 StoreFile(HFile)中；最后，对刚读取过的 Cell，它可能存在于 BlockCache 中。既然相同的 Cell 可能存储在三个地方，在读取的时候只需要扫瞄这三个地方，然后将结果合并即可(Merge Read)，在 HBase 中扫瞄的顺序依次是：BlockCache、MemStore、StoreFile(HFile)。其中 StoreFile 的扫瞄先会使用 Bloom Filter 过滤那些不可能符合条件的 HFile，然后使用 Block Index 快速定位 Cell，并将其加载到 BlockCache 中，然后从 BlockCache 中读取。我们知道一个 HStore 可能存在多个 StoreFile(HFile)，此时需要扫瞄多个 HFile，如果 HFile 过多又是会引起性能问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585461-55084b02-31ea-4bb5-9df2-2ab8931fad2c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u650f6de0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=278&originWidth=769&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107309&status=done&style=none&taskId=ueb6d7da0-a4dc-47eb-bce5-8a4918d43e7&title=" alt="image.png"></p>
<h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>MemStore 每次 Flush 会创建新的 HFile，而过多的 HFile 会引起读的性能问题，那么如何解决这个问题呢？HBase 采用 Compaction 机制来解决这个问题，有点类似 Java 中的 GC 机制，起初 Java 不停的申请内存而不释放，增加性能，然而天下没有免费的午餐，最终我们还是要在某个条件下去收集垃圾，很多时候需要 Stop-The-World，这种 Stop-The-World 有些时候也会引起很大的问题，因而设计是一种权衡，没有完美的。还是类似 Java 中的 GC，在 HBase 中 Compaction 分为两种：Minor Compaction 和 Major Compaction。</p>
<ol>
<li>Minor Compaction 是指选取一些小的、相邻的 StoreFile 将他们合并成一个更大的 StoreFile，在这个过程中不会处理已经 Deleted 或 Expired 的 Cell。一次 Minor Compaction 的结果是更少并且更大的 StoreFile。（这个是对的吗？BigTable 中是这样描述 Minor Compaction 的：As write operations execute, the size of the memtable in- creases. When the memtable size reaches a threshold, the memtable is frozen, a new memtable is created, and the frozen memtable is converted to an SSTable and written to GFS. This minor compaction process has two goals: it shrinks the memory usage of the tablet server, and it reduces the amount of data that has to be read from the commit log during recovery if this server dies. Incom- ing read and write operations can continue while com- pactions occur. 也就是说它将 memtable 的数据 flush 的一个 HFile&#x2F;SSTable 称为一次 Minor Compaction）</li>
<li>Major Compaction 是指将所有的 StoreFile 合并成一个 StoreFile，在这个过程中，标记为 Deleted 的 Cell 会被删除，而那些已经 Expired 的 Cell 会被丢弃，那些已经超过最多版本数的 Cell 会被丢弃。一次 Major Compaction 的结果是一个 HStore 只有一个 StoreFile 存在。Major Compaction 可以手动或自动触发，然而由于它会引起很多的 IO 操作而引起性能问题，因而它一般会被安排在周末、凌晨等集群比较闲的时间。</li>
</ol>
<p>更形象一点，如下面两张图分别表示 Minor Compaction 和 Major Compaction。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585472-7b9745d6-455b-458e-a5e5-a751cc03fadd.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub1833466&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=723&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=94709&status=done&style=none&taskId=u8358d499-81ee-4051-817d-9540dc51bc5&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585518-f8e5d988-133a-4f90-b87d-3370099c3bb1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua80b4458&margin=%5Bobject%20Object%5D&name=image.png&originHeight=339&originWidth=653&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=93417&status=done&style=none&taskId=u2201da79-e7a4-4e5e-af63-b9e178ad60a&title=" alt="image.png"></p>
<h2 id="HRegion-Split"><a href="#HRegion-Split" class="headerlink" title="HRegion Split"></a>HRegion Split</h2><p>最初，一个 Table 只有一个 HRegion，随着数据写入增加，如果一个 HRegion 到达一定的大小，就需要 Split 成两个 HRegion，这个大小由 hbase.hregion.max.filesize 指定，默认为 10GB。当 split 时，两个新的 HRegion 会在同一个 HRegionServer 中创建，它们各自包含父 HRegion 一半的数据，当 Split 完成后，父 HRegion 会下线，而新的两个子 HRegion 会向 HMaster 注册上线，处于负载均衡的考虑，这两个新的 HRegion 可能会被 HMaster 分配到其他的 HRegionServer 中。关于 Split 的详细信息，可以参考这篇文章：<a href="http://hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">《Apache HBase Region Splitting and Merging》</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586158-3ba24d92-6644-4a0f-91a1-d00da5867a28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7d90fe99&margin=%5Bobject%20Object%5D&name=image.png&originHeight=361&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=85469&status=done&style=none&taskId=u7e157502-2bf1-4daf-9c17-071a1dc9564&title=" alt="image.png"></p>
<h2 id="HRegion-负载均衡"><a href="#HRegion-负载均衡" class="headerlink" title="HRegion 负载均衡"></a>HRegion 负载均衡</h2><p>在 HRegion Split 后，两个新的 HRegion 最初会和之前的父 HRegion 在相同的 HRegionServer 上，出于负载均衡的考虑，HMaster 可能会将其中的一个甚至两个重新分配的其他的 HRegionServer 中，此时会引起有些 HRegionServer 处理的数据在其他节点上，直到下一次 Major Compaction 将数据从远端的节点移动到本地节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586722-3a111ac3-cc8a-4dfd-ab85-4e6f68fe4306.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucfafb6f6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=358&originWidth=714&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=113593&status=done&style=none&taskId=u3068847b-f220-4283-af84-153c8256a06&title=" alt="image.png"></p>
<h2 id="HRegionServer-Recovery"><a href="#HRegionServer-Recovery" class="headerlink" title="HRegionServer Recovery"></a>HRegionServer Recovery</h2><p>当一台 HRegionServer 宕机时，由于它不再发送 Heartbeat 给 ZooKeeper 而被监测到，此时 ZooKeeper 会通知 HMaster，HMaster 会检测到哪台 HRegionServer 宕机，它将宕机的 HRegionServer 中的 HRegion 重新分配给其他的 HRegionServer，同时 HMaster 会把宕机的 HRegionServer 相关的 WAL 拆分分配给相应的 HRegionServer(将拆分出的 WAL 文件写入对应的目的 HRegionServer 的 WAL 目录中，并并写入对应的 DataNode 中），从而这些 HRegionServer 可以 Replay 分到的 WAL 来重建 MemStore。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587040-3b89bd6c-f56a-4d12-b005-539cdc9e8aae.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u53643cd9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=368&originWidth=708&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=133786&status=done&style=none&taskId=ued635896-8d3d-47e9-aaa1-848ae861ace&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587014-ac39bb9d-e5ab-48af-9f60-8389745baa26.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u22d50009&margin=%5Bobject%20Object%5D&name=image.png&originHeight=378&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=79489&status=done&style=none&taskId=u3d4037a7-ea2b-4d85-8a02-fa381b36016&title=" alt="image.png"><br>HBase 架构简单总结 在 NoSQL 中，存在著名的 CAP 理论，即 Consistency、Availability、Partition Tolerance 不可全得，目前市场上基本上的 NoSQL 都采用 Partition Tolerance 以实现数据得水平扩展，来处理 Relational DataBase 遇到的无法处理数据量太大的问题，或引起的性能问题。因而只有剩下 C 和 A 可以选择。HBase 在两者之间选择了 Consistency，然后使用多个 HMaster 以及支持 HRegionServer 的 failure 监控、ZooKeeper 引入作为协调者等各种手段来解决 Availability 问题，然而当网络的 Split-Brain(Network Partition)发生时，它还是无法完全解决 Availability 的问题。从这个角度上，Cassandra 选择了 A，即它在网络 Split-Brain 时还是能正常写，而使用其他技术来解决 Consistency 的问题，如读的时候触发 Consistency 判断和处理。这是设计上的限制。<br>从实现上的优点</p>
<ol>
<li>HBase 采用强一致性模型，在一个写返回后，保证所有的读都读到相同的数据。</li>
<li>通过 HRegion 动态 Split 和 Merge 实现自动扩展，并使用 HDFS 提供的多个数据备份功能，实现高可用性。</li>
<li>采用 HRegionServer 和 DataNode 运行在相同的服务器上实现数据的本地化，提升读写性能，并减少网络压力。</li>
<li>内建 HRegionServer 的宕机自动恢复。采用 WAL 来 Replay 还未持久化到 HDFS 的数据。</li>
<li>可以无缝的和 Hadoop&#x2F;MapReduce 集成。</li>
</ol>
<p>实现上的缺点</p>
<ol>
<li>WAL 的 Replay 过程可能会很慢。</li>
<li>灾难恢复比较复杂，也会比较慢。</li>
<li>Major Compaction 会引起 IO Storm。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture/">https://www.mapr.com/blog/in-depth-look-hbase-architecture/</a><br><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable</a><br><a href="http://hbase.apache.org/book.html">http://hbase.apache.org/book.html</a><br><a href="http://www.searchtb.com/2011/01/understanding-hbase.html">http://www.searchtb.com/2011/01/understanding-hbase.html</a><br><a href="http://research.google.com/archive/bigtable-osdi06.pdf">http://research.google.com/archive/bigtable-osdi06.pdf</a></p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase 系统架构</title>
    <url>/article/hbase/hbase-architecture/</url>
    <content><![CDATA[<p>本文基本是对 MapR 的官网文章<a href="https://mapr.com/blog/in-depth-look-hbase-architecture/">An In-Depth Look at the HBase Architecture</a>的翻译</p>
<h2 id="HBase-存储架构"><a href="#HBase-存储架构" class="headerlink" title="HBase 存储架构"></a>HBase 存储架构</h2><p>HBase 采用 Master&#x2F;Slave 架构搭建集群，它隶属于 Hadoop 生态系统，由一下类型节点组成：HMaster 节点、HRegionServer 节点、ZooKeeper 集群，而在底层，它将数据存储于 HDFS 中，因而涉及到 HDFS 的 NameNode、DataNode 等，总体结构如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578858-a17a0bfb-0f8d-419b-885f-148ebbca588f.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u723b4673&margin=%5Bobject%20Object%5D&name=image.png&originHeight=411&originWidth=711&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=240958&status=done&style=none&taskId=u454e491c-809a-4e79-83c8-a5682ce06d5&title=" alt="image.png"></p>
<h3 id="HMaster-节点"><a href="#HMaster-节点" class="headerlink" title="HMaster 节点"></a>HMaster 节点</h3><ul>
<li>管理 HRegionServer，实现其负载均衡。</li>
<li>管理和分配 HRegion，比如在 HRegion split 时分配新的 HRegion；在 HRegionServer 退出时迁移其内的 HRegion 到其他 HRegionServer 上。</li>
<li>实现 DDL 操作（Data Definition Language，namespace 和 table 的增删改，column familiy 的增删改等）。</li>
<li>管理 namespace 和 table 的元数据（实际存储在 HDFS 上）。</li>
<li>权限控制（ACL）。</li>
</ul>
<h3 id="HRegionServer-节点"><a href="#HRegionServer-节点" class="headerlink" title="HRegionServer 节点"></a>HRegionServer 节点</h3><ul>
<li>存放和管理本地 HRegion。</li>
<li>读写 HDFS，管理 Table 中的数据。</li>
<li>Client 直接通过 HRegionServer 读写数据（从 HMaster 中获取元数据，找到 RowKey 所在的 HRegion&#x2F;HRegionServer 后）。</li>
</ul>
<h3 id="ZooKeeper-集群协调系统"><a href="#ZooKeeper-集群协调系统" class="headerlink" title="ZooKeeper 集群协调系统"></a>ZooKeeper 集群协调系统</h3><ul>
<li>存放整个 HBase 集群的元数据以及集群的状态信息。</li>
<li>实现 HMaster 主从节点的 failover。</li>
</ul>
<p>HBase Client 通过 RPC 方式和 HMaster、HRegionServer 通信；一个 HRegionServer 可以存放 1000 个 HRegion；底层 Table 数据存储于 HDFS 中，而 HRegion 所处理的数据尽量和数据所在的 DataNode 在一起，实现数据的本地化；数据本地化并不是总能实现，比如在 HRegion 移动(如因 Split)时，需要等下一次 Compact 才能继续回到本地化。<br>《An In-Depth Look At The HBase Architecture》的架构图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578621-e7f149be-14ec-4a2d-b62e-6fcbe2acacf7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8bc90172&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=632&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108396&status=done&style=none&taskId=u04136b8b-47ca-414a-99ef-8f070c7ddb5&title=" alt="image.png"><br>这个架构图比较清晰的表达了 HMaster 和 NameNode 都支持多个热备份，使用 ZooKeeper 来做协调；ZooKeeper 并不是云般神秘，它一般由三台机器组成一个集群，内部使用 PAXOS 算法支持三台 Server 中的一台宕机，也有使用五台机器的，此时则可以支持同时两台宕机，既少于半数的宕机，然而随着机器的增加，它的性能也会下降；RegionServer 和 DataNode 一般会放在相同的 Server 上实现数据的本地化。</p>
<h2 id="HRegion"><a href="#HRegion" class="headerlink" title="HRegion"></a>HRegion</h2><p>HBase 使用 RowKey 将表水平切割成多个 HRegion，从 HMaster 的角度，每个 HRegion 都纪录了它的 StartKey 和 EndKey（第一个 HRegion 的 StartKey 为空，最后一个 HRegion 的 EndKey 为空），由于 RowKey 是排序的，因而 Client 可以通过 HMaster 快速的定位每个 RowKey 在哪个 HRegion 中。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 负责 HRegion 的启动和管理，和 Client 的通信，负责数据的读(使用 HDFS)。每个 HRegionServer 可以同时管理 1000 个左右的 HRegion（这个数字怎么来的？没有从代码中看到限制，难道是出于经验？超过 1000 个会引起性能问题？来回答这个问题：感觉这个 1000 的数字是从 BigTable 的论文中来的（5 Implementation 节）：Each tablet server manages a set of tablets(typically we have somewhere between ten to a thousand tablets per tablet server)）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578679-bdc90194-2fa0-4548-9d6a-dc05c68b2b28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf01c9495&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108162&status=done&style=none&taskId=u6b6133cb-a01c-4ce1-9c25-07763a60d97&title=" alt="image.png"></p>
<h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2><p>HMaster 没有单点故障问题，可以启动多个 HMaster，通过 ZooKeeper 的 Master Election 机制保证同时只有一个 HMaster 出于 Active 状态，其他的 HMaster 则处于热备份状态。一般情况下会启动两个 HMaster，非 Active 的 HMaster 会定期的和 Active HMaster 通信以获取其最新状态，从而保证它是实时更新的，因而如果启动了多个 HMaster 反而增加了 Active HMaster 的负担。前文已经介绍过了 HMaster 的主要用于 HRegion 的分配和管理，DDL(Data Definition Language，既 Table 的新建、删除、修改等)的实现等，既它主要有两方面的职责：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578676-90123c3d-eef5-4a0f-9854-893368a11cb3.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u78a55d4e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=367&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=86163&status=done&style=none&taskId=u176d4cf8-2a32-44ce-89a5-46dfff7582d&title=" alt="image.png"></p>
<h3 id="协调-HRegionServer"><a href="#协调-HRegionServer" class="headerlink" title="协调 HRegionServer"></a>协调 HRegionServer</h3><ul>
<li>启动时 HRegion 的分配，以及负载均衡和修复时 HRegion 的重新分配。</li>
<li>监控集群中所有 HRegionServer 的状态(通过 Heartbeat 和监听 ZooKeeper 中的状态)。</li>
</ul>
<h3 id="Admin-职能"><a href="#Admin-职能" class="headerlink" title="Admin 职能"></a>Admin 职能</h3><ul>
<li>创建、删除、修改 Table 的定义。</li>
</ul>
<h2 id="ZooKeeper-协调者"><a href="#ZooKeeper-协调者" class="headerlink" title="ZooKeeper 协调者"></a>ZooKeeper 协调者</h2><p>ZooKeeper 为 HBase 集群提供协调服务，它管理着 HMaster 和 HRegionServer 的状态(available&#x2F;alive 等)，并且会在它们宕机时通知给 HMaster，从而 HMaster 可以实现 HMaster 之间的 failover，或对宕机的 HRegionServer 中的 HRegion 集合的修复(将它们分配给其他的 HRegionServer)。ZooKeeper 集群本身使用一致性协议(PAXOS 协议)保证每个节点状态的一致性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578733-c859758f-8f4f-4919-a401-76ece989c145.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u355c5a55&margin=%5Bobject%20Object%5D&name=image.png&originHeight=318&originWidth=703&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=100372&status=done&style=none&taskId=u8d5eb963-5e89-4827-87e6-99f933cf92d&title=" alt="image.png"></p>
<h2 id="How-The-Components-Work-Together"><a href="#How-The-Components-Work-Together" class="headerlink" title="How The Components Work Together"></a>How The Components Work Together</h2><p>ZooKeeper 协调集群所有节点的共享信息，在 HMaster 和 HRegionServer 连接到 ZooKeeper 后创建 Ephemeral 节点，并使用 Heartbeat 机制维持这个节点的存活状态，如果某个 Ephemeral 节点实效，则 HMaster 会收到通知，并做相应的处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580371-8380eb6c-c579-418b-be2b-48b0f83658b0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u09e4cba8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=116454&status=done&style=none&taskId=u3c9ac6e6-13d4-46c1-b3fa-95947b15824&title=" alt="image.png"><br>另外，HMaster 通过监听 ZooKeeper 中的 Ephemeral 节点(默认：&#x2F;hbase&#x2F;rs&#x2F;*)来监控 HRegionServer 的加入和宕机。在第一个 HMaster 连接到 ZooKeeper 时会创建 Ephemeral 节点(默认：&#x2F;hbasae&#x2F;master)来表示 Active 的 HMaster，其后加进来的 HMaster 则监听该 Ephemeral 节点，如果当前 Active 的 HMaster 宕机，则该节点消失，因而其他 HMaster 得到通知，而将自身转换成 Active 的 HMaster，在变为 Active 的 HMaster 之前，它会创建在&#x2F;hbase&#x2F;back-masters&#x2F;下创建自己的 Ephemeral 节点。</p>
<h3 id="HBase-的第一次读写"><a href="#HBase-的第一次读写" class="headerlink" title="HBase 的第一次读写"></a>HBase 的第一次读写</h3><p>在 HBase 0.96 以前，HBase 有两个特殊的 Table：-ROOT-和.META.（如<a href="http://research.google.com/archive/bigtable-osdi06.pdf">BigTable</a>中的设计），其中-ROOT- Table 的位置存储在 ZooKeeper，它存储了.META. Table 的 RegionInfo 信息，并且它只能存在一个 HRegion，而.META. Table 则存储了用户 Table 的 RegionInfo 信息，它可以被切分成多个 HRegion，因而对第一次访问用户 Table 时，首先从 ZooKeeper 中读取-ROOT- Table 所在 HRegionServer；然后从该 HRegionServer 中根据请求的 TableName，RowKey 读取.META. Table 所在 HRegionServer；最后从该 HRegionServer 中读取.META. Table 的内容而获取此次请求需要访问的 HRegion 所在的位置，然后访问该 HRegionSever 获取请求的数据，这需要三次请求才能找到用户 Table 所在的位置，然后第四次请求开始获取真正的数据。当然为了提升性能，客户端会缓存-ROOT- Table 位置以及-ROOT-&#x2F;.META. Table 的内容。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580326-61fe3d03-5e26-4113-a242-d514c6e314a2.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6618f3ca&margin=%5Bobject%20Object%5D&name=image.png&originHeight=228&originWidth=399&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=45988&status=done&style=none&taskId=uc4946914-9a62-4a41-aab7-e197f2ede54&title=" alt="image.png"><br>可是即使客户端有缓存，在初始阶段需要三次请求才能直到用户 Table 真正所在的位置也是性能低下的，而且真的有必要支持那么多的 HRegion 吗？或许对 Google 这样的公司来说是需要的，但是对一般的集群来说好像并没有这个必要。在 BigTable 的论文中说，每行 METADATA 存储 1KB 左右数据，中等大小的 Tablet(HRegion)在 128MB 左右，3 层位置的 Schema 设计可以支持 2^34 个 Tablet(HRegion)。即使去掉-ROOT- Table，也还可以支持 2^17(131072)个 HRegion， 如果每个 HRegion 还是 128MB，那就是 16TB，这个貌似不够大，但是现在的 HRegion 的最大大小都会设置的比较大，比如我们设置了 2GB，此时支持的大小则变成了 4PB，对一般的集群来说已经够了，因而在 HBase 0.96 以后去掉了-ROOT- Table，只剩下这个特殊的目录表叫做 Meta Table(hbase:meta)，它存储了集群中所有用户 HRegion 的位置信息，而 ZooKeeper 的节点中(&#x2F;hbase&#x2F;meta-region-server)存储的则直接是这个 Meta Table 的位置，并且这个 Meta Table 如以前的-ROOT- Table 一样是不可 split 的。这样，客户端在第一次访问用户 Table 的流程就变成了：</p>
<ul>
<li>从 ZooKeeper(&#x2F;hbase&#x2F;meta-region-server)中获取 hbase:meta 的位置（HRegionServer 的位置），缓存该位置信息。</li>
<li>从 HRegionServer 中查询用户 Table 对应请求的 RowKey 所在的 HRegionServer，缓存该位置信息。</li>
<li>从查询到 HRegionServer 中读取 Row。</li>
</ul>
<p>从这个过程中，我们发现客户会缓存这些位置信息，然而第二步它只是缓存当前 RowKey 对应的 HRegion 的位置，因而如果下一个要查的 RowKey 不在同一个 HRegion 中，则需要继续查询 hbase:meta 所在的 HRegion，然而随着时间的推移，客户端缓存的位置信息越来越多，以至于不需要再次查找 hbase:meta Table 的信息，除非某个 HRegion 因为宕机或 Split 被移动，此时需要重新查询并且更新缓存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580741-c98bab14-3341-4784-9af5-cbad496ba448.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2d56a83a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=356&originWidth=590&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=75992&status=done&style=none&taskId=u1bb7d5f9-92df-4a3c-a110-20319264562&title=" alt="image.png"></p>
<h3 id="hbase-meta-表"><a href="#hbase-meta-表" class="headerlink" title="hbase:meta 表"></a>hbase:meta 表</h3><p>hbase:meta 表存储了所有用户 HRegion 的位置信息，它的 RowKey 是：tableName,regionStartKey,regionId,replicaId 等，它只有 info 列族，这个列族包含三个列，他们分别是：info:regioninfo 列是 RegionInfo 的 proto 格式：regionId,tableName,startKey,endKey,offline,split,replicaId；info:server 格式：HRegionServer 对应的 server:port；info:serverstartcode 格式是 HRegionServer 的启动时间戳。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580891-6feb81e6-8d18-4d3c-9583-be28019444e0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9776aea4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=362&originWidth=736&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115586&status=done&style=none&taskId=u6aecdbed-2fa8-4c2d-9f07-d26905069e2&title=" alt="image.png"></p>
<h2 id="HRegionServer-详解"><a href="#HRegionServer-详解" class="headerlink" title="HRegionServer 详解"></a>HRegionServer 详解</h2><p>HRegionServer 一般和 DataNode 在同一台机器上运行，实现数据的本地性。HRegionServer 包含多个 HRegion，由 WAL(HLog)、BlockCache、MemStore、HFile 组成。</p>
<ol>
<li>WAL 即 Write Ahead Log，在早期版本中称为 HLog，它是 HDFS 上的一个文件，如其名字所表示的，所有写操作都会先保证将数据写入这个 Log 文件后，才会真正更新 MemStore，最后写入 HFile 中。采用这种模式，可以保证 HRegionServer 宕机后，我们依然可以从该 Log 文件中读取数据，Replay 所有的操作，而不至于数据丢失。这个 Log 文件会定期 Roll 出新的文件而删除旧的文件(那些已持久化到 HFile 中的 Log 可以删除)。WAL 文件存储在&#x2F;hbase&#x2F;WALs&#x2F;${HRegionServer_Name}的目录中(在 0.94 之前，存储在&#x2F;hbase&#x2F;.logs&#x2F;目录中)，一般一个 HRegionServer 只有一个 WAL 实例，也就是说一个 HRegionServer 的所有 WAL 写都是串行的(就像 log4j 的日志写也是串行的)，这当然会引起性能问题，因而在 HBase 1.0 之后，通过 <a href="https://issues.apache.org/jira/browse/HBASE-5699">HBASE-5699</a> 实现了多个 WAL 并行写(MultiWAL)，该实现采用 HDFS 的多个管道写，以单个 HRegion 为单位。关于 WAL 可以参考 Wikipedia 的 <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">Write-Ahead Logging</a> 。顺便吐槽一句，英文版的维基百科竟然能毫无压力的正常访问了，这是某个 GFW 的疏忽还是以后的常态？</li>
<li>BlockCache 是一个读缓存，即“引用局部性”原理（也应用于 CPU，<a href="http://baike.baidu.com/link?url=Dh2u9KvowXcl2PloHJFTB9vEOoVS3WxPhDCVvbQGL_piyKFQ2iTHYAYf5mLAsFrcBUig6NC7A4-Aki61qnGCTK#3_1">分空间局部性和时间局部性</a>，空间局部性是指 CPU 在某一时刻需要某个数据，那么有很大的概率在一下时刻它需要的数据在其附近；时间局部性是指某个数据在被访问过一次后，它有很大的概率在不久的将来会被再次的访问），将数据预读取到内存中，以提升读的性能。HBase 中提供两种 BlockCache 的实现：默认 on-heap LruBlockCache 和 BucketCache(通常是 off-heap)。通常 BucketCache 的性能要差于 LruBlockCache，然而由于 GC 的影响，LruBlockCache 的延迟会变的不稳定，而 BucketCache 由于是自己管理 BlockCache，而不需要 GC，因而它的延迟通常比较稳定，这也是有些时候需要选用 BucketCache 的原因。这篇文章 <a href="http://www.n10k.com/blog/blockcache-101/">BlockCache101</a> 对 on-heap 和 off-heap 的 BlockCache 做了详细的比较。</li>
<li>HRegion 是一个 Table 中的一个 Region 在一个 HRegionServer 中的表达。一个 Table 可以有一个或多个 Region，他们可以在一个相同的 HRegionServer 上，也可以分布在不同的 HRegionServer 上，一个 HRegionServer 可以有多个 HRegion，他们分别属于不同的 Table。HRegion 由多个 Store(HStore)构成，每个 HStore 对应了一个 Table 在这个 HRegion 中的一个 Column Family，即每个 Column Family 就是一个集中的存储单元，因而最好将具有相近 IO 特性的 Column 存储在一个 Column Family，以实现高效读取(数据局部性原理，可以提高缓存的命中率)。HStore 是 HBase 中存储的核心，它实现了读写 HDFS 功能，一个 HStore 由一个 MemStore 和 0 个或多个 StoreFile 组成。<ul>
<li>MemStore 是一个写缓存(In Memory Sorted Buffer)，所有数据的写在完成 WAL 日志写后，会 写入 MemStore 中，由 MemStore 根据一定的算法将数据 Flush 到地层 HDFS 文件中(HFile)，通常每个 HRegion 中的每个 Column Family 有一个自己的 MemStore。</li>
<li>HFile(StoreFile) 用于存储 HBase 的数据(Cell&#x2F;KeyValue)。在 HFile 中的数据是按 RowKey、Column Family、Column 排序，对相同的 Cell(即这三个值都一样)，则按 timestamp 倒序排列。</li>
</ul>
</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581299-289e4273-4207-453d-9a8f-664f4911c72c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u35254fb8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=366&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=95333&status=done&style=none&taskId=u12039456-1add-4c7c-958a-c13ce2debd8&title=" alt="image.png"><br>虽然上面这张图展现的是最新的 HRegionServer 的架构(但是并不是那么的精确)，但是我一直比较喜欢看以下这张图，即使它展现的应该是 0.94 以前的架构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581512-9c74e462-666b-434c-8a29-8d2dcc9afd98.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u71a1066c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=347&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=214681&status=done&style=none&taskId=u3a1655c4-b13b-4c95-a9d6-3fc382b506b&title=" alt="image.png"></p>
<h3 id="HRegionServer-中数据写流程图解"><a href="#HRegionServer-中数据写流程图解" class="headerlink" title="HRegionServer 中数据写流程图解"></a>HRegionServer 中数据写流程图解</h3><p>当客户端发起一个 Put 请求时，首先它从 hbase:meta 表中查出该 Put 数据最终需要去的 HRegionServer。然后客户端将 Put 请求发送给相应的 HRegionServer，在 HRegionServer 中它首先会将该 Put 操作写入 WAL 日志文件中(Flush 到磁盘中)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582098-1768ce69-621c-42ab-8e9f-c088e8777cca.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub4d83a95&margin=%5Bobject%20Object%5D&name=image.png&originHeight=363&originWidth=716&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=71683&status=done&style=none&taskId=u8836b841-21cd-45ad-ad75-2b5427b07bb&title=" alt="image.png"><br>写完 WAL 日志文件后，HRegionServer 根据 Put 中的 TableName 和 RowKey 找到对应的 HRegion，并根据 Column Family 找到对应的 HStore，并将 Put 写入到该 HStore 的 MemStore 中。此时写成功，并返回通知客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582636-fd38aaea-d523-4b11-b13c-1efdef987fd7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf32f92cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=298&originWidth=664&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=63155&status=done&style=none&taskId=u30b36f42-9271-4e99-b1dd-7ce3205c36d&title=" alt="image.png"></p>
<h3 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h3><p>MemStore 是一个 In Memory Sorted Buffer，在每个 HStore 中都有一个 MemStore，即它是一个 HRegion 的一个 Column Family 对应一个实例。它的排列顺序以 RowKey、Column Family、Column 的顺序以及 Timestamp 的倒序，如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582832-94bc8fd5-adc7-418c-9d39-f165199fa60e.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u512fd7af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=719&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=106803&status=done&style=none&taskId=u85f74483-7f18-4a00-a4e7-60cabcf63e6&title=" alt="image.png"><br>每一次 Put&#x2F;Delete 请求都是先写入到 MemStore 中，当 MemStore 满后会 Flush 成一个新的 StoreFile(底层实现是 HFile)，即一个 HStore(Column Family)可以有 0 个或多个 StoreFile(HFile)。有以下三种情况可以触发 MemStore 的 Flush 动作，需要注意的是 MemStore 的最小 Flush 单元是 HRegion 而不是单个 MemStore。据说这是 Column Family 有个数限制的其中一个原因，估计是因为太多的 Column Family 一起 Flush 会引起性能问题？具体原因有待考证。</p>
<ol>
<li>当一个 HRegion 中的所有 MemStore 的大小总和超过了 hbase.hregion.memstore.flush.size 的大小，默认 128MB。此时当前的 HRegion 中所有的 MemStore 会 Flush 到 HDFS 中。</li>
<li>当全局 MemStore 的大小超过了 hbase.regionserver.global.memstore.upperLimit 的大小，默认 40％的内存使用量。此时当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 顺序是 MemStore 大小的倒序（一个 HRegion 中所有 MemStore 总和作为该 HRegion 的 MemStore 的大小还是选取最大的 MemStore 作为参考？有待考证），直到总体的 MemStore 使用量低于 hbase.regionserver.global.memstore.lowerLimit，默认 38%的内存使用量。</li>
<li>当前 HRegionServer 中 WAL 的大小超过了 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs 的数量，当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 使用时间顺序，最早的 MemStore 先 Flush 直到 WAL 的数量少于 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs。<a href="http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/">这里</a>说这两个相乘的默认大小是 2GB，查代码，hbase.regionserver.max.logs 默认值是 32，而 hbase.regionserver.hlog.blocksize 是 HDFS 的默认 blocksize，32MB。但不管怎么样，因为这个大小超过限制引起的 Flush 不是一件好事，可能引起长时间的延迟，因而这篇文章给的建议：“Hint: keep hbase.regionserver.hlog.blocksize _ hbase.regionserver.maxlogs just a bit above hbase.regionserver.global.memstore.lowerLimit _ HBASE_HEAPSIZE.”。并且需要注意，<a href="http://hbase.apache.org/book.html#_memstore_flush">这里</a>给的描述是有错的(虽然它是官方的文档)。</li>
</ol>
<p>在 MemStore Flush 过程中，还会在尾部追加一些 meta 数据，其中就包括 Flush 时最大的 WAL sequence 值，以告诉 HBase 这个 StoreFile 写入的最新数据的序列，那么在 Recover 时就直到从哪里开始。在 HRegion 启动时，这个 sequence 会被读取，并取最大的作为下一次更新时的起始 sequence。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583046-e073a721-456c-4607-89f7-ec5a222e50f0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8e41b38a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=248&originWidth=622&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=64652&status=done&style=none&taskId=u01119a37-ba73-457e-89cf-4e03d0108f9&title=" alt="image.png"></p>
<h2 id="HFile-格式"><a href="#HFile-格式" class="headerlink" title="HFile 格式"></a>HFile 格式</h2><p>HBase 的数据以 KeyValue(Cell)的形式顺序的存储在 HFile 中，在 MemStore 的 Flush 过程中生成 HFile，由于 MemStore 中存储的 Cell 遵循相同的排列顺序，因而 Flush 过程是顺序写，我们直到磁盘的顺序写性能很高，因为不需要不停的移动磁盘指针。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583239-35f30a61-6003-4baa-b78e-d0406b53f458.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uec0329c3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=698&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115221&status=done&style=none&taskId=u3b84bd8d-8533-4733-9068-58f3d383a88&title=" alt="image.png"><br>HFile 参考 BigTable 的 SSTable 和 Hadoop 的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html">TFile</a>实现，从 HBase 开始到现在，HFile 经历了三个版本，其中 V2 在 0.92 引入，V3 在 0.98 引入。首先我们来看一下 V1 的格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583656-2174688c-da96-443f-a46f-d8e391ffc97b.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9844c88d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=160&originWidth=554&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=72628&status=done&style=none&taskId=u55f4c3b1-daf2-4893-935c-09a8dd5acb9&title=" alt="image.png"><br>V1 的 HFile 由多个 Data Block、Meta Block、FileInfo、Data Index、Meta Index、Trailer 组成，其中 Data Block 是 HBase 的最小存储单元，在前文中提到的 BlockCache 就是基于 Data Block 的缓存的。一个 Data Block 由一个魔数和一系列的 KeyValue(Cell)组成，魔数是一个随机的数字，用于表示这是一个 Data Block 类型，以快速监测这个 Data Block 的格式，防止数据的破坏。Data Block 的大小可以在创建 Column Family 时设置(HColumnDescriptor.setBlockSize())，默认值是 64KB，大号的 Block 有利于顺序 Scan，小号 Block 利于随机查询，因而需要权衡。Meta 块是可选的，FileInfo 是固定长度的块，它纪录了文件的一些 Meta 信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY 等。Data Index 和 Meta Index 纪录了每个 Data 块和 Meta 块的其实点、未压缩时大小、Key(起始 RowKey？)等。Trailer 纪录了 FileInfo、Data Index、Meta Index 块的起始位置，Data Index 和 Meta Index 索引的数量等。其中 FileInfo 和 Trailer 是固定长度的。<br>HFile 里面的每个 KeyValue 对就是一个简单的 byte 数组。但是这个 byte 数组里面包含了很多项，并且有固定的结构。我们来看看里面的具体结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583953-34c63a35-4c72-417a-bb89-8902777196ee.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ufac2071c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=93&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=68710&status=done&style=none&taskId=u99911b0c-045d-4a97-bbe0-73cbdafbed4&title=" alt="image.png"><br>开始是两个固定长度的数值，分别表示 Key 的长度和 Value 的长度。紧接着是 Key，开始是固定长度的数值，表示 RowKey 的长度，紧接着是 RowKey，然后是固定长度的数值，表示 Family 的长度，然后是 Family，接着是 Qualifier，然后是两个固定长度的数值，表示 Time Stamp 和 Key Type（Put&#x2F;Delete）。Value 部分没有这么复杂的结构，就是纯粹的二进制数据了。随着 HFile 版本迁移，KeyValue(Cell)的格式并未发生太多变化，只是在 V3 版本，尾部添加了一个可选的 Tag 数组。<br>HFileV1 版本的在实际使用过程中发现它占用内存多，并且 Bloom File 和 Block Index 会变的很大，而引起启动时间变长。其中每个 HFile 的 Bloom Filter 可以增长到 100MB，这在查询时会引起性能问题，因为每次查询时需要加载并查询 Bloom Filter，100MB 的 Bloom Filer 会引起很大的延迟；另一个，Block Index 在一个 HRegionServer 可能会增长到总共 6GB，HRegionServer 在启动时需要先加载所有这些 Block Index，因而增加了启动时间。为了解决这些问题，在 0.92 版本中引入 HFileV2 版本：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916584996-bbbb6bb6-fc78-4a2c-8547-8ec1dbf366a1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7e338f01&margin=%5Bobject%20Object%5D&name=image.png&originHeight=418&originWidth=566&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=59249&status=done&style=none&taskId=u3169ce73-eb5d-4b8b-8c12-fe22df00816&title=" alt="image.png"><br>在这个版本中，Block Index 和 Bloom Filter 添加到了 Data Block 中间，而这种设计同时也减少了写的内存使用量；另外，为了提升启动速度，在这个版本中还引入了延迟读的功能，即在 HFile 真正被使用时才对其进行解析。<br>FileV3 版本基本和 V2 版本相比，并没有太大的改变，它在 KeyValue(Cell)层面上添加了 Tag 数组的支持；并在 FileInfo 结构中添加了和 Tag 相关的两个字段。关于具体 HFile 格式演化介绍，可以参考<a href="http://hbase.apache.org/book.html#_hfile_format_2">这里</a>。<br>对 HFileV2 格式具体分析，它是一个多层的类 B+树索引，采用这种设计，可以实现查找不需要读取整个文件：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585756-2c38fca8-e68c-4d91-a8dd-7d557a9b30bc.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u667d00a9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=349&originWidth=688&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107524&status=done&style=none&taskId=u8dc1ef81-99a0-428d-b317-b7c86f91e80&title=" alt="image.png"><br>Data Block 中的 Cell 都是升序排列，每个 block 都有它自己的 Leaf-Index，每个 Block 的最后一个 Key 被放入 Intermediate-Index 中，Root-Index 指向 Intermediate-Index。在 HFile 的末尾还有 Bloom Filter 用于快速定位那么没有在某个 Data Block 中的 Row；TimeRange 信息用于给那些使用时间查询的参考。在 HFile 打开时，这些索引信息都被加载并保存在内存中，以增加以后的读取性能。</p>
<h2 id="HBase-读的实现"><a href="#HBase-读的实现" class="headerlink" title="HBase 读的实现"></a>HBase 读的实现</h2><p>通过前文的描述，我们知道在 HBase 写时，相同 Cell(RowKey&#x2F;ColumnFamily&#x2F;Column 相同)并不保证在一起，甚至删除一个 Cell 也只是写入一个新的 Cell，它含有 Delete 标记，而不一定将一个 Cell 真正删除了，因而这就引起了一个问题，如何实现读的问题？要解决这个问题，我们先来分析一下相同的 Cell 可能存在的位置：首先对新写入的 Cell，它会存在于 MemStore 中；然后对之前已经 Flush 到 HDFS 中的 Cell，它会存在于某个或某些 StoreFile(HFile)中；最后，对刚读取过的 Cell，它可能存在于 BlockCache 中。既然相同的 Cell 可能存储在三个地方，在读取的时候只需要扫瞄这三个地方，然后将结果合并即可(Merge Read)，在 HBase 中扫瞄的顺序依次是：BlockCache、MemStore、StoreFile(HFile)。其中 StoreFile 的扫瞄先会使用 Bloom Filter 过滤那些不可能符合条件的 HFile，然后使用 Block Index 快速定位 Cell，并将其加载到 BlockCache 中，然后从 BlockCache 中读取。我们知道一个 HStore 可能存在多个 StoreFile(HFile)，此时需要扫瞄多个 HFile，如果 HFile 过多又是会引起性能问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585461-55084b02-31ea-4bb5-9df2-2ab8931fad2c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u650f6de0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=278&originWidth=769&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107309&status=done&style=none&taskId=ueb6d7da0-a4dc-47eb-bce5-8a4918d43e7&title=" alt="image.png"></p>
<h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>MemStore 每次 Flush 会创建新的 HFile，而过多的 HFile 会引起读的性能问题，那么如何解决这个问题呢？HBase 采用 Compaction 机制来解决这个问题，有点类似 Java 中的 GC 机制，起初 Java 不停的申请内存而不释放，增加性能，然而天下没有免费的午餐，最终我们还是要在某个条件下去收集垃圾，很多时候需要 Stop-The-World，这种 Stop-The-World 有些时候也会引起很大的问题，因而设计是一种权衡，没有完美的。还是类似 Java 中的 GC，在 HBase 中 Compaction 分为两种：Minor Compaction 和 Major Compaction。</p>
<ol>
<li>Minor Compaction 是指选取一些小的、相邻的 StoreFile 将他们合并成一个更大的 StoreFile，在这个过程中不会处理已经 Deleted 或 Expired 的 Cell。一次 Minor Compaction 的结果是更少并且更大的 StoreFile。（这个是对的吗？BigTable 中是这样描述 Minor Compaction 的：As write operations execute, the size of the memtable in- creases. When the memtable size reaches a threshold, the memtable is frozen, a new memtable is created, and the frozen memtable is converted to an SSTable and written to GFS. This minor compaction process has two goals: it shrinks the memory usage of the tablet server, and it reduces the amount of data that has to be read from the commit log during recovery if this server dies. Incom- ing read and write operations can continue while com- pactions occur. 也就是说它将 memtable 的数据 flush 的一个 HFile&#x2F;SSTable 称为一次 Minor Compaction）</li>
<li>Major Compaction 是指将所有的 StoreFile 合并成一个 StoreFile，在这个过程中，标记为 Deleted 的 Cell 会被删除，而那些已经 Expired 的 Cell 会被丢弃，那些已经超过最多版本数的 Cell 会被丢弃。一次 Major Compaction 的结果是一个 HStore 只有一个 StoreFile 存在。Major Compaction 可以手动或自动触发，然而由于它会引起很多的 IO 操作而引起性能问题，因而它一般会被安排在周末、凌晨等集群比较闲的时间。</li>
</ol>
<p>更形象一点，如下面两张图分别表示 Minor Compaction 和 Major Compaction。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585472-7b9745d6-455b-458e-a5e5-a751cc03fadd.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub1833466&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=723&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=94709&status=done&style=none&taskId=u8358d499-81ee-4051-817d-9540dc51bc5&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585518-f8e5d988-133a-4f90-b87d-3370099c3bb1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua80b4458&margin=%5Bobject%20Object%5D&name=image.png&originHeight=339&originWidth=653&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=93417&status=done&style=none&taskId=u2201da79-e7a4-4e5e-af63-b9e178ad60a&title=" alt="image.png"></p>
<h2 id="HRegion-Split"><a href="#HRegion-Split" class="headerlink" title="HRegion Split"></a>HRegion Split</h2><p>最初，一个 Table 只有一个 HRegion，随着数据写入增加，如果一个 HRegion 到达一定的大小，就需要 Split 成两个 HRegion，这个大小由 hbase.hregion.max.filesize 指定，默认为 10GB。当 split 时，两个新的 HRegion 会在同一个 HRegionServer 中创建，它们各自包含父 HRegion 一半的数据，当 Split 完成后，父 HRegion 会下线，而新的两个子 HRegion 会向 HMaster 注册上线，处于负载均衡的考虑，这两个新的 HRegion 可能会被 HMaster 分配到其他的 HRegionServer 中。关于 Split 的详细信息，可以参考这篇文章：<a href="http://hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">《Apache HBase Region Splitting and Merging》</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586158-3ba24d92-6644-4a0f-91a1-d00da5867a28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7d90fe99&margin=%5Bobject%20Object%5D&name=image.png&originHeight=361&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=85469&status=done&style=none&taskId=u7e157502-2bf1-4daf-9c17-071a1dc9564&title=" alt="image.png"></p>
<h2 id="HRegion-负载均衡"><a href="#HRegion-负载均衡" class="headerlink" title="HRegion 负载均衡"></a>HRegion 负载均衡</h2><p>在 HRegion Split 后，两个新的 HRegion 最初会和之前的父 HRegion 在相同的 HRegionServer 上，出于负载均衡的考虑，HMaster 可能会将其中的一个甚至两个重新分配的其他的 HRegionServer 中，此时会引起有些 HRegionServer 处理的数据在其他节点上，直到下一次 Major Compaction 将数据从远端的节点移动到本地节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586722-3a111ac3-cc8a-4dfd-ab85-4e6f68fe4306.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucfafb6f6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=358&originWidth=714&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=113593&status=done&style=none&taskId=u3068847b-f220-4283-af84-153c8256a06&title=" alt="image.png"></p>
<h2 id="HRegionServer-Recovery"><a href="#HRegionServer-Recovery" class="headerlink" title="HRegionServer Recovery"></a>HRegionServer Recovery</h2><p>当一台 HRegionServer 宕机时，由于它不再发送 Heartbeat 给 ZooKeeper 而被监测到，此时 ZooKeeper 会通知 HMaster，HMaster 会检测到哪台 HRegionServer 宕机，它将宕机的 HRegionServer 中的 HRegion 重新分配给其他的 HRegionServer，同时 HMaster 会把宕机的 HRegionServer 相关的 WAL 拆分分配给相应的 HRegionServer(将拆分出的 WAL 文件写入对应的目的 HRegionServer 的 WAL 目录中，并并写入对应的 DataNode 中），从而这些 HRegionServer 可以 Replay 分到的 WAL 来重建 MemStore。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587040-3b89bd6c-f56a-4d12-b005-539cdc9e8aae.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u53643cd9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=368&originWidth=708&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=133786&status=done&style=none&taskId=ued635896-8d3d-47e9-aaa1-848ae861ace&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587014-ac39bb9d-e5ab-48af-9f60-8389745baa26.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u22d50009&margin=%5Bobject%20Object%5D&name=image.png&originHeight=378&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=79489&status=done&style=none&taskId=u3d4037a7-ea2b-4d85-8a02-fa381b36016&title=" alt="image.png"><br>HBase 架构简单总结 在 NoSQL 中，存在著名的 CAP 理论，即 Consistency、Availability、Partition Tolerance 不可全得，目前市场上基本上的 NoSQL 都采用 Partition Tolerance 以实现数据得水平扩展，来处理 Relational DataBase 遇到的无法处理数据量太大的问题，或引起的性能问题。因而只有剩下 C 和 A 可以选择。HBase 在两者之间选择了 Consistency，然后使用多个 HMaster 以及支持 HRegionServer 的 failure 监控、ZooKeeper 引入作为协调者等各种手段来解决 Availability 问题，然而当网络的 Split-Brain(Network Partition)发生时，它还是无法完全解决 Availability 的问题。从这个角度上，Cassandra 选择了 A，即它在网络 Split-Brain 时还是能正常写，而使用其他技术来解决 Consistency 的问题，如读的时候触发 Consistency 判断和处理。这是设计上的限制。<br>从实现上的优点</p>
<ol>
<li>HBase 采用强一致性模型，在一个写返回后，保证所有的读都读到相同的数据。</li>
<li>通过 HRegion 动态 Split 和 Merge 实现自动扩展，并使用 HDFS 提供的多个数据备份功能，实现高可用性。</li>
<li>采用 HRegionServer 和 DataNode 运行在相同的服务器上实现数据的本地化，提升读写性能，并减少网络压力。</li>
<li>内建 HRegionServer 的宕机自动恢复。采用 WAL 来 Replay 还未持久化到 HDFS 的数据。</li>
<li>可以无缝的和 Hadoop&#x2F;MapReduce 集成。</li>
</ol>
<p>实现上的缺点</p>
<ol>
<li>WAL 的 Replay 过程可能会很慢。</li>
<li>灾难恢复比较复杂，也会比较慢。</li>
<li>Major Compaction 会引起 IO Storm。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture/">https://www.mapr.com/blog/in-depth-look-hbase-architecture/</a><br><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable</a><br><a href="http://hbase.apache.org/book.html">http://hbase.apache.org/book.html</a><br><a href="http://www.searchtb.com/2011/01/understanding-hbase.html">http://www.searchtb.com/2011/01/understanding-hbase.html</a><br><a href="http://research.google.com/archive/bigtable-osdi06.pdf">http://research.google.com/archive/bigtable-osdi06.pdf</a></p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase（一）系统架构</title>
    <url>/article/hbase/hbase-architecture/</url>
    <content><![CDATA[<p>本文基本是对 MapR 的官网文章<a href="https://mapr.com/blog/in-depth-look-hbase-architecture/">An In-Depth Look at the HBase Architecture</a>的翻译</p>
<h2 id="HBase-存储架构"><a href="#HBase-存储架构" class="headerlink" title="HBase 存储架构"></a>HBase 存储架构</h2><p>HBase 采用 Master&#x2F;Slave 架构搭建集群，它隶属于 Hadoop 生态系统，由一下类型节点组成：HMaster 节点、HRegionServer 节点、ZooKeeper 集群，而在底层，它将数据存储于 HDFS 中，因而涉及到 HDFS 的 NameNode、DataNode 等，总体结构如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578858-a17a0bfb-0f8d-419b-885f-148ebbca588f.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u723b4673&margin=%5Bobject%20Object%5D&name=image.png&originHeight=411&originWidth=711&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=240958&status=done&style=none&taskId=u454e491c-809a-4e79-83c8-a5682ce06d5&title=" alt="image.png"></p>
<h3 id="HMaster-节点"><a href="#HMaster-节点" class="headerlink" title="HMaster 节点"></a>HMaster 节点</h3><ul>
<li>管理 HRegionServer，实现其负载均衡。</li>
<li>管理和分配 HRegion，比如在 HRegion split 时分配新的 HRegion；在 HRegionServer 退出时迁移其内的 HRegion 到其他 HRegionServer 上。</li>
<li>实现 DDL 操作（Data Definition Language，namespace 和 table 的增删改，column familiy 的增删改等）。</li>
<li>管理 namespace 和 table 的元数据（实际存储在 HDFS 上）。</li>
<li>权限控制（ACL）。</li>
</ul>
<h3 id="HRegionServer-节点"><a href="#HRegionServer-节点" class="headerlink" title="HRegionServer 节点"></a>HRegionServer 节点</h3><ul>
<li>存放和管理本地 HRegion。</li>
<li>读写 HDFS，管理 Table 中的数据。</li>
<li>Client 直接通过 HRegionServer 读写数据（从 HMaster 中获取元数据，找到 RowKey 所在的 HRegion&#x2F;HRegionServer 后）。</li>
</ul>
<h3 id="ZooKeeper-集群协调系统"><a href="#ZooKeeper-集群协调系统" class="headerlink" title="ZooKeeper 集群协调系统"></a>ZooKeeper 集群协调系统</h3><ul>
<li>存放整个 HBase 集群的元数据以及集群的状态信息。</li>
<li>实现 HMaster 主从节点的 failover。</li>
</ul>
<p>HBase Client 通过 RPC 方式和 HMaster、HRegionServer 通信；一个 HRegionServer 可以存放 1000 个 HRegion；底层 Table 数据存储于 HDFS 中，而 HRegion 所处理的数据尽量和数据所在的 DataNode 在一起，实现数据的本地化；数据本地化并不是总能实现，比如在 HRegion 移动(如因 Split)时，需要等下一次 Compact 才能继续回到本地化。<br>《An In-Depth Look At The HBase Architecture》的架构图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578621-e7f149be-14ec-4a2d-b62e-6fcbe2acacf7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8bc90172&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=632&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108396&status=done&style=none&taskId=u04136b8b-47ca-414a-99ef-8f070c7ddb5&title=" alt="image.png"><br>这个架构图比较清晰的表达了 HMaster 和 NameNode 都支持多个热备份，使用 ZooKeeper 来做协调；ZooKeeper 并不是云般神秘，它一般由三台机器组成一个集群，内部使用 PAXOS 算法支持三台 Server 中的一台宕机，也有使用五台机器的，此时则可以支持同时两台宕机，既少于半数的宕机，然而随着机器的增加，它的性能也会下降；RegionServer 和 DataNode 一般会放在相同的 Server 上实现数据的本地化。</p>
<h2 id="HRegion"><a href="#HRegion" class="headerlink" title="HRegion"></a>HRegion</h2><p>HBase 使用 RowKey 将表水平切割成多个 HRegion，从 HMaster 的角度，每个 HRegion 都纪录了它的 StartKey 和 EndKey（第一个 HRegion 的 StartKey 为空，最后一个 HRegion 的 EndKey 为空），由于 RowKey 是排序的，因而 Client 可以通过 HMaster 快速的定位每个 RowKey 在哪个 HRegion 中。HRegion 由 HMaster 分配到相应的 HRegionServer 中，然后由 HRegionServer 负责 HRegion 的启动和管理，和 Client 的通信，负责数据的读(使用 HDFS)。每个 HRegionServer 可以同时管理 1000 个左右的 HRegion（这个数字怎么来的？没有从代码中看到限制，难道是出于经验？超过 1000 个会引起性能问题？来回答这个问题：感觉这个 1000 的数字是从 BigTable 的论文中来的（5 Implementation 节）：Each tablet server manages a set of tablets(typically we have somewhere between ten to a thousand tablets per tablet server)）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578679-bdc90194-2fa0-4548-9d6a-dc05c68b2b28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf01c9495&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108162&status=done&style=none&taskId=u6b6133cb-a01c-4ce1-9c25-07763a60d97&title=" alt="image.png"></p>
<h2 id="HMaster"><a href="#HMaster" class="headerlink" title="HMaster"></a>HMaster</h2><p>HMaster 没有单点故障问题，可以启动多个 HMaster，通过 ZooKeeper 的 Master Election 机制保证同时只有一个 HMaster 出于 Active 状态，其他的 HMaster 则处于热备份状态。一般情况下会启动两个 HMaster，非 Active 的 HMaster 会定期的和 Active HMaster 通信以获取其最新状态，从而保证它是实时更新的，因而如果启动了多个 HMaster 反而增加了 Active HMaster 的负担。前文已经介绍过了 HMaster 的主要用于 HRegion 的分配和管理，DDL(Data Definition Language，既 Table 的新建、删除、修改等)的实现等，既它主要有两方面的职责：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578676-90123c3d-eef5-4a0f-9854-893368a11cb3.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u78a55d4e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=367&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=86163&status=done&style=none&taskId=u176d4cf8-2a32-44ce-89a5-46dfff7582d&title=" alt="image.png"></p>
<h3 id="协调-HRegionServer"><a href="#协调-HRegionServer" class="headerlink" title="协调 HRegionServer"></a>协调 HRegionServer</h3><ul>
<li>启动时 HRegion 的分配，以及负载均衡和修复时 HRegion 的重新分配。</li>
<li>监控集群中所有 HRegionServer 的状态(通过 Heartbeat 和监听 ZooKeeper 中的状态)。</li>
</ul>
<h3 id="Admin-职能"><a href="#Admin-职能" class="headerlink" title="Admin 职能"></a>Admin 职能</h3><ul>
<li>创建、删除、修改 Table 的定义。</li>
</ul>
<h2 id="ZooKeeper-协调者"><a href="#ZooKeeper-协调者" class="headerlink" title="ZooKeeper 协调者"></a>ZooKeeper 协调者</h2><p>ZooKeeper 为 HBase 集群提供协调服务，它管理着 HMaster 和 HRegionServer 的状态(available&#x2F;alive 等)，并且会在它们宕机时通知给 HMaster，从而 HMaster 可以实现 HMaster 之间的 failover，或对宕机的 HRegionServer 中的 HRegion 集合的修复(将它们分配给其他的 HRegionServer)。ZooKeeper 集群本身使用一致性协议(PAXOS 协议)保证每个节点状态的一致性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916578733-c859758f-8f4f-4919-a401-76ece989c145.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u355c5a55&margin=%5Bobject%20Object%5D&name=image.png&originHeight=318&originWidth=703&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=100372&status=done&style=none&taskId=u8d5eb963-5e89-4827-87e6-99f933cf92d&title=" alt="image.png"></p>
<h2 id="How-The-Components-Work-Together"><a href="#How-The-Components-Work-Together" class="headerlink" title="How The Components Work Together"></a>How The Components Work Together</h2><p>ZooKeeper 协调集群所有节点的共享信息，在 HMaster 和 HRegionServer 连接到 ZooKeeper 后创建 Ephemeral 节点，并使用 Heartbeat 机制维持这个节点的存活状态，如果某个 Ephemeral 节点实效，则 HMaster 会收到通知，并做相应的处理。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580371-8380eb6c-c579-418b-be2b-48b0f83658b0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u09e4cba8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=722&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=116454&status=done&style=none&taskId=u3c9ac6e6-13d4-46c1-b3fa-95947b15824&title=" alt="image.png"><br>另外，HMaster 通过监听 ZooKeeper 中的 Ephemeral 节点(默认：&#x2F;hbase&#x2F;rs&#x2F;*)来监控 HRegionServer 的加入和宕机。在第一个 HMaster 连接到 ZooKeeper 时会创建 Ephemeral 节点(默认：&#x2F;hbasae&#x2F;master)来表示 Active 的 HMaster，其后加进来的 HMaster 则监听该 Ephemeral 节点，如果当前 Active 的 HMaster 宕机，则该节点消失，因而其他 HMaster 得到通知，而将自身转换成 Active 的 HMaster，在变为 Active 的 HMaster 之前，它会创建在&#x2F;hbase&#x2F;back-masters&#x2F;下创建自己的 Ephemeral 节点。</p>
<h3 id="HBase-的第一次读写"><a href="#HBase-的第一次读写" class="headerlink" title="HBase 的第一次读写"></a>HBase 的第一次读写</h3><p>在 HBase 0.96 以前，HBase 有两个特殊的 Table：-ROOT-和.META.（如<a href="http://research.google.com/archive/bigtable-osdi06.pdf">BigTable</a>中的设计），其中-ROOT- Table 的位置存储在 ZooKeeper，它存储了.META. Table 的 RegionInfo 信息，并且它只能存在一个 HRegion，而.META. Table 则存储了用户 Table 的 RegionInfo 信息，它可以被切分成多个 HRegion，因而对第一次访问用户 Table 时，首先从 ZooKeeper 中读取-ROOT- Table 所在 HRegionServer；然后从该 HRegionServer 中根据请求的 TableName，RowKey 读取.META. Table 所在 HRegionServer；最后从该 HRegionServer 中读取.META. Table 的内容而获取此次请求需要访问的 HRegion 所在的位置，然后访问该 HRegionSever 获取请求的数据，这需要三次请求才能找到用户 Table 所在的位置，然后第四次请求开始获取真正的数据。当然为了提升性能，客户端会缓存-ROOT- Table 位置以及-ROOT-&#x2F;.META. Table 的内容。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580326-61fe3d03-5e26-4113-a242-d514c6e314a2.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6618f3ca&margin=%5Bobject%20Object%5D&name=image.png&originHeight=228&originWidth=399&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=45988&status=done&style=none&taskId=uc4946914-9a62-4a41-aab7-e197f2ede54&title=" alt="image.png"><br>可是即使客户端有缓存，在初始阶段需要三次请求才能直到用户 Table 真正所在的位置也是性能低下的，而且真的有必要支持那么多的 HRegion 吗？或许对 Google 这样的公司来说是需要的，但是对一般的集群来说好像并没有这个必要。在 BigTable 的论文中说，每行 METADATA 存储 1KB 左右数据，中等大小的 Tablet(HRegion)在 128MB 左右，3 层位置的 Schema 设计可以支持 2^34 个 Tablet(HRegion)。即使去掉-ROOT- Table，也还可以支持 2^17(131072)个 HRegion， 如果每个 HRegion 还是 128MB，那就是 16TB，这个貌似不够大，但是现在的 HRegion 的最大大小都会设置的比较大，比如我们设置了 2GB，此时支持的大小则变成了 4PB，对一般的集群来说已经够了，因而在 HBase 0.96 以后去掉了-ROOT- Table，只剩下这个特殊的目录表叫做 Meta Table(hbase:meta)，它存储了集群中所有用户 HRegion 的位置信息，而 ZooKeeper 的节点中(&#x2F;hbase&#x2F;meta-region-server)存储的则直接是这个 Meta Table 的位置，并且这个 Meta Table 如以前的-ROOT- Table 一样是不可 split 的。这样，客户端在第一次访问用户 Table 的流程就变成了：</p>
<ul>
<li>从 ZooKeeper(&#x2F;hbase&#x2F;meta-region-server)中获取 hbase:meta 的位置（HRegionServer 的位置），缓存该位置信息。</li>
<li>从 HRegionServer 中查询用户 Table 对应请求的 RowKey 所在的 HRegionServer，缓存该位置信息。</li>
<li>从查询到 HRegionServer 中读取 Row。</li>
</ul>
<p>从这个过程中，我们发现客户会缓存这些位置信息，然而第二步它只是缓存当前 RowKey 对应的 HRegion 的位置，因而如果下一个要查的 RowKey 不在同一个 HRegion 中，则需要继续查询 hbase:meta 所在的 HRegion，然而随着时间的推移，客户端缓存的位置信息越来越多，以至于不需要再次查找 hbase:meta Table 的信息，除非某个 HRegion 因为宕机或 Split 被移动，此时需要重新查询并且更新缓存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580741-c98bab14-3341-4784-9af5-cbad496ba448.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2d56a83a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=356&originWidth=590&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=75992&status=done&style=none&taskId=u1bb7d5f9-92df-4a3c-a110-20319264562&title=" alt="image.png"></p>
<h3 id="hbase-meta-表"><a href="#hbase-meta-表" class="headerlink" title="hbase:meta 表"></a>hbase:meta 表</h3><p>hbase:meta 表存储了所有用户 HRegion 的位置信息，它的 RowKey 是：tableName,regionStartKey,regionId,replicaId 等，它只有 info 列族，这个列族包含三个列，他们分别是：info:regioninfo 列是 RegionInfo 的 proto 格式：regionId,tableName,startKey,endKey,offline,split,replicaId；info:server 格式：HRegionServer 对应的 server:port；info:serverstartcode 格式是 HRegionServer 的启动时间戳。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916580891-6feb81e6-8d18-4d3c-9583-be28019444e0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9776aea4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=362&originWidth=736&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115586&status=done&style=none&taskId=u6aecdbed-2fa8-4c2d-9f07-d26905069e2&title=" alt="image.png"></p>
<h2 id="HRegionServer-详解"><a href="#HRegionServer-详解" class="headerlink" title="HRegionServer 详解"></a>HRegionServer 详解</h2><p>HRegionServer 一般和 DataNode 在同一台机器上运行，实现数据的本地性。HRegionServer 包含多个 HRegion，由 WAL(HLog)、BlockCache、MemStore、HFile 组成。</p>
<ol>
<li>WAL 即 Write Ahead Log，在早期版本中称为 HLog，它是 HDFS 上的一个文件，如其名字所表示的，所有写操作都会先保证将数据写入这个 Log 文件后，才会真正更新 MemStore，最后写入 HFile 中。采用这种模式，可以保证 HRegionServer 宕机后，我们依然可以从该 Log 文件中读取数据，Replay 所有的操作，而不至于数据丢失。这个 Log 文件会定期 Roll 出新的文件而删除旧的文件(那些已持久化到 HFile 中的 Log 可以删除)。WAL 文件存储在&#x2F;hbase&#x2F;WALs&#x2F;${HRegionServer_Name}的目录中(在 0.94 之前，存储在&#x2F;hbase&#x2F;.logs&#x2F;目录中)，一般一个 HRegionServer 只有一个 WAL 实例，也就是说一个 HRegionServer 的所有 WAL 写都是串行的(就像 log4j 的日志写也是串行的)，这当然会引起性能问题，因而在 HBase 1.0 之后，通过 <a href="https://issues.apache.org/jira/browse/HBASE-5699">HBASE-5699</a> 实现了多个 WAL 并行写(MultiWAL)，该实现采用 HDFS 的多个管道写，以单个 HRegion 为单位。关于 WAL 可以参考 Wikipedia 的 <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">Write-Ahead Logging</a> 。顺便吐槽一句，英文版的维基百科竟然能毫无压力的正常访问了，这是某个 GFW 的疏忽还是以后的常态？</li>
<li>BlockCache 是一个读缓存，即“引用局部性”原理（也应用于 CPU，<a href="http://baike.baidu.com/link?url=Dh2u9KvowXcl2PloHJFTB9vEOoVS3WxPhDCVvbQGL_piyKFQ2iTHYAYf5mLAsFrcBUig6NC7A4-Aki61qnGCTK#3_1">分空间局部性和时间局部性</a>，空间局部性是指 CPU 在某一时刻需要某个数据，那么有很大的概率在一下时刻它需要的数据在其附近；时间局部性是指某个数据在被访问过一次后，它有很大的概率在不久的将来会被再次的访问），将数据预读取到内存中，以提升读的性能。HBase 中提供两种 BlockCache 的实现：默认 on-heap LruBlockCache 和 BucketCache(通常是 off-heap)。通常 BucketCache 的性能要差于 LruBlockCache，然而由于 GC 的影响，LruBlockCache 的延迟会变的不稳定，而 BucketCache 由于是自己管理 BlockCache，而不需要 GC，因而它的延迟通常比较稳定，这也是有些时候需要选用 BucketCache 的原因。这篇文章 <a href="http://www.n10k.com/blog/blockcache-101/">BlockCache101</a> 对 on-heap 和 off-heap 的 BlockCache 做了详细的比较。</li>
<li>HRegion 是一个 Table 中的一个 Region 在一个 HRegionServer 中的表达。一个 Table 可以有一个或多个 Region，他们可以在一个相同的 HRegionServer 上，也可以分布在不同的 HRegionServer 上，一个 HRegionServer 可以有多个 HRegion，他们分别属于不同的 Table。HRegion 由多个 Store(HStore)构成，每个 HStore 对应了一个 Table 在这个 HRegion 中的一个 Column Family，即每个 Column Family 就是一个集中的存储单元，因而最好将具有相近 IO 特性的 Column 存储在一个 Column Family，以实现高效读取(数据局部性原理，可以提高缓存的命中率)。HStore 是 HBase 中存储的核心，它实现了读写 HDFS 功能，一个 HStore 由一个 MemStore 和 0 个或多个 StoreFile 组成。<ul>
<li>MemStore 是一个写缓存(In Memory Sorted Buffer)，所有数据的写在完成 WAL 日志写后，会 写入 MemStore 中，由 MemStore 根据一定的算法将数据 Flush 到地层 HDFS 文件中(HFile)，通常每个 HRegion 中的每个 Column Family 有一个自己的 MemStore。</li>
<li>HFile(StoreFile) 用于存储 HBase 的数据(Cell&#x2F;KeyValue)。在 HFile 中的数据是按 RowKey、Column Family、Column 排序，对相同的 Cell(即这三个值都一样)，则按 timestamp 倒序排列。</li>
</ul>
</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581299-289e4273-4207-453d-9a8f-664f4911c72c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u35254fb8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=366&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=95333&status=done&style=none&taskId=u12039456-1add-4c7c-958a-c13ce2debd8&title=" alt="image.png"><br>虽然上面这张图展现的是最新的 HRegionServer 的架构(但是并不是那么的精确)，但是我一直比较喜欢看以下这张图，即使它展现的应该是 0.94 以前的架构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916581512-9c74e462-666b-434c-8a29-8d2dcc9afd98.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u71a1066c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=347&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=214681&status=done&style=none&taskId=u3a1655c4-b13b-4c95-a9d6-3fc382b506b&title=" alt="image.png"></p>
<h3 id="HRegionServer-中数据写流程图解"><a href="#HRegionServer-中数据写流程图解" class="headerlink" title="HRegionServer 中数据写流程图解"></a>HRegionServer 中数据写流程图解</h3><p>当客户端发起一个 Put 请求时，首先它从 hbase:meta 表中查出该 Put 数据最终需要去的 HRegionServer。然后客户端将 Put 请求发送给相应的 HRegionServer，在 HRegionServer 中它首先会将该 Put 操作写入 WAL 日志文件中(Flush 到磁盘中)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582098-1768ce69-621c-42ab-8e9f-c088e8777cca.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub4d83a95&margin=%5Bobject%20Object%5D&name=image.png&originHeight=363&originWidth=716&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=71683&status=done&style=none&taskId=u8836b841-21cd-45ad-ad75-2b5427b07bb&title=" alt="image.png"><br>写完 WAL 日志文件后，HRegionServer 根据 Put 中的 TableName 和 RowKey 找到对应的 HRegion，并根据 Column Family 找到对应的 HStore，并将 Put 写入到该 HStore 的 MemStore 中。此时写成功，并返回通知客户端。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582636-fd38aaea-d523-4b11-b13c-1efdef987fd7.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf32f92cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=298&originWidth=664&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=63155&status=done&style=none&taskId=u30b36f42-9271-4e99-b1dd-7ce3205c36d&title=" alt="image.png"></p>
<h3 id="MemStore-Flush"><a href="#MemStore-Flush" class="headerlink" title="MemStore Flush"></a>MemStore Flush</h3><p>MemStore 是一个 In Memory Sorted Buffer，在每个 HStore 中都有一个 MemStore，即它是一个 HRegion 的一个 Column Family 对应一个实例。它的排列顺序以 RowKey、Column Family、Column 的顺序以及 Timestamp 的倒序，如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916582832-94bc8fd5-adc7-418c-9d39-f165199fa60e.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u512fd7af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=719&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=106803&status=done&style=none&taskId=u85f74483-7f18-4a00-a4e7-60cabcf63e6&title=" alt="image.png"><br>每一次 Put&#x2F;Delete 请求都是先写入到 MemStore 中，当 MemStore 满后会 Flush 成一个新的 StoreFile(底层实现是 HFile)，即一个 HStore(Column Family)可以有 0 个或多个 StoreFile(HFile)。有以下三种情况可以触发 MemStore 的 Flush 动作，需要注意的是 MemStore 的最小 Flush 单元是 HRegion 而不是单个 MemStore。据说这是 Column Family 有个数限制的其中一个原因，估计是因为太多的 Column Family 一起 Flush 会引起性能问题？具体原因有待考证。</p>
<ol>
<li>当一个 HRegion 中的所有 MemStore 的大小总和超过了 hbase.hregion.memstore.flush.size 的大小，默认 128MB。此时当前的 HRegion 中所有的 MemStore 会 Flush 到 HDFS 中。</li>
<li>当全局 MemStore 的大小超过了 hbase.regionserver.global.memstore.upperLimit 的大小，默认 40％的内存使用量。此时当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 顺序是 MemStore 大小的倒序（一个 HRegion 中所有 MemStore 总和作为该 HRegion 的 MemStore 的大小还是选取最大的 MemStore 作为参考？有待考证），直到总体的 MemStore 使用量低于 hbase.regionserver.global.memstore.lowerLimit，默认 38%的内存使用量。</li>
<li>当前 HRegionServer 中 WAL 的大小超过了 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs 的数量，当前 HRegionServer 中所有 HRegion 中的 MemStore 都会 Flush 到 HDFS 中，Flush 使用时间顺序，最早的 MemStore 先 Flush 直到 WAL 的数量少于 hbase.regionserver.hlog.blocksize _ hbase.regionserver.max.logs。<a href="http://blog.sematext.com/2012/07/16/hbase-memstore-what-you-should-know/">这里</a>说这两个相乘的默认大小是 2GB，查代码，hbase.regionserver.max.logs 默认值是 32，而 hbase.regionserver.hlog.blocksize 是 HDFS 的默认 blocksize，32MB。但不管怎么样，因为这个大小超过限制引起的 Flush 不是一件好事，可能引起长时间的延迟，因而这篇文章给的建议：“Hint: keep hbase.regionserver.hlog.blocksize _ hbase.regionserver.maxlogs just a bit above hbase.regionserver.global.memstore.lowerLimit _ HBASE_HEAPSIZE.”。并且需要注意，<a href="http://hbase.apache.org/book.html#_memstore_flush">这里</a>给的描述是有错的(虽然它是官方的文档)。</li>
</ol>
<p>在 MemStore Flush 过程中，还会在尾部追加一些 meta 数据，其中就包括 Flush 时最大的 WAL sequence 值，以告诉 HBase 这个 StoreFile 写入的最新数据的序列，那么在 Recover 时就直到从哪里开始。在 HRegion 启动时，这个 sequence 会被读取，并取最大的作为下一次更新时的起始 sequence。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583046-e073a721-456c-4607-89f7-ec5a222e50f0.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8e41b38a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=248&originWidth=622&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=64652&status=done&style=none&taskId=u01119a37-ba73-457e-89cf-4e03d0108f9&title=" alt="image.png"></p>
<h2 id="HFile-格式"><a href="#HFile-格式" class="headerlink" title="HFile 格式"></a>HFile 格式</h2><p>HBase 的数据以 KeyValue(Cell)的形式顺序的存储在 HFile 中，在 MemStore 的 Flush 过程中生成 HFile，由于 MemStore 中存储的 Cell 遵循相同的排列顺序，因而 Flush 过程是顺序写，我们直到磁盘的顺序写性能很高，因为不需要不停的移动磁盘指针。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583239-35f30a61-6003-4baa-b78e-d0406b53f458.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uec0329c3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=351&originWidth=698&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115221&status=done&style=none&taskId=u3b84bd8d-8533-4733-9068-58f3d383a88&title=" alt="image.png"><br>HFile 参考 BigTable 的 SSTable 和 Hadoop 的<a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/file/tfile/TFile.html">TFile</a>实现，从 HBase 开始到现在，HFile 经历了三个版本，其中 V2 在 0.92 引入，V3 在 0.98 引入。首先我们来看一下 V1 的格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583656-2174688c-da96-443f-a46f-d8e391ffc97b.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9844c88d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=160&originWidth=554&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=72628&status=done&style=none&taskId=u55f4c3b1-daf2-4893-935c-09a8dd5acb9&title=" alt="image.png"><br>V1 的 HFile 由多个 Data Block、Meta Block、FileInfo、Data Index、Meta Index、Trailer 组成，其中 Data Block 是 HBase 的最小存储单元，在前文中提到的 BlockCache 就是基于 Data Block 的缓存的。一个 Data Block 由一个魔数和一系列的 KeyValue(Cell)组成，魔数是一个随机的数字，用于表示这是一个 Data Block 类型，以快速监测这个 Data Block 的格式，防止数据的破坏。Data Block 的大小可以在创建 Column Family 时设置(HColumnDescriptor.setBlockSize())，默认值是 64KB，大号的 Block 有利于顺序 Scan，小号 Block 利于随机查询，因而需要权衡。Meta 块是可选的，FileInfo 是固定长度的块，它纪录了文件的一些 Meta 信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY 等。Data Index 和 Meta Index 纪录了每个 Data 块和 Meta 块的其实点、未压缩时大小、Key(起始 RowKey？)等。Trailer 纪录了 FileInfo、Data Index、Meta Index 块的起始位置，Data Index 和 Meta Index 索引的数量等。其中 FileInfo 和 Trailer 是固定长度的。<br>HFile 里面的每个 KeyValue 对就是一个简单的 byte 数组。但是这个 byte 数组里面包含了很多项，并且有固定的结构。我们来看看里面的具体结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916583953-34c63a35-4c72-417a-bb89-8902777196ee.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ufac2071c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=93&originWidth=553&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=68710&status=done&style=none&taskId=u99911b0c-045d-4a97-bbe0-73cbdafbed4&title=" alt="image.png"><br>开始是两个固定长度的数值，分别表示 Key 的长度和 Value 的长度。紧接着是 Key，开始是固定长度的数值，表示 RowKey 的长度，紧接着是 RowKey，然后是固定长度的数值，表示 Family 的长度，然后是 Family，接着是 Qualifier，然后是两个固定长度的数值，表示 Time Stamp 和 Key Type（Put&#x2F;Delete）。Value 部分没有这么复杂的结构，就是纯粹的二进制数据了。随着 HFile 版本迁移，KeyValue(Cell)的格式并未发生太多变化，只是在 V3 版本，尾部添加了一个可选的 Tag 数组。<br>HFileV1 版本的在实际使用过程中发现它占用内存多，并且 Bloom File 和 Block Index 会变的很大，而引起启动时间变长。其中每个 HFile 的 Bloom Filter 可以增长到 100MB，这在查询时会引起性能问题，因为每次查询时需要加载并查询 Bloom Filter，100MB 的 Bloom Filer 会引起很大的延迟；另一个，Block Index 在一个 HRegionServer 可能会增长到总共 6GB，HRegionServer 在启动时需要先加载所有这些 Block Index，因而增加了启动时间。为了解决这些问题，在 0.92 版本中引入 HFileV2 版本：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916584996-bbbb6bb6-fc78-4a2c-8547-8ec1dbf366a1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7e338f01&margin=%5Bobject%20Object%5D&name=image.png&originHeight=418&originWidth=566&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=59249&status=done&style=none&taskId=u3169ce73-eb5d-4b8b-8c12-fe22df00816&title=" alt="image.png"><br>在这个版本中，Block Index 和 Bloom Filter 添加到了 Data Block 中间，而这种设计同时也减少了写的内存使用量；另外，为了提升启动速度，在这个版本中还引入了延迟读的功能，即在 HFile 真正被使用时才对其进行解析。<br>FileV3 版本基本和 V2 版本相比，并没有太大的改变，它在 KeyValue(Cell)层面上添加了 Tag 数组的支持；并在 FileInfo 结构中添加了和 Tag 相关的两个字段。关于具体 HFile 格式演化介绍，可以参考<a href="http://hbase.apache.org/book.html#_hfile_format_2">这里</a>。<br>对 HFileV2 格式具体分析，它是一个多层的类 B+树索引，采用这种设计，可以实现查找不需要读取整个文件：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585756-2c38fca8-e68c-4d91-a8dd-7d557a9b30bc.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u667d00a9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=349&originWidth=688&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107524&status=done&style=none&taskId=u8dc1ef81-99a0-428d-b317-b7c86f91e80&title=" alt="image.png"><br>Data Block 中的 Cell 都是升序排列，每个 block 都有它自己的 Leaf-Index，每个 Block 的最后一个 Key 被放入 Intermediate-Index 中，Root-Index 指向 Intermediate-Index。在 HFile 的末尾还有 Bloom Filter 用于快速定位那么没有在某个 Data Block 中的 Row；TimeRange 信息用于给那些使用时间查询的参考。在 HFile 打开时，这些索引信息都被加载并保存在内存中，以增加以后的读取性能。</p>
<h2 id="HBase-读的实现"><a href="#HBase-读的实现" class="headerlink" title="HBase 读的实现"></a>HBase 读的实现</h2><p>通过前文的描述，我们知道在 HBase 写时，相同 Cell(RowKey&#x2F;ColumnFamily&#x2F;Column 相同)并不保证在一起，甚至删除一个 Cell 也只是写入一个新的 Cell，它含有 Delete 标记，而不一定将一个 Cell 真正删除了，因而这就引起了一个问题，如何实现读的问题？要解决这个问题，我们先来分析一下相同的 Cell 可能存在的位置：首先对新写入的 Cell，它会存在于 MemStore 中；然后对之前已经 Flush 到 HDFS 中的 Cell，它会存在于某个或某些 StoreFile(HFile)中；最后，对刚读取过的 Cell，它可能存在于 BlockCache 中。既然相同的 Cell 可能存储在三个地方，在读取的时候只需要扫瞄这三个地方，然后将结果合并即可(Merge Read)，在 HBase 中扫瞄的顺序依次是：BlockCache、MemStore、StoreFile(HFile)。其中 StoreFile 的扫瞄先会使用 Bloom Filter 过滤那些不可能符合条件的 HFile，然后使用 Block Index 快速定位 Cell，并将其加载到 BlockCache 中，然后从 BlockCache 中读取。我们知道一个 HStore 可能存在多个 StoreFile(HFile)，此时需要扫瞄多个 HFile，如果 HFile 过多又是会引起性能问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585461-55084b02-31ea-4bb5-9df2-2ab8931fad2c.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u650f6de0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=278&originWidth=769&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=107309&status=done&style=none&taskId=ueb6d7da0-a4dc-47eb-bce5-8a4918d43e7&title=" alt="image.png"></p>
<h2 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h2><p>MemStore 每次 Flush 会创建新的 HFile，而过多的 HFile 会引起读的性能问题，那么如何解决这个问题呢？HBase 采用 Compaction 机制来解决这个问题，有点类似 Java 中的 GC 机制，起初 Java 不停的申请内存而不释放，增加性能，然而天下没有免费的午餐，最终我们还是要在某个条件下去收集垃圾，很多时候需要 Stop-The-World，这种 Stop-The-World 有些时候也会引起很大的问题，因而设计是一种权衡，没有完美的。还是类似 Java 中的 GC，在 HBase 中 Compaction 分为两种：Minor Compaction 和 Major Compaction。</p>
<ol>
<li>Minor Compaction 是指选取一些小的、相邻的 StoreFile 将他们合并成一个更大的 StoreFile，在这个过程中不会处理已经 Deleted 或 Expired 的 Cell。一次 Minor Compaction 的结果是更少并且更大的 StoreFile。（这个是对的吗？BigTable 中是这样描述 Minor Compaction 的：As write operations execute, the size of the memtable in- creases. When the memtable size reaches a threshold, the memtable is frozen, a new memtable is created, and the frozen memtable is converted to an SSTable and written to GFS. This minor compaction process has two goals: it shrinks the memory usage of the tablet server, and it reduces the amount of data that has to be read from the commit log during recovery if this server dies. Incom- ing read and write operations can continue while com- pactions occur. 也就是说它将 memtable 的数据 flush 的一个 HFile&#x2F;SSTable 称为一次 Minor Compaction）</li>
<li>Major Compaction 是指将所有的 StoreFile 合并成一个 StoreFile，在这个过程中，标记为 Deleted 的 Cell 会被删除，而那些已经 Expired 的 Cell 会被丢弃，那些已经超过最多版本数的 Cell 会被丢弃。一次 Major Compaction 的结果是一个 HStore 只有一个 StoreFile 存在。Major Compaction 可以手动或自动触发，然而由于它会引起很多的 IO 操作而引起性能问题，因而它一般会被安排在周末、凌晨等集群比较闲的时间。</li>
</ol>
<p>更形象一点，如下面两张图分别表示 Minor Compaction 和 Major Compaction。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585472-7b9745d6-455b-458e-a5e5-a751cc03fadd.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub1833466&margin=%5Bobject%20Object%5D&name=image.png&originHeight=329&originWidth=723&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=94709&status=done&style=none&taskId=u8358d499-81ee-4051-817d-9540dc51bc5&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916585518-f8e5d988-133a-4f90-b87d-3370099c3bb1.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua80b4458&margin=%5Bobject%20Object%5D&name=image.png&originHeight=339&originWidth=653&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=93417&status=done&style=none&taskId=u2201da79-e7a4-4e5e-af63-b9e178ad60a&title=" alt="image.png"></p>
<h2 id="HRegion-Split"><a href="#HRegion-Split" class="headerlink" title="HRegion Split"></a>HRegion Split</h2><p>最初，一个 Table 只有一个 HRegion，随着数据写入增加，如果一个 HRegion 到达一定的大小，就需要 Split 成两个 HRegion，这个大小由 hbase.hregion.max.filesize 指定，默认为 10GB。当 split 时，两个新的 HRegion 会在同一个 HRegionServer 中创建，它们各自包含父 HRegion 一半的数据，当 Split 完成后，父 HRegion 会下线，而新的两个子 HRegion 会向 HMaster 注册上线，处于负载均衡的考虑，这两个新的 HRegion 可能会被 HMaster 分配到其他的 HRegionServer 中。关于 Split 的详细信息，可以参考这篇文章：<a href="http://hortonworks.com/blog/apache-hbase-region-splitting-and-merging/">《Apache HBase Region Splitting and Merging》</a>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586158-3ba24d92-6644-4a0f-91a1-d00da5867a28.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7d90fe99&margin=%5Bobject%20Object%5D&name=image.png&originHeight=361&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=85469&status=done&style=none&taskId=u7e157502-2bf1-4daf-9c17-071a1dc9564&title=" alt="image.png"></p>
<h2 id="HRegion-负载均衡"><a href="#HRegion-负载均衡" class="headerlink" title="HRegion 负载均衡"></a>HRegion 负载均衡</h2><p>在 HRegion Split 后，两个新的 HRegion 最初会和之前的父 HRegion 在相同的 HRegionServer 上，出于负载均衡的考虑，HMaster 可能会将其中的一个甚至两个重新分配的其他的 HRegionServer 中，此时会引起有些 HRegionServer 处理的数据在其他节点上，直到下一次 Major Compaction 将数据从远端的节点移动到本地节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916586722-3a111ac3-cc8a-4dfd-ab85-4e6f68fe4306.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucfafb6f6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=358&originWidth=714&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=113593&status=done&style=none&taskId=u3068847b-f220-4283-af84-153c8256a06&title=" alt="image.png"></p>
<h2 id="HRegionServer-Recovery"><a href="#HRegionServer-Recovery" class="headerlink" title="HRegionServer Recovery"></a>HRegionServer Recovery</h2><p>当一台 HRegionServer 宕机时，由于它不再发送 Heartbeat 给 ZooKeeper 而被监测到，此时 ZooKeeper 会通知 HMaster，HMaster 会检测到哪台 HRegionServer 宕机，它将宕机的 HRegionServer 中的 HRegion 重新分配给其他的 HRegionServer，同时 HMaster 会把宕机的 HRegionServer 相关的 WAL 拆分分配给相应的 HRegionServer(将拆分出的 WAL 文件写入对应的目的 HRegionServer 的 WAL 目录中，并并写入对应的 DataNode 中），从而这些 HRegionServer 可以 Replay 分到的 WAL 来重建 MemStore。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587040-3b89bd6c-f56a-4d12-b005-539cdc9e8aae.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u53643cd9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=368&originWidth=708&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=133786&status=done&style=none&taskId=ued635896-8d3d-47e9-aaa1-848ae861ace&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647916587014-ac39bb9d-e5ab-48af-9f60-8389745baa26.png#clientId=u7e4f54de-bf6f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u22d50009&margin=%5Bobject%20Object%5D&name=image.png&originHeight=378&originWidth=724&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=79489&status=done&style=none&taskId=u3d4037a7-ea2b-4d85-8a02-fa381b36016&title=" alt="image.png"><br>HBase 架构简单总结 在 NoSQL 中，存在著名的 CAP 理论，即 Consistency、Availability、Partition Tolerance 不可全得，目前市场上基本上的 NoSQL 都采用 Partition Tolerance 以实现数据得水平扩展，来处理 Relational DataBase 遇到的无法处理数据量太大的问题，或引起的性能问题。因而只有剩下 C 和 A 可以选择。HBase 在两者之间选择了 Consistency，然后使用多个 HMaster 以及支持 HRegionServer 的 failure 监控、ZooKeeper 引入作为协调者等各种手段来解决 Availability 问题，然而当网络的 Split-Brain(Network Partition)发生时，它还是无法完全解决 Availability 的问题。从这个角度上，Cassandra 选择了 A，即它在网络 Split-Brain 时还是能正常写，而使用其他技术来解决 Consistency 的问题，如读的时候触发 Consistency 判断和处理。这是设计上的限制。<br>从实现上的优点</p>
<ol>
<li>HBase 采用强一致性模型，在一个写返回后，保证所有的读都读到相同的数据。</li>
<li>通过 HRegion 动态 Split 和 Merge 实现自动扩展，并使用 HDFS 提供的多个数据备份功能，实现高可用性。</li>
<li>采用 HRegionServer 和 DataNode 运行在相同的服务器上实现数据的本地化，提升读写性能，并减少网络压力。</li>
<li>内建 HRegionServer 的宕机自动恢复。采用 WAL 来 Replay 还未持久化到 HDFS 的数据。</li>
<li>可以无缝的和 Hadoop&#x2F;MapReduce 集成。</li>
</ol>
<p>实现上的缺点</p>
<ol>
<li>WAL 的 Replay 过程可能会很慢。</li>
<li>灾难恢复比较复杂，也会比较慢。</li>
<li>Major Compaction 会引起 IO Storm。</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.mapr.com/blog/in-depth-look-hbase-architecture/">https://www.mapr.com/blog/in-depth-look-hbase-architecture/</a><br><a href="http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable">http://jimbojw.com/wiki/index.php?title=Understanding_Hbase_and_BigTable</a><br><a href="http://hbase.apache.org/book.html">http://hbase.apache.org/book.html</a><br><a href="http://www.searchtb.com/2011/01/understanding-hbase.html">http://www.searchtb.com/2011/01/understanding-hbase.html</a><br><a href="http://research.google.com/archive/bigtable-osdi06.pdf">http://research.google.com/archive/bigtable-osdi06.pdf</a></p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase LSM树</title>
    <url>/article/hbase/hbase-lsm/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/181498475">https://zhuanlan.zhihu.com/p/181498475</a></p>
</blockquote>
<p>LSM 树(Log-Structured-Merge-Tree)的名字往往会给初识者一个错误的印象，事实上，LSM 树并不像 B+树、红黑树一样是一颗严格的树状数据结构，它其实是一种存储结构，目前<strong>HBase、LevelDB、RocksDB 这些 NoSQL 存储都是采用的 LSM 树</strong>。<br>LSM 树的核心特点是<strong>利用顺序写来提高写性能</strong>，但因为分层(此处分层是指的<strong>分为内存和文件两部分</strong>)的设计会稍微降低读性能，但是<strong>通过牺牲小部分读性能换来高性能写</strong>，使得 LSM 树成为非常流行的存储结构。</p>
<p>数据库存储有两种数据结构，一种 B+树，另外一种是 LSM。数据库，我们知道是用 B+树，但是对于 LSM，就不是所有人都知道。因为这种数据结构适用大数据的存储场景，适用于写多读少的场景。</p>
<h1 id="LSM-数据结构"><a href="#LSM-数据结构" class="headerlink" title="LSM 数据结构"></a>LSM 数据结构</h1><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648782774822-e07bae96-e83e-45d9-9c48-88500f652b40.png#clientId=u2acb4bb6-2979-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=511&id=u09414e6c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=511&originWidth=879&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=204654&status=done&style=none&taskId=u846292cb-eb66-4a68-81ac-2585241568f&title=&width=879" alt="image.png"><br>LSM 数据结构如上图，写入数据时：</p>
<ul>
<li>先写入 WAL，用于故障恢复，如果断电，由于有 WAL Log 的存在，不会导致数据丢失。</li>
<li>再写入 MemTable 中，如果 MemTable 满，则数据被迁移到 Imutable Memtable 中。</li>
<li>后台线程发现有 Imutable Memtable，就写入到 SStable， SStable 的 key 都是有序的。</li>
<li>当 level0 的 ssTbale 满，就把数据迁移到 level1，并且和 level1 的数据进行归并排序，依次类推</li>
</ul>
<h1 id="各种操作"><a href="#各种操作" class="headerlink" title="各种操作"></a>各种操作</h1><ul>
<li>写入操作，写入 WAL Log 和 Memtable 就认为成功</li>
<li>读取，先到 Memtable 和 Imutable memtable 查找，如果查不到就到 SSTable 中查找，查找每个 SStable，使用布隆过滤器进行加速，指导找到数据。</li>
<li>删除，只进行标记，在合并 SSTable 时才会被真正删除</li>
<li>修改，知识插入数据，合并数据时，才会将旧值删除。数据读取时，新数据位置总是比旧数据位置高，因此总能读到最新值。</li>
</ul>
<h1 id="LSM-存储引擎"><a href="#LSM-存储引擎" class="headerlink" title="LSM 存储引擎"></a>LSM 存储引擎</h1><table><thead><tr>
<th>名称</th>
<th>语言</th>
</tr>
</thead><tbody><tr>
<td>levelDB</td>
<td>C++</td>
</tr>
<tr>
<td>RocksDB</td>
<td>C++</td>
</tr>
<tr>
<td>Pebble</td>
<td>go</td>
</tr>
<tr>
<td>BadgerDB</td>
<td>go</td>
</tr>
<tr>
<td>WiredTiger</td>
<td>C++</td>
</tr>
</tbody></table><h2 id="1、LSM-树的核心思想"><a href="#1、LSM-树的核心思想" class="headerlink" title="1、LSM 树的核心思想"></a>1、LSM 树的核心思想</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152629-31cc029c-b053-4c4a-8b43-942de4a48509.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u972f3a25&margin=%5Bobject%20Object%5D&name=image.png&originHeight=658&originWidth=1200&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=386575&status=done&style=none&taskId=ucf8d5271-fc9c-4832-9e79-91b6a6f1164&title=" alt="image.png"><br>如上图所示，LSM 树有以下三个重要组成部分：<br><strong>1、MemTable</strong><br>MemTable 是在内存中的数据结构，用于保存最近更新的数据，会按照 Key 有序地组织这些数据，LSM 树对于具体如何组织有序地组织数据并没有明确的数据结构定义，例如<strong>Hbase 使跳跃表来保证内存中 key 的有序。</strong><br>因为数据暂时保存在内存中，内存并不是可靠存储，如果断电会丢失数据，因此通常会通过 WAL(Write-ahead logging，预写式日志)的方式来保证数据的可靠性。<br><strong>2、Immutable MemTable</strong><br>当 MemTable 达到一定大小后，会转化成 Immutable MemTable。Immutable MemTable 是将转 MemTable 变为 SSTable 的一种中间状态。写操作由新的 MemTable 处理，在转存过程中不阻塞数据更新操作。<br><strong>3、SSTable(Sorted String Table)</strong><br>有序键值对集合，是 LSM 树组在磁盘中的数据结构。为了加快 SSTable 的读取，<strong>可以通过建立 key 的索引以及布隆过滤器来加快 key 的查找。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152281-96ed0749-fbd8-4a16-9d45-5732d2ed7fe3.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u58026748&margin=%5Bobject%20Object%5D&name=image.png&originHeight=232&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=88602&status=done&style=none&taskId=ua10f98a5-34fb-43d8-a2db-b9f33da7459&title=" alt="image.png"><br>这里需要关注一个重点，LSM 树(Log-Structured-Merge-Tree)正如它的名字一样，<strong>LSM 树会将所有的数据插入、修改、删除等操作记录(注意是操作记录)保存在内存之中，当此类操作达到一定的数据量后，再批量地顺序写入到磁盘当中</strong>。这与 B+树不同，B+树数据的更新会直接在原数据所在处修改对应的值，但是 LSM 数的数据更新是日志式的，当一条数据更新是直接 append 一条更新记录完成的。这样设计的目的就是为了顺序写，不断地将 Immutable MemTable flush 到持久化存储即可，而不用去修改之前的 SSTable 中的 key，保证了顺序写。<br>因此当 MemTable 达到一定大小 flush 到持久化存储变成 SSTable 后，在不同的 SSTable 中，可能存在相同 Key 的记录，当然最新的那条记录才是准确的。这样设计的虽然大大提高了写性能，但同时也会带来一些问题：<br>1）<strong>冗余存储</strong>，对于某个 key，<strong>实际上除了最新的那条记录外，其他的记录都是冗余无用的，但是仍然占用了存储空间</strong>。因此需要进行<strong>Compact</strong>操作(合并多个 SSTable)来清除冗余的记录。<br>2）<strong>读取时需要从最新的倒着查询，直到找到某个 key 的记录</strong>。最坏情况需要查询完所有的 SSTable，这里可以通过前面提到的<strong>索引&#x2F;布隆过滤器来优化查找速度</strong>。</p>
<h2 id="2、LSM-树的-Compact-策略"><a href="#2、LSM-树的-Compact-策略" class="headerlink" title="2、LSM 树的 Compact 策略"></a>2、LSM 树的 Compact 策略</h2><p>从上面可以看出，Compact 操作是十分关键的操作，否则 SSTable 数量会不断膨胀。在 Compact 策略上，主要介绍两种基本策略：size-tiered 和 leveled。<br>不过在介绍这两种策略之前，先介绍三个比较重要的概念，事实上不同的策略就是围绕这三个概念之间做出权衡和取舍。<br>1）读放大:读取数据时实际读取的数据量大于真正的数据量。例如在 LSM 树中需要先在 MemTable 查看当前 key 是否存在，不存在继续从 SSTable 中寻找。<br>2）写放大:写入数据时实际写入的数据量大于真正的数据量。例如在 LSM 树中写入时可能触发 Compact 操作，导致实际写入的数据量远大于该 key 的数据量。<br>3）空间放大:数据实际占用的磁盘空间比数据的真正大小更多。上面提到的冗余存储，对于一个 key 来说，只有最新的那条记录是有效的，而之前的记录都是可以被清理回收的。</p>
<ol>
<li>size-tiered 策略<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152721-e76596d5-0080-4b6e-9151-9cfab81e195b.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucf78aa97&margin=%5Bobject%20Object%5D&name=image.png&originHeight=580&originWidth=1200&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=341829&status=done&style=none&taskId=u026339dc-3aa2-4024-bc4e-562e51f9a72&title=" alt="image.png"><br>size-tiered 策略保证每层 SSTable 的大小相近，同时限制每一层 SSTable 的数量。如上图，每层限制 SSTable 为 N，当每层 SSTable 达到 N 后，则触发 Compact 操作合并这些 SSTable，并将合并后的结果写入到下一层成为一个更大的 sstable。<br>由此可以看出，当层数达到一定数量时，最底层的单个 SSTable 的大小会变得非常大。并且 size-tiered 策略会导致空间放大比较严重。即使对于同一层的 SSTable，每个 key 的记录是可能存在多份的，只有当该层的 SSTable 执行 compact 操作才会消除这些 key 的冗余记录。</li>
<li>leveled 策略<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152613-d422f605-292d-417b-87bc-8293944590ad.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u284ea5cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=499&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=330444&status=done&style=none&taskId=u502a56c4-3097-4817-a916-1aed1559928&title=" alt="image.png"><br>每一层的总大小固定，从上到下逐渐变大<br>leveled 策略也是采用分层的思想，每一层限制总文件的大小。<br>但是跟 size-tiered 策略不同的是，leveled 会将每一层切分成多个大小相近的 SSTable。这些 SSTable 是这一层是全局有序的，意味着一个 key 在每一层至多只有 1 条记录，不存在冗余记录。之所以可以保证全局有序，是因为合并策略和 size-tiered 不同，接下来会详细提到。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152744-2b567574-b5e3-4ffb-a230-7cf04ae15775.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4940d6eb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=363231&status=done&style=none&taskId=u66e495e6-8efd-4697-8afe-a41167577ea&title=" alt="image.png"><br>每一层的 SSTable 是全局有序的<br>假设存在以下这样的场景:</li>
<li>L1 的总大小超过 L1 本身大小限制：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881153366-fc8a14ae-e81a-4315-a823-aa9301034a63.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7305f53a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=585&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=304750&status=done&style=none&taskId=u8e4a79e9-6fac-4129-87dd-70f98c97b19&title=" alt="image.png"><br>此时 L1 超过了最大阈值限制</li>
<li>此时会从 L1 中选择至少一个文件，然后把它跟 L2 有交集的部分(非常关键)进行合并。生成的文件会放在 L2:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154456-8eafca00-e9c2-4d81-9297-7515721d5176.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf2d62342&margin=%5Bobject%20Object%5D&name=image.png&originHeight=702&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=374127&status=done&style=none&taskId=u2847075c-c596-4828-a44b-16f31687308&title=" alt="image.png"><br>如上图所示，此时 L1 第二 SSTable 的 key 的范围覆盖了 L2 中前三个 SSTable，那么就需要将 L1 中第二个 SSTable 与 L2 中前三个 SSTable 执行 Compact 操作。</li>
<li>如果 L2 合并后的结果仍旧超出 L5 的阈值大小，需要重复之前的操作 —— 选至少一个文件然后把它合并到下一层:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154356-0f57d4a5-8b6a-426c-b06e-0337b9cebaf6.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uacf7f33c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=585&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=336026&status=done&style=none&taskId=u058e9f79-1f83-428d-9016-ce1bd31b84c&title=" alt="image.png"><br>需要注意的是，多个不相干的合并是可以并发进行的：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154543-74fc0e7a-d5dd-42a5-b761-e6653799f498.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u75b8bce7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=741&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=492133&status=done&style=none&taskId=u9267fc93-dbcf-4cbf-8cdf-506e6bbab99&title=" alt="image.png"><br>leveled 策略相较于 size-tiered 策略来说，每层内 key 是不会重复的，即使是最坏的情况，除开最底层外，其余层都是重复 key，按照相邻层大小比例为 10 来算，冗余占比也很小。因此空间放大问题得到缓解。但是写放大问题会更加突出。举一个最坏场景，如果 LevelN 层某个 SSTable 的 key 的范围跨度非常大，覆盖了 LevelN+1 层所有 key 的范围，那么进行 Compact 时将涉及 LevelN+1 层的全部数据。</li>
</ol>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>LSM 树是非常值得了解的知识，理解了 LSM 树可以很自然地理解 Hbase，LevelDb 等存储组件的架构设计。<strong>ClickHouse 中的 MergeTree 也是 LSM 树的思想，Log-Structured 还可以联想到 Kafka 的存储方式</strong>。<br>虽然介绍了上面两种策略，但是各个存储都在自己的 Compact 策略上面做了很多特定的优化，例如<strong>Hbase 分为 Major 和 Minor 两种 Compact</strong>，这里不再做过多介绍，推荐阅读文末的 RocksDb 合并策略介绍。</p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase（三）LSM树</title>
    <url>/article/hbase/hbase-lsm/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/181498475">https://zhuanlan.zhihu.com/p/181498475</a></p>
</blockquote>
<p>LSM 树(Log-Structured-Merge-Tree)的名字往往会给初识者一个错误的印象，事实上，LSM 树并不像 B+树、红黑树一样是一颗严格的树状数据结构，它其实是一种存储结构，目前<strong>HBase、LevelDB、RocksDB 这些 NoSQL 存储都是采用的 LSM 树</strong>。<br>LSM 树的核心特点是<strong>利用顺序写来提高写性能</strong>，但因为分层(此处分层是指的<strong>分为内存和文件两部分</strong>)的设计会稍微降低读性能，但是<strong>通过牺牲小部分读性能换来高性能写</strong>，使得 LSM 树成为非常流行的存储结构。</p>
<p>数据库存储有两种数据结构，一种 B+树，另外一种是 LSM。数据库，我们知道是用 B+树，但是对于 LSM，就不是所有人都知道。因为这种数据结构适用大数据的存储场景，适用于写多读少的场景。</p>
<h1 id="LSM-数据结构"><a href="#LSM-数据结构" class="headerlink" title="LSM 数据结构"></a>LSM 数据结构</h1><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648782774822-e07bae96-e83e-45d9-9c48-88500f652b40.png#clientId=u2acb4bb6-2979-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=511&id=u09414e6c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=511&originWidth=879&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=204654&status=done&style=none&taskId=u846292cb-eb66-4a68-81ac-2585241568f&title=&width=879" alt="image.png"><br>LSM 数据结构如上图，写入数据时：</p>
<ul>
<li>先写入 WAL，用于故障恢复，如果断电，由于有 WAL Log 的存在，不会导致数据丢失。</li>
<li>再写入 MemTable 中，如果 MemTable 满，则数据被迁移到 Imutable Memtable 中。</li>
<li>后台线程发现有 Imutable Memtable，就写入到 SStable， SStable 的 key 都是有序的。</li>
<li>当 level0 的 ssTbale 满，就把数据迁移到 level1，并且和 level1 的数据进行归并排序，依次类推</li>
</ul>
<h1 id="各种操作"><a href="#各种操作" class="headerlink" title="各种操作"></a>各种操作</h1><ul>
<li>写入操作，写入 WAL Log 和 Memtable 就认为成功</li>
<li>读取，先到 Memtable 和 Imutable memtable 查找，如果查不到就到 SSTable 中查找，查找每个 SStable，使用布隆过滤器进行加速，指导找到数据。</li>
<li>删除，只进行标记，在合并 SSTable 时才会被真正删除</li>
<li>修改，知识插入数据，合并数据时，才会将旧值删除。数据读取时，新数据位置总是比旧数据位置高，因此总能读到最新值。</li>
</ul>
<h1 id="LSM-存储引擎"><a href="#LSM-存储引擎" class="headerlink" title="LSM 存储引擎"></a>LSM 存储引擎</h1><table><thead><tr>
<th>名称</th>
<th>语言</th>
</tr>
</thead><tbody><tr>
<td>levelDB</td>
<td>C++</td>
</tr>
<tr>
<td>RocksDB</td>
<td>C++</td>
</tr>
<tr>
<td>Pebble</td>
<td>go</td>
</tr>
<tr>
<td>BadgerDB</td>
<td>go</td>
</tr>
<tr>
<td>WiredTiger</td>
<td>C++</td>
</tr>
</tbody></table><h2 id="1、LSM-树的核心思想"><a href="#1、LSM-树的核心思想" class="headerlink" title="1、LSM 树的核心思想"></a>1、LSM 树的核心思想</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152629-31cc029c-b053-4c4a-8b43-942de4a48509.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u972f3a25&margin=%5Bobject%20Object%5D&name=image.png&originHeight=658&originWidth=1200&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=386575&status=done&style=none&taskId=ucf8d5271-fc9c-4832-9e79-91b6a6f1164&title=" alt="image.png"><br>如上图所示，LSM 树有以下三个重要组成部分：<br><strong>1、MemTable</strong><br>MemTable 是在内存中的数据结构，用于保存最近更新的数据，会按照 Key 有序地组织这些数据，LSM 树对于具体如何组织有序地组织数据并没有明确的数据结构定义，例如<strong>Hbase 使跳跃表来保证内存中 key 的有序。</strong><br>因为数据暂时保存在内存中，内存并不是可靠存储，如果断电会丢失数据，因此通常会通过 WAL(Write-ahead logging，预写式日志)的方式来保证数据的可靠性。<br><strong>2、Immutable MemTable</strong><br>当 MemTable 达到一定大小后，会转化成 Immutable MemTable。Immutable MemTable 是将转 MemTable 变为 SSTable 的一种中间状态。写操作由新的 MemTable 处理，在转存过程中不阻塞数据更新操作。<br><strong>3、SSTable(Sorted String Table)</strong><br>有序键值对集合，是 LSM 树组在磁盘中的数据结构。为了加快 SSTable 的读取，<strong>可以通过建立 key 的索引以及布隆过滤器来加快 key 的查找。</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152281-96ed0749-fbd8-4a16-9d45-5732d2ed7fe3.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u58026748&margin=%5Bobject%20Object%5D&name=image.png&originHeight=232&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=88602&status=done&style=none&taskId=ua10f98a5-34fb-43d8-a2db-b9f33da7459&title=" alt="image.png"><br>这里需要关注一个重点，LSM 树(Log-Structured-Merge-Tree)正如它的名字一样，<strong>LSM 树会将所有的数据插入、修改、删除等操作记录(注意是操作记录)保存在内存之中，当此类操作达到一定的数据量后，再批量地顺序写入到磁盘当中</strong>。这与 B+树不同，B+树数据的更新会直接在原数据所在处修改对应的值，但是 LSM 数的数据更新是日志式的，当一条数据更新是直接 append 一条更新记录完成的。这样设计的目的就是为了顺序写，不断地将 Immutable MemTable flush 到持久化存储即可，而不用去修改之前的 SSTable 中的 key，保证了顺序写。<br>因此当 MemTable 达到一定大小 flush 到持久化存储变成 SSTable 后，在不同的 SSTable 中，可能存在相同 Key 的记录，当然最新的那条记录才是准确的。这样设计的虽然大大提高了写性能，但同时也会带来一些问题：<br>1）<strong>冗余存储</strong>，对于某个 key，<strong>实际上除了最新的那条记录外，其他的记录都是冗余无用的，但是仍然占用了存储空间</strong>。因此需要进行<strong>Compact</strong>操作(合并多个 SSTable)来清除冗余的记录。<br>2）<strong>读取时需要从最新的倒着查询，直到找到某个 key 的记录</strong>。最坏情况需要查询完所有的 SSTable，这里可以通过前面提到的<strong>索引&#x2F;布隆过滤器来优化查找速度</strong>。</p>
<h2 id="2、LSM-树的-Compact-策略"><a href="#2、LSM-树的-Compact-策略" class="headerlink" title="2、LSM 树的 Compact 策略"></a>2、LSM 树的 Compact 策略</h2><p>从上面可以看出，Compact 操作是十分关键的操作，否则 SSTable 数量会不断膨胀。在 Compact 策略上，主要介绍两种基本策略：size-tiered 和 leveled。<br>不过在介绍这两种策略之前，先介绍三个比较重要的概念，事实上不同的策略就是围绕这三个概念之间做出权衡和取舍。<br>1）读放大:读取数据时实际读取的数据量大于真正的数据量。例如在 LSM 树中需要先在 MemTable 查看当前 key 是否存在，不存在继续从 SSTable 中寻找。<br>2）写放大:写入数据时实际写入的数据量大于真正的数据量。例如在 LSM 树中写入时可能触发 Compact 操作，导致实际写入的数据量远大于该 key 的数据量。<br>3）空间放大:数据实际占用的磁盘空间比数据的真正大小更多。上面提到的冗余存储，对于一个 key 来说，只有最新的那条记录是有效的，而之前的记录都是可以被清理回收的。</p>
<ol>
<li>size-tiered 策略<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152721-e76596d5-0080-4b6e-9151-9cfab81e195b.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucf78aa97&margin=%5Bobject%20Object%5D&name=image.png&originHeight=580&originWidth=1200&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=341829&status=done&style=none&taskId=u026339dc-3aa2-4024-bc4e-562e51f9a72&title=" alt="image.png"><br>size-tiered 策略保证每层 SSTable 的大小相近，同时限制每一层 SSTable 的数量。如上图，每层限制 SSTable 为 N，当每层 SSTable 达到 N 后，则触发 Compact 操作合并这些 SSTable，并将合并后的结果写入到下一层成为一个更大的 sstable。<br>由此可以看出，当层数达到一定数量时，最底层的单个 SSTable 的大小会变得非常大。并且 size-tiered 策略会导致空间放大比较严重。即使对于同一层的 SSTable，每个 key 的记录是可能存在多份的，只有当该层的 SSTable 执行 compact 操作才会消除这些 key 的冗余记录。</li>
<li>leveled 策略<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152613-d422f605-292d-417b-87bc-8293944590ad.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u284ea5cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=499&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=330444&status=done&style=none&taskId=u502a56c4-3097-4817-a916-1aed1559928&title=" alt="image.png"><br>每一层的总大小固定，从上到下逐渐变大<br>leveled 策略也是采用分层的思想，每一层限制总文件的大小。<br>但是跟 size-tiered 策略不同的是，leveled 会将每一层切分成多个大小相近的 SSTable。这些 SSTable 是这一层是全局有序的，意味着一个 key 在每一层至多只有 1 条记录，不存在冗余记录。之所以可以保证全局有序，是因为合并策略和 size-tiered 不同，接下来会详细提到。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881152744-2b567574-b5e3-4ffb-a230-7cf04ae15775.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4940d6eb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=720&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=363231&status=done&style=none&taskId=u66e495e6-8efd-4697-8afe-a41167577ea&title=" alt="image.png"><br>每一层的 SSTable 是全局有序的<br>假设存在以下这样的场景:</li>
<li>L1 的总大小超过 L1 本身大小限制：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881153366-fc8a14ae-e81a-4315-a823-aa9301034a63.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7305f53a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=585&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=304750&status=done&style=none&taskId=u8e4a79e9-6fac-4129-87dd-70f98c97b19&title=" alt="image.png"><br>此时 L1 超过了最大阈值限制</li>
<li>此时会从 L1 中选择至少一个文件，然后把它跟 L2 有交集的部分(非常关键)进行合并。生成的文件会放在 L2:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154456-8eafca00-e9c2-4d81-9297-7515721d5176.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf2d62342&margin=%5Bobject%20Object%5D&name=image.png&originHeight=702&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=374127&status=done&style=none&taskId=u2847075c-c596-4828-a44b-16f31687308&title=" alt="image.png"><br>如上图所示，此时 L1 第二 SSTable 的 key 的范围覆盖了 L2 中前三个 SSTable，那么就需要将 L1 中第二个 SSTable 与 L2 中前三个 SSTable 执行 Compact 操作。</li>
<li>如果 L2 合并后的结果仍旧超出 L5 的阈值大小，需要重复之前的操作 —— 选至少一个文件然后把它合并到下一层:<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154356-0f57d4a5-8b6a-426c-b06e-0337b9cebaf6.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uacf7f33c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=585&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=336026&status=done&style=none&taskId=u058e9f79-1f83-428d-9016-ce1bd31b84c&title=" alt="image.png"><br>需要注意的是，多个不相干的合并是可以并发进行的：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647881154543-74fc0e7a-d5dd-42a5-b761-e6653799f498.png#clientId=u8b7829c3-cff1-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u75b8bce7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=741&originWidth=1440&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=492133&status=done&style=none&taskId=u9267fc93-dbcf-4cbf-8cdf-506e6bbab99&title=" alt="image.png"><br>leveled 策略相较于 size-tiered 策略来说，每层内 key 是不会重复的，即使是最坏的情况，除开最底层外，其余层都是重复 key，按照相邻层大小比例为 10 来算，冗余占比也很小。因此空间放大问题得到缓解。但是写放大问题会更加突出。举一个最坏场景，如果 LevelN 层某个 SSTable 的 key 的范围跨度非常大，覆盖了 LevelN+1 层所有 key 的范围，那么进行 Compact 时将涉及 LevelN+1 层的全部数据。</li>
</ol>
<h2 id="3、总结"><a href="#3、总结" class="headerlink" title="3、总结"></a>3、总结</h2><p>LSM 树是非常值得了解的知识，理解了 LSM 树可以很自然地理解 Hbase，LevelDb 等存储组件的架构设计。<strong>ClickHouse 中的 MergeTree 也是 LSM 树的思想，Log-Structured 还可以联想到 Kafka 的存储方式</strong>。<br>虽然介绍了上面两种策略，但是各个存储都在自己的 Compact 策略上面做了很多特定的优化，例如<strong>Hbase 分为 Major 和 Minor 两种 Compact</strong>，这里不再做过多介绍，推荐阅读文末的 RocksDb 合并策略介绍。</p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase Docker搭建</title>
    <url>/article/hbase/hbase-docker/</url>
    <content><![CDATA[<p>docker 脚本可以<a href="https://github.com/smizy/docker-hbase">从链接获取</a><br>修改 docker-compse.xml 文件，注意端口映射</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">version: &quot;2&quot;
services:

  zookeeper-1:
    container_name: zookeeper-1
    networks: [&quot;vnet&quot;]
    hostname: zookeeper-1.vnet
    image: smizy&#x2F;zookeeper:3.4-alpine
    ports:  [&quot;2181:2181&quot;]
    environment:
      - SERVICE_2181_NAME&#x3D;zookeeper
      - SERVICE_2888_IGNORE&#x3D;true
      - SERVICE_3888_IGNORE&#x3D;true

    command: -server 1 1 vnet

  namenode-1:
    container_name: namenode-1
    networks: [&quot;vnet&quot;]
    hostname: namenode-1.vnet
    image: smizy&#x2F;hadoop-base:2.7.6-alpine
    expose: [&quot;8020&quot;]
    ports:  [&quot;50070:50070&quot;,&quot;8020:8020&quot;]
    environment:
      - SERVICE_8020_NAME&#x3D;namenode
      - SERVICE_50070_IGNORE&#x3D;true
      - HADOOP_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181
      - HADOOP_HEAPSIZE&#x3D;1000
      - HADOOP_NAMENODE_HA&#x3D;

    entrypoint: entrypoint.sh
    command: namenode-1

  datanode-1:
    container_name: datanode-1
    networks: [&quot;vnet&quot;]
    hostname: datanode-1.vnet
    image: smizy&#x2F;hadoop-base:2.7.6-alpine
    expose: [&quot;50010&quot;, &quot;50020&quot;, &quot;50075&quot;]
    environment:
      - SERVICE_50010_NAME&#x3D;datanode
      - SERVICE_50020_IGNORE&#x3D;true
      - SERVICE_50075_IGNORE&#x3D;true
      - HADOOP_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181
      - HADOOP_HEAPSIZE&#x3D;1000
      - HADOOP_NAMENODE_HA&#x3D;

    entrypoint: entrypoint.sh
    command: datanode

  hmaster-1:
    container_name: hmaster-1
    networks: [&quot;vnet&quot;]
    hostname: hmaster-1.vnet
    image: smizy&#x2F;hbase:1.2.6.1-alpine
    expose: [16000]
    ports:  [&quot;16010:16010&quot;,&quot;16000:16000&quot;]
    depends_on: [&quot;zookeeper-1&quot;]
    environment:
      - SERVICE_16000_NAME&#x3D;hmaster
      - SERVICE_16010_IGNORE&#x3D;true
      - HBASE_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181

    volumes_from:
      - namenode-1
    command: hmaster-1

  regionserver-1:
    container_name: regionserver-1
    networks: [&quot;vnet&quot;]
    hostname: regionserver-1.vnet
    image: smizy&#x2F;hbase:1.2.6.1-alpine
    expose: [16020, 16030]
    ports: [&quot;16020:16020&quot;, &quot;16030:16030&quot;]
    depends_on: [&quot;zookeeper-1&quot;]
    environment:
      - SERVICE_16020_NAME&#x3D;regionserver
      - SERVICE_16030_IGNORE&#x3D;true
      - HBASE_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181

    command: regionserver

networks:
  vnet:
    external:
      name: vnet</code></pre>

<h2 id="运行-Hadoop-和-Hbase"><a href="#运行-Hadoop-和-Hbase" class="headerlink" title="运行 Hadoop 和 Hbase"></a>运行 Hadoop 和 Hbase</h2><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"># docker-machine default
docker-machine create --engine-registry-mirror&#x3D;https:&#x2F;&#x2F;xxx.mirror.aliyuncs.com -d virtualbox default

# load default env as needed
eval $(docker-machine env default)

# network
docker network create vnet

# make docker-compose.yml with small size (no redudency)
zookeeper&#x3D;1 namenode&#x3D;1 datanode&#x3D;1 .&#x2F;make_docker_compose_yml.sh hdfs hbase &gt; docker-compose.yml

# or with default size(zookeeper&#x3D;3, namenode&#x3D;2, journalnode&#x3D;3, datanode&#x3D;3, hmaster&#x3D;2, regionserver&#x3D;3)
.&#x2F;make_docker_compose_yml.sh hdfs hbase &gt; docker-compose.yml

# hadoop+hbase startup
docker-compose up -d

# tail logs for a while
docker-compose logs -f

# check ps
docker-compose ps

     Name                   Command               State                  Ports
---------------------------------------------------------------------------------------------
datanode-1       entrypoint.sh datanode           Up      50010&#x2F;tcp, 50020&#x2F;tcp, 50075&#x2F;tcp
hmaster-1        entrypoint.sh hmaster-1          Up      16000&#x2F;tcp, 0.0.0.0:32771-&gt;16010&#x2F;tcp
namenode-1       entrypoint.sh namenode-1         Up      0.0.0.0:32770-&gt;50070&#x2F;tcp, 8020&#x2F;tcp
regionserver-1   entrypoint.sh regionserver       Up      16020&#x2F;tcp, 16030&#x2F;tcp
zookeeper-1      entrypoint.sh -server 1 1 vnet   Up      2181&#x2F;tcp, 2888&#x2F;tcp, 3888&#x2F;tcp

# check stats
docker ps --format &#123;&#123;.Names&#125;&#125; | xargs docker stats

# hbase shell
docker exec -it -u hbase regionserver-1 hbase shell
hbase(main):001:0&gt; create &#39;test&#39;, &#39;cf&#39;
hbase(main):002:0&gt; list &#39;test&#39;
hbase(main):003:0&gt; put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
hbase(main):004:0&gt; put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
hbase(main):005:0&gt; put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
hbase(main):006:0&gt; scan &#39;test&#39;
hbase(main):007:0&gt; get &#39;test&#39;, &#39;row1&#39;
hbase(main):008:0&gt; disable &#39;test&#39;
hbase(main):009:0&gt; drop &#39;test&#39;
hbase(main):010:0&gt; exit

# hadoop&#x2F;hbase shutdown
docker-compose stop

# cleanup container
docker-compose rm -v</code></pre>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
  </entry>
  <entry>
    <title>HBase（二）Docker搭建</title>
    <url>/article/hbase/hbase-docker/</url>
    <content><![CDATA[<p>docker 脚本可以<a href="https://github.com/smizy/docker-hbase">从链接获取</a><br>修改 docker-compse.xml 文件，注意端口映射</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">version: &quot;2&quot;
services:

  zookeeper-1:
    container_name: zookeeper-1
    networks: [&quot;vnet&quot;]
    hostname: zookeeper-1.vnet
    image: smizy&#x2F;zookeeper:3.4-alpine
    ports:  [&quot;2181:2181&quot;]
    environment:
      - SERVICE_2181_NAME&#x3D;zookeeper
      - SERVICE_2888_IGNORE&#x3D;true
      - SERVICE_3888_IGNORE&#x3D;true

    command: -server 1 1 vnet

  namenode-1:
    container_name: namenode-1
    networks: [&quot;vnet&quot;]
    hostname: namenode-1.vnet
    image: smizy&#x2F;hadoop-base:2.7.6-alpine
    expose: [&quot;8020&quot;]
    ports:  [&quot;50070:50070&quot;,&quot;8020:8020&quot;]
    environment:
      - SERVICE_8020_NAME&#x3D;namenode
      - SERVICE_50070_IGNORE&#x3D;true
      - HADOOP_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181
      - HADOOP_HEAPSIZE&#x3D;1000
      - HADOOP_NAMENODE_HA&#x3D;

    entrypoint: entrypoint.sh
    command: namenode-1

  datanode-1:
    container_name: datanode-1
    networks: [&quot;vnet&quot;]
    hostname: datanode-1.vnet
    image: smizy&#x2F;hadoop-base:2.7.6-alpine
    expose: [&quot;50010&quot;, &quot;50020&quot;, &quot;50075&quot;]
    environment:
      - SERVICE_50010_NAME&#x3D;datanode
      - SERVICE_50020_IGNORE&#x3D;true
      - SERVICE_50075_IGNORE&#x3D;true
      - HADOOP_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181
      - HADOOP_HEAPSIZE&#x3D;1000
      - HADOOP_NAMENODE_HA&#x3D;

    entrypoint: entrypoint.sh
    command: datanode

  hmaster-1:
    container_name: hmaster-1
    networks: [&quot;vnet&quot;]
    hostname: hmaster-1.vnet
    image: smizy&#x2F;hbase:1.2.6.1-alpine
    expose: [16000]
    ports:  [&quot;16010:16010&quot;,&quot;16000:16000&quot;]
    depends_on: [&quot;zookeeper-1&quot;]
    environment:
      - SERVICE_16000_NAME&#x3D;hmaster
      - SERVICE_16010_IGNORE&#x3D;true
      - HBASE_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181

    volumes_from:
      - namenode-1
    command: hmaster-1

  regionserver-1:
    container_name: regionserver-1
    networks: [&quot;vnet&quot;]
    hostname: regionserver-1.vnet
    image: smizy&#x2F;hbase:1.2.6.1-alpine
    expose: [16020, 16030]
    ports: [&quot;16020:16020&quot;, &quot;16030:16030&quot;]
    depends_on: [&quot;zookeeper-1&quot;]
    environment:
      - SERVICE_16020_NAME&#x3D;regionserver
      - SERVICE_16030_IGNORE&#x3D;true
      - HBASE_ZOOKEEPER_QUORUM&#x3D;zookeeper-1.vnet:2181

    command: regionserver

networks:
  vnet:
    external:
      name: vnet</code></pre>

<h2 id="运行-Hadoop-和-Hbase"><a href="#运行-Hadoop-和-Hbase" class="headerlink" title="运行 Hadoop 和 Hbase"></a>运行 Hadoop 和 Hbase</h2><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"># docker-machine default
docker-machine create --engine-registry-mirror&#x3D;https:&#x2F;&#x2F;xxx.mirror.aliyuncs.com -d virtualbox default

# load default env as needed
eval $(docker-machine env default)

# network
docker network create vnet

# make docker-compose.yml with small size (no redudency)
zookeeper&#x3D;1 namenode&#x3D;1 datanode&#x3D;1 .&#x2F;make_docker_compose_yml.sh hdfs hbase &gt; docker-compose.yml

# or with default size(zookeeper&#x3D;3, namenode&#x3D;2, journalnode&#x3D;3, datanode&#x3D;3, hmaster&#x3D;2, regionserver&#x3D;3)
.&#x2F;make_docker_compose_yml.sh hdfs hbase &gt; docker-compose.yml

# hadoop+hbase startup
docker-compose up -d

# tail logs for a while
docker-compose logs -f

# check ps
docker-compose ps

     Name                   Command               State                  Ports
---------------------------------------------------------------------------------------------
datanode-1       entrypoint.sh datanode           Up      50010&#x2F;tcp, 50020&#x2F;tcp, 50075&#x2F;tcp
hmaster-1        entrypoint.sh hmaster-1          Up      16000&#x2F;tcp, 0.0.0.0:32771-&gt;16010&#x2F;tcp
namenode-1       entrypoint.sh namenode-1         Up      0.0.0.0:32770-&gt;50070&#x2F;tcp, 8020&#x2F;tcp
regionserver-1   entrypoint.sh regionserver       Up      16020&#x2F;tcp, 16030&#x2F;tcp
zookeeper-1      entrypoint.sh -server 1 1 vnet   Up      2181&#x2F;tcp, 2888&#x2F;tcp, 3888&#x2F;tcp

# check stats
docker ps --format &#123;&#123;.Names&#125;&#125; | xargs docker stats

# hbase shell
docker exec -it -u hbase regionserver-1 hbase shell
hbase(main):001:0&gt; create &#39;test&#39;, &#39;cf&#39;
hbase(main):002:0&gt; list &#39;test&#39;
hbase(main):003:0&gt; put &#39;test&#39;, &#39;row1&#39;, &#39;cf:a&#39;, &#39;value1&#39;
hbase(main):004:0&gt; put &#39;test&#39;, &#39;row2&#39;, &#39;cf:b&#39;, &#39;value2&#39;
hbase(main):005:0&gt; put &#39;test&#39;, &#39;row3&#39;, &#39;cf:c&#39;, &#39;value3&#39;
hbase(main):006:0&gt; scan &#39;test&#39;
hbase(main):007:0&gt; get &#39;test&#39;, &#39;row1&#39;
hbase(main):008:0&gt; disable &#39;test&#39;
hbase(main):009:0&gt; drop &#39;test&#39;
hbase(main):010:0&gt; exit

# hadoop&#x2F;hbase shutdown
docker-compose stop

# cleanup container
docker-compose rm -v</code></pre>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HBase（四）读优化</title>
    <url>/article/hbase/hbase-read-optimize/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://blog.csdn.net/weixin_40954192/article/details/106942029">https://blog.csdn.net/weixin_40954192&#x2F;article&#x2F;details&#x2F;106942029</a></p>
</blockquote>
<p>LSM 存储引擎是在 B+树的基础上衍生过来的，目的就是为了在读和写之间，提高写的性能。所以，LSM 树的弊端也由此可见，对读并不是很友好，所以，针对 LSM 树，有后续 compact，布隆过滤器，blockCache 等优化方式。来弥补对读的查询。<br>LSM 树的索引一般由 2 部分构成，一部分是内存部分，一部分是磁盘部分。内存部分采用跳跃表来维护一个有序的 KV 集合,也就是 memstore.随着内存不断数据写入，一旦内存占用超过一定的阈值，就把内存部分数据进行导出（这里的 flush 操作实则是通过两个跳跃表来完成的），形成一个有序的数据文件，存储在磁盘上，磁盘部分则是对应的 hFile。</p>
<h2 id="keyValue-存储格式"><a href="#keyValue-存储格式" class="headerlink" title="keyValue 存储格式"></a>keyValue 存储格式</h2><p>LSM 树中存储的是多个 keyValue 组成的集合。每一个 KeyValue 由一个字节数组来表示。如图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915437003-ca220200-1508-4b7f-9a2e-65f702f2d1e9.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=263&id=uf54582c0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=263&originWidth=1165&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=37515&status=done&style=none&taskId=ue4a68932-475c-49b0-9604-0ec8205fec1&title=&width=1165" alt="image.png"></p>
<h2 id="LSM-索引结构"><a href="#LSM-索引结构" class="headerlink" title="LSM 索引结构"></a>LSM 索引结构</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915452495-be03b890-a16f-4960-9043-b7a11fcf17ec.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=740&id=u1c1b950f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=740&originWidth=1006&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=90458&status=done&style=none&taskId=ueac0d2b5-5c06-43c2-af65-786d4db2922&title=&width=1006" alt="image.png">在 hbase 实现中，memstore 的数据达到某个级别的阈值之后，都会进行 flush 到 disk 中，形成一个 file。（前提为了怕 memstore 内存数据丢失，会先将数据写入到所属 regionServer 的 WAL 预写日志中）这个 file 的存储也就是一个小的 B+树，因为 hbase 一般是部署在 hdfs 上，hdfs 不支持对文件的 update 操作，而且最终随着磁盘文件越来越多，对读的影响很大。所以内存 flush 到磁盘上的小树，定期也会合并成一个大树。来增强读操作的性能，整体上 hbase 就是用了 lsm tree 的思路。</p>
<h2 id="多路归并"><a href="#多路归并" class="headerlink" title="多路归并"></a>多路归并</h2><p>为了优化读取操作的性能，hbase 会进行两种类型的 compact。<br><strong>一种是 major Compact，是将所有的 HFile 一次性多路归并成一个文件</strong>。这种方式的好处是，合并之后只有一个文件，这样读取的性能肯定是最高的。但它的问题是合并所有的文件可能需要很长的时间并消耗大量的 IO 贷款，所以 major Compact 不宜使用太频繁，适合周期性的跑。或者我们手动设置在闲时合并。<br><strong>另一种是 minor Compact，即选中少数几个 Hfile，将他们多路归并成一个文件</strong>。这种方式的有点是可以进行局部的 Compact，通过少量的 IO 减少文件个数，提高读取操作的性能。适合较高频率的跑。但它的缺点是只合并了局部的数据，对于那些全局删除操作，无法在合并过程中完全删除。</p>
<h2 id="多路归并原理"><a href="#多路归并原理" class="headerlink" title="多路归并原理"></a>多路归并原理</h2><p>比如现在我们有 K 个文件，其中第 i 个文件内存存储有 N 个正整数（这些整数在文件内按照从小到大的顺序排序）<br>多路归并的算法原理就是对每个文件设计一个指针，取出 K 个指针中数值最小的一个（对应的 K 个文件），然后把最小的那个指针后移，接着继续找 K 个指针中数值最小的一个，继续后移指针…直到文件全部读完为止。如图<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915475324-aaf3a59d-f6fe-4944-9012-5e22fc9149da.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=791&id=u06632d08&margin=%5Bobject%20Object%5D&name=image.png&originHeight=791&originWidth=742&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=70335&status=done&style=none&taskId=u585d56ee-4dad-479e-b1dc-eb44883e88f&title=&width=742" alt="image.png"><br>针对读取操作，还涉及到了布隆过滤器。<br>布隆过滤器是由一个长度为 N 的 01 数组组成的。首先将数组 array 每个元素初始设为 0，对集合 A 中的每个元素 w，做 K 次哈希，第 i 次哈希值对 N 取模得到一个 index(i).即 index(i) &#x3D; Hash_i（w） % N,将 array 数组中的 array[index(i)] 置为 1.最终变为一个这些元素为 1 的 01 数组。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647915498955-975c2bea-6ff2-4e5d-af75-1169d740f0ce.png#clientId=uc658cd9c-7178-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=699&id=u7296dd92&margin=%5Bobject%20Object%5D&name=image.png&originHeight=699&originWidth=886&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=99911&status=done&style=none&taskId=u6465223c-5d78-4432-9628-51e703954a2&title=&width=886" alt="image.png">正是由于布隆过滤器只需占用极小的空间，便可给出 “可能存在” 和 “肯定不存在”的存在性判断。因此可以提前过滤掉很多不必要的数据块，从而节省了大量的磁盘 IO。hbase 的 get 操作就是通过运用低成本高效率的布隆过滤器来过滤大量无效数据块的，从而节省了大量磁盘 IO。</p>
<p>如果在表中设置了 Bloomfilter，那么 HBase 会在生成 StoreFile 时包含一份 bloomfilter 结构的数据，称其为 MetaBlock；MetaBlock 与 DataBlock（真实的 KeyValue 数据）一起由 LRUBlockCache 维护。所以，开启 bloomfilter 会有一定的存储及内存 cache 开销。</p>
<p>布隆过滤器的 3 中类型：</p>
<ul>
<li>none，关闭布隆过滤器功能</li>
<li>row，按照 rowkey 计算布隆过滤器的二进制串并存储。get 查询时，必须带 rowkey.</li>
<li>rowcol，按照 rowkey+family+qualifier 这 3 个字段拼出 byte[]来计算布隆过滤器值并存储。如果查询时，get 可以指定到这 3 个字段，则肯定可以通过布隆过滤器提高性能。</li>
</ul>
<p>任何类型的 get（基于 rowkey 或 row+col）Bloom Filter 的优化都能生效，关键是 get 的类型要匹配 Bloom Filter 的类型<br>基于 row 的 scan 是没办法走 Bloom Filter 的。因为<strong>Bloom Filter</strong>是需要事先知道过滤项的。对于顺序 scan 是没有事先办法知道 rowkey 的。而 get 是指明了 rowkey 所以可以用 Bloom Filter，scan 指明 column 同理。</p>
<p>一般意义上的 scan 操作，是没法使用布隆过滤器提升性能的，因为布隆过滤器的 key 不确定。但是 row+col+qualify 的 scan 可以借助布隆过滤器去掉不存在此 qualify 的 storefile，也算是不错的优化了，而且指明 qualify 也能减少流量，因此 scan 尽量指明 qualify<br>关于<strong>BlockCache</strong>的内容较多，在后续文章补充。</p>
]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title>InnoDB中的页合并与分裂</title>
    <url>/article/mysql/mysql-page-merge-and-split/</url>
    <content><![CDATA[<p>原文链接：<br><a href="https://www.percona.com/blog/2017/04/10/innodb-page-merging-and-page-splitting/">https://www.percona.com/blog/2017/04/10/innodb-page-merging-and-page-splitting/</a><br><a href="https://www.percona.com/blog/2020/06/24/mysql-table-fragmentation-beware-of-bulk-insert-with-failure-or-rollback/">https://www.percona.com/blog/2020/06/24/mysql-table-fragmentation-beware-of-bulk-insert-with-failure-or-rollback/</a></p>
<p>如果您遇到了全球（为数不多的）MySQL 顾问之一并要求他&#x2F;她审查您的查询和&#x2F;或模式，我相信他&#x2F;她会告诉您有关良好主键设计的重要性的一些信息. 特别是在 InnoDB 的情况下，我相信他们已经开始向您解释索引合并和页面拆分。这两个概念与性能密切相关，您在设计任何索引（不仅仅是 PK）时都应该考虑这种关系。</p>
<p>这对你来说可能听起来像笨蛋，你可能是对的。这不是一件容易的事情，尤其是在谈论内部结构时。这不是您经常处理的事情，而且通常您根本不想处理它。<br>但有时它是必需的。如果是这样，这篇文章适合你。</p>
<p>在本文中，我想解释一些最不清楚的 InnoDB 幕后操作：页面索引创建、页面合并和页面拆分。<br>在 Innodb 中，所有数据都是一个索引。你可能也听说过吧？但这究竟是什么意思？</p>
<h2 id="文件表组件"><a href="#文件表组件" class="headerlink" title="文件表组件"></a>文件表组件</h2><p>假设您安装了 MySQL，最新的 5.7 版本（<a href="https://www.percona.com/software/mysql-database/percona-server">Percona Server for MySQL</a>，对吗？），并且在架构 windmills 中有一个名为 wmills 的表。在数据目录（通常为 &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;）中，您将看到它包含：</p>
<pre class="line-numbers language-none"><code class="language-none">data&#x2F;
  windmills&#x2F;
      wmills.ibd
      wmills.frm</code></pre>

<p>这是因为参数 innodb_file_per_table 从 MySQL5.6 开始已经设置为 1。这样设置，schema 中每个表都是一个文件（如果是分区表，则有多个文件）。<br>这里重要的是名为 wmills.ibd 的文件。这个文件被分为 N 个段(Segment) 。每个段 都与一个索引相关联。<br>尽管文件不会因删除数据而收缩，段本身会增长或收缩，下一级为区。一个区仅存在一个段中，并且固定尺寸为 1MB（在默认页大小的情况下）。页(page)是区(extent)的下一级，默认大小为 16KB。<br>因此，一个区(extent)最多可包含 64 页(page)。一个页可以包含 2 到 N 行。一个页可以容纳的行数与行大小有关，这是表结构设计时定义的。InnoDB 中有一条规则说，至少两行必须适合一个页面。因此，我们有 8000 字节的行大小限制。如果您认为这听起来就像俄罗斯娃娃（Matryoshka dolls），没错下面这张图能帮助你理解：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646668915534-ed853d29-e5d1-483a-96f5-c493531c15a0.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=727&id=uc6d38939&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1453&originWidth=1024&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=215070&status=done&style=none&taskId=u307ec0b7-5103-4ca1-ac09-04cec335d3e&title=&width=512" alt="image.png"></p>
<h2 id="根，分支与叶子"><a href="#根，分支与叶子" class="headerlink" title="根，分支与叶子"></a>根，分支与叶子</h2><p>每个页（逻辑上讲即叶子节点）是包含了 2-N 行数据，根据主键排列。树有着特殊的页区管理不同的分支，即内部节点（INodes）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646669878783-8795eebb-61d5-4169-ba9c-09589a032e23.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=236&id=uc383ca06&margin=%5Bobject%20Object%5D&name=image.png&originHeight=471&originWidth=1024&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=88704&status=done&style=none&taskId=uffc6a5d3-ae8e-4734-bdd9-7963bbcbf20&title=&width=512" alt="image.png"><br>这个图片仅是示例，并不能说明下面的实际输出。<br>具体来看一下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ROOT NODE #3: 4 records, 68 bytes
NODE POINTER RECORD ≥ (id&#x3D;2) → #197
INTERNAL NODE #197: 464 records, 7888 bytes
NODE POINTER RECORD ≥ (id&#x3D;2) → #5
LEAF NODE #5: 57 records, 7524 bytes
 RECORD: (id&#x3D;2) → (uuid&#x3D;&quot;884e471c-0e82-11e7-8bf6-08002734ed50&quot;, millid&#x3D;139, kwatts_s&#x3D;1956, date&#x3D;&quot;2017-05-01&quot;, location&#x3D;&quot;For beauty&#39;s pattern to succeeding men.Yet do thy&quot;, active&#x3D;1, time&#x3D;&quot;2017-03-21 22:05:45&quot;, strrecordtype&#x3D;&quot;Wit&quot;)</code></pre>

<p>下面是表结构：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">CREATE TABLE &#96;wmills&#96; (
  &#96;id&#96; bigint(11) NOT NULL AUTO_INCREMENT,
  &#96;uuid&#96; char(36) COLLATE utf8_bin NOT NULL,
  &#96;millid&#96; smallint(6) NOT NULL,
  &#96;kwatts_s&#96; int(11) NOT NULL,
  &#96;date&#96; date NOT NULL,
  &#96;location&#96; varchar(50) COLLATE utf8_bin DEFAULT NULL,
  &#96;active&#96; tinyint(2) NOT NULL DEFAULT &#39;1&#39;,
  &#96;time&#96; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  &#96;strrecordtype&#96; char(3) COLLATE utf8_bin NOT NULL,
  PRIMARY KEY (&#96;id&#96;),
  KEY &#96;IDX_millid&#96; (&#96;millid&#96;)
) ENGINE&#x3D;InnoDB;</code></pre>

<p>所有的 B 树都有着一个入口，也就是根节点，在上图中#3 就是根节点。根节点（页）包含了如索引 ID、INodes 数量等信息。INode 页包含了关于页本身的信息、值的范围等。最后还有叶子节点，也就是我们数据实际所在的位置。在示例中，我们可以看到叶子节点#5 有 57 行记录，共 7524 bytes。在这行信息后是具体的记录，可以看到数据行内容。<br>这里想引出的概念是当你使用 InnoDB 管理表和行，InnoDB 会将他们会以分支、页和记录的形式组织起来。InnoDB 不是按行的来操作的，它可操作的最小粒度是页，页加载进内存后才会通过扫描页来获取行&#x2F;记录。<br>现在页的结构清楚了吗？好，我们继续。</p>
<h2 id="页的内部原理"><a href="#页的内部原理" class="headerlink" title="页的内部原理"></a>页的内部原理</h2><p>页可以空或者填充满（100%），行记录会按照主键顺序来排列。例如在使用 AUTO_INCREMENT 时，你会有顺序的 ID 1、2、3、4 等。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670330112-d3a07653-9aed-40c1-aa43-e390bcdb252f.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9b61c215&margin=%5Bobject%20Object%5D&name=image.png&originHeight=203&originWidth=502&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=9573&status=done&style=none&taskId=u20366bda-86f8-4ea6-a3a7-4f458028d7e&title=" alt="image.png"><br>页还有另一个重要的属性：<strong>MERGE_THRESHOLD</strong>。该参数的默认值是 50%页的大小，它在 InnoDB 的合并操作中扮演了很重要的角色。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670575250-0189aa82-3b1f-449f-b5d7-7fff7b68f559.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucbf5a575&margin=%5Bobject%20Object%5D&name=image.png&originHeight=205&originWidth=538&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=11879&status=done&style=none&taskId=ufdb2bd63-8d94-4fa0-a4e6-f135015a4ac&title=" alt="image.png"><br>当你插入数据时，如果数据（大小）能够放的进页中的话，那他们是按顺序将页填满的。<br>若当前页满，则下一行记录会被插入下一页（NEXT）中。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670627767-5435a231-c2ac-44fb-b12f-f9ebedfec97c.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u85e37165&margin=%5Bobject%20Object%5D&name=image.png&originHeight=213&originWidth=502&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=9464&status=done&style=none&taskId=u38f7fbf9-f3cd-40ad-9046-033c82813c1&title=" alt="image.png"><br>根据 B 树的特性，它可以自顶向下遍历，但也可以在各叶子节点水平遍历。因为每个叶子节点都有着一个指向包含下一条（顺序）记录的页的指针。例如，页#5 有指向页#6 的指针，页#6 有指向前一页（#5）的指针和后一页（#7）的指针。<br>这种机制下可以做到快速的顺序扫描（如范围扫描）。之前提到过，这就是当你基于自增主键进行插入的情况。但如果你不仅插入还进行删除呢？</p>
<h2 id="页合并"><a href="#页合并" class="headerlink" title="页合并"></a>页合并</h2><p>当你删了一行记录时，实际上记录并没有被物理删除，记录被标记（flaged）为删除并且它的空间变得允许被其他记录声明使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670744381-096c5efd-35a7-4db2-aec0-f0fcb64d2f3a.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uab3ccebe&margin=%5Bobject%20Object%5D&name=image.png&originHeight=262&originWidth=538&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=16177&status=done&style=none&taskId=u61879170-9951-4647-8550-140ace92b8a&title=" alt="image.png"><br>当页中删除的记录达到 MERGE_THRESHOLD（默认页体积的 50%），InnoDB 会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670788088-7e174566-bd14-4f60-8f89-44560bb5c82c.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=udfa9e513&margin=%5Bobject%20Object%5D&name=image.png&originHeight=213&originWidth=502&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=9464&status=done&style=none&taskId=u7ae45bf4-87e4-470e-8aeb-85b5f926073&title=" alt="image.png"><br>在示例中，页#6 使用了不到一半的空间，页#5 又有足够的删除数量，现在同样处于 50%使用以下。从 InnoDB 的角度来看，它们能够进行合并。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670821447-c45708d3-6252-4d1d-aa20-6f76b33a703c.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u0d51d5a4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=238&originWidth=537&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=16067&status=done&style=none&taskId=u50d0dee4-a871-4afa-8b2f-f2faae78c20&title=" alt="image.png"><br>合并操作使得页#5 保留它之前的数据，并且容纳来自页#6 的数据。页#6 变成一个空页，可以接纳新数据。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670865660-41e697c1-0a3f-4e0d-950a-3163e180b401.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7c3c5848&margin=%5Bobject%20Object%5D&name=image.png&originHeight=218&originWidth=557&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=8559&status=done&style=none&taskId=uaf08e29c-dc2b-431a-9050-ccc0465860e&title=" alt="image.png"><br>如果我们在 UPDATE 操作中让页中数据体积达到类似的阈值点，InnoDB 也会进行一样的操作。<br>规则就是：页合并发生在删除或更新操作中，关联到当前页的相邻页。如果页合并成功，在 INFOMATION_SCHEMA.INNODB_METRICS 中的 index_page_merge_successful 将会增加。</p>
<h2 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h2><p>前面提到，页可能填充至 100%，在页填满了之后，下一页会继续接管新的记录。但如果有下面这种情况呢？<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670893131-2f4e7133-29a8-4030-a8a7-ba6bab61fd4c.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7b78a3b1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=264&originWidth=537&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=21313&status=done&style=none&taskId=u249cd554-5170-4ecb-8c75-c8b71745f22&title=" alt="image.png"><br>页#10 没有足够空间去容纳新（或更新）的记录。根据“下一页”的逻辑，记录应该由页#11 负责。然而：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646670967482-e1325a24-4460-4248-9e38-211e884901a6.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u768444b0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=238&originWidth=537&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=12917&status=done&style=none&taskId=u8743fa09-b41c-4ff7-8ae7-13ebc032feb&title=" alt="image.png"><br>页#11 也同样满了，数据也不可能不按顺序地插入。怎么办？<br>还记得之前说的链表吗（译注：指 B+树的每一层都是双向链表）？页#10 有指向页#9 和页#11 的指针。<br>InnoDB 的做法是（简化版）：</p>
<ol>
<li>创建新页</li>
<li>判断当前页（页#10）可以从哪里进行分裂（记录行层面）</li>
<li>移动记录行</li>
<li>重新定义页之间的关系</li>
</ol>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646671011269-44341865-977e-4047-9e20-5f699efa1c9b.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud9c1aeb9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=238&originWidth=537&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=16401&status=done&style=none&taskId=uc5f805ab-046e-4249-97b7-2a3d4606c79&title=" alt="image.png"><br>新的页#12 被创建：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646671080650-1c3b1d9b-f12c-4358-a95d-38ae092933dc.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3f1c9d31&margin=%5Bobject%20Object%5D&name=image.png&originHeight=238&originWidth=537&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=11563&status=done&style=none&taskId=u1d844c88-c5b3-4393-9c33-a97f5251b4b&title=" alt="image.png"><br>页#11 保持原样，只有页之间的关系发生了改变：</p>
<ul>
<li>页#10 相邻的前一页为页#9，后一页为页#12</li>
<li>页#12 相邻的前一页为页#10，后一页为页#11</li>
<li>页#11 相邻的前一页为页#10，后一页为页#13</li>
</ul>
<p>（译注：页#13 可能本来就有，这里意思为页#10 与页#11 之间插入了页#12）<br>这样 B 树水平方向的一致性仍然满足，因为满足原定的顺序排列逻辑。然而从物理存储上讲页是乱序的，而且大概率会落到不同的区。<br>规律总结：页分裂会发生在插入或更新，并且造成页的错位（dislocation，落入不同的区）<br>InnoDB 用 INFORMATION_SCHEMA.INNODB_METRICS 表来跟踪页的分裂数。可以查看其中的 index_page_splits 和 index_page_reorg_attempts&#x2F;successful 统计。<br>一旦创建分裂的页，唯一（译注：实则仍有其他方法，见下文）将原先顺序恢复的办法就是新分裂出来的页因为低于合并阈值（merge threshold）被删掉。这时候 InnoDB 用页合并将数据合并回来。<br>另一种方式就是用 OPTIMIZE 重新整理表。这可能是个很重量级和耗时的过程，但可能是唯一将大量分布在不同区的页理顺的方法。<br>另一方面，要记住在合并和分裂的过程，InnoDB 会在索引树上加写锁（x-latch）。在操作频繁的系统中这可能会是个隐患。它可能会导致索引的锁争用（index latch contention）。如果表中没有合并和分裂（也就是写操作）的操作，称为“乐观”更新，只需要使用读锁（S）。带有合并也分裂操作则称为“悲观”更新，使用写锁（X)。</p>
<h2 id="我的主键"><a href="#我的主键" class="headerlink" title="我的主键"></a>我的主键</h2><p>好的主键不仅对于数据查找很重要，而且也影响写操作时数据在区上的分布（也就是与页分裂和页合并操作相关）。<br>在第一个测试中我使用的是是自增主键，第二个测试主键是基于一个 1-200 的 ID 与自增值的，第三个测试也是 1-200 的 ID 不过与 UUID 联合。<br>插入操作时，InnoDB 需要增加页，视为“分裂”操作：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646671241539-f683066e-2371-4731-a610-4bb5c0229b0d.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=234&id=ucb06f6a3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=467&originWidth=767&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=219981&status=done&style=none&taskId=u240fdc6a-e1ee-480d-8100-8db03084e59&title=&width=383.5" alt="image.png"><br>表现因不同主键而异。<br>在头两种情况中数据的分布更为紧凑，也就是说他们拥有更好的空间利用率。对比半随机（semi-random）特性的 UUID 会导致明显的页稀疏分布（页数量更多，相关分裂操作更多）。<br>在页合并的情况中，尝试合并的次数因主键类型的不同而表现得更加不一致。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646671257790-eb064217-dffb-4a4b-9db6-fb09a09bd1d1.png#clientId=u8b15385f-1173-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=271&id=u8f89039a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=542&originWidth=1024&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=325826&status=done&style=none&taskId=u95d1fdea-dad3-481e-ab3b-0f338d66428&title=&width=512" alt="image.png"><br>在插入-更新-删除操作中，自增主键有更少的合并尝试次数，成功比例比其他两种类型低 9.45%。UUID 型主键（图表的右一侧）有更多的合并尝试，但是合并成功率明显更高，达 22.34%，因为数据稀疏分布让很多页都有部分空闲空间。<br>在辅助索引与上面主键索引相似的情况下，测试的表现也是类似的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MySQL&#x2F;InnoDB 不断地进行这些操作，你可能只能了解到很少的信息。但他们可能给你造成伤害，特别是比起用 SSD，你还在用传统的机械存储（spindle storage）的时候（顺便提一下 SSD 会有另外的问题）。<br>坏消息就是我们用什么参数或者魔法去改变服务端。但好消息是我们可以在设计的时候做很多（有帮助）的事。<br>恰当地使用主键和设计辅助索引，并且记住不要滥用（索引）。如果你已经预计到会有很多插入&#x2F;删除&#x2F;更新操作，规划一个合适的时间窗来管理（整理）表。<br>有个很重要的点，InnoDB 中你不会有断断续续的行记录，但是你会在页-区的维度上遇到这些问题。忽略表的管理工作会导致需要在 IO 层面、内存层面和 InnoDB 缓冲池层面做更多工作。<br>你必须不时（at regular intervals）重建一些表。可以采用一些技巧，比如分区和外部的工具（pt-osc）。不要让表变得过大和过于碎片化（fragmented）。<br>磁盘空间浪费？需要读多个表去获取需要的数据而不是一次搞定？每次搜索导致明显更多的读操作？那是你的锅，不要找借口！</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK中的设计模式</title>
    <url>/article/design-pattern/jdk-design-pattern/</url>
    <content><![CDATA[<p>本文主要是归纳了 JDK 中所包含的设计模式，包括作用和其设计类图。</p>
<h2 id="一、设计模式的作用"><a href="#一、设计模式的作用" class="headerlink" title="一、设计模式的作用"></a>一、设计模式的作用</h2><ol>
<li>反复出现问题的解决方案</li>
<li>增强软件的灵活性</li>
<li>适应软件不断变化</li>
</ol>
<h2 id="二、设计模式的七大原则"><a href="#二、设计模式的七大原则" class="headerlink" title="二、设计模式的七大原则"></a>二、设计模式的七大原则</h2><ol>
<li><strong>开闭原则 OCP</strong>（Open Close Principle），一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。</li>
<li><strong>里氏代换原则 LSP</strong>（Liskov Substitution Principle），子类可以扩展父类的功能，但不能改变父类原有的功能</li>
<li><strong>依赖倒转原则 DIP</strong>（Dependence Inversion Principle），面向接口编程，依赖于抽象而不依赖于具体。</li>
<li><strong>接口隔离原则 ISP</strong>（Interface Segregation Principle），建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少。</li>
<li><strong>合成复用原则 CRP</strong>（Composite Reuse Principle），要尽量的使用合成和聚合，而不是继承关系达到复用的目的</li>
<li><strong>迪米特法则 LOD</strong>（Law Of Demeter），也叫最少知识原则 LKP(Least Knowledge Principle)，一个对象应该对其他对象保持最少的了解。</li>
<li><strong>单一职责原则 SRP</strong>（Single Responsibility Principle），一个类只负责一项职责，应该仅有一个引起它变化的原因</li>
</ol>
<h2 id="三、JDK-中使用到的设计模式以及分析"><a href="#三、JDK-中使用到的设计模式以及分析" class="headerlink" title="三、JDK 中使用到的设计模式以及分析"></a>三、JDK 中使用到的设计模式以及分析</h2><h3 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a><strong>创建型模式</strong></h3><ol>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-singleton-pattern/">单例模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-factory-pattern/">简单工厂、工厂方法、抽象工厂模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-builder-pattern/">建造者模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-prototype-pattern/">原型模式</a></li>
</ol>
<h3 id="结构型模式"><a href="#结构型模式" class="headerlink" title="结构型模式"></a><strong>结构型模式</strong></h3><ol>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-adapter-pattern/">适配器模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-bridge-pattern/">桥接模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-composite-pattern/">组合模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-decorator-pattern/">装饰模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-facade-pattern/">外观模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-flyweight-pattern/">享元模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-proxy-pattern/">代理模式</a></li>
</ol>
<h3 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a><strong>行为型模式</strong></h3><ol>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-strategy-pattern/">策略模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-template-method-pattern/">模板方法模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-observer-pattern/">观察者模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-iterator-pattern/">迭代器模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-responsibility-pattern/">责任链模式</a></li>
<li><a href="https://www.alicharles.com/article/design-pattern/jdk-command-pattern/">命令模式</a></li>
<li>访问者模式</li>
<li>状态模式</li>
<li>备忘录模式</li>
<li>中介者模式</li>
<li>解释器模式</li>
</ol>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive文件格式</title>
    <url>/article/hive/hive-file-format/</url>
    <content><![CDATA[<h2 id="一、文件定义"><a href="#一、文件定义" class="headerlink" title="一、文件定义"></a>一、文件定义</h2><p>ORC File，它的全名是 Optimized Row Columnar (ORC) file，其实就是对 RCFile 做了一些优化。<br>据官方文档介绍，这种文件格式可以提供一种高效的方法来存储 Hive 数据。它的设计目标是来克服 Hive 其他格式的缺陷。<br>运用 ORC File 可以提高 Hive 的读、写以及处理数据的性能。<br>和 RCFile 格式相比，ORC File 格式有以下优点：<br>1、每个 task 只输出单个文件，这样可以减少 NameNode 的负载；<br>2、支持各种复杂的数据类型，比如： datetime, decimal, 以及一些复杂类型 struct, list, map, and union；<br>3、在文件中存储了一些轻量级的索引数据；<br>4、基于数据类型的块模式压缩：<br>a、integer 类型的列用行程长度编码 run-length encoding;<br>b、String 类型的列用字典编码 dictionary encoding；<br>5、用多个互相独立的 RecordReaders 并行读相同的文件；<br>6、无需扫描 markers 就可以分割文件；<br>7、绑定读写所需要的内存；<br>8、metadata 的存储是用 Protocol Buffers 的，所以它支持添加和删除一些列。</p>
<h2 id="二、文件结构"><a href="#二、文件结构" class="headerlink" title="二、文件结构"></a>二、文件结构</h2><p>ORC File 包含一组组的行数据，称为 stripes，除此之外，ORC File 的 file footer 还包含一些额外的辅助信息。<br>在 ORC File 文件的最后，有一个被称为 postscript 的区，它主要是用来存储压缩参数及压缩页脚的大小。<br>在默认情况下，一个 stripe 的大小为 250MB。大尺寸的 stripes 使得从 HDFS 读数据更高效。<br>在 file footer 里面包含了该 ORC File 文件中 stripes 的信息，每个 stripe 中有多少行，以及每列的数据类型。<br>当然，它里面还包含了列级别的一些聚合的结果，比如：count, min, max, and sum。<br>下图显示出可 ORC File 文件结构：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647844523024-2b5c70d6-ad6d-4c2d-b9b3-7574e6b90e5f.png#clientId=u33b0a1c0-a42f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uedd4c4f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=601&originWidth=439&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=161175&status=done&style=none&taskId=ucae6d17b-cb33-424e-94d1-c8bfe888641&title=" alt="image.png"></p>
<h2 id="三、Stripe-结构"><a href="#三、Stripe-结构" class="headerlink" title="三、Stripe 结构"></a>三、Stripe 结构</h2><p>从上图我们可以看出，每个 Stripe 都包含 index data、row data 以及 stripe footer。Stripe footer 包含流位置的目录；Row data 在表扫描的时候会用到。<br>Index data 包含每列的最大和最小值以及每列所在的行。<br>行索引里面提供了偏移量，它可以跳到正确的压缩块位置。具有相对频繁的行索引，使得在 stripe 中快速读取的过程中可以跳过很多行，尽管这个 stripe 的大小很大。<br>在默认情况下，最大可以跳过 10000 行。拥有通过过滤谓词而跳过大量的行的能力，你可以在表的 secondary keys 进行排序，从而可以大幅减少执行时间。<br>比如你的表的主分区是交易日期，那么你可以对次分区（state、zip code 以及 last name）进行排序。</p>
<h2 id="四、Hive-里面如何用-ORCFile"><a href="#四、Hive-里面如何用-ORCFile" class="headerlink" title="四、Hive 里面如何用 ORCFile"></a>四、Hive 里面如何用 ORCFile</h2><p>在建 Hive 表的时候我们就应该指定文件的存储格式。所以你可以在 Hive QL 语句里面指定用 ORCFile 这种文件格式，如下：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">CREATE TABLE ... STORED AS ORC
ALTER TABLE ... [PARTITION partition_spec] SET FILEFORMAT ORC
SET hive.default.fileformat&#x3D;Orc</code></pre>

<p>所有关于 ORCFile 的参数都是在 Hive QL 语句的 TBLPROPERTIES 字段里面出现，他们是：</p>
<table><thead><tr>
<th>Key</th>
<th>Default</th>
<th>Notes</th>
</tr>
</thead><tbody><tr>
<td>orc.compress</td>
<td>ZLIB</td>
<td>high level compression (one of NONE, ZLIB, SNAPPY)</td>
</tr>
<tr>
<td>orc.compress.size</td>
<td>262,144</td>
<td>number of bytes in each compression chunk</td>
</tr>
<tr>
<td>orc.stripe.size</td>
<td>268435456</td>
<td>number of bytes in each stripe</td>
</tr>
<tr>
<td>orc.row.index.stride</td>
<td>10,000</td>
<td>number of rows between index entries (must be &gt;&#x3D; 1000)</td>
</tr>
<tr>
<td>orc.create.index</td>
<td>true</td>
<td>whether to create row indexes</td>
</tr>
</tbody></table><p>下面的例子是建立一个没有启用压缩的 ORCFile 的表</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">create table Addresses (
  name string,
  street string,
  city string,
  state string,
  zip int
) stored as orc tblproperties (&quot;orc.compress&quot;&#x3D;&quot;NONE&quot;);</code></pre>

<h2 id="五、序列化和压缩"><a href="#五、序列化和压缩" class="headerlink" title="五、序列化和压缩"></a>五、序列化和压缩</h2><p>对 ORCFile 文件中的列进行压缩是基于这列的数据类型是 integer 或者 string。具体什么序列化我就不涉及了。<br>想深入了解的可以看看下面的英文：<br>Integer Column Serialization<br>Integer columns are serialized in two streams.<br>1、present bit stream: is the value non-null?<br>2、data stream: a stream of integers<br>Integer data is serialized in a way that takes advantage of the common distribution of numbers:<br>1、Integers are encoded using a variable-width encoding that has fewer bytes for small integers.<br>2、Repeated values are run-length encoded.<br>3、Values that differ by a constant in the range (-128 to 127) are run-length encoded.<br>The variable-width encoding is based on Google’s protocol buffers and uses the high bit to represent whether this byte is not the last and the lower 7 bits to encode data. To encode negative numbers, a zigzag encoding is used where 0, -1, 1, -2, and 2 map into 0, 1, 2, 3, 4, and 5 respectively.</p>
<p>Each set of numbers is encoded this way:<br>1、If the first byte (b0) is negative:<br>-b0 variable-length integers follow.<br>2、If the first byte (b0) is positive:<br>it represents b0 + 3 repeated integers<br>the second byte (-128 to +127) is added between each repetition<br>1 variable-length integer.<br>In run-length encoding, the first byte specifies run length and whether the values are literals or duplicates. Duplicates can step by -128 to +128. Run-length encoding uses protobuf style variable-length integers.</p>
<p>String Column Serialization<br>Serialization of string columns uses a dictionary to form unique column values The dictionary is sorted to speed up predicate filtering and improve compression ratios.<br>String columns are serialized in four streams.<br>1、present bit stream: is the value non-null?<br>2、dictionary data: the bytes for the strings<br>3、dictionary length: the length of each entry<br>4、row data: the row values<br>Both the dictionary length and the row values are run length encoded streams of integers.</p>
]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（七）组合模式</title>
    <url>/article/design-pattern/jdk-composite-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>将对象组合成树形结构以表示“部分整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>组合模式解耦了客户程序与复杂元素内部结构，从而使客户程序可以像处理简单元素一样来处理复杂元素。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、抽象构件（component）:是组合中对象的接口，适当情况下，实现所有类共有方法的默认行为，声明一个接口，用于管理和访问 component 子部件<br>2、 树枝构件（composite）：定义具有叶节点的组件的行为<br>3、 叶子构件（leaf）：定义叶节点的行为<br>4、 客户角色（client）：使用 component 接口操作组件行为</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>组合模式类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394693687-7df5b20d-72cf-427e-9bbe-774618e4950d.png#clientId=u41e983d5-1616-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4857537f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=389&originWidth=868&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33492&status=done&style=none&taskId=ue4d4763b-ff94-4fa7-be5c-5d8f3d7177b&title=" alt="image.png"><br>采用统一的方式 operation()，处理 composite 和 leaf。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public abstract class Component&#123;
    public abstract void operation();
    public void add(Component component)&#123;&#125;;
    public void remove(Component component)&#123;&#125;;
&#125;

public class Composite extends Component&#123;
    String name;
    ArrayList children &#x3D; new ArrayList();

    public Composite(String name)&#123;
        this.name &#x3D; name;
    &#125;

    public void add(Component component)&#123;
        children.add(component);
    &#125;

    public void remove(Component component)&#123;
        children.remove(component);
    &#125;

    public void operation()&#123;
        System.out.println(name);
        Iterator iterator &#x3D; children.iterator();
        while(iterator.hasNext())&#123;
            Component child &#x3D; (Component)iterator.next();
            child.operation();
        &#125;
    &#125;
&#125;

public class Leaf extends Component&#123;
    String name;

    public Leaf(String name)&#123;
        this.name &#x3D; name;
    &#125;

    public void operation()&#123;
        System.out.println(name);
    &#125;
&#125;</code></pre>

<p>通过调用 operation 打印整个层次结构树。</p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中体现有 org.w3c.dom.Node 和 javax.swing.JComponent，以 Node 为例。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394693698-5cba9e03-5349-4b4a-8b3d-0137f8565604.png#clientId=u41e983d5-1616-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4be6ba3f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=435&originWidth=710&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33529&status=done&style=none&taskId=ud69337e5-1587-4304-ba43-dc0b36be9b9&title=" alt="image.png"><br>其中 Node 既充当 Component 角色，也充当 Composite 角色。其中 Document 相当于层次结构的根节点。Text 为叶子节点，其他的为中间树枝节点（只列出部分 XML 节点对象）。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、组合模式可以很容易的增加新的构件。<br>2、 使用组合模式可以使客户端变的很容易设计，因为客户端可以对组合和叶节点一视同仁。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、使用组合模式后，控制树枝构件的类型不太容易。<br>2、用继承的方法来增加新的行为很困难。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、你想表示对象的部分-整体层次结构。<br>2、 你希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（三）建造者模式</title>
    <url>/article/design-pattern/jdk-builder-pattern/</url>
    <content><![CDATA[<p>将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。<br>建造模式是将复杂的内部创建封装在内部，对于外部调用的人来说，只需要传入建造者和建造工具，对于内部是如何建造成成品的，调用者无需关心，其类图如下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312892476-cba9f8b3-8fa5-4ac7-a707-c0f2fd798ccb.png#clientId=uf68f83de-da72-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u851a440b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=338&originWidth=782&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=22011&status=done&style=none&taskId=u5951e2c5-4c3f-4a6f-aa74-74b51f9198e&title=" alt="image.png"></p>
<h2 id="建造者角色"><a href="#建造者角色" class="headerlink" title="建造者角色"></a>建造者角色</h2><p>Product : 产品类，由多个部件构成。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">class Product &#123;
    List&lt;String&gt; parts &#x3D; new ArrayList&lt;String&gt;();

    public void AddPart(String part) &#123;
        parts.add(part);
    &#125;

    public void show() &#123;
        for (String part : parts) &#123;
            System.out.println(part);
        &#125;
    &#125;
&#125;</code></pre>

<p>Builder : 抽象建造者，确定产品由 AB 部件构成，并声明一个得到产品建造后结果的方法 getResult。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">interface Builder &#123;
    public void buildPartA();
    public void buildPartB();
    public Product getResult();
&#125;</code></pre>

<p>ConcreteBuilder : 实现 Builder 接口中的具体方法。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">class ConcreteBuilder implements Builder &#123;
    private Product product &#x3D; new Product();

    public void buildPartA() &#123;
        product.AddPart(&quot;part A&quot;);
    &#125;

    public void buildPartB() &#123;
        product.AddPart(&quot;part B&quot;);
    &#125;

    public Product getResult() &#123;
        return product;
    &#125;
&#125;</code></pre>

<p>Director : 指挥者类，指挥建造 Product 的过程（控制构建各部分组件的顺序）。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">class Director &#123;
    public void construct(Builder builder) &#123;
        builder.buildPartA();
        builder.buildPartB();
    &#125;
&#125;</code></pre>

<p>Client : 用户并不需要知道具体的建造过程，只需指定建造 Product 具体类型。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class BuilderPattern &#123;
    public static void main(String[] args) &#123;
        Director director &#x3D; new Director();
        Builder builder &#x3D; new ConcreteBuilder();

        director.construct(builder);
        Product product &#x3D; builder.getResult();
        product.show();
    &#125;
&#125;</code></pre>

<p>与抽象工厂的区别：在建造者模式里，有个指导者，由指导者来管理建造者，用户是与指导者联系的，指导者联系建造者最后得到产品。即建造模式可以强制实行一种分步骤进行的建造过程。</p>
<h2 id="JDK-中使用的建造者模式"><a href="#JDK-中使用的建造者模式" class="headerlink" title="JDK 中使用的建造者模式"></a>JDK 中使用的建造者模式</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312892556-a165f083-1405-44fe-a04c-1d4c97a408a6.png#clientId=uf68f83de-da72-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub7ef1453&margin=%5Bobject%20Object%5D&name=image.png&originHeight=563&originWidth=1025&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=46326&status=done&style=none&taskId=u1a3c07a8-89d6-489c-ac04-db27cf7404a&title=" alt="image.png"><br>DOMParser 使用 parse 方法建造 Document 对象，使用 getDocument 获取 XML 的 Document 对象。</p>
<h3 id="建造者模式的优点"><a href="#建造者模式的优点" class="headerlink" title="建造者模式的优点"></a>建造者模式的优点</h3><p>1、建造者模式的封装性很好。使用建造者模式可以有效的封装变化，在使用建造者模式的场景中，一般产品类和建造者类是比较稳定的，因此，将主要的业务逻辑封装在导演类中对整体而言可以取得比较好的稳定性。<br>2、建造者模式很容易进行扩展。如果有新的需求，通过实现一个新的建造者类就可以完成，基本上不用修改之前已经测试通过的代码，因此也就不会对原有功能引入风险。</p>
<h3 id="建造者模式与工厂模式的区别"><a href="#建造者模式与工厂模式的区别" class="headerlink" title="建造者模式与工厂模式的区别"></a>建造者模式与工厂模式的区别</h3><p>1、建造者模式与工厂模式是极为相似的，总体上，建造者模式仅仅只比工厂模式多了一个“导演类”的角色。在建造者模式的类图中，假如把这个导演类看做是最终调用的客户端，那么图中剩余的部分就可以看作是一个简单的工厂模式了。<br>2、与工厂模式相比，建造者模式一般用来创建更为复杂的对象，因为对象的创建过程更为复杂，因此将对象的创建过程独立出来组成一个新的类——导演类。也就是说，工厂模式是将对象的全部创建过程封装在工厂类中，由工厂类向客户端提供最终的产品；而建造者模式中，建造者类一般只提供产品类中各个组件的建造，而将具体建造过程交付给导演类。由导演类负责将各个组件按照特定的规则组建为产品，然后将组建好的产品交付给客户端。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>建造者模式与工厂模式类似，适用的场景也很相似。一般来说，如果产品的建造很复杂，那么请用工厂模式；如果产品的建造更复杂，那么请用建造者模式。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（九）外观模式</title>
    <url>/article/design-pattern/jdk-facade-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>提供一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易访问。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>通过外观的包装，使应用程序只能看到外观对象，而不会看到具体的细节对象，降低应用程序的复杂度，并且提高了程序的可维护性。封装一组交互类，一致地对外提供接口，简化子系统调用。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、外观角色（Facade）：是模式的核心，他被客户 client 角色调用，知道各个子系统的功能。同时根据客户角色已有的需求预订几种功能组合。<br>2、子系统角色（Subsystem classes）：实现子系统的功能，并处理由 Facade 对象指派的任务。对子系统而言，facade 和 client 角色是未知的，没有 Facade 的任何相关信息；即没有指向 Facade 的实例。<br>3、 客户角色（client）：调用 facade 角色获得完成相应的功能。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>外观模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394983121-feeb0507-eb88-4d2a-b5a9-9c959efd7d9b.png#clientId=u813378e4-b28a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u413bc06c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=503&originWidth=823&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=48939&status=done&style=none&taskId=ufff6c00b-9d5f-4730-900d-4fd0fd5f185&title=" alt="image.png"><br>Facade 外观类负责将客户的请求代理给适当的子类系统，子系统类负责处理由 Facade 对象指派的任务。对子系统而言，facade 和 client 角色是未知的，没有 Facade 的任何相关信息；没有指向 Facade 的实例。</p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 日志框架主要包括如下几个部件：<br>Logger：日志记录对象。用于记录日志信息。<br>Handler：用于处理日志信息的输出。在 Handler 类中，可以决定日志是输出到文件中还是控制台中（相当于 log4j 中的 appender）。<br>Filter：用于过滤日志。在 Filter 类中，可以根据日志级别或者某种条件来决定是否输出该日志。这样达到去除冗余信息的目的。<br>Formatter：用于格式化日志信息。该类可以将日志文本格式化成 XML 或者 HTML 的格式，这完全依赖于具体的实现。<br>Level：用于表示日志的级别。 JDK 日志框架默认有如下级别：SEVERE（最高值） 、WARNING 、INFO 、CONFIG 、FINE 、FINER 、FINEST（最低值）、ALL(记录所有信息) OFF(不记录任何级别信息)。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394983169-ecfea32a-3754-4df3-83b5-475b9a8b522b.png#clientId=u813378e4-b28a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u455cbf3f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=592&originWidth=966&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=64242&status=done&style=none&taskId=ueb1b7ca3-c96b-4f9a-985d-a44567dff77&title=" alt="image.png"><br>使用 LogManager.getLogger 获取 Logger，然后通过 logger.info 等接口记录日志。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、对客户屏蔽子系统组件，减少了客户处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户代码将变得很简单，与之关联的对象也很少。<br>2、实现了子系统与客户之间的松耦合关系，这使得子系统的组件变化不会影响到调用它的客户类，只需要调整外观类即可。<br>3、降低了大型软件系统中的编译依赖性，并简化了系统在不同平台之间的移植过程，因为编译一个子系统一般不需要编译所有其他的子系统。一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。<br>4、只是提供了一个访问子系统的统一入口，并不影响用户直接使用子系统类。<strong>**</strong></p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、不能很好地限制客户使用子系统类，如果对客户访问子系统类做太多的限制则减少了可变性和灵活性。<br>2、 在不引入抽象外观类的情况下，增加新的子系统可能需要修改外观类或客户端的源代码，违背了“开闭原则”。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、当你要为一个复杂子系统提供一个简单接口时。子系统往往因为不断演化而变得越来越复杂。大多数模式使用时都会产生更多更小的类。这使得子系统更具可重用性，也更容易对子系统进行定制，但这也给那些不需要定制子系统的用户带来一些使用上的困难。facade 可以提供一个简单的缺省视图，这一视图对大多数用户来说已经足够，而那些需要更多的可定制性的用户可以越过 facade 层。<br>2、客户程序与抽象类的实现部分之间存在着很大的依赖性。引入 facade 将这个子系统与客户以及其他的子系统分离，可以提高子系统的独立性 和可移植性。<br>3、当你需要构建一个层次结构的子系统时，使用 facade 模式定义子系统中每层的入口点。如果子系统之间是相互依赖的，你可以让它们仅通过 facade 进行通讯，从而简化了它们之间的依赖关系。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（二）工厂模式</title>
    <url>/article/design-pattern/jdk-factory-pattern/</url>
    <content><![CDATA[<p>工厂模式是我们最常用的实例化对象模式，使用工厂方法代替 new 操作的一种模式，使用工厂模式，可能多做一些工作，但会给你系统带来更大的可扩展性和尽量少的修改量。</p>
<h2 id="1、简单工厂模式"><a href="#1、简单工厂模式" class="headerlink" title="1、简单工厂模式"></a>1、简单工厂模式</h2><p>简单工厂模式是属于创建型模式，又叫做静态工厂方法（Static Factory Method）模式，但不属于 23 种 GOF 设计模式之一。<br>简单工厂模式是由一个工厂对象决定创建出哪一种产品类的实例。简单工厂模式是工厂模式家族中最简单实用的模式，可以理解为是不同工厂模式的一个特殊实现。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312731635-85e6872e-a94b-4693-830f-b39271c2bc1f.png#clientId=u31449aae-d0c8-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf16bdcdc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=483&originWidth=1233&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=117127&status=done&style=none&taskId=u92c2d22b-1a22-4b5d-b1c7-49c1d7f8ce9&title=" alt="image.png"><br>简单工厂模式的实质是由一个工厂类根据传入的参数，动态决定应该创建哪一个产品类（这些产品类继承自一个父类或接口）的实例。<br><strong>使用场景</strong><br>1、工厂类负责创建的对象比较少；<br>2、客户只知道传入工厂类的参数，对于如何创建对象（逻辑）不关心；<br>3、由于简单工厂很容易违反高内聚责任分配原则，因此一般只在很简单的情况下应用。<br><strong>JDK 中使用的简单工厂</strong><br>代替构造函数创建对象，方法名比构造函数清晰<br>如 Integer.valueOf，Class.forName 等方法</p>
<h2 id="2、工厂方法模式"><a href="#2、工厂方法模式" class="headerlink" title="2、工厂方法模式"></a>2、工厂方法模式</h2><p>工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法把类的实例化推迟到子类。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312731140-a0aafa90-5a80-4dad-83e7-8265c691ab22.png#clientId=u31449aae-d0c8-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9d6bd374&margin=%5Bobject%20Object%5D&name=image.png&originHeight=518&originWidth=1295&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=110790&status=done&style=none&taskId=u60536269-8e5a-478a-b7d3-8a2a9efe199&title=" alt="image.png"><br>JDK 中使用的工厂方法<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312730182-cf689595-714c-4d36-8359-78781ffe975a.png#clientId=u31449aae-d0c8-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud9b44865&margin=%5Bobject%20Object%5D&name=image.png&originHeight=607&originWidth=958&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=83226&status=done&style=none&taskId=u664da234-c8ab-48e4-a706-67dc9fdb7a3&title=" alt="image.png"><br>如上图所示，ArrayList 和 LinkedList 使用具体的工厂类的 iterator 方法，分别创建实现 Iterator 接口类的 ArrayList$Itr和ArrayList$ListItr,以及 LinkedList$ListItr 的具体产品类。</p>
<h2 id="3、抽象工厂模式"><a href="#3、抽象工厂模式" class="headerlink" title="3、抽象工厂模式"></a>3、抽象工厂模式</h2><p>抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。<br>抽象工厂允许客户使用抽象的接口来创建一组相关的产品，而不需要知道（或关心）实际产出的具体产品是什么。这样一来，客户就从具体的产品中被解耦。<br>抽象工厂的方法经常以工厂方法的方式实现，抽象工厂的任务是定义一个负责创建一组产品的接口。这个接口内的每个方法都负责创建一个具体产品，<br>同时利用实现抽象工厂的子类来提供这些具体的做法，所以在抽象工厂中利用工厂实现生产方法是相当自然在做法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312731595-301d90a5-6b5f-4da8-8e32-96d19bfb3c30.png#clientId=u31449aae-d0c8-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub322c434&margin=%5Bobject%20Object%5D&name=image.png&originHeight=625&originWidth=1320&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=125791&status=done&style=none&taskId=ued59f856-7188-425b-87c9-9141719760d&title=" alt="image.png"><br>JDK 中使用的抽象工厂<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312731132-e60e3a16-5f75-49b0-b0d8-cd2a4ed4c76e.png#clientId=u31449aae-d0c8-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u846d3d23&margin=%5Bobject%20Object%5D&name=image.png&originHeight=595&originWidth=986&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=61956&status=done&style=none&taskId=ue613c9e6-bb5a-47d7-b26c-15db9431332&title=" alt="image.png"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1、 所有的工厂都是用来封装对象的创建。<br>2、 简单工厂，虽然不是真正的设计模式，但仍不失为一个简单的方法，可以将客户程序从具体类解耦。<br>3、 工厂方法，使用继承，把对象的创建委托给子类，由子类来实现工厂方法来创建对象。<br>4、 抽象工厂，使用对象组合，对象的创建被实现在工厂接口所暴露出来的方法中。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（一）单例模式</title>
    <url>/article/design-pattern/jdk-singleton-pattern/</url>
    <content><![CDATA[<p>单例模式确保一个类只有一个实例，并提供一个全局访问点。<br>其类图如下所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648312497129-b46ae00b-ed09-43d2-b1ed-52150a27aad2.png#clientId=u071cfa4a-1edc-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ueae36114&margin=%5Bobject%20Object%5D&name=image.png&originHeight=332&originWidth=874&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=78397&status=done&style=none&taskId=u12f2e13d-ba01-4d4a-838c-6d2c02a4a69&title=" alt="image.png"><br>本文主要从饿汉式，懒汉式，懒汉式改进，来讲解单例模式。</p>
<h2 id="1、饿汉式单例"><a href="#1、饿汉式单例" class="headerlink" title="1、饿汉式单例"></a><strong>1、饿汉式单例</strong></h2><p>饿汉式单例类是在 Java 语言里实现得最为简便的单例类。在类被加载时，就会将自己实例化。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class Singleton &#123;
    private static Singleton uniqueInstance &#x3D; new Singleton();
    private Singleton() &#123;
        &#x2F;&#x2F; Exists only to defeat instantiation.
    &#125;
    public static Singleton getInstance() &#123;
        return uniqueInstance;
    &#125;
    &#x2F;&#x2F; other methods...
&#125;</code></pre>

<h2 id="2、懒汉式（双重加锁）"><a href="#2、懒汉式（双重加锁）" class="headerlink" title="2、懒汉式（双重加锁）"></a><strong>2、懒汉式（双重加锁）</strong></h2><p>通过 synchronized 关键字，同步不同线程对 getInstance()的访问。这就是所谓的懒汉模式。与饿汉式单例类不同的是，懒汉式单例类在第一次被引用时将自己实例化。这种简单实现的问题在于，每次访问 getInstance()都需要同步操作，而事实上同步只在第一次访问时有意义。为了避免不必要的同步操作，在 JDK1.5 以后可以使用一种双重检查加锁的方法。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class Singleton &#123;
    &#x2F;&#x2F; volatile is very important for uniqueInstance consistency.
    private volatile static Singleton uniqueInstance &#x3D; null;
    private Singleton() &#123;
       &#x2F;&#x2F; Exists only to defeat instantiation.
    &#125;
    public static Singleton getInstance() &#123;
       &#x2F;&#x2F; first check no need to synchronize.
       if (uniqueInstance &#x3D;&#x3D; null) &#123;
           &#x2F;&#x2F; second check need to synchronize, but only run limit times.
           synchronized (Singleton.class) &#123;
              if (uniqueInstance &#x3D;&#x3D; null) &#123;
                  uniqueInstance &#x3D; new Singleton();
              &#125;
           &#125;
       &#125;
       return uniqueInstance;
    &#125;
    &#x2F;&#x2F; Other methods...
&#125;</code></pre>

<p>volatile 确保 uniqueInstance 被初始化为单例后的改变对所有线程可见，多线程能够正确处理 uniqueInstance 变量。getInstance()中包含两次判空操作，第一次判空每次访问都会执行，而第二次判空只在初始访问存在大量并发的情况下出现。通过两次判空避免了不必要的线程同步。之所以限制必须在 JDK1.5 后使用是因为，之前的 Java 存储模型不能保证 volatile 语义的完全正确实现。</p>
<h2 id="3、懒汉式改进"><a href="#3、懒汉式改进" class="headerlink" title="3、懒汉式改进"></a>3、懒汉式改进</h2><p>为了突破这种限制《Effective Java》中给出了一种精妙的解决方法，充分利用了 Java 虚拟机的特性。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class Singleton &#123;
    &#x2F;&#x2F; an inner class holder the uniqueInstance.
    private static class SingletonHolder &#123;
       static final Singleton uniqueInstance &#x3D; new Singleton();
    &#125;
    private Singleton() &#123;
       &#x2F;&#x2F; Exists only to defeat instantiation.
    &#125;
    public static Singleton getInstance() &#123;
       return SingletonHolder.uniqueInstance;
    &#125;
    &#x2F;&#x2F; Other methods...
&#125;</code></pre>

<p>当 getInstance 方法第一次被调用时，在第一次调用 SingletonHolder.uniqueInstance，初始化 SingletonHolder 类，这种用法的优雅之处在于 getInstance 方法不需要同步，执行只有一个字段访问，因此惰性初始化对实际的访问没有任何额外的代价。VM 同步字段访问，只需要初始化 SingletonHolder 类，一旦被初始化，后续的字段访问不会涉及到任何判断和同步。<br>JDK 中使用单例模式的有 Runtime、NumberFormat 等类。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol>
<li>单件模式确保程序中一个类最多只有一个实例，提供访问实例的全局点。</li>
<li>在 Java 中实现单件模式需要私有的构造器，一个静态方法和一个静态变量。</li>
<li>确定在性能和资源上的限制，使用适当的方案解决多线程问题</li>
<li>使用多个类加载器，可能会导致单件失效而产生多个实例</li>
</ol>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（六）桥接模式</title>
    <url>/article/design-pattern/jdk-bridge-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>将抽象部分与实现部分分离，使它们都可以独立的变化</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>某个类具有两个或两个以上的维度变化，如果只是用继承将无法实现这种需要，或者使得设计变得相当臃肿，把变化部分抽象出来，使变化部分与主类分离开来，从而将多个维度的变化彻底分离，提供一个管理类来组合不同维度上的变化，通过这种组合来满足业务的需要，从达到抽象化、实现化和脱耦。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、抽象化(Abstraction)角色：抽象化给出的定义，并保存一个对实现化对象的引用。<br>2、修正抽象化(RefinedAbstraction)角色：扩展抽象化角色，改变和修正父类对抽象化的定义。<br>3、实现化(Implementor)角色：这个角色给出实现化角色的接口，但不给出具体的实现。必须指出的是，这个接口不一定和抽象化角色的接口定义相同，实际上，这两个接口可以非常不一样。实现化角色应当只给出底层操作，而抽象化角色应当只给出基于底层操作的更高一层的操作。<br>4、具体实现化(ConcreteImplementor)角色：这个角色给出实现化角色接口的具体实现。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>通过对象组合的方式，Bridge 模式把两个角色之间的继承关系改为了耦合的关系，从而使这两者可以从容自若的各自独立的变化。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394568658-023fec66-64dd-40b0-a92d-465abcdeb612.png#clientId=u4e992676-b736-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u0a35916d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=276&originWidth=671&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=24309&status=done&style=none&taskId=u7766f2c5-8a49-443b-896f-439f0dd0ba1&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中的 java.util.logging 包中的 Handler 和 Formatter，Handler 是一个抽象类，需要根据实际情况创建真正使用的具体 Handler（如 ConsoleHandler、FileHandler 等），实现各自的 publish、flush 以及 close 等方法,负责从 Logger 中取出日志消息并将消息发送出去，比如发送到控制台、文件、网络上的其他日志服务或操作系统日志等。Handler 一个 Handler 具有使用定义好的各种日志级别、自己的过滤器（Filter）、格式化器（Formatter）、错误管理器（ErrorManager）以及编码字符集等。其中 Formatter 也是一个抽象类，可以使用（XMLFormatter，SimpleFormatter）来格式输出日志信息。将 Handler 和 Formatter 通过桥接，将抽象和实现分开。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394568695-03ac0b72-df9d-4086-9ba4-3b1abcf8e828.png#clientId=u4e992676-b736-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud0e38123&margin=%5Bobject%20Object%5D&name=image.png&originHeight=380&originWidth=947&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=39579&status=done&style=none&taskId=u058aea6c-7c2b-443f-802d-153506e4e43&title=" alt="image.png"></p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><p>桥接模式则把原来的基类的实现化细节抽象出来，在构造到一个实现化的结构中，然后再把原来的基类改造成一个抽象化的等级结构，这样就可以实现系统在多个维度上的独立变化，它很好的符合了开放-封闭原则和优先使用对象，而不是继承这两个面向对象原则。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、分离抽象接口及其实现部分。<br>2、桥接模式有时类似于多继承方案，但是多继承方案违背了类的单一职责原则（即一个类只有一个变化的原因），复用性比较差，而且多继承结构中类的个数非常庞大，桥接模式是比多继承方案更好的解决方法。<br>3、桥接模式提高了系统的可扩充性，在两个变化维度中任意扩展一个维度，都不需要修改原有系统。<br>4、 实现细节对客户透明，可以对用户隐藏实现细节。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。<br>2、 桥接模式要求正确识别出系统中两个独立变化的维度，因此其使用范围具有一定的局限性。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系。<br>2、抽象化角色和实现化角色可以以继承的方式独立扩展而互不影响，在程序运行时可以动态将一个抽象化子类的对象和一个实现化子类的对象进行组合，即系统需要对抽象化角色和实现化角色进行动态耦合。<br>3、 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展。<br>4、虽然在系统中使用继承是没有问题的，但是由于抽象化角色和具体化角色需要独立变化，设计要求需要独立管理这两者。<br>5、 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十三）模板方法模式</title>
    <url>/article/design-pattern/jdk-template-method-pattern/</url>
    <content><![CDATA[<h2 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h2><p>定义一个操作中的算法的骨架，而将步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义算法的某些特定步骤。</p>
<h2 id="2、模式中的角色"><a href="#2、模式中的角色" class="headerlink" title="2、模式中的角色"></a>2、模式中的角色</h2><p>抽象模板类（AbstractTemplate）：实现了模板方法，定义了算法的骨架。<br>具体模板类（ConcreteTemplate)：实现抽象类中的抽象方法，已完成完整的算法。</p>
<h2 id="3、模式解读"><a href="#3、模式解读" class="headerlink" title="3、模式解读"></a>3、模式解读</h2><p>模板方式模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395550490-8058e515-fe25-457f-9654-69c2d8e3fbe9.png#clientId=ue10b6c59-eefb-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucc44435c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=489&originWidth=778&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=73747&status=done&style=none&taskId=u00e60f97-cfd3-4616-abb2-617f62ff3f9&title=" alt="image.png"><br>模板方法中的方法可以分为两大类：模板方法和基本方法。<br>模板方法，一个模板方法是定义在抽象类中的，把基本操作方法组合在一起形成一个总算法或一个总行为的方法。一个抽象类可以有任意多个模板方法，而不限于一个。每一个模板方法都可以调用任意多个具体方法。<br>基本方法，又可以分为三种：抽象方法(Abstract Method)、具体方法(Concrete Method)和钩子方法(Hook Method)。<br>抽象方法：一个抽象方法由抽象类声明，由具体子类实现。在 Java 语言里抽象方法以 abstract 关键字标示。<br>具体方法：一个具体方法由抽象类声明并实现，而子类并不实现或置换。<br>钩子方法：一个钩子方法由抽象类声明并实现，而子类会加以扩展。通常抽象类给出的实现是一个空实现，作为方法的默认实现。<br>抽象模板角色类，abstractMethod()、hookMethod()等基本方法是顶级逻辑的组成步骤，这个顶级逻辑由 templateMethod()方法代表。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public abstract class AbstractTemplate &#123;
    &#x2F;**
     * 模板方法
     *&#x2F;
    public void templateMethod()&#123;
        &#x2F;&#x2F;调用基本方法
        abstractMethod();
        hookMethod();
        concreteMethod();
    &#125;
    &#x2F;**
     * 基本方法的声明（由子类实现）
     *&#x2F;
    protected abstract void abstractMethod();
    &#x2F;**
     * 基本方法(空方法)
     *&#x2F;
    protected void hookMethod()&#123;&#125;
    &#x2F;**
     * 基本方法（已经实现）
     *&#x2F;
    private final void concreteMethod()&#123;
        &#x2F;&#x2F;业务相关的代码
    &#125;
&#125;</code></pre>

<p>具体模板角色类，实现了父类所声明的基本方法，abstractMethod()方法所代表的就是强制子类实现的剩余逻辑，而 hookMethod()方法是可选择实现的逻辑，不是必须实现的。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class ConcreteTemplate extends AbstractTemplate&#123;
    &#x2F;&#x2F;基本方法的实现
    @Override
    public void abstractMethod() &#123;
        &#x2F;&#x2F;业务相关的代码
    &#125;
    &#x2F;&#x2F;重写父类的方法
    @Override
    public void hookMethod() &#123;
        &#x2F;&#x2F;业务相关的代码
    &#125;
&#125;</code></pre>

<p>在上面的例子中，AbstractTemplate 是一个抽象类，它带有三个方法。其中 abstractMethod()是一个抽象方法，它由抽象类声明为抽象方法，并由子类实现；hookMethod()是一个钩子方法，它由抽象类声明并提供默认实现，并且由子类置换掉。concreteMethod()是一个具体方法，它由抽象类声明并实现。默认钩子方法，一个钩子方法常常由抽象类给出一个空实现作为此方法的默认实现。这种空的钩子方法叫做“Do Nothing Hook”。显然，这种默认钩子方法在缺省适配模式里面已经见过了，一个缺省适配模式讲的是一个类为一个接口提供一个默认的空实现，从而使得缺省适配类的子类不必像实现接口那样必须给出所有方法的实现，因为通常一个具体类并不需要所有的方法。</p>
<h2 id="4、JDK-涉及到的设计模式"><a href="#4、JDK-涉及到的设计模式" class="headerlink" title="4、JDK 涉及到的设计模式"></a>4、JDK 涉及到的设计模式</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395550359-db679185-db41-4acb-8e60-d668a708003d.png#clientId=ue10b6c59-eefb-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u211064e1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=341&originWidth=642&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=30227&status=done&style=none&taskId=ue02a812c-e9d1-495b-a216-779df7e9f5f&title=" alt="image.png"><br>ThreadPoolExecutor 中在模板方法中 runWorker 中提供基本方法 beforeExecute 和 afterExecute 供子类实现。</p>
<h2 id="5、模式总结"><a href="#5、模式总结" class="headerlink" title="5、模式总结"></a>5、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>模板方法模式通过把不变的行为搬移到超类，去除了子类中的重复代码。<br>子类实现算法的某些细节，有助于算法的扩展。<br>通过一个父类调用子类实现的操作，通过子类扩展增加新的行为，符合“开放-封闭原则”。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>每个不同的实现都需要定义一个子类，这会导致类的个数的增加，设计更加抽象。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>在某些类的算法中，用了相同的方法，造成代码的重复。<br>控制子类扩展，子类必须遵守算法规则。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十七）命令模式</title>
    <url>/article/design-pattern/jdk-command-pattern/</url>
    <content><![CDATA[<h2 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h2><p>命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也支持可撤销的操作。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>用于“行为请求者”与“行为实现者”解耦，可实现二者之间的松耦合，以便适应变化。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、命令（Command）角色：定义命令的接口，声明执行的方法。<br>2、具体命令（ConcreteCommand）角色：命令接口实现对象，通常它会持有命令的接收者，通过调用接收者相应的功能方法来执行当前命令所要完成的操作。<br>3、接收者（Receiver）角色：真正执行命令的对象。任何类都可以成为一个接收者，只要它能够实现命令要求实现的相应功能即可。<br>4、请求者（Invoker）角色：要求命令对象执行相关请求的对象，通常会持有命令对象，可以是多个命令对象。这是客户端真正触发命令并要求命令执行相应操作的入口点。<br>5、客户端（Client）角色：创建具体的命令对象，并设置命令对象的接收者。注意，这里的客户端并不是我们通常所指的客户端，而是指组装命令和接收者的地方，把这个 Client 称为装配者或者意义会更明了，真正使用命令的客户端是从 Invoker 来触发执行的，而不是从这个 Client 端命令的调用。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>命令模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648396034660-328dcd5e-5a49-4619-b853-ee2882d6296c.png#clientId=u0bb84733-8015-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u47e249f1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=563&originWidth=1068&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=122093&status=done&style=none&taskId=ue978323e-759e-48f3-8272-5d60f63a606&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648396034516-72ed3d0b-3eb6-45c8-8d4d-f738a39fdec2.png#clientId=u0bb84733-8015-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u28145138&margin=%5Bobject%20Object%5D&name=image.png&originHeight=524&originWidth=918&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=46479&status=done&style=none&taskId=uc7c576df-0f02-4d2e-a8d4-386c66fdb83&title=" alt="image.png"></p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、封装性很好<br>2、扩展性很好</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、可能会导致系统具有过多的具体命令类</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、对于大多数请求-响应模式的功能，比较适合使用命令模式，正如命令模式定义说的那样，命令模式对实现记录日志、撤销操作等功能比较方便。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（五）适配器模式</title>
    <url>/article/design-pattern/jdk-adapter-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>将一个类的接口转换成客户希望的另外一个接口。Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>即 Adapter 模式使得原本由于接口不兼容而不能一起工作的那些类可以在一起工作。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>目标接口（Target）：客户所期待的接口。目标可以是具体的或抽象的类，也可以是接口。<br>需要适配的类（Adaptee）：需要适配的类或适配者类。<br>适配器（Adapter）：通过包装一个需要适配的对象，把原接口转换成目标接口。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>在 GoF 的设计模式中，对适配器模式讲了两种类型，类适配器模式和对象适配器模式。由于类适配器模式通过多重继承对一个接口与另一个接口进行匹配，而 C&#x3D;、java 等语言都不支持多重继承，因而这里只是介绍对象适配器。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394415478-ce34ebc6-c75e-495c-a027-99fcaad03f52.png#clientId=udc1a5ed7-d307-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc724e000&margin=%5Bobject%20Object%5D&name=image.png&originHeight=456&originWidth=861&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=53638&status=done&style=none&taskId=u2ad79016-5006-42e5-b81f-69fc567e84e&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>InputStreamReader 类实现面向字节的输入输出向面向字符的输入输出的转换，使用适配器模式，以字符的方式从输入流中读取。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394415547-22152ac8-e1bd-4b87-b5f8-2bb14a6d93c9.png#clientId=udc1a5ed7-d307-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua9a7001b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=382&originWidth=882&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=57629&status=done&style=none&taskId=u3ef724bd-031e-44d5-bcdf-12f0cb083d3&title=" alt="image.png"></p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、 通过适配器，客户端可以调用同一接口，因而对客户端来说是透明的。这样做更简单、更直接、更紧凑。<br>2、 复用了现存的类，解决了现存类和复用环境要求不一致的问题。<br>3、将目标类和适配者类解耦，通过引入一个适配器类重用现有的适配者类，而无需修改原有代码。<br>4、 一个对象适配器可以把多个不同的适配者类适配到同一个目标，也就是说，同一个适配器可以把适配者类和它的子类都适配到目标接口。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>对于对象适配器来说，更换适配器的实现过程比较复杂。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、 系统需要使用现有的类，而这些类的接口不符合系统的接口。<br>2、 想要建立一个可以重用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。<br>3、 两个类所做的事情相同或相似，但是具有不同接口的时候。<br>4、 旧的系统开发的类已经实现了一些功能，但是客户端却只能以另外接口的形式访问，但我们不希望手动更改原有类的时候。<br>5、 使用第三方组件，组件接口定义和自己定义的不同，不希望修改自己的接口，但是要使用第三方组件接口的功能。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十一）代理模式</title>
    <url>/article/design-pattern/jdk-proxy-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>为另一个对象提供一个替身或占位符以控制对这个对象的访问。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>在某些情况下，一个对象不想或者不能直接引用另一个对象，而代理对象可以在客户端和目标对象之间起到中介的作用，提供额外的处理或者不同的操作。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、抽象主题角色(Subject)：声明真实对象和代理对象的共同接口；<br>2、 代理角色(Proxy)：代理对象角色内部含有对真实对象的引用，从而可以操作真实对象，同时代理对象提供与真实对象相同的接口以便在任何时刻都能代替真实对象。同时，代理对象可以在执行真实对象操作时，附加其他的操作，相当于对真实对象进行封装。<br>3、真实主题角色(RealSubject)：代理角色所代表的真实对象，是我们最终要引用的对象。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>代理模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395324883-e19f0053-40d6-415f-abf1-de1c35f0557e.png#clientId=uba13fbea-375f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6d5192e9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=520&originWidth=875&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=105629&status=done&style=none&taskId=u6861b05b-2a4a-4ffe-8557-370a66eead0&title=" alt="image.png"><br>RealSubject 通常是真正做事的对象，proxy 会控制对 RealSubject 的访问。Proxy 持有 Subject 的引用，所以必要时它可以将请求转发给 Subject，在某些例子中，Proxy 还负责 RealSubject 的创建和销毁。Procy 和 RealSubject 都实现了 Subject 接口，任何用到 RealSubject 的地方都可以使用 Proxy 对象取代。</p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中体现：动态代理和远程方法调用 RMI，以动态代理为例。所谓 Dynamic Proxy 是这样一种 class，它是在运行时生成的 class，在生成它时你必须提供一组 interface 给它，然后该 class 就宣称它实现了这些 interface。你当然可以把该 class 的实例当作这些 interface 中的任何一个来用。当然啦，这个 Dynamic Proxy 其实就是一个 Proxy，它不会替你作实质性的工作，在生成它的实例时你必须提供一个 handler，由它接管实际的工作，类图如下所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395324726-dbbb19a3-b928-4c9c-8d78-3fc7c61b62ba.png#clientId=uba13fbea-375f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc20650f8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=450&originWidth=851&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=32275&status=done&style=none&taskId=u3a378490-f6e9-47bf-92bb-bac29aec279&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F;抽象角色(之前是抽象类，此处应改为接口)：

public interface Subject&#123;
    public void request();
&#125;

&#x2F;&#x2F;具体角色RealSubject：实现了Subject接口的request()方法。
public class RealSubject implements Subject &#123;
    public RealSubject() &#123;

    &#125;

    public void request() &#123;
        System.out.println(&quot;From real subject.&quot;);
    &#125;
&#125;

&#x2F;&#x2F;代理角色：
import java.lang.reflect.Method;
import java.lang.reflect.InvocationHandler;

public class DynamicSubject implements InvocationHandler &#123;

    private Object sub;
    public DynamicSubject(Object sub) &#123;
        this.sub &#x3D; sub;
    &#125;

    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;
        System.out.println(&quot;before calling &quot; + method);
        method.invoke(sub,args);
        System.out.println(&quot;after calling &quot; + method);
        return null;
    &#125;

&#125;</code></pre>

<p>该代理类的内部属性为 Object 类，实际使用时通过该类的构造函数 DynamicSubject(Object sub)对其赋值；此外，在该类还实现了 invoke 方法，该方法中的”method.invoke(sub,args)” 其实就是调用被代理对象的将要被执行的方法，方法参数 sub 是实际的被代理对象，args 为执行被代理对象相应操作所需的参数。通过动态代理类，我们可以在调用之前或之后执行一些相关操作。<br>客户端代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Proxy;
import java.lang.reflect.Constructor;
import java.lang.reflect.Method;

public class Client &#123;
    public static void main(String[] args) throws Throwable &#123;
        RealSubject realSubject &#x3D; new RealSubject(); &#x2F;&#x2F;在这里指定被代理类
        InvocationHandler handler &#x3D; new DynamicSubject(realSubject); &#x2F;&#x2F;初始化代理类
        Class clazz &#x3D; realSubject.getClass();
        Subject subject &#x3D; (Subject) Proxy.newProxyInstance(clazz.getClassLoader(),clazz.getInterfaces(),handler);
        subject.request();
    &#125;
&#125;</code></pre>

<p>通过这种方式，被代理的对象(RealSubject)可以在运行时动态改变，需要控制的接口(Subject 接口)可以在运行时改变，控制的方式(DynamicSubject 类)也可以动态改变，从而实现了非常灵活的动态代理关系。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><p>与其他模式比较<br>1、适配器 Adapter 为它所适配的对象提供了一个不同的接口。相反，代理提供了与它的实体相同的接口。然而，用于访问保护的代理可能会拒绝执行实体的操作，因此，它的接口实际上可能只是实体接口的一个子集。<br>2、装饰器模式 Decorator：尽管 Decorator 的实现部分与代理相似，但 Decorator 的目的不一样。Decorator 为对象添加一个或多个功能，而代理则控制对对象的访问。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、透明调用被代理对象，无须知道复杂实现细节<br>2、 增加被代理类的功能</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。实现代理模式需要额外的工作，有些代理模式的实现非常复杂。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、远程代理(RemoteProxy)，可以隐藏一个对象存在于不同地址空间的事实。也使得客户端可以访问在远程机器上的对象，远程机器可能具有更好的计算性能与处理速度，可以快速响应并处理客户端请求。<br>2、虚拟代理(VirtualProxy)，允许内存开销较大的对象在需要的时候创建。只有我们真正需要这个对象的时候才创建。<br>3、写入时复制代理(Copy-On-Write Proxy)，用来控制对象的复制，方法是延迟对象的复制，直到客户真的需要为止。是虚拟代理的一个变体。<br>4、保护代理(Protection-AccessProxy)，为不同的客户提供不同级别的目标对象访问权限<br>5、缓存代理(CacheProxy)，为开销大的运算结果提供暂时存储，它允许多个客户共享结果，以减少计算或网络延迟。<br>6、防火墙代理(Firewall Proxy)，控制网络资源的访问，保护主题免于恶意客户的侵害。<br>7、同步代理(SynchronizationProxy)，在多线程的情况下为主题提供安全的访问。<br>8、智能引用代理(Smar ReferenceProxy)，当一个对象被引用时，提供一些额外的操作，比如将对此对象调用的次数记录下来等。<br>9、复杂隐藏代理(ComplexityHidingProxy)，用来隐藏一个类的复杂集合的复杂度，并进行访问控制。有时候也称为外观代理(Façade Proxy)，这不难理解。复杂隐藏代理和外观模式是不一样的，因为代理控制访问，而外观模式是不一样的，因为代理控制访问，而外观模式只提供另一组接口。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十五）迭代器模式</title>
    <url>/article/design-pattern/jdk-iterator-pattern/</url>
    <content><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>迭代器模式提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露其内部的表示。</p>
<h2 id="2-解决的问题"><a href="#2-解决的问题" class="headerlink" title="2. 解决的问题"></a>2. 解决的问题</h2><p>把游走的任务放在迭代器上，而不是聚合上，这样简化了聚合的接口和实现，也让责任各得其所。</p>
<h2 id="3-模式中的角色"><a href="#3-模式中的角色" class="headerlink" title="3. 模式中的角色"></a>3. 模式中的角色</h2><p>1、抽象迭代器(Iterator)：定义出遍历元素所需的接口。<br>2、具体迭代器(ConcreteIterator)：实现 Iterator 接口，并保持迭代过程中的游标位置。<br>3、聚集(Aggregate)：给出创建迭代器(Iterator)对象的接口。<br>4、具体聚集(ConcreteAggregate)：实现创建迭代器(Iterator)对象的接口，返回一个合适的具体迭代器实例。<br>5、客户端(Client)：持有对聚集及其迭代子对象的引用，调用迭代器对象的迭代接口。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>迭代器模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395894327-847aa1b6-af5b-4f37-8b7a-752a17d0efb1.png#clientId=u2fe704bb-ed5e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=udb7d5c2f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=564&originWidth=807&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=100567&status=done&style=none&taskId=u0d4646e4-1889-4b8b-b81e-5609f74859b&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中 Iterator 和 Collection<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395894174-a01b1c2a-f150-4234-9c87-f25309b4074c.png#clientId=u2fe704bb-ed5e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9bc52632&margin=%5Bobject%20Object%5D&name=image.png&originHeight=536&originWidth=889&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=57544&status=done&style=none&taskId=udc2a284f-8950-4fd0-a394-9a2d34e2069&title=" alt="image.png"><br>ArrayList 为具体聚合对象，创建了具体的 ArrayList$Itr和ArrayList$ListItr 的具体迭代器类。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、迭代器模式简化了聚集的界面。<br>2、因为每一个聚集对象可以有多个迭代器对象，每个迭代器状态是独立的。<br>3、由于遍历算法被封装在迭代器角色里面，因此迭代的算法可以独立于聚集角色变化。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、迭代器模式给客户端一个聚集被顺序化的感觉。<br>2、迭代器给出的聚集元素没有类型特征。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十二）策略模式</title>
    <url>/article/design-pattern/jdk-strategy-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>策略模式，又叫算法簇模式，就是定义了不同的算法族，并且之间可以互相替换，此模式让算法的变化独立于使用算法的客户。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>可以动态的改变对象的行为。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、环境对象(context)：该类中实现了对抽象策略中定义的接口或者抽象类的引用。<br>2、抽象策略对象(Strategy)：它可由接口或抽象类来实现。<br>3、具体策略对象(ConcreteStrategy)：它封装了实现同不功能的不同算法。<br>利用策略模式构建应用程序，可以根据用户配置等内容，选择不同有算法来实现应用程序的功能。具体的选择有环境对象来完成。采用这种方式可以避免由于使用条件语句而带来的代码混乱，提高应用程序的灵活性与条理性。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>策略模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395476139-64516c7e-b11f-47ef-af62-edb91ca34f0d.png#clientId=u75c7c9d0-edfe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u80c3b1a9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=335&originWidth=715&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29670&status=done&style=none&taskId=u165b42e2-0a1b-42ba-8995-32d349ffe78&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395476131-a9f3b2d0-e0b6-4617-98b8-e9b8d6edf16c.png#clientId=u75c7c9d0-edfe-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7fb060e4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=271&originWidth=1112&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29427&status=done&style=none&taskId=uc650afc0-cc5d-4e5c-a49d-ed0d4bb79c5&title=" alt="image.png"><br>ThreadPoolExecutor 的 4 中线程池拒绝策略，也可以自定义实现 RejectedExecutionHandler 进行扩展<br>AbortPolicy，无法处理任务任务的时候，直接抛出异常，<br>DiscardPolicy 丢弃当前将要加入队列的任务本身<br>DiscardOldestPolicy 丢弃任务队列中最旧任务<br>CallerRunsPolicy 由调用者线程去执行，在任务提交速度过快的情况，可减少任务提交的速度，同时可以保证任务的执行。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、策略类之间可以自由切换，由于策略类实现自同一个抽象，所以他们之间可以自由切换。<br>2、易于扩展，增加一个新的策略对策略模式来说非常容易，基本上可以在不改变原有代码的基础上进行扩展。<br>3、避免使用多重条件，如果不使用策略模式，对于所有的算法，必须使用条件语句进行连接，通过条件判断来决定使用哪一种算法，在上一篇文章中我们已经提到，使用多重条件判断是非常不容易维护的。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、维护各个策略类会给开发带来额外开销，可能大家在这方面都有经验：一般来说，策略类的数量超过 5 个，就比较令人头疼了。<br>2、必须对客户端（调用者）暴露所有的策略类，因为使用哪种策略是由客户端来决定的，因此，客户端应该知道有什么策略，并且了解各种策略之间的区别，否则，后果很严重。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、多个类只区别在表现行为不同，可以使用 Strategy 模式，在运行时动态选择具体要执行的行为。<br>2、需要在不同情况下使用不同的策略(算法)，或者策略还可能在未来用其它方式来实现。<br>3、对客户隐藏具体策略(算法)的实现细节，彼此完全独立。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（八）装饰模式</title>
    <url>/article/design-pattern/jdk-decorator-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>动态地将责任附加到对象上，若要扩展功能，装饰者提供了比继承更有弹性的替代方案。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>在不必改变原类文件和使用继承的情况下，动态的扩展一个对象的功能。它是通过创建一个包装对象，也就是装饰来包裹真实的对象，防止类继承带来的爆炸式增长。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、抽象构件(Component)角色：给出一个抽象接口，以规范准备接收附加责任的对象。<br>2、具体构件(ConcreteComponent)角色：定义一个将要接收附加责任的类。<br>3、装饰(Decorator)角色：持有一个构件(Component)对象的实例，并定义一个与抽象构件接口一致的接口。<br>4、具体装饰(ConcreteDecorator)角色：负责给构件对象“贴上”附加的责任。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>装饰模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394777907-fae93886-e09a-48e6-9e25-b569adba7d81.png#clientId=ubbece9b9-e1fa-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc91300a6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=452&originWidth=822&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=39604&status=done&style=none&taskId=u72b7ac02-5349-494d-b26f-27638822828&title=" alt="image.png"><br>Decorator 通过 operation()，调用 ConcreteComponent 的 operation 方法。<br>具体 ConcreteDecorator 给 Component 添加额外的行为，在 operation 方法中，先调用 decorator 的 operation 方法，然后添加新的行为 addedBehavior2。</p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>装饰模式在 Java 语言中的最著名的应用莫过于 Java I&#x2F;O 标准库的设计了。由于 Java I&#x2F;O 库需要很多性能的各种组合，如果这些性能都是用继承的方法实现的，那么每一种组合都需要一个类，这样就会造成大量性能重复的类出现。而如果采用装饰模式，那么类的数目就会大大减少，性能的重复也可以减至最少。因此装饰模式是 Java I&#x2F;O 库的基本模式。Java I&#x2F;O 库的对象结构图如下，由于 Java I&#x2F;O 的对象众多，因此只画出 InputStream 的部分。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394777894-37746650-feda-49e4-a8fa-318c5b2e89d3.png#clientId=ubbece9b9-e1fa-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub033c95d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=414&originWidth=842&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29300&status=done&style=none&taskId=u4e2834f0-8895-4f33-952b-272a433490a&title=" alt="image.png"><br>抽象构件(Component)角色，由 InputStream 扮演，为各种子类型提供统一的接口。具体构件(ConcreteComponent)角色：由 ByteArrayInputStream、FileInputStream、PipedInputStream、StringBufferInputStream 等类扮演，实现了抽象构件角色所规定的接口。抽象装饰(Decorator)角色，由 FilterInputStream 扮演，实现了 InputStream 所规定的接口。具体装饰(ConcreteDecorator)角色，由几个类扮演，分别是 BufferedInputStream、DataInputStream 以及两个不常用到的类 LineNumberInputStream、PushbackInputStream。</p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="半透明的装饰模式"><a href="#半透明的装饰模式" class="headerlink" title="半透明的装饰模式"></a>半透明的装饰模式</h3><p>装饰模式和适配器模式都是“包装模式(Wrapper Pattern)”，它们都是通过封装其他对象达到设计的目的的，但是它们的形态有很大区别。<br>理想的装饰模式在对被装饰对象进行功能增强的同时，要求具体构件角色、装饰角色的接口与抽象构件角色的接口完全一致。而适配器模式则不然，一般而言，适配器模式并不要求对源对象的功能进行增强，但是会改变源对象的接口，以便和目标接口相符合。<br>装饰模式有透明和半透明两种，这两种的区别就在于装饰角色的接口与抽象构件角色的接口是否完全一致。透明的装饰模式也就是理想的装饰模式，要求具体构件角色、装饰角色的接口与抽象构件角色的接口完全一致。相反，如果装饰角色的接口与抽象构件角色接口不一致，也就是说装饰角色的接口比抽象构件角色的接口宽的话，装饰角色实际上已经成了一个适配器角色，这种装饰模式也是可以接受的，称为“半透明”的装饰模式，如下图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648394777957-7ba18fe8-779a-45fe-9ffc-32c8d634368a.png#clientId=ubbece9b9-e1fa-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue9ad5ed6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=291&originWidth=728&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=19203&status=done&style=none&taskId=ua2b4252f-f6d6-4988-8094-3c5d10227f9&title=" alt="image.png"></p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、 装饰模式与继承关系的目的都是要扩展对象的功能，但是装饰模式可以提供比继承更多的灵活性。装饰模式允许系统动态决定“贴上”一个需要的“装饰”，或者除掉一个不需要的“装饰”。继承关系则不同，继承关系是静态的，它在系统运行前就决定了。<br>2、通过使用不同的具体装饰类以及这些装饰类的排列组合，设计师可以创造出很多不同行为的组合。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>由于使用装饰模式，可以比使用继承关系需要较少数目的类。使用较少的类，当然使设计比较易于进行。但是，在另一方面，使用装饰模式会产生比使用继承关系更多的对象。更多的对象会使得查错变得困难，特别是这些对象看上去都很相像。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、 在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。<br>2、处理那些可以撤消的职责。<br>3、当不能采用生成子类的方法进行扩充时。一种情况是，可能有大量独立的扩展，为支持每一种组合将产生大量的子类，使得子类数目呈爆炸性增长。另一种情况可能是因为类定义被隐藏，或类定义不能用于生成子类。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十六）责任链模式</title>
    <url>/article/design-pattern/jdk-responsibility-pattern/</url>
    <content><![CDATA[<h2 id="1、概述"><a href="#1、概述" class="headerlink" title="1、概述"></a>1、概述</h2><p>责任链模式避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>如果有多个对象都有可能接受请求，可以避免请求发送者与接收者耦合在一起。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>1、抽象处理者角色(Handler): 定义一个处理请求的接口，和一个后继连接(可选)<br>2、具体处理者角色(ConcreteHandler): 处理它所负责的请求，可以访问后继者，如果可以处理请求则处理，否则将该请求转给他的后继者。<br>3、客户类(Client): 向一个链上的具体处理者 ConcreteHandler 对象提交请求。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>责任链模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395971572-0bdf5afa-a5dd-4ea0-8366-f3e5f908a066.png#clientId=u45c09cd2-d39b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u36a52fdc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=461&originWidth=700&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=47357&status=done&style=none&taskId=ub6ca0213-5d64-4293-99bb-e19d86e5139&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中体现 ava.util.logging.Logger 会将 log 委托给 parent 的 logger 和 ClassLoader 的委托模型<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395971561-e0775992-1222-4769-8af9-357c985a9c50.png#clientId=u45c09cd2-d39b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uef5a2e51&margin=%5Bobject%20Object%5D&name=image.png&originHeight=530&originWidth=952&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=38194&status=done&style=none&taskId=u259428cf-71af-4b3e-9b3e-8201c79cc03&title=" alt="image.png"></p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、降低耦合度，该模式使得一个对象无需知道是其他哪一个对象处理其请求。对象仅需知道该请求会被“正确”地处理。接收者和发送者都没有对方的明确的信息，且链中的对象不需知道链的结构。<br>2、职责链可简化对象的相互连接，仅需保持一个指向其后继者的引用，而不需保持它所有的候选接受者的引用。<br>3、增强了给对象指派职责的灵活性，当在对象中分派职责时，职责链给你更多的灵活性。你可以通过在运行时刻对该链进行动态的增加或修改来增加或改变处理一个请求的那些职责。你可以将这种机制与静态的特例化处理对象的继承机制结合起来使用。<br>4、增加新的请求处理类很方便</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、不能保证请求一定被接收。既然一个请求没有明确的接收者，那么就不能保证它一定会被处理，该请求可能一直到链的末端都得不到处理。一个请求也可能因该链没有被正确配置而得不到处理。<br>2、系统性能将受到一定影响，而且在进行代码调试时不太方便；可能会造成循环调用。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、有多个的对象可以处理一个请求，哪个对象处理该请求运行时刻自动确定。<br>2、你想在不明确指定接收者的情况下，向多个对象中的一个提交一个请求。<br>3、可动态指定一组对象处理请求。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十四）观察者模式</title>
    <url>/article/design-pattern/jdk-observer-pattern/</url>
    <content><![CDATA[<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>有时被称作发布&#x2F;订阅模式，观察者模式定义了对象之间的一对多的依赖关系，这样一来，当一个对象改变状态时，它的所有依赖着都会收到通知并自动更新。</p>
<h2 id="2-解决的问题"><a href="#2-解决的问题" class="headerlink" title="2. 解决的问题"></a>2. 解决的问题</h2><p>将一个系统分割成一个一些类相互协作的类有一个不好的副作用，那就是需要维护相关对象间的一致性。我们不希望为了维持一致性而使各类紧密耦合，这样会给维护、扩展和重用都带来不便。观察者就是解决这类的耦合关系的。</p>
<h2 id="3-模式中的角色"><a href="#3-模式中的角色" class="headerlink" title="3. 模式中的角色"></a>3. 模式中的角色</h2><p>1、抽象主题（Subject）：它把所有观察者对象的引用保存到一个聚集里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象。<br>2、具体主题（ConcreteSubject）：将有关状态存入具体观察者对象；在具体主题内部状态改变时，给所有登记过的观察者发出通知。<br>3、抽象观察者（Observer）：为所有的具体观察者定义一个接口，在得到主题通知时更新自己。<br>4、具体观察者（ConcreteObserver）：实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题状态协调。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>模板方式模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395691496-3449d8d6-1e6c-4098-a65d-750b465b9e79.png#clientId=u97477a4e-217a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u42be28d6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=532&originWidth=886&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=102362&status=done&style=none&taskId=u9a6c5a4f-4fd9-482a-9147-c59b63aa5e0&title=" alt="image.png"></p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中体现 java.util.Observer 和 Observable<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395691319-24bf7a01-959e-4e48-afe9-55dadc9e8ba2.png#clientId=u97477a4e-217a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5c20bcc9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=287&originWidth=618&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=21535&status=done&style=none&taskId=u43d3f0dc-ad40-47a3-a497-5877930d97f&title=" alt="image.png"></p>
<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>1、观察者模式解除了主题和具体观察者的耦合，让耦合的双方都依赖于抽象，而不是依赖具体。从而使得各自的变化都不会影响另一边的变化。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>1、依赖关系并未完全解除，抽象通知者依旧依赖抽象的观察者。</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、当一个对象的改变需要给变其它对象时，而且它不知道具体有多少个对象有待改变时。<br>2、 一个抽象某型有两个方面，当其中一个方面依赖于另一个方面，这时用观察者模式可以将这两者封装在独立的对象中使它们各自独立地改变和复用。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（四）原型模式</title>
    <url>/article/design-pattern/jdk-prototype-pattern/</url>
    <content><![CDATA[<p>用原型实例指定创建对象的种类，并且通过复制这些原型创建新的对象。<br>在原型模式中，所发动创建的对象通过请求原型对象来拷贝原型对象自己来实现创建过程，当然所发动创建的对象需要知道原型对象的类型。这里也就是说所发动创建的对象只需要知道原型对象的类型就可以获得更多的原型实例对象，至于这些原型对象时如何创建的根本不需要关心，其类图如下所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648313188451-9214a6e1-a03e-40c4-a78c-404d85d2228a.png#clientId=u7cda6d28-aff4-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u59b5ea5d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=483&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=18632&status=done&style=none&taskId=ud21905df-8c79-4a5a-8d62-5863b178258&title=" alt="image.png"><br>原型模式主要包含如下三个角色：</p>
<ul>
<li><strong>Prototype</strong>：抽象原型类。声明克隆自身的接口。</li>
<li><strong>ConcretePrototype</strong>：具体原型类。实现克隆的具体操作。</li>
<li><strong>Client</strong>：客户类。让一个原型克隆自身，从而获得一个新的对象。</li>
</ul>
<p>讲到原型模式，我们就不得不区分两个概念：深拷贝、浅拷贝。</p>
<ul>
<li><strong>浅拷贝</strong>：使用一个已知实例对新创建实例的成员变量逐个赋值，这个方式被称为浅拷贝。</li>
<li><strong>深拷贝</strong>：当一个类的拷贝构造方法，不仅要复制对象的所有非引用成员变量值，还要为引用类型的成员变量创建新的实例，并且初始化为形式参数实例值。</li>
</ul>
<h2 id="JDK-中使用的原型模式"><a href="#JDK-中使用的原型模式" class="headerlink" title="JDK 中使用的原型模式"></a>JDK 中使用的原型模式</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648313188444-67fe8954-aec8-42e0-aa2d-cc18c7c00697.png#clientId=u7cda6d28-aff4-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ubfc0d4bc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=255&originWidth=433&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=10391&status=done&style=none&taskId=u68df6cd2-517f-495e-9b05-453dc1d6d53&title=" alt="image.png"><br>所有的 Java 类都继承至 Object，而 Object 类提供了一个 clone()方法，该方法可以将一个 java 对象复制一份，因此在 java 中可以直接使用 clone()方法来复制一个对象。但是需要实现 clone 的 Java 类必须要实现一个接口:Cloneable.该接口表示该类能够复制且具体复制的能力，如果不实现该接口而直接调用 clone()方法会抛出 CloneNotSupportedException 异常。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class ObjectClone implements Cloneable&#123;
    public Object clone()&#123;
        Object object &#x3D; null;
        try &#123;
                object &#x3D; super.clone();
        &#125; catch (CloneNotSupportedException exception) &#123;
                System.err.println(&quot;Not support cloneable&quot;);
        &#125;
        return object;
    &#125;
&#125;</code></pre>

<p>Java 中任何实现了 Cloneable 接口的类都可以通过调用 clone()方法来复制一份自身然后传给调用者。一般而言，clone()方法满足：<br>1）对任何的对象 x，都有 x.clone() !&#x3D;x，即克隆对象与原对象不是同一个对象。<br>2）对任何的对象 x，都有 x.clone().getClass()&#x3D;&#x3D;x.getClass()，即克隆对象与原对象的类型一样。<br>3）如果对象 x 的 equals()方法定义恰当，那么 x.clone().equals(x)应该成立。</p>
<h2 id="原型模式优点"><a href="#原型模式优点" class="headerlink" title="原型模式优点"></a>原型模式优点</h2><p>1、如果创建新的对象比较复杂时，可以利用原型模式简化对象的创建过程，同时也能够提高效率。<br>2、可以使用深克隆保持对象的状态。<br>3、原型模式提供了简化的创建结构。</p>
<h2 id="原型模式缺点"><a href="#原型模式缺点" class="headerlink" title="原型模式缺点"></a>原型模式缺点</h2><p>1、在实现深克隆的时候可能需要比较复杂的代码。<br>2、需要为每一个类配备一个克隆方法，而且这个克隆方法需要对类的功能进行通盘考虑，这对全新的类来说不是很难，但对已有的类进行改造时，不一定是件容易的事，必须修改其源代码，违背了“开闭原则”。</p>
<h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p>1、如果创建新对象成本较大，我们可以利用已有的对象进行复制来获得。<br>2、如果系统要保存对象的状态，而对象的状态变化很小，或者对象本身占内存不大的时候，也可以使用原型模式配合备忘录模式来应用。相反，如果对象的状态变化很大，或者对象占用的内存很大，那么采用状态模式会比原型模式更好。<br>3、需要避免使用分层次的工厂类来创建分层次的对象，并且类的实例对象只有一个或很少的几个组合状态，通过复制原型对象得到新实例可能比使用构造函数创建一个新实例更加方便。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1、原型模式向客户隐藏了创建对象的复杂性。客户只需要知道要创建对象的类型，然后通过请求就可以获得和该对象一模一样的新对象，无须知道具体的创建过程。<br>2、克隆分为浅克隆和深克隆两种。<br>3、我们虽然可以利用原型模式来获得一个新对象，但有时对象的复制可能会相当的复杂，比如深克隆。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（一）Java内存区域与内存溢出</title>
    <url>/article/jvm/java-oom/</url>
    <content><![CDATA[<h2 id="Java-内存区域"><a href="#Java-内存区域" class="headerlink" title="Java 内存区域"></a>Java 内存区域</h2><p>Java 虚拟机所管理的内存将包括以下几个运行时数据区域，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398202584-ea2c0566-27ce-4d75-ade9-46ec5fdd6861.png#clientId=u9ab6b3aa-6681-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uffe2023a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=508&originWidth=778&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=42074&status=done&style=none&taskId=u0aab7c79-af15-4f25-abdc-84c9405a262&title=" alt="image.png"></p>
<h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>ProgramCounterRegister 是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变程序计数器的值来选取下一条要执行的字节码指令，分支、循环、跳转、异常跳转、线程恢复等基础功能都需要依赖这个计数器来完成。<br>由于 Java 虚拟机的多线程时通过线程切换并分配处理器执行时间来实现的，对于单核处理器在某一个时间都只会有一个线程在运行，为了线程切换后能恢复到正确的执行位置，每个线程都需要维护一个独立的程序计数器，各个线程之间的计数器互不影响，独立存储。<br>如果当前线程正在执行一个 Java 方法，程序计数器记录的是正在执行的虚拟机字节码指令的指令。如果当前线程正在执行一个 Native 方法，程序计数器记录值则为空。此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。</p>
<h3 id="Java-虚拟机栈"><a href="#Java-虚拟机栈" class="headerlink" title="Java 虚拟机栈"></a>Java 虚拟机栈</h3><p>与程序计数器一样，Java 虚拟机也是线程私有的，它的生命周期与线程相同。每个方法被执行的时候会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机中从入栈到出栈的过程。<br>如果线程请求栈深度大于虚拟机所允许的深度，抛出 StackOverflowError 异常；<br>如果虚拟机栈可以动态扩展，扩展时无法申请到足够的内存时会抛出 OutOfMemoryError。</p>
<h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，只不过一个是执行 Java 方法（也是字节码）服务，而本地方法栈则是使用到的 Native 方法服务，HotSpot 虚拟机直接将两者合二为一，与虚拟机栈一样，本地方法栈也会抛出 StackOverflowError 和 OutOfMemoryError 异常。</p>
<h3 id="Java-堆"><a href="#Java-堆" class="headerlink" title="Java 堆"></a>Java 堆</h3><p>Java 堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。Java 堆是垃圾收集器管理的主要区域，很多时候称为 GC 堆。<br>如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出 OutOfMemoryError</p>
<h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>Method Area 与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、JIT 编译后的代码等数据。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError。<br>Method Area 与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、JIT 编译后的代码等数据。但项目中如果存在类的动态编译，就需要观察方法区的大小是否能够满足类存储。<br>垃圾回收较少发生在该内存区域，它存储的信息相对比较稳定，回收的主要目标是常量池和对类型的卸载。对类型的卸载相当苛刻，要求满足以下三个条件才能算是“无用”的类：<br>该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例<br>加载该类的 ClassLoader 已经被回收<br>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。<br>当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError。</p>
<h3 id="运行时常量池"><a href="#运行时常量池" class="headerlink" title="运行时常量池"></a>运行时常量池</h3><p>Runtime Constant Pool 是方法区的一部分。用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。<br>运行时常量池相对于 Class 文件常量池的一个重要特征在于其具备动态性，Java 语言并不要求常量一定只有编译期才能产生，在运行期间也能产生新的常量放入常量池中，如 String.intern()方法。当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。</p>
<h3 id="直接内存"><a href="#直接内存" class="headerlink" title="直接内存"></a>直接内存</h3><p>Direct Memory 并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范中定义的内存区域，但是这部分也是频繁使用。在 Java 的 NIO 中使用到，服务器管理员忽略直接内存后果是，各个内存区域总和大于物理内存限制，从而导致动态扩展时出现 OutOfMemoryError 异常。</p>
<h2 id="实战：OutOfMemoryError-异常"><a href="#实战：OutOfMemoryError-异常" class="headerlink" title="实战：OutOfMemoryError 异常"></a>实战：OutOfMemoryError 异常</h2><h3 id="1、Java-堆溢出"><a href="#1、Java-堆溢出" class="headerlink" title="1、Java 堆溢出"></a>1、Java 堆溢出</h3><p>Java 堆用于存储对象实例，我们只要不断创建对象，并且保证 GC Roots 到对象之间有可达路径来避免 GC 清除这些对象，就会在对象数量到达最大堆的容量限制后产生内存溢出异常。<br>VM Args: -Xms10m -Xmx10m -XX:+HeapDumpOnOutOfMemoryError<br>XX:+HeapDumpOnOutOfMemoryError 这个参数可以让虚拟机在出现内存溢出异常时 Dump 出当前的内存堆转储快照以便事后进行分析。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">import java.util.ArrayList;
import java.util.List;
&#x2F;**
 * VM Args: -Xms10m -Xmx10m -XX:+HeapDumpOnOutOfMemoryError
 *&#x2F;
public class HeapOOM &#123;
    static class OOMObject&#123;
        private String name;
        public OOMObject(String name) &#123;
            this.name &#x3D; name;
        &#125;
    &#125;
    public static void main(String[] args) &#123;
        List&lt;OOMObject&gt; list &#x3D; new ArrayList&lt;OOMObject&gt;();
        long i &#x3D; 1;
        while(true) &#123;
            list.add(new OOMObject(&quot;IpConfig...&quot; + i++));
        &#125;
    &#125;
&#125;</code></pre>

<p>抛出的异常：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">Dumping heap to java_pid27828.hprof ...
Heap dump file created [14123367 bytes in 0.187 secs]
Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space
at java.lang.AbstractStringBuilder.&lt;init&gt;(AbstractStringBuilder.java:45)
at java.lang.StringBuilder.&lt;init&gt;(StringBuilder.java:92)
at com.baoxian.HeapOOM.main(HeapOOM.java:22)</code></pre>

<p>注：出现 Java 堆内存溢出时，异常堆栈信息 java.lang.OutOfMemoryError 后面会紧跟着 JavaHeapSpace。<br>要解决这个异常，一般手段是首先通过内存映像分析工具比如 Eclipse Memory Analyzer 对 dump 出来的堆转储快照进行分析，重点是确认内存中对象是否是必要的，也就是要弄清楚到底是出现了内存泄露 Memory Leak 还是内存溢出 Memory Overflow。<br>如果是内存泄露，可进一步通过工具查看泄露对象到 GC Roots 的引用链。于是就能找到泄露对象时通过怎样的路径与 GC Roots 相关联并导致垃圾收集器无法自动回收它们。掌握了泄露对象的类型信息，以及 GC Roots 引用链的信息，就可以比较准确的定位出泄露代码的位置了。<br>如果不存在泄露，那么就该修改-Xms 和-Xms 堆参数看能否加大点。</p>
<h3 id="2、虚拟机栈和本地方法栈溢出"><a href="#2、虚拟机栈和本地方法栈溢出" class="headerlink" title="2、虚拟机栈和本地方法栈溢出"></a>2、虚拟机栈和本地方法栈溢出</h3><p>-Xoss 参数设置本地方法栈大小，对于 HotSpot 没用。栈容量只由-Xss 参数设定。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * VM Args: -Xss128k
 * @author Administrator
 *
 *&#x2F;
public class JavaVMStackSOF &#123;
    private int stackLength &#x3D; 1;
    public void stackLeak() &#123;
        stackLength++;
        stackLeak();
    &#125;
    public static void main(String[] args) throws Throwable&#123;
        JavaVMStackSOF oom &#x3D; new JavaVMStackSOF();
        try &#123;
            oom.stackLeak();
        &#125; catch (Throwable e) &#123;
            System.out.println(&quot;stack length: &quot; + oom.stackLength);
            throw e;
        &#125;
    &#125;
&#125;</code></pre>

<p>抛出异常：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">stack length: 1007
Exception in thread &quot;main&quot; java.lang.StackOverflowError
at com.baoxian.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11)
at com.baoxian.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12)
at com.baoxian.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12)
at com.baoxian.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:12)</code></pre>

<h3 id="3、运行时常量池溢出"><a href="#3、运行时常量池溢出" class="headerlink" title="3、运行时常量池溢出"></a>3、运行时常量池溢出</h3><p>运行时常量池分配在方法区内，可以通过-XX:PermSize 和-XX:MaxPermSize 限制方法区大小，从而间接限制其中常量池的容量。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">import java.util.ArrayList;
import java.util.List;
&#x2F;**
 * VM Args: -XX:PermSize&#x3D;10M -XX:MaxPermSize&#x3D;10M
 *&#x2F;
public class RuntimeConstantPoolOOM &#123;
    public static void main(String[] args) &#123;
        &#x2F;&#x2F; 使用List保持着常量池引用，避免Full GC回收常量池行为
        List&lt;String&gt; list &#x3D; new ArrayList&lt;String&gt;;();
        &#x2F;&#x2F; 10MB的PermSize在integer范围内足够产生OOM了
        int i &#x3D; 0;
        while (true) &#123;
            list.add(String.valueOf(i++).intern());
        &#125;
    &#125;
&#125;</code></pre>

<p>异常：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space
at java.lang.String.intern(Native Method)
at com.baoxian.RuntimeConstantPoolOOM.main(RuntimeConstantPoolOOM.java:18)</code></pre>

<p>运行时常量池溢出，在 java.lang.OutOfMemoryError 后面紧跟着是 PermGen space</p>
<h3 id="4、方法区溢出"><a href="#4、方法区溢出" class="headerlink" title="4、方法区溢出"></a>4、方法区溢出</h3><p>方法区用于存放 Class 的相关信息，如类名、访问修饰符、常量池、字段描述符、方法描述等。对于这个区域的测试，基本的思路是运行时产生大量的类去填满方法区，直到溢出。比如动态代理会生成动态类。<br>使用 CGLib 技术直接操作字节码运行，生成大量的动态类。当前很多主流框架如 Spring 和 Hibernate 对类进行增强都会使用 CGLib 这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的 Class 可以加载入内存。<br>异常：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method)</code></pre>

<p>同样，跟常量池一样，都是 PermGen space 字符串出现<br>方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，判定条件是非常苛刻的。在经常动态生成大量 Class 的应用中，需要特别注意类的回收状况。这类场景除了上面提到的程序使用 GCLib 字节码技术外，常见的还有：大量 JSP 或动态产生的 JSP 文件的应用（JSP 第一次运行时需要编译为 Java 类）、基于 OSGi 应用等。</p>
<h3 id="5、本机直接内存溢出"><a href="#5、本机直接内存溢出" class="headerlink" title="5、本机直接内存溢出"></a>5、本机直接内存溢出</h3><p>DirectMemory 容量可以通过-XX:MaxDirectMemorySize 指定，如果不指定，则默认与 Java 堆的最大值-Xmx 指定一样。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * VM Args: -Xmx20M -XX:MaxDirectMemorySize&#x3D;10M
 *&#x2F;
public class DirectMemoryOOM &#123;
    private static final int _1MB &#x3D; 1024 * 1024;
    public static void main(String[] args) &#123;
        Field unsafeField &#x3D; Unsafe.class.getDeclaredFields()[0];
        unsafeField.setAccessible(true);
        Unsafe unsafe &#x3D; (Unsafe) unsafeField.get(null);
        while(true) &#123;
            unsafe.allocateMemory(_1MB);
        &#125;
    &#125;
&#125;</code></pre>

<p>在 OutOfMemoryError 后面不会有任何东西了，这就是 DirectMemory 内存溢出了。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK设计模式（十）享元模式</title>
    <url>/article/design-pattern/jdk-flyweight-pattern/</url>
    <content><![CDATA[<h2 id="1、定义"><a href="#1、定义" class="headerlink" title="1、定义"></a>1、定义</h2><p>采用一个共享来避免大量拥有相同内容对象的开销。</p>
<h2 id="2、解决的问题"><a href="#2、解决的问题" class="headerlink" title="2、解决的问题"></a>2、解决的问题</h2><p>使用共享物件，用来尽可能减少内存使用量，以及分享资讯给尽可能多的相似物件；适合用于只是因重复而导致使用无法令人接受的大量内存的大量物件。</p>
<h2 id="3、模式中的角色"><a href="#3、模式中的角色" class="headerlink" title="3、模式中的角色"></a>3、模式中的角色</h2><p>内蕴状态存储在享元内部，不会随环境的改变而有所不同，是可以共享的；外蕴状态是不可以共享的，它随环境的改变而改变的，因此外蕴状态是由客户端来保持（因为环境的变化是由客户端引起的）。在每个具体的环境下，客户端将外蕴状态传递给享元，从而创建不同的对象出来。享元模式可分为：单纯享元模式和复合享元模式。<br>1、 抽象享元角色(Flyweight)：为具体享元角色规定了必须实现的方法，而外蕴状态就是以参数的形式通过此方法传入。在 Java 中可以由抽象类、接口来担当。<br>2、具体享元角色(ConcreteFlyweight)：实现抽象角色规定的方法。如果存在内蕴状态，就负责为内蕴状态提供存储空间。<br>3、复合享元角色(ConcreteCompositeFlyweight)：它所代表的对象是不可以共享的，并且可以分解成为多个单纯享元对象的组合。<br>4、享元工厂角色(FlyweightFactory)：负责创建和管理享元角色。要想达到共享的目的，这个角色的实现是关键！<br>5、客户端角色(client)：维护对所有享元对象的引用，而且还需要存储对应的外蕴状态。</p>
<h2 id="4、模式解读"><a href="#4、模式解读" class="headerlink" title="4、模式解读"></a>4、模式解读</h2><p>享元模式的类图如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648395132246-6f6a485b-fb25-4196-aa2a-b77369c50f2e.png#clientId=uf5f969c2-5399-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua4efe0d7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=308&originWidth=781&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=20055&status=done&style=none&taskId=u65ef4130-df66-422d-b911-31311a53d00&title=" alt="image.png"><br>左半部，和简单工厂模式类似；再看右半部，像合成模式，合成模式用在此处就是为了将具体享元角色和复合享元角色同等对待和处理，通过将享元模式与合成模式组合在一起，可以确保复合享元中所包含的每个单纯享元都具有相同的外蕴状态，而这些单纯享元的内蕴状态往往是不同的。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 复合的享元模式:
 * 复合享元是不能共享的。
 * 但是复合享元是可以分解为可共享的单纯享元。
 *&#x2F;
public class FlyweightTest &#123;
    public static void main(String[] args)&#123;
        FlyweightFactory f &#x3D; new FlyweightFactory();

        Flyweight fly &#x3D; f.factory(&quot;aba&quot;);
        fly.operation(&quot;charles&quot;);

        f.checkFlyweight();
    &#125;
&#125;

&#x2F;**
 * 抽象享元
 *&#x2F;
abstract class Flyweight&#123;
    public abstract void operation(String extrinsicState);
&#125;

&#x2F;**
 * 具体享元
 *&#x2F;
class ConcreteFlyweight extends Flyweight&#123;

    private Character inState;

    public ConcreteFlyweight(Character inState)&#123;
        this.inState &#x3D; inState;
    &#125;

    &#x2F;**
     * 外蕴状态改变方法行为，但不会改变内蕴状态
     *&#x2F;
    @Override
    public void operation(String extState)&#123;
        String str &#x3D; &quot;inState:&quot; + inState + &quot;;extState:&quot; + extState;
        System.out.println(str);
    &#125;

&#125;

&#x2F;**
 * 复合享元
 *&#x2F;
class CompositeFlyweight extends Flyweight&#123;
    private Map&lt;Character , Flyweight&gt; map;

    public CompositeFlyweight()&#123;
        map &#x3D; new HashMap&lt;Character, Flyweight&gt;();
    &#125;

    public void add(Character c, Flyweight fly)&#123;
        map.put(c , fly);
    &#125;

    @Override
    public void operation(String extState)&#123;
        Iterator&lt;Map.Entry&lt;Character , Flyweight&gt;&gt; it &#x3D; map.entrySet().iterator();
        while(it.hasNext()) &#123;
            Map.Entry&lt;Character , Flyweight&gt; entry &#x3D; it.next();
            Flyweight fly &#x3D; entry.getValue();
            fly.operation(extState);
        &#125;
    &#125;
&#125;

&#x2F;**
 * 享元工厂
 *&#x2F;
class FlyweightFactory&#123;
    private Map&lt;Character , Flyweight&gt; map;

    public FlyweightFactory()&#123;
        map &#x3D; new HashMap&lt;Character , Flyweight&gt;();
    &#125;

    &#x2F;**
     * 单纯享元工厂
     *&#x2F;
    public Flyweight factory(Character state) &#123;

        Flyweight flyweight;

        if(map.containsKey(state)) &#123;
            flyweight &#x3D; map.get(state);
        &#125; else&#123;
            flyweight &#x3D; new ConcreteFlyweight(state);
            map.put(state , flyweight);
        &#125;

        return flyweight;
    &#125;

    &#x2F;**
     * 复合享元工厂
     * 此处Character的复合类型恰好是String，
     * 当无此巧合时，可使用List等聚集类型传入.
     *&#x2F;
    public Flyweight factory(String compositeState)&#123;
        CompositeFlyweight composite &#x3D; new CompositeFlyweight();

        for(int i &#x3D; 0 ; i &lt;compositeState.length(); i++)&#123;
            Character c &#x3D; new Character(compositeState.charAt(i));
            composite.add(c , this.factory(c));
        &#125;

        return composite;
    &#125;

    &#x2F;**
     * 辅助方法
     *&#x2F;
    public void checkFlyweight() &#123;
        Iterator&lt;Map.Entry&lt;Character, Flyweight&gt;&gt; it &#x3D; map.entrySet().iterator();
        System.out.println(&quot;checkFlyweight:&quot;);
        while(it.hasNext()) &#123;
            Map.Entry&lt;Character , Flyweight&gt; entry &#x3D; it.next();
            Character key &#x3D; entry.getKey();
            System.out.println(&quot;key:&quot; + key);
        &#125;
    &#125;

&#125;</code></pre>

<p>从复杂度上来讲，复合享元模式显而易见是比单纯享元模式复杂的。再从享元模式的关键——共享，来分析：复合享元模式在共享上面是没有达到预期的效果，可以说是没有起到共享的目的。虽然对于它内部包含的单纯享元角色来说还是能够起到共享的作用，但是复合享元角色中一个内蕴状态和对象使用了空间来保存，肯定不会节省空间和对象个数的。所以复合享元模式是违背享元模式初衷的，因此我们应该尽量使用单纯享元模式。</p>
<h2 id="5、JDK-涉及到的设计模式"><a href="#5、JDK-涉及到的设计模式" class="headerlink" title="5、JDK 涉及到的设计模式"></a>5、JDK 涉及到的设计模式</h2><p>JDK 中体现有 Integer.valueOf(int i)，Character.valueOf(char c)以及 String 常量池。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public static Integer valueOf(String s) throws NumberFormatException &#123;
    return Integer.valueOf(parseInt(s, 10));
&#125;

&#x2F;* i 在IntegerCache中，返回共享对象，不在其中创建新的Integer对象 *&#x2F;
public static Integer valueOf(int i) &#123;
    if (i &gt;&#x3D; IntegerCache.low &amp;&amp; i &lt;&#x3D; IntegerCache.high)
        return IntegerCache.cache[i + (-IntegerCache.low)];
    return new Integer(i);
&#125;

&#x2F;* IntegerCache，一个内部类，注意它的属性都是定义为static final *&#x2F;
private static class IntegerCache &#123;
    static final int low &#x3D; -128;
    static final int high;
    static final Integer cache[];

    static &#123;
        &#x2F;**
         * h值，可以通过设置jdk的AutoBoxCacheMax参数调整，
         * 自动缓存区间设置为[-128,N],注意区间的下界是固定
         *&#x2F;
        int h &#x3D; 127;
        String integerCacheHighPropValue &#x3D;
            sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);
        if (integerCacheHighPropValue !&#x3D; null) &#123;
            try &#123;
                int i &#x3D; parseInt(integerCacheHighPropValue);
                i &#x3D; Math.max(i, 127);
                &#x2F;&#x2F; 数组大小最大为Integer.MAX_VALUE
                h &#x3D; Math.min(i, Integer.MAX_VALUE - (-low) -1);
            &#125; catch( NumberFormatException nfe) &#123;
                &#x2F;&#x2F; 不能解析为int，忽略
            &#125;
        &#125;
        high &#x3D; h;

        cache &#x3D; new Integer[(high - low) + 1];
        int j &#x3D; low;
        for(int k &#x3D; 0; k &lt;cache.length; k++)
            cache[k] &#x3D; new Integer(j++); &#x2F;&#x2F;-128到high值逐一分配到缓存数组

        &#x2F;&#x2F; range [-128, 127] must be interned (JLS7 5.1.7)
        assert IntegerCache.high &gt;&#x3D; 127;
    &#125;

    private IntegerCache() &#123;&#125;
&#125;</code></pre>

<h2 id="6、模式总结"><a href="#6、模式总结" class="headerlink" title="6、模式总结"></a>6、模式总结</h2><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>享元模式优点就在于它能够大幅度的降低内存中对象的数量；而为了做到这一步也带来了它的缺点：它使得系统逻辑复杂化，而且在一定程度上外蕴状态影响了系统的速度。**</p>
<h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>1、当我们发现某个类型的对象有大量的实例时，我们是否可以对这些实例进行分类，经过分类后，我们发现只有很少的类别的情况下。<br>2、我们发现通过使用享元模式后能够提高系统的性能和不会带来更多的复杂度时。<br>3、享元模式一般是给出本地内存资源节省的一个方案，并不适合互联网上的分布式应用的情况，不过享元模式对于排他性的要求资源的控制，是个不错的选择的。</p>
]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（二）垃圾收集算法与收集器</title>
    <url>/article/jvm/jvm-gc/</url>
    <content><![CDATA[<p>Java 堆中几乎存放着 java 中所有的对象实例，垃圾收集器在对堆进行回收前，需要确定哪些对象还”存活”着，哪些已经“死去”。垃圾回收必须能够完成两件事情：正确检测出垃圾对象；释放垃圾对象占用的空间。</p>
<h2 id="1、垃圾检测算法"><a href="#1、垃圾检测算法" class="headerlink" title="1、垃圾检测算法"></a>1、垃圾检测算法</h2><p>当前常见的检测垃圾的方法包括两种：1. 引用计数法；2. 可达性分析算法。</p>
<h3 id="1-1-引用计数算法（Reference-Counting）"><a href="#1-1-引用计数算法（Reference-Counting）" class="headerlink" title="1.1 引用计数算法（Reference Counting）"></a>1.1 引用计数算法（Reference Counting）</h3><p>给对象添加一个引用计数器，每当该对象被引用，它的计数器值就＋ 1；当引用失效时，计数器就－1；在任何情况下，当计数器值为 0 时，就表示该对象不再被使用。<br>缺点：它很难解决对象之间相互引用，引起的循环引用问题，会产生无法被释放的内存区域。因此，主流的 JVM 都没有选用引用计数法来管理内存。</p>
<h3 id="1-2-根搜索算法（GC-Roots-Tracing）"><a href="#1-2-根搜索算法（GC-Roots-Tracing）" class="headerlink" title="1.2 根搜索算法（GC Roots Tracing）"></a>1.2 根搜索算法（GC Roots Tracing）</h3><p>主流的商用程序语言中（Java 和 C&#x3D;，甚至包括古老的 Lisp），都是使用根搜索算法来判断对象是否存活，通过一系列“GC Roots”的对象作为起始点向下搜索，搜索所走过的路径为引用链（Reference Chain），当一个对象到 GC Roots 没有任何引用链相连，则证明此对象是不可用的，如图中 object5, object6, object7 虽然会有关联，但是到 GC Roots 是不可达的，将其判定为可回收的对象。<br>在 Java 语言中，可作为 GC Roots 的对象包括以下元素：<br>虚拟机栈（栈帧中的本地变量表）中的引用的对象<br>方法区中的类静态属性引用的对象；<br>方法区中的常量引用的对象；<br>本地方法栈中 JNI 的引用的对象；<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398449290-2a85e419-5602-486d-844f-6471951360aa.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u894e24cb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=599&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=25098&status=done&style=none&taskId=u098c5cc5-19be-44e7-b748-a71594c38ac&title=" alt="image.png"><br>对于引用，我们希望能描述这样一类对象：当在内存还足够的时候，能保存在内存之中；如果内存在进行垃圾收集后还是非常紧张，则可抛弃这些对象，很多系统的缓存功能都符合这样的应用场景。从 JDK1.2 版本开始，把对象的引用分为四种级别，从而使程序能更加灵活的控制对象的生命周期，这四种级别由高到低依次为：强引用（StrongReference）、软引用（SoftReference）、弱引用（WeakReference）和虚引用（PhantomReference）。</p>
<h2 id="2、垃圾收集算法"><a href="#2、垃圾收集算法" class="headerlink" title="2、垃圾收集算法"></a>2、垃圾收集算法</h2><p>由于垃圾收集算法的实现涉及到大量的程序细节，而且各个平台的虚拟机操作内存的方法又各不同，下面只是介绍几种算法的思想及发展过程。</p>
<h3 id="2-1-标记-清除算法"><a href="#2-1-标记-清除算法" class="headerlink" title="2.1 标记-清除算法"></a>2.1 标记-清除算法</h3><p>该垃圾收集算法主要分成”标记“和”清除“两个阶段：首先标记出所有需要回收的对象，而后在标记完成后统一回收所有被标记的对象。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398449287-f0c7b499-37f6-4058-870a-7809a7671e19.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u31cd5304&margin=%5Bobject%20Object%5D&name=image.png&originHeight=408&originWidth=623&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=14725&status=done&style=none&taskId=u0928d8da-e4f7-4993-a972-a35bc20fd7e&title=" alt="image.png"><br>缺点：1. 效率问题，标记和清除两个过程的效率都不高；2. 空间碎片问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一个垃圾回收动作。</p>
<h3 id="2-2-复制算法"><a href="#2-2-复制算法" class="headerlink" title="2.2 复制算法"></a>2.2 复制算法</h3><p>为了解决标记－清除存在的效率问题，复制算法将内存划分为相等的两块，每次只使用其中一块。当这一块内存用完时，就将还存活的对象复制到另一块上面，然后将已经使用过的内存空间一次清理掉。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398449297-41fb97ca-9631-4bfd-843d-f47e513c9b8d.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u850af66c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=398&originWidth=625&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=15314&status=done&style=none&taskId=u5c6754f6-71c8-445f-8e36-46d0d4e1136&title=" alt="image.png"><br>Survivor 上的垃圾回收是这种算法，新生代中的 Eden 和 Survivor 的默认比例是 8:1，所有只有 10%的空间是会被“浪费“的。<br>缺点：将内存缩小为了原来的一半，对内存空间耗费较大。在对象存活率较高时，需要进行多次复制操作，效率会变低。</p>
<h3 id="2-3-标记-整理算法"><a href="#2-3-标记-整理算法" class="headerlink" title="2.3 标记-整理算法"></a>2.3 标记-整理算法</h3><p>将原有标记－清除算法进行改造，不是直接对可回收对象进行清理，而是让所有存活对象都向另一端移动，然后直接清理掉端边界以外的内存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398449312-5eb0eb55-08df-469f-99d6-be78441d54d5.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8adf4df8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=409&originWidth=636&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=14587&status=done&style=none&taskId=uab464f5b-8d98-44ea-9852-b7d514d747f&title=" alt="image.png"></p>
<h3 id="2-4-分代收集算法"><a href="#2-4-分代收集算法" class="headerlink" title="2.4 分代收集算法"></a>2.4 分代收集算法</h3><p>当前商业虚拟机的垃圾回收器采用“分代回收”（Generation Collection）算法，根据对象的存活周期的不同将内存划分成几块，一般把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。<br>在新生代，每次垃圾收集器都发现有大批对象死去，只有少量存活，采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集；而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须“标记－清除”或者“标记－整理”算法进行回收。<br>新创建的对象被分配在新生代，如果对象经过几次回收后仍然存活，那么就把这个对象划分到老年代。老年代的收集频度不象年轻代那么频繁，这样就减少了每次垃圾回收所需要扫描的对象，从而提高了垃圾回收效率。<br>JVM 将整个堆划分为 Young 区、Old 区和 Perm 区，分别存放不同年龄的对象，这三个区存放的对象有如下区别：</p>
<ol>
<li>Young 区分为 Eden 区和两个相同大小的 Survivor 区，其中所有新创建的对象都分配在 Eden 区域中，当 Eden 区域满后会触发 minor GC 将 Eden 区仍然存活的对象复制到其中一个 Survivor 区域中，另外一个 Survivor 区中的存活对象也复制到这个 Survivor 区域中，并始终保持一个 Survivor 区时空的。一般建议 Young 区地大小为整个堆的 1&#x2F;4。</li>
<li>Old 区存放 Young 区 Survivor 满后触发 minor GC 后仍然存活的对象，当 Eden 区满后会将存活的对象放入 Survivor 区域，如果 Survivor 区存不下这些对象，GC 收集器就会将这些对象直接存放到 Old 区中，如果 Survivor 区中的对象足够老，也直接存放到 Old 区中。如果 Old 区满了，将会触发 Full GC 回收整个堆内存。</li>
<li>Perm 区主要存放类的 Class 对象和常量，如果类不停地动态加载，也会导致 Perm 区满。Perm 区地垃圾回收也是有 Full GC 触发地。</li>
</ol>
<h2 id="3、垃圾收集器"><a href="#3、垃圾收集器" class="headerlink" title="3、垃圾收集器"></a>3、垃圾收集器</h2><p>如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图列出了 HotSpot 虚拟机的垃圾收集器，两个垃圾器之间存在连线，就说明它们可以搭配使用。新生代的垃圾回收器包括 Serial、ParNew、Parallel Scavenge，老年代的垃圾回收器包括 CMS、Serial Old、Parallel Old。其中新生代的三种垃圾回收器都采用了复制算法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398449333-444cec4d-56f7-4db7-a1c3-37967dfef324.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ubd0126a3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=404&originWidth=664&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=28776&status=done&style=none&taskId=u708367bb-e42e-4436-824c-f878c7d11a5&title=" alt="image.png"></p>
<h3 id="3-1-Serial-收集器"><a href="#3-1-Serial-收集器" class="headerlink" title="3.1 Serial 收集器"></a>3.1 Serial 收集器</h3><p>Serial 收集器是一个单线程收集器，这个“单线程”不只是说它只会使用一个 CPU 或者一条线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，必须暂停其他所有的工作线程，直到它垃圾收集结束。它对于运行在 client 模式下的虚拟机来说是一个不错的选择<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398450742-0affb50d-4070-4d61-a1ac-a257cd2363ec.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uac1df451&margin=%5Bobject%20Object%5D&name=image.png&originHeight=315&originWidth=940&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33333&status=done&style=none&taskId=u6efeb708-bc0d-46f2-b018-c880e31e9aa&title=" alt="image.png"></p>
<h3 id="3-2-ParNew-收集器"><a href="#3-2-ParNew-收集器" class="headerlink" title="3.2 ParNew 收集器"></a>3.2 ParNew 收集器</h3><p>ParNew 收集器其实就是 Serial 收集器的多线程版本，由于除了 Serial 收集器外，只有它能够与 CMS 收集器配合工作，因此，在运行在 Server 模式下的虚拟机中，ParNew 收集器是首选的新生代收集器。<br>ParNew 收集器是使用-XX:+UseConcMarkSweepGC 选项后的默认新生代收集器，也可以使用-XX:+UseParNewGC 强制指定。使用-XX:ParallelGCThreads 可以限制垃圾收集的线程数。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398450754-4548ac5d-ab02-43d7-80f2-05f9a1972964.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8b9d874e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=343&originWidth=952&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=37263&status=done&style=none&taskId=u7bd0ea3d-c6cc-47d9-951a-e5f8fe9f598&title=" alt="image.png"></p>
<h3 id="3-3-Parallel-Scavenge-收集器"><a href="#3-3-Parallel-Scavenge-收集器" class="headerlink" title="3.3 Parallel Scavenge 收集器"></a>3.3 Parallel Scavenge 收集器</h3><p>这也是一个并行的新生代垃圾收集器，不同于其他收集器（以尽可能缩短垃圾收集时用户线程的停顿时间为目的），它是唯一一个以达到一个可控制的吞吐量为目标的垃圾收集器。<br>throughput &#x3D; 运行用户代码的时间 &#x2F; 总时间（垃圾收集时间＋运行用户代码的时间）。<br>在后台运算的任务中，不需要太多的交互，保证运行的高吞吐量可以高效地利用 CPU 时间，尽快完成程序的运算任务。<br>Parallel Scavenge 收集器可以使用自适应调节策略，使用-XX:+UserAdaptiveSizePolicy 选项之后，就不需要指定-Xmn、-XX:SurvivorRatio 等参数，虚拟机可以根据当前系统的运行情况动态收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398450836-e69959b1-ebce-4ce9-934f-2a26a8c0018f.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u344e17be&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=958&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33932&status=done&style=none&taskId=u3c2c0dc0-faf3-4417-8b20-19f21520f68&title=" alt="image.png"></p>
<h3 id="3-4-Serial-Old-收集器"><a href="#3-4-Serial-Old-收集器" class="headerlink" title="3.4 Serial Old 收集器"></a>3.4 Serial Old 收集器</h3><p>该收集器使用标记-整理算法对老年代垃圾进行回收，它主要的两大用途：1. 配合 Parallel Scavenge 收集器；2. 作为 CMS 收集器在并发收集出现 Concurrent Mode Failure 时使用的后备预案。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398450801-9fed94d2-61d7-4c76-a606-0107f4685bd4.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u07471e9c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=315&originWidth=940&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33333&status=done&style=none&taskId=uf5e62bd7-af21-4473-8d49-d1ea1c3f6a4&title=" alt="image.png"></p>
<h3 id="3-5-Parallel-Old-收集器"><a href="#3-5-Parallel-Old-收集器" class="headerlink" title="3.5 Parallel Old 收集器"></a>3.5 Parallel Old 收集器</h3><p>Parallel Old 是 Parallel Scavenge 收集器的老年代版本，使用多线程和标记整理算法。在注重吞吐量和 CPU 资源敏感的场合，优先考虑使用 Parallel Scavenge + Parallel Old 收集器的组合，切记 Parallel Scavenge 是无法与 CMS 收集器组合使用的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398450862-3f93cf54-b666-41fb-9f33-41f1d55c3045.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7d9f548d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=958&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33932&status=done&style=none&taskId=u4a24f1e5-560e-49ab-b9a1-1c3f18807fd&title=" alt="image.png"></p>
<h3 id="3-6-Concurrent-Mark-Sweep-收集器"><a href="#3-6-Concurrent-Mark-Sweep-收集器" class="headerlink" title="3.6 Concurrent Mark Sweep 收集器"></a>3.6 Concurrent Mark Sweep 收集器</h3><p>首先说明下并发与并行的却别：<br>并行：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态；<br>并发：指用户线程与垃圾收集线程同时执行。<br>CMS 收集器是一款并发收集器，是一种以获取最短回收停顿时间为目标的收集器，它是基于标记-清除算法实现的，它整个过程包含四个有效的步骤：</p>
<ol>
<li>初始标记（CMS initial mark）</li>
<li>并发标记（CMS concurrent mark）</li>
<li>重新标记（CMS remark）</li>
<li>并发清除（CMS concurrent sweep）<br>其中，初始标记、重新标记仍然需要”Stop the World”，但是它们的速度都很快。初始标记只是标记一下 GC Roots 能直接关联到的对象，速度很快，并发标记阶段就是进行 GC Roots Tracing 的过程，重新标记是为了修正并发标记期间，因用户线程继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始化标记阶段稍长一些，但远比并发标记的时间短。<br>由于整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，所以总体上来说，CMS 收集器的内存回收过程是与用户线程一起并发的执行的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398452313-537a9a19-7c00-42be-afda-f9e11f3ace2a.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u0597192c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=1038&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=41451&status=done&style=none&taskId=u013928bf-c6ab-4af8-bb14-f4f7c34e5b5&title=" alt="image.png"><br>CMS 的主要优点是并发收集、低停顿，也称之为并发收集低停顿收集器（Concurrent Low Pause Collector），其主要缺点如下：</li>
<li>CMS 收集器对 CPU 资源非常敏感，在并发阶段，它虽然不会导致用户线程停顿，但是它会占用一部分 CPU 资源进行垃圾收集从而导致应用程序变慢，总吞吐量会降低。</li>
<li>由于 CMS 并发清除阶段用户线程还在运行，伴随程序的运行必然还有的新的垃圾产生，这一部分垃圾出现在标记过程之后，CMS 无法在当次收集中处理掉它们，只好留待下一次 GC 时再进行清理。也是由于垃圾收集阶段用户线程还需要运行需要预留足够内存给用户线程使用，如果 CMS 运行期间预留内存无法满足程序需要，就会出现一次“Concurrent Mode Failure”失败，虚拟机只得临时启动 Serial Old 进行老年代垃圾收集，这样会导致长时间停顿</li>
<li>由于 CMS 是一款采用标记-清除算法实现的垃圾收集器，收集结束时会有大量的空间碎片产生，空间碎片过多时，如果分配大对象找不到足够大的连续空间分配当前对象，就不得不提前触发一次 Full GC。</li>
</ol>
<h3 id="3-7-G1-收集器"><a href="#3-7-G1-收集器" class="headerlink" title="3.7 G1 收集器"></a>3.7 G1 收集器</h3><p>G1 基于“标记-整理”算法实现，不会产生空间碎片，对于长时间运行的应用系统来说非常重要；另外它可以非常精准地控制停顿，既能让使用者指定一个长度为 M 毫秒的时间片段内，消耗在垃圾收集上的时间不得超过 N 毫秒。<br>G1 收集器可以实现在基本不牺牲吞吐的前提下完成低停顿的内存回收，这是由于它能够避免全区域的垃圾回收，而 G1 将 Java 堆（包括新生代、老生代）划分成多个大小固定的独立区域，并且跟踪这些区域里面的垃圾堆积程度，在后台维护一个优先列表，每次根据允许的收集时间，优先回收垃圾最多的区域（这就是 Garbage First 名称的由来）。</p>
<h2 id="4、垃圾收集器参数总结"><a href="#4、垃圾收集器参数总结" class="headerlink" title="4、垃圾收集器参数总结"></a>4、垃圾收集器参数总结</h2><h3 id="4-1-垃圾收集器设置的相关选项"><a href="#4-1-垃圾收集器设置的相关选项" class="headerlink" title="4. 1 垃圾收集器设置的相关选项"></a>4. 1 垃圾收集器设置的相关选项</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398452328-00cc519f-15d0-4fea-b3e1-6558435190bd.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u07fe99e2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=278&originWidth=661&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=35046&status=done&style=none&taskId=u5e1b245c-d160-4eec-9596-59060485eff&title=" alt="image.png"></p>
<h3 id="4-2-垃圾收集器设置的相关参数"><a href="#4-2-垃圾收集器设置的相关参数" class="headerlink" title="4.2 垃圾收集器设置的相关参数"></a>4.2 垃圾收集器设置的相关参数</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398452362-5713494e-b62d-4ee6-89d4-cdec0b5d7141.png#clientId=u32559f0f-68af-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u44f63282&margin=%5Bobject%20Object%5D&name=image.png&originHeight=449&originWidth=866&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=67872&status=done&style=none&taskId=uecd940f8-7a22-435a-9525-eecda0039e7&title=" alt="image.png"></p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（六）虚拟机类加载委派模型</title>
    <url>/article/jvm/jvm-classloader-delegate/</url>
    <content><![CDATA[<h2 id="双亲委派模型"><a href="#双亲委派模型" class="headerlink" title="双亲委派模型"></a>双亲委派模型</h2><p>当一个类装载器（class loader）被请求装载类时，它首先按照顺序在上层装载器、父装载器以及自身的装载器的缓存里检查这个类是否已经存在。简单来说，就是在缓存里查看这个类是否已经被自己装载过了，如果没有的话，继续查找父类的缓存，直到在 bootstrap 类装载器里也没有找到的话，它就会自己在文件系统里去查找并且加载这个类。<br>ClassLoader 的 loadClass 方法</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected Class&lt;?&gt; loadClass(String name, boolean resolve)
            throws ClassNotFoundException &#123;
    synchronized (getClassLoadingLock(name)) &#123;
        &#x2F;&#x2F; First, check if the class has already been loaded
        Class&lt;?&gt; c &#x3D; findLoadedClass(name);
        if (c &#x3D;&#x3D; null) &#123;
            long t0 &#x3D; System.nanoTime();
            try &#123;
                if (parent !&#x3D; null) &#123;
                    c &#x3D; parent.loadClass(name, false);
                &#125; else &#123;
                    c &#x3D; findBootstrapClassOrNull(name);
                &#125;
            &#125; catch (ClassNotFoundException e) &#123;
                &#x2F;&#x2F; ClassNotFoundException thrown if class not found
                &#x2F;&#x2F; from the non-null parent class loader
            &#125;

            if (c &#x3D;&#x3D; null) &#123;
                &#x2F;&#x2F; If still not found, then invoke findClass in order
                &#x2F;&#x2F; to find the class.
                long t1 &#x3D; System.nanoTime();
                c &#x3D; findClass(name);
                &#x2F;&#x2F; this is the defining class loader; record the stats
                sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);
                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);
                sun.misc.PerfCounter.getFindClasses().increment();
            &#125;
        &#125;
        if (resolve) &#123;
            resolveClass(c);
        &#125;
        return c;
    &#125;
&#125;</code></pre>

<p>1）先找缓存（findLoadedClass），没有的话就判断有没有 parent，有的话就用 parent 来递归的 loadClass，然而 ExtClassLoader 并没有设置 parent，则会通过 findBootstrapClassOrNull 来加载 class，而 findBootstrapClassOrNull 则会通过 JNI 方法“private native Class findBootstrapClass(String name)“来使用 BootStrapClassLoader 来加载 class。<br>2）然后如果 parent 未找到 class，则会调用 findClass 来加载 class，findClass 是一个 protected 的空方法，可以覆盖它以便自定义 class 加载过程。另外，虽然 ClassLoader 加载类是使用 loadClass 方法，<strong>但是鼓励用 ClassLoader 的子类重写 findClass(String)，而不是重写 loadClass</strong>，这样就不会覆盖了类加载默认的双亲委派机制。<br>双亲委派模型有一个缺陷，如果父 ClassLoader 想加载子 ClassLoader 中的类比较困难，而在有的应用中这种加载方式是需要的，比如 JNDI,Servlet 等。</p>
<h2 id="破坏双亲委派模型"><a href="#破坏双亲委派模型" class="headerlink" title="破坏双亲委派模型"></a>破坏双亲委派模型</h2><p>1） JDK1.2 java.lang.ClassLoader 提供新的 protected 方法 findClass()和 public 方法 loadClass()，来实现自定义类加载和破坏委派模型。<br>2）JDK1.3 使用线程上下文（ThreadContextClassLoader）解决让父类加载器请求子类完成类的加载，例如 JNDI，JDBC，JCE，JAXB，以及应用服务器 Tocmat 等<br>3）OSGi，代码热替换（HotSwap），代码热部署（HotDeployment）<br>关于 JDBC 的 SPI 加载，可参照 ServiceLoader 深入解析，本文主要讲解下 jetty 的类加载机制。<br>Jetty 的 ClassLoader 体系结构如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648399628171-785f1ba4-e962-4d19-ae98-ca31a4cc8ce3.png#clientId=u48792fe7-b3c5-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u272e4341&margin=%5Bobject%20Object%5D&name=image.png&originHeight=463&originWidth=574&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=25025&status=done&style=none&taskId=ub33bb7ca-0d15-4681-bd85-318ee1778ba&title=" alt="image.png"><br>Jetty 有两种运行方式，一种进程内运行(通过反射执行 MainClass),一种是进程外执行 ( 通过 Runtime.getRuntime().exec()), 进程外执行时由于线程上下文不能进程之间传递。<br>Jetty 至少要保证其内部运行的多个 webapp 之间私有的类库不受影响，并且公有的类库可以共享。Jetty 中有一个 org.mortbay.jetty.webapp.WebAppClassLoader，负责加载一个 webapp context 中的应用类，WebAppClassLoader 以系统类加载器作为 parent，用于加载系统类。不过 servlet 规范使得 web 容器的 ClassLoader 比正常的 ClassLoader 委托模型稍稍复杂，Servlet 规范要求：<br>1）WEB-INF&#x2F;lib 和 WEB-INF&#x2F;classes 优先于父容器中的类加载，比如 WEB-INF&#x2F;classes 下有个 XYZ 类，classpath 下也有个 XYZ 类，jetty 中优先加载的是 WEB-INF&#x2F;classes 下的，这与正常的父加载器优先相反(child-first)。<br>2）系统类比如 java.lang.String 不遵循第一条，WEB-INF&#x2F;classes 或 WEB-INF&#x2F;lib 下的类不能替换系统类。不过规范中没有明确规定哪些是系统类，jetty 中的实现是按照类的全路径名判断。<br>3）Server 的实现类不被应用中的类引用，即 Server 的实现类不能被任何应用类加载器加载。不过，同样的，规范里没有明确规定哪些是 Server 的实现类，jetty 中同样是按照类的全路径名判断。<br>为了处理上述三个问题，jetty 的应用类加载器(org.mortbay.jetty.webapp.WebAppClassLoader)做了些特殊处理。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public WebAppClassLoader(ClassLoader parent, Context context)
        throws IOException &#123;
    super(new URL[] &#123;&#125;, parent !&#x3D; null ? parent
            : (Thread.currentThread().getContextClassLoader() !&#x3D; null ? Thread.currentThread().getContextClassLoader()
            : (WebAppClassLoader.class.getClassLoader() !&#x3D; null ? WebAppClassLoader.class.getClassLoader()
            : ClassLoader.getSystemClassLoader())));
    _parent &#x3D; getParent();
    _context &#x3D; context;
    if (_parent &#x3D;&#x3D; null)
        throw new IllegalArgumentException(&quot;no parent classloader!&quot;);

    _extensions.add(&quot;.jar&quot;);
    _extensions.add(&quot;.zip&quot;);

    &#x2F;&#x2F; TODO remove this system property
    String extensions &#x3D; System.getProperty(WebAppClassLoader.class.getName() + &quot;.extensions&quot;);
    if (extensions !&#x3D; null) &#123;
        StringTokenizer tokenizer &#x3D; new StringTokenizer(extensions, &quot;,;&quot;);
        while (tokenizer.hasMoreTokens())
            _extensions.add(tokenizer.nextToken().trim());
    &#125;
    if (context.getExtraClasspath() !&#x3D; null)
        addClassPath(context.getExtraClasspath());
&#125;</code></pre>

<p>他是以当前线程上下文的 ClassLoader 为父 classloader, 如果上下文没有设定 classLoader ，就使用加载 WebAppClassLoader 的加载器，如果还是没有，则采用系统类加载器。很明显，默认情况下，如果采用进程内运行，那么这个 parent 就是 Loader( 系统自定义类加载器 ) ，如果是进程外， parent 就是系统类加载器。<br>WebAppClassLoader 可以设定是否由 parent 优先加载 lib&#x2F; 、 classes 下的类。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123;
    Class&lt;?&gt; c &#x3D; findLoadedClass(name);
    ClassNotFoundException ex &#x3D; null;
    boolean tried_parent &#x3D; false;

    boolean system_class &#x3D; _context.isSystemClass(name);
    boolean server_class &#x3D; _context.isServerClass(name);

    if (system_class &amp;&amp; server_class) &#123;
        return null;
    &#125;

    if (c &#x3D;&#x3D; null &amp;&amp; _parent !&#x3D; null &amp;&amp; (_context.isParentLoaderPriority() || system_class) &amp;&amp; !server_class) &#123;
        tried_parent &#x3D; true;
        try &#123;
            c &#x3D; _parent.loadClass(name);
            if (LOG.isDebugEnabled())
                LOG.debug(&quot;loaded &quot; + c);
        &#125;
        catch (ClassNotFoundException e) &#123;
            ex &#x3D; e;
        &#125;
    &#125;

    if (c &#x3D;&#x3D; null) &#123;
        try &#123;
            c &#x3D; this.findClass(name);
        &#125;
        catch (ClassNotFoundException e) &#123;
            ex &#x3D; e;
        &#125;
    &#125;

    if (c &#x3D;&#x3D; null &amp;&amp; _parent !&#x3D; null &amp;&amp; !tried_parent &amp;&amp; !server_class)
        c &#x3D; _parent.loadClass(name);

    if (c &#x3D;&#x3D; null &amp;&amp; ex !&#x3D; null)
        throw ex;

    if (resolve)
        resolveClass(c);

    if (LOG.isDebugEnabled())
        LOG.debug(&quot;loaded &#123;&#125; from &#123;&#125;&quot;, c, c &#x3D;&#x3D; null ? null : c.getClassLoader());

    return c;
&#125;</code></pre>

<p>findLoadedClass(name)-检查类是否已经加载<br>1）判断该类是否为系统类或 server 类<br>2）如果该类未加载且父加载器不为空且设置了父加载器优先或类类为系统类，且该类不是 server 类，则尝试使用父加载器加载该类<br>3）如果不是父加载器优先或者父加载器未加载到该类，使用 WebAppClassLoader 加载该类<br>4）如果是不是父加载器优先，并且 WebAppClassLoader 未加载到该类，尝试使用父加载器加载该类<br>5）找到则返回，否则抛出 ClassNotFoundException<br>再看下 findClass 方法</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected Class&lt;?&gt; findClass(final String name) throws ClassNotFoundException &#123;
    Class&lt;?&gt; clazz &#x3D; null;

    if (_transformers.isEmpty())
        clazz &#x3D; super.findClass(name);
    else &#123;
        String path &#x3D; name.replace(&#39;.&#39;, &#39;&#x2F;&#39;).concat(&quot;.class&quot;);
        URL url &#x3D; getResource(path);
        if (url &#x3D;&#x3D; null)
            throw new ClassNotFoundException(name);

        InputStream content &#x3D; null;
        try &#123;
            content &#x3D; url.openStream();
            byte[] bytes &#x3D; IO.readBytes(content);

            for (ClassFileTransformer transformer : _transformers) &#123;
                byte[] tmp &#x3D; transformer.transform(this, name, null, null, bytes);
                if (tmp !&#x3D; null)
                    bytes &#x3D; tmp;
            &#125;

            clazz &#x3D; defineClass(name, bytes, 0, bytes.length);
        &#125;
        catch (IOException e) &#123;
            throw new ClassNotFoundException(name, e);
        &#125;
        catch (IllegalClassFormatException e) &#123;
            throw new ClassNotFoundException(name, e);
        &#125;
        finally &#123;
            if (content !&#x3D; null) &#123;
                try &#123;
                    content.close();
                &#125;
                catch (IOException e) &#123;
                    throw new ClassNotFoundException(name, e);
                &#125;
            &#125;
        &#125;
    &#125;

    return clazz;
&#125;</code></pre>

<p>_transformers 为空调用父类的 findClass，不为空找到对应的类文件对其进行转换。</p>
<h3 id="1、设置-ClassLoader-Priority"><a href="#1、设置-ClassLoader-Priority" class="headerlink" title="1、设置 ClassLoader Priority"></a>1、设置 ClassLoader Priority</h3><p>上述过程涉及一个加载器优先级的概念，这也是针对前述第一条规范中 WEB-INF&#x2F;lib 和 WEB-INF&#x2F;classes 类优先的处理。jetty 中父加载器优先的配置项可以通过环境变量<br>org.eclipse.jetty.server.webapp.parentLoaderPriority&#x3D;false(默认)&#x2F;true 来设置<br>也可以通过<br>org.eclipse.jetty.webapp.WebAppContext.setParentLoaderPriority(boolean)方法来设置<br>优于该<strong>配置默认是 false</strong>，因此在 load class 过程中优先使用 WebAppClassLoader 加载 WEB-INF&#x2F;lib 和 WEB-INF&#x2F;classes 中的类。<strong>当将该配置项设为 true 时需要确认类加载顺序没有问题</strong>。</p>
<h3 id="2、设置系统类"><a href="#2、设置系统类" class="headerlink" title="2、设置系统类"></a>2、设置系统类</h3><p>规范 2 中约定系统类不能被应用类覆盖，但是没有明确规定哪些时系统类，jetty 中以类的 package 路径名来区分，当类的 package 路径名位包含于</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; System classes are classes that cannot be replaced by
&#x2F;&#x2F; the web application, and they are *always* loaded via
&#x2F;&#x2F; system classloader.
public final static String[] __dftSystemClasses &#x3D;
&#123;
       &quot;java.&quot;,                            &#x2F;&#x2F; Java SE classes (per servlet spec v2.5 &#x2F; SRV.9.7.2)
       &quot;javax.&quot;,                           &#x2F;&#x2F; Java SE classes (per servlet spec v2.5 &#x2F; SRV.9.7.2)
       &quot;org.xml.&quot;,                         &#x2F;&#x2F; needed by javax.xml
       &quot;org.w3c.&quot;,                         &#x2F;&#x2F; needed by javax.xml
       &quot;org.eclipse.jetty.jmx.&quot;,           &#x2F;&#x2F; webapp cannot change jmx classes
       &quot;org.eclipse.jetty.util.annotation.&quot;,  &#x2F;&#x2F; webapp cannot change jmx annotations
       &quot;org.eclipse.jetty.continuation.&quot;,  &#x2F;&#x2F; webapp cannot change continuation classes
       &quot;org.eclipse.jetty.jndi.&quot;,          &#x2F;&#x2F; webapp cannot change naming classes
       &quot;org.eclipse.jetty.jaas.&quot;,          &#x2F;&#x2F; webapp cannot change jaas classes
       &quot;org.eclipse.jetty.websocket.&quot;,     &#x2F;&#x2F; webapp cannot change &#x2F; replace websocket classes
       &quot;org.eclipse.jetty.util.log.&quot;,      &#x2F;&#x2F; webapp should use server log
       &quot;org.eclipse.jetty.servlet.ServletContextHandler.Decorator&quot;, &#x2F;&#x2F; for CDI &#x2F; weld use
       &quot;org.eclipse.jetty.servlet.DefaultServlet&quot;, &#x2F;&#x2F; webapp cannot change default servlets
       &quot;org.eclipse.jetty.jsp.JettyJspServlet&quot;, &#x2F;&#x2F;webapp cannot change jetty jsp servlet
       &quot;org.eclipse.jetty.servlets.AsyncGzipFilter&quot; &#x2F;&#x2F; special case for AsyncGzipFilter
&#125; ;</code></pre>

<p>时，会被认为是系统类。（该定义位于 WebAppContext 中）<br>因此，我们可以通过 org.eclipse.jetty.webapp.WebAppContext.setSystemClasses(String Array)或者 org.eclipse.jetty.webapp.WebAppContext.addSystemClass(String)来设置系统类。 再次提醒，系统类是对多有应用都可见。</p>
<h3 id="3、设置-Server-类"><a href="#3、设置-Server-类" class="headerlink" title="3、设置 Server 类"></a>3、设置 Server 类</h3><p>规范 3 中约定 Server 类不对任何应用可见。jetty 同样是用 package 路径名来区分哪些是 Server 类。Server 类包括：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; Server classes are classes that are hidden from being
&#x2F;&#x2F; loaded by the web application using system classloader,
&#x2F;&#x2F; so if web application needs to load any of such classes,
&#x2F;&#x2F; it has to include them in its distribution.
public final static String[] __dftServerClasses &#x3D;
&#123;
       &quot;-org.eclipse.jetty.jmx.&quot;,          &#x2F;&#x2F; don&#39;t hide jmx classes
       &quot;-org.eclipse.jetty.util.annotation.&quot;, &#x2F;&#x2F; don&#39;t hide jmx annotation
       &quot;-org.eclipse.jetty.continuation.&quot;, &#x2F;&#x2F; don&#39;t hide continuation classes
       &quot;-org.eclipse.jetty.jndi.&quot;,         &#x2F;&#x2F; don&#39;t hide naming classes
       &quot;-org.eclipse.jetty.jaas.&quot;,         &#x2F;&#x2F; don&#39;t hide jaas classes
       &quot;-org.eclipse.jetty.servlets.&quot;,     &#x2F;&#x2F; don&#39;t hide jetty servlets
       &quot;-org.eclipse.jetty.servlet.DefaultServlet&quot;, &#x2F;&#x2F; don&#39;t hide default servlet
       &quot;-org.eclipse.jetty.jsp.&quot;,          &#x2F;&#x2F;don&#39;t hide jsp servlet
       &quot;-org.eclipse.jetty.servlet.listener.&quot;, &#x2F;&#x2F; don&#39;t hide useful listeners
       &quot;-org.eclipse.jetty.websocket.&quot;,    &#x2F;&#x2F; don&#39;t hide websocket classes from webapps (allow webapp to use ones from system classloader)
       &quot;-org.eclipse.jetty.apache.&quot;,       &#x2F;&#x2F; don&#39;t hide jetty apache impls
       &quot;-org.eclipse.jetty.util.log.&quot;,     &#x2F;&#x2F; don&#39;t hide server log
       &quot;-org.eclipse.jetty.servlet.ServletContextHandler.Decorator&quot;, &#x2F;&#x2F; don&#39;t hide CDI &#x2F; weld interface
       &quot;org.objectweb.asm.&quot;,               &#x2F;&#x2F; hide asm used by jetty
       &quot;org.eclipse.jdt.&quot;,                 &#x2F;&#x2F; hide jdt used by jetty
       &quot;org.eclipse.jetty.&quot;                &#x2F;&#x2F; hide other jetty classes
&#125; ;</code></pre>

<p>我们可以通过， org.eclipse.jetty.webapp.WebAppContext.setServerClasses(String Array) 或 org.eclipse.jetty.webapp.WebAppContext.addServerClass(String)方法设置 Server 类。 注意，Server 类是对所有应用都不可见的，但是 WEB-INF&#x2F;lib 下的类可以替换 Server 类。<br>当默认的 WebAppClassLoader 不能满足需求时，可以自定义 WebApp ClassLoader，不过 jetty 建议自定义的 classloader 要扩展于默认的 WebAppClassLoader 实现。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（五）虚拟机类加载机制</title>
    <url>/article/jvm/jvm-classloader/</url>
    <content><![CDATA[<p>Java 提供了动态的装载特性；它会在运行时的第一次引用到一个 class 的时候对它进行装载和链接，而不是在编译期进行。JVM 的类装载器负责动态装载，基本上所有的类加载器都是 java.lang.ClassLoader 类的一个实例。</p>
<h2 id="Java-类装载器"><a href="#Java-类装载器" class="headerlink" title="Java 类装载器"></a>Java 类装载器</h2><p>有如下几个特点：</p>
<ul>
<li><strong>层级结构</strong>：Java 里的类装载器被组织成了有父子关系的层级结构。Bootstrap 类装载器是所有装载器的父亲。</li>
<li><strong>代理模式</strong>：基于层级结构，类的装载可以在装载器之间进行代理。当装载器装载一个类时，首先会检查它是否在父装载器中进行装载了。如果上层的装载器已经装载了这个类，这个类会被直接使用。反之，类装载器会请求装载这个类。</li>
<li><strong>可见性限制</strong>：一个子装载器可以查找父装载器中的类，但是一个父装载器不能查找子装载器里的类。</li>
<li><strong>不允许卸载</strong>：类装载器可以装载一个类但是不可以卸载它，不过可以删除当前的类装载器，然后创建一个新的类装载器。</li>
</ul>
<p>每个类装载器都有一个自己的命名空间用来保存已装载的类。当一个类装载器装载一个类时，它会通过保存在命名空间里的类全局限定名(Fully Qualified Class Name)进行搜索来检测这个类是否已经被加载了。如果两个类的全局限定名是一样的，但是如果命名空间不一样的话，那么它们还是不同的类。不同的命名空间表示 class 被不同的类装载器装载。<br>目前 Java 类装载器的代理模型如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648399366418-3969f698-05c9-4cff-add1-293b1155152d.png#clientId=u306ac21e-5323-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ubed89250&margin=%5Bobject%20Object%5D&name=image.png&originHeight=386&originWidth=462&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=16966&status=done&style=none&taskId=u223acd15-5d93-4b1c-ae01-9341960c4b0&title=" alt="image.png"><br>当一个类装载器<strong>（class loader）</strong>被请求装载类时，它首先按照顺序在上层装载器、父装载器以及自身的装载器的缓存里检查这个类是否已经存在。简单来说，就是在缓存里查看这个类是否已经被自己装载过了，如果没有的话，继续查找父类的缓存，直到在 bootstrap 类装载器里也没有找到的话，它就会自己在文件系统里去查找并且加载这个类。</p>
<ul>
<li><strong>启动类加载器（Bootstrap ClassLoader）</strong>: 这个类装载器是在 JVM 启动的时候创建的。用于加载 $JAVA_HOME&#x2F;jre&#x2F;lib 下面的类库（或者通过参数-Xbootclasspath 指定），由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不能直接通过引用进行操作。</li>
<li><strong>扩展类加载器（ExtClassLoader）</strong>: 它装载除了基本的 Java API 以外的扩展类。它也负责装载其他的安全扩展功能。在 sun.misc.Launcher 里作为一个内部类 ExtClassLoader 定义的（即 sun.misc.Launcher$ExtClassLoader），ExtClassLoader 会加载 $JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext 下的类库（或者通过参数-Djava.ext.dirs 指定）。</li>
<li><strong>系统类加载器（AppClassloader）</strong>: 如果说 bootstrap class loader 和 extension class loader 负责加载的是 JVM 的组件，那么 system class loader 负责加载的是应用程序类。它负责加载用户在$CLASSPATH里指定的类，是在sun.misc.Launcher里作为一个内部类AppClassLoader定义的（即 sun.misc.Launcher$AppClassLoader），AppClassLoader 会加载 java 环境变量 CLASSPATH 所指定的路径下的类库，而 CLASSPATH 所指定的路径可以通过 System.getProperty(“java.class.path”)获取；当然，该变量也可以覆盖，可以使用参数-cp，例如：java -cp 路径 （可以指定要执行的 class 目录）。</li>
<li><strong>用户自定义类加载器（UserDefined ClassLoader）</strong>: 这是应用程序开发者用直接用代码实现的类装载器。比如 tomcat 的 StandardClassLoader 属于这一类；当然，大部分情况下使用 AppClassLoader 就足够了。</li>
</ul>
<p>如果类装载器查找到一个没有装载的类，它会按照下图的流程来装载和链接这个类：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648399366431-5776227c-885b-4b1a-98a0-30342d03a183.png#clientId=u306ac21e-5323-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3de9051c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=322&originWidth=584&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=23564&status=done&style=none&taskId=ucb17e3d8-fa5e-4875-932d-82e7c9904d7&title=" alt="image.png"></p>
<h2 id="类装载器阶段"><a href="#类装载器阶段" class="headerlink" title="类装载器阶段"></a>类装载器阶段</h2><p>各阶段描述如下：<br>**Loading: **类的信息从文件中获取并且载入到 JVM 的内存里。<br>**Verifying:**检查读入的结构是否符合 Java 语言规范以及 JVM 规范的描述。这是类装载中最复杂的过程，并且花费的时间也是最长的。并且 JVM TCK 工具的大部分场景的用例也用来测试在装载错误的类的时候是否会出现错误。<br>**Preparing:**分配一个结构用来存储类信息，这个结构中包含了类中定义的成员变量，方法和接口的信息。<br>**Resolving:**把这个类的常量池中的所有的符号引用改变成直接引用。<br>**Initializing:**把类中的变量初始化成合适的值。执行静态初始化程序，把静态变量初始化成指定的值。<br>JVM 规范定义了上面的几个任务，不过它允许具体执行的时候能够有些灵活的变动。</p>
<h2 id="ClassLoader-加载原理"><a href="#ClassLoader-加载原理" class="headerlink" title="ClassLoader 加载原理"></a>ClassLoader 加载原理</h2><p>下面贴下 jdk 关于类加载的源码，上述四种类加载器中 CustomClassLoader 是用户自定义的，BootStrapClassLoader 是 jvm 创建的，就不展示了；这里展示下 AppClassLoader 和 ExtClassLoader 的启动过程，前面介绍过，AppClassLoader 和 ExtClassLoader 都是在 sun.misc.Launcher 里定义的，大家可以下载 openjdk 来查看。</p>
<h3 id="1、Launcher-初始化"><a href="#1、Launcher-初始化" class="headerlink" title="1、Launcher 初始化"></a>1、Launcher 初始化</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Launcher() &#123;
    &#x2F;&#x2F; Create the extension class loader
    ClassLoader extcl;
    try &#123;
        extcl &#x3D; ExtClassLoader.getExtClassLoader();
    &#125; catch (IOException e) &#123;
        throw new InternalError(
            &quot;Could not create extension class loader&quot;, e);
    &#125;

    &#x2F;&#x2F; Now create the class loader to use to launch the application
    try &#123;
        loader &#x3D; AppClassLoader.getAppClassLoader(extcl);
    &#125; catch (IOException e) &#123;
        throw new InternalError(
            &quot;Could not create application class loader&quot;, e);
    &#125;

    &#x2F;&#x2F; Also set the context class loader for the primordial thread.
    Thread.currentThread().setContextClassLoader(loader);

    &#x2F;&#x2F; Finally, install a security manager if requested
    String s &#x3D; System.getProperty(&quot;java.security.manager&quot;);
    if (s !&#x3D; null) &#123;
        SecurityManager sm &#x3D; null;
        if (&quot;&quot;.equals(s) || &quot;default&quot;.equals(s)) &#123;
            sm &#x3D; new java.lang.SecurityManager();
        &#125; else &#123;
            try &#123;
                sm &#x3D; (SecurityManager)loader.loadClass(s).newInstance();
            &#125; catch (IllegalAccessException e) &#123;
            &#125; catch (InstantiationException e) &#123;
            &#125; catch (ClassNotFoundException e) &#123;
            &#125; catch (ClassCastException e) &#123;
            &#125;
        &#125;
        if (sm !&#x3D; null) &#123;
            System.setSecurityManager(sm);
        &#125; else &#123;
            throw new InternalError(
                &quot;Could not create SecurityManager: &quot; + s);
        &#125;
    &#125;
&#125;</code></pre>

<p>1）通过 ExtClassLoader.getExtClassLoader()创建了 ExtClassLoader；<br>2）通过 AppClassLoader.getAppClassLoader(ExtClassLoader)创建了 AppClassLoader，并将 ExtClassLoader 设为 AppClassLoader 的 parent ClassLoader；<br>3）通过 Thread.currentThread().setContextClassLoader(loader)把 AppClassLoader 设为线程的上下文 ClassLoader；<br>4）根据 jvm 参数-Djava.security.manager 创建安全管理器，”java.security.manager”默认系统属性为空字符串””。</p>
<h3 id="2、ExtClassLoader-初始化过程"><a href="#2、ExtClassLoader-初始化过程" class="headerlink" title="2、ExtClassLoader 初始化过程"></a>2、ExtClassLoader 初始化过程</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;*
 * The class loader used for loading installed extensions.
 *&#x2F;
static class ExtClassLoader extends URLClassLoader &#123;

    static &#123;
        ClassLoader.registerAsParallelCapable();
    &#125;

    &#x2F;**
     * create an ExtClassLoader. The ExtClassLoader is created
     * within a context that limits which files it can read
     *&#x2F;
    public static ExtClassLoader getExtClassLoader() throws IOException
    &#123;
        final File[] dirs &#x3D; getExtDirs();

        try &#123;
            &#x2F;&#x2F; Prior implementations of this doPrivileged() block supplied
            &#x2F;&#x2F; aa synthesized ACC via a call to the private method
            &#x2F;&#x2F; ExtClassLoader.getContext().

            return AccessController.doPrivileged(
                new PrivilegedExceptionAction&lt;ExtClassLoader&gt;() &#123;
                    public ExtClassLoader run() throws IOException &#123;
                        int len &#x3D; dirs.length;
                        for (int i &#x3D; 0; i &lt;len; i++) &#123;
                            MetaIndex.registerDirectory(dirs[i]);
                        &#125;
                        return new ExtClassLoader(dirs);
                    &#125;
                &#125;);
        &#125; catch (java.security.PrivilegedActionException e) &#123;
            throw (IOException) e.getException();
        &#125;
    &#125;

    void addExtURL(URL url) &#123;
        super.addURL(url);
    &#125;

    &#x2F;*
     * Creates a new ExtClassLoader for the specified directories.
     *&#x2F;
    public ExtClassLoader(File[] dirs) throws IOException &#123;
        super(getExtURLs(dirs), null, factory);
        SharedSecrets.getJavaNetAccess().
            getURLClassPath(this).initLookupCache(this);
    &#125;

    private static File[] getExtDirs() &#123;
        String s &#x3D; System.getProperty(&quot;java.ext.dirs&quot;);
        File[] dirs;
        if (s !&#x3D; null) &#123;
            StringTokenizer st &#x3D;
                new StringTokenizer(s, File.pathSeparator);
            int count &#x3D; st.countTokens();
            dirs &#x3D; new File[count];
            for (int i &#x3D; 0; i &lt;count; i++) &#123;
                dirs[i] &#x3D; new File(st.nextToken());
            &#125;
        &#125; else &#123;
            dirs &#x3D; new File[0];
        &#125;
        return dirs;
    &#125;

    private static URL[] getExtURLs(File[] dirs) throws IOException &#123;
        Vector&lt;URL&gt; urls &#x3D; new Vector&lt;URL&gt;();
        for (int i &#x3D; 0; i &lt;dirs.length; i++) &#123;
            String[] files &#x3D; dirs[i].list();
            if (files !&#x3D; null) &#123;
                for (int j &#x3D; 0; j &lt;files.length; j++) &#123;
                    if (!files[j].equals(&quot;meta-index&quot;)) &#123;
                        File f &#x3D; new File(dirs[i], files[j]);
                        urls.add(getFileURL(f));
                    &#125;
                &#125;
            &#125;
        &#125;
        URL[] ua &#x3D; new URL[urls.size()];
        urls.copyInto(ua);
        return ua;
    &#125;

    &#x2F;*
     * Searches the installed extension directories for the specified
     * library name. For each extension directory, we first look for
     * the native library in the subdirectory whose name is the value
     * of the system property &lt;code&gt;os.arch&lt;&#x2F;code&gt;. Failing that, we
     * look in the extension directory itself.
     *&#x2F;
    public String findLibrary(String name) &#123;
        name &#x3D; System.mapLibraryName(name);
        URL[] urls &#x3D; super.getURLs();
        File prevDir &#x3D; null;
        for (int i &#x3D; 0; i &lt;urls.length; i++) &#123;
            &#x2F;&#x2F; Get the ext directory from the URL
            File dir &#x3D; new File(urls[i].getPath()).getParentFile();
            if (dir !&#x3D; null &amp;&amp; !dir.equals(prevDir)) &#123;
                &#x2F;&#x2F; Look in architecture-specific subdirectory first
                &#x2F;&#x2F; Read from the saved system properties to avoid deadlock
                String arch &#x3D; VM.getSavedProperty(&quot;os.arch&quot;);
                if (arch !&#x3D; null) &#123;
                    File file &#x3D; new File(new File(dir, arch), name);
                    if (file.exists()) &#123;
                        return file.getAbsolutePath();
                    &#125;
                &#125;
                &#x2F;&#x2F; Then check the extension directory
                File file &#x3D; new File(dir, name);
                if (file.exists()) &#123;
                    return file.getAbsolutePath();
                &#125;
            &#125;
            prevDir &#x3D; dir;
        &#125;
        return null;
    &#125;

    private static AccessControlContext getContext(File[] dirs)
        throws IOException
    &#123;
        PathPermissions perms &#x3D;
            new PathPermissions(dirs);

        ProtectionDomain domain &#x3D; new ProtectionDomain(
            new CodeSource(perms.getCodeBase(),
                (java.security.cert.Certificate[]) null),
            perms);

        AccessControlContext acc &#x3D;
            new AccessControlContext(new ProtectionDomain[] &#123; domain &#125;);

        return acc;
    &#125;
&#125;</code></pre>

<p>这里大家关注下 getExtDirs()这个方法，它会获取属性”java.ext.dirs”所对应的值，然后通过系统分隔符分割，然后加载分割后的字符串对应的目录作为 ClassLoader 的类加载库。</p>
<h3 id="3、AppClassLoader-初始化"><a href="#3、AppClassLoader-初始化" class="headerlink" title="3、AppClassLoader 初始化"></a>3、AppClassLoader 初始化</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * The class loader used for loading from java.class.path.
 * runs in a restricted security context.
 *&#x2F;
static class AppClassLoader extends URLClassLoader &#123;

    static &#123;
        ClassLoader.registerAsParallelCapable();
    &#125;

    public static ClassLoader getAppClassLoader(final ClassLoader extcl)
        throws IOException
    &#123;
        final String s &#x3D; System.getProperty(&quot;java.class.path&quot;);
        final File[] path &#x3D; (s &#x3D;&#x3D; null) ? new File[0] : getClassPath(s);

        &#x2F;&#x2F; Note: on bugid 4256530
        &#x2F;&#x2F; Prior implementations of this doPrivileged() block supplied
        &#x2F;&#x2F; a rather restrictive ACC via a call to the private method
        &#x2F;&#x2F; AppClassLoader.getContext(). This proved overly restrictive
        &#x2F;&#x2F; when loading  classes. Specifically it prevent
        &#x2F;&#x2F; accessClassInPackage.sun.* grants from being honored.
        &#x2F;&#x2F;
        return AccessController.doPrivileged(
            new PrivilegedAction&lt;AppClassLoader&gt;() &#123;
                public AppClassLoader run() &#123;
                URL[] urls &#x3D;
                    (s &#x3D;&#x3D; null) ? new URL[0] : pathToURLs(path);
                return new AppClassLoader(urls, extcl);
            &#125;
        &#125;);
    &#125;

    final URLClassPath ucp;

    &#x2F;*
     * Creates a new AppClassLoader
     *&#x2F;
    AppClassLoader(URL[] urls, ClassLoader parent) &#123;
        super(urls, parent, factory);
        ucp &#x3D; SharedSecrets.getJavaNetAccess().getURLClassPath(this);
        ucp.initLookupCache(this);
    &#125;

    &#x2F;**
     * Override loadClass so we can checkPackageAccess.
     *&#x2F;
    public Class&lt;?&gt; loadClass(String name, boolean resolve)
        throws ClassNotFoundException
    &#123;
        int i &#x3D; name.lastIndexOf(&#39;.&#39;);
        if (i !&#x3D; -1) &#123;
            SecurityManager sm &#x3D; System.getSecurityManager();
            if (sm !&#x3D; null) &#123;
                sm.checkPackageAccess(name.substring(0, i));
            &#125;
        &#125;

        if (ucp.knownToNotExist(name)) &#123;
            &#x2F;&#x2F; The class of the given name is not found in the parent
            &#x2F;&#x2F; class loader as well as its local URLClassPath.
            &#x2F;&#x2F; Check if this class has already been defined dynamically;
            &#x2F;&#x2F; if so, return the loaded class; otherwise, skip the parent
            &#x2F;&#x2F; delegation and findClass.
            Class&lt;?&gt; c &#x3D; findLoadedClass(name);
            if (c !&#x3D; null) &#123;
                if (resolve) &#123;
                    resolveClass(c);
                &#125;
                return c;
            &#125;
            throw new ClassNotFoundException(name);
        &#125;

        return (super.loadClass(name, resolve));
    &#125;

    &#x2F;**
     * allow any classes loaded from classpath to exit the VM.
     *&#x2F;
    protected PermissionCollection getPermissions(CodeSource codesource)
    &#123;
        PermissionCollection perms &#x3D; super.getPermissions(codesource);
        perms.add(new RuntimePermission(&quot;exitVM&quot;));
        return perms;
    &#125;

    &#x2F;**
     * This class loader supports dynamic additions to the class path
     * at runtime.
     *
     * @see java.lang.instrument.Instrumentation&#x3D;appendToSystemClassPathSearch
     *&#x2F;
    private void appendToClassPathForInstrumentation(String path) &#123;
        assert(Thread.holdsLock(this));

        &#x2F;&#x2F; addURL is a no-op if path already contains the URL
        super.addURL( getFileURL(new File(path)) );
    &#125;

    &#x2F;**
     * create a context that can read any directories (recursively)
     * mentioned in the class path. In the case of a jar, it has to
     * be the directory containing the jar, not just the jar, as jar
     * files might refer to other jar files.
     *&#x2F;

    private static AccessControlContext getContext(File[] cp)
        throws java.net.MalformedURLException
    &#123;
        PathPermissions perms &#x3D;
            new PathPermissions(cp);

        ProtectionDomain domain &#x3D;
            new ProtectionDomain(new CodeSource(perms.getCodeBase(),
                (java.security.cert.Certificate[]) null),
            perms);

        AccessControlContext acc &#x3D;
            new AccessControlContext(new ProtectionDomain[] &#123; domain &#125;);

        return acc;
    &#125;
&#125;</code></pre>

<p>首先获取”java.class.path”对应的属性，并转换为 URL[]并设置为 ClassLoader 的类加载库，注意这里的方法入参 classloader 就是 ExtClassLoader，在创 AppClassLoader 会传入 ExtClassLoader 作为 parent ClassLoader。<br>上面就是 ClassLoader 的启动和初始化过程，后面会把 loader 作为应用程序的默认 ClassLoader 使用，看下面的测试用例:</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String... args) &#123;
    ClassLoader loader &#x3D; Test.class.getClassLoader();
    System.err.println(loader);
    while (loader !&#x3D; null) &#123;
        loader &#x3D; loader.getParent();
        System.err.println(loader);
    &#125;
&#125;</code></pre>

<p>结果输出</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">sun.misc.Launcher$AppClassLoader@75b84c92
sun.misc.Launcher$ExtClassLoader@1540e19d
null</code></pre>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（三）内存分配与回收策略</title>
    <url>/article/jvm/jvm-gc-allocation/</url>
    <content><![CDATA[<p>对象的分配的细节取决于当前使用哪一种垃圾收集器组合，以及和内存相关参数有关，本文主要讨论 Serial&#x2F;SerialOld 收集器的内存分配和回收的策略，其他几种垃圾收集器可以自己去探讨。<br>先介绍下 MinorGC 和 FullGC 的概念。<br><strong>新生代 GC（MinorGC</strong>）: 发生在新生代，Java 对象大多都有朝生夕死的特性，MinorGC 非常频繁，回收速度也比较快。<br><strong>老年代 GC（MajorGC&#x2F;FullGC）</strong>: 发生在老年代，出现 MajorGC 经常至少伴随一次的 MinorGC，但非绝对。MajorGC 的速度一般比 MinorGC 慢 10 倍以上。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398550331-f66fe7ce-115e-4b49-bdcc-f17ee4cc2a0b.png#clientId=uc6b6d1e2-f7d5-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3769d526&margin=%5Bobject%20Object%5D&name=image.png&originHeight=269&originWidth=626&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=15172&status=done&style=none&taskId=u60ea5eca-8ee0-4d4c-b13f-2a9271bd3b0&title=" alt="image.png"><br>下面是最普遍的内存分配规则。</p>
<h2 id="1、对象优先在-eden-分配"><a href="#1、对象优先在-eden-分配" class="headerlink" title="1、对象优先在 eden 分配"></a>1、对象优先在 eden 分配</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 对象优先在Eden分配
 * vm参数，新生代10M, eden区8M，surivior区1M(from,to)
 * -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio&#x3D;8 -XX:+UseSerialGC -XX:+PrintGCDetails
 *&#x2F;
public static void testAllocation() &#123;
    byte[] allocation1, allocation2 ,allocation3 ,allocation4;
    allocation1 &#x3D; new byte[2 * _1MB];
    allocation2 &#x3D; new byte[2 * _1MB];
    allocation3 &#x3D; new byte[2 * _1MB];
    allocation4 &#x3D; new byte[4 * _1MB]; &#x2F;&#x2F;出现一次Minor GC
&#125;</code></pre>

<p>使用串行垃圾回收，新生代 10M, eden 区 8M，surivior 区 1M(from,to)<br>从输出结果看 执行 allocation4 &#x3D; new byte[4 * _1MB];会发生一次 GC，GC 的结果是 7458K→601K，而总内存占用量几乎没有减少，因为 allocation1，allocation2，allocation3 都是存活，发现 Eden 区已经占用了 6M，剩余空间不足以分配 allocation4 的 4M 的空间，因此发生 MinorGC，GC 期间发现已有的 3 个 2MB 大小的对象无法放入到 Survivor 空间（只有 1M 大小），所以只好通过分配担保机制提前转移到老年代中去。<br>GC 结束后， eden 被占用 4M（allocation4），survivor 空闲，老年代占用 6M （allocation1，allocation2，allocation3） 。</p>
<h2 id="2、大对象直接进入老年代"><a href="#2、大对象直接进入老年代" class="headerlink" title="2、大对象直接进入老年代"></a>2、大对象直接进入老年代</h2><p>虚拟机提供-XX:PretenureSizeThreshold 参数，令大于这个设置值的对象直接在老年代分配，这样做可以避免在 Eden 和两个 Survivor 区域之间发生大量的内存复制操作</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 大对象直接进入老年代
 * vm参数，新生代10M, eden区8M，surivior区1M(from,to)
 * -XX:PretenureSizeThreshold&#x3D;3145728 -XX:+PrintGCDetails -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio&#x3D;8 -XX:+UseSerialGC
 *&#x2F;
public static void testPretenureSizeThreshold() &#123;
    byte[] allocation;
    allocation &#x3D; new byte[4 * _1MB]; &#x2F;&#x2F;直接分配在老年代(大于3M)
&#125;</code></pre>

<p>PretenureSizeThreshold 参数在 UseParallelGC 或者 UseG1GC 的时候都是不起作用的，只在 Serial 和 ParNew 新生代收集器中有效。</p>
<h2 id="3、长期存活对象将进入老年代"><a href="#3、长期存活对象将进入老年代" class="headerlink" title="3、长期存活对象将进入老年代"></a>3、长期存活对象将进入老年代</h2><p>对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold 设置，当对象达到这个年龄后就将进入老年代。<br>如果对象在 Eden 出生并且经过第一次 MinorGC 后仍然存活，并且能够被 Survivor 容纳的话，被移动到 Survivor 空间中，并将对象年龄设置成 1，对象在 Survivor 中每熬过一次 MinorGC，年龄就增加 1 岁。年龄到一定程度（默认为 15 岁），就会被晋升到到老年代中。可以通过参数-XX:MaxTenuringThreshold 设置。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 长期存活的对象进入老年代
 * vm参数，新生代10M, eden区16M，surivior区2M(from,to)
 * -XX:MaxTenuringThreshold&#x3D;1 -Xms40M -Xmx40M -Xmn20M -XX:SurvivorRatio&#x3D;8 -XX:+UseSerialGC  -XX:+PrintTenuringDistribution -XX:+PrintGCDetails
 *&#x2F;
public static void testTenuringThreshold() &#123;
    byte[] allocation1, allocation2 ,allocation3;
    allocation1 &#x3D; new byte[1&#x2F;2 * _1MB];
    &#x2F;&#x2F; 什么时候进入老年代取决于MaxTenuringThreshold的设置
    allocation2 &#x3D; new byte[8 * _1MB];
    allocation3 &#x3D; new byte[8 * _1MB];
    allocation3 &#x3D; null;
    allocation3 &#x3D; new byte[8 * _1MB];
&#125;</code></pre>

<p>-XX:MaxTenuringThreshold&#x3D;1 -XX:MaxTenuringThreshold&#x3D;15 发生了两次 Minor GC，第一次是在给 allocation3 进行分配的时候会出现一次 Minor GC，此时 survivor 区域不能容纳 allocation2，但是可以容纳 allocation1，所以 allocation1 将会进入 survivor 区域并且年龄为 1，达到了阈值，将在下一次 GC 时晋升到老年代，而 allocation2 则会通过担保机制进入老年代。第二次发生 GC 是在第二次给 allocation3 分配空间时，这时，allocation1 的年龄加 1，晋升到老年代，此次 GC 也可以清理出原来 allocation3 占据的 4MB 空间，将 allocation3 分配在 Eden 区。所以，最后的结果是 allocation1、allocation2 在老年代，allocation3 在 Eden 区。</p>
<h2 id="4、动态对象年龄判定"><a href="#4、动态对象年龄判定" class="headerlink" title="4、动态对象年龄判定"></a>4、动态对象年龄判定</h2><p>为了更好地适应不同程序的内存状况，虚拟机并不是永远的要求对象的年龄必须达到了 MaxTenuringThreshold 才能晋升老年代；如果在 Survivor 空间中相同年龄所有对象的大小总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 动态对象年龄判断
 * vm参数，新生代10M, eden区16M，surivior区2M(from,to)
 * -Xms40M -Xmx40M -Xmn20M -XX:SurvivorRatio&#x3D;8 -XX:+UseSerialGC -XX:+PrintTenuringDistribution -XX:+PrintGCDetails
 *&#x2F;
public static void testDynamicTenuringThreshold() &#123;
    byte[] allocation1, allocation2 ,allocation3,allocation4;
    allocation1 &#x3D; new byte[_1MB &#x2F; 2];
    allocation2 &#x3D; new byte[_1MB &#x2F; 2];
    &#x2F;&#x2F; allocation1 + allocation2 大于surivior空间的一半
    allocation3 &#x3D; new byte[8 * _1MB];
    allocation4 &#x3D; new byte[8 * _1MB];
    allocation4 &#x3D; null;
    allocation4 &#x3D; new byte[8 * _1MB];
&#125;</code></pre>

<p>发生了两次 Minor GC，第一次发生在给 allocation4 分配内存时，此时 allocation1、allocation2 将会进入 survivor 区，而 allocation3 通过担保机制将会进入老年代。第二次发生在给 allocation4 分配内存时，此时，survivor 区的 allocation1、allocation2 达到了 survivor 区容量的一半，将会进入老年代，此次 GC 可以清理出 allocation4 原来的 4MB 空间，并将 allocation4 分配在 Eden 区。最终，allocation1、allocation2、allocation3 在老年代，allocation4 在 Eden 区。</p>
<h2 id="5、空间分配担保"><a href="#5、空间分配担保" class="headerlink" title="5、空间分配担保"></a>5、空间分配担保</h2><h3 id="jdk1-6-update24-之前的担保流程"><a href="#jdk1-6-update24-之前的担保流程" class="headerlink" title="jdk1.6 update24 之前的担保流程"></a>jdk1.6 update24 之前的担保流程</h3><p>在发生 Minor GC 之前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果这个条件成立，那么 Minor GC 可以确保是安全的。如果不成立，则虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于则进行一次 Minor GC。如果小于或者没有设置 HandlePromotionFailure，则要进行一次 Full GC。<br>取平均值进行比较其实仍然是一种动态概率的手段，如果某次 Minor GC 存活后的对象突增，远远高于平均值的话，依然会导致担保失败。如果出现了 HandlePromotionFailure 失败，则会重新发起一次 Full GC，大部分情况都会将 HandlePromotionFailure 打开，避免过于频繁的 Full GC。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398550385-d0b55dea-87c7-4f39-8f90-b57013c543bf.png#clientId=uc6b6d1e2-f7d5-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u59b841d2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=357&originWidth=723&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=31084&status=done&style=none&taskId=ub70f10b6-edf4-40a0-9701-0aaa3ad6b09&title=" alt="image.png"></p>
<h3 id="jdk1-6-update24-之后的担保流程"><a href="#jdk1-6-update24-之后的担保流程" class="headerlink" title="jdk1.6 update24 之后的担保流程"></a>jdk1.6 update24 之后的担保流程</h3><p>在 jdk1.6 update24 之后，HandlePromotionFailure 参数不会影响虚拟机空间分配担保策略，虚拟机改为，只要老年代最大连续空间大于新生代对象总和或者大于历次晋升平均大小，都将进行 minor gc，否则将进行 Full gc。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398550299-cad9a607-6e9f-4ab8-a9ef-04dee9a81e74.png#clientId=uc6b6d1e2-f7d5-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u30b7ea0d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=151&originWidth=726&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=14065&status=done&style=none&taskId=u27f99744-0684-4846-a839-f4a029094c2&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 空间分配担保
 * vm参数，新生代10M, eden区8M，surivior区1M(from,to)
 * -XX:HandlePromotionFailure
 * -XX:+PrintGCDetails -Xms20M -Xmx20M -Xmn10M -XX:+UseSerialGC -XX:+PrintTenuringDistribution -XX:SurvivorRatio&#x3D;8
 *&#x2F;
public static void testHandlePromotionFailure() &#123;
    byte[] allocation1, allocation2 ,allocation3,allocation4, allocation5, allocation6 ,allocation7;
    allocation1 &#x3D; new byte[2 * _1MB];
    allocation2 &#x3D; new byte[2 * _1MB];
    allocation3 &#x3D; new byte[2 * _1MB];
    allocation1 &#x3D; null;
    allocation4 &#x3D; new byte[2 * _1MB];
    allocation5 &#x3D; new byte[2 * _1MB];
    allocation6 &#x3D; new byte[2 * _1MB];
    allocation4 &#x3D; null;
    allocation5 &#x3D; null;
    allocation6 &#x3D; null;
    allocation7 &#x3D; new byte[2 * _1MB];
&#125;</code></pre>

<p>发生了两次 GC，第一次发生在给 allocation4 分配内存空间时，由于老年代的连续可用空间大于存活的对象总和， 所以 allocation2、allocation3 将会进入老年代，allocation1 的空间将被回收，allocation4 分配在新生代；第二次发生在给 allocation7 分配内存空间时，此次 GC 将 allocation4、allocation5、allocation6 所占的内存全部回收。最后，allocation2、allocation3 在老年代，allocation7 在新生代。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（四）类文件结构解析</title>
    <url>/article/jvm/jvm-class/</url>
    <content><![CDATA[<h2 id="Java-Class-文件结构"><a href="#Java-Class-文件结构" class="headerlink" title="Java Class 文件结构"></a>Java Class 文件结构</h2><p>如下图所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398732871-52f4c2d6-8314-4223-b07a-ea59ac0f6ce7.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3b5ec65e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=924&originWidth=1244&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=101607&status=done&style=none&taskId=ufab1464f-fa80-4848-9d69-094bca2ea40&title=" alt="image.png"><br>对于以下 java 源文件代码</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class Charles implements ICharles&#123;
  private String name;
  public void say() &#123;
    System.out.println(&quot;charles&quot;);
  &#125;
  public String getName() &#123;
    return name;
  &#125;
  public void setName(String name) &#123;
    this.name &#x3D; name;
  &#125;
&#125;</code></pre>

<p>生成的类文件字节码为<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398732886-29c2ac32-cf7a-4197-828b-aa50372bcb8f.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u824c699c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=938&originWidth=698&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=139186&status=done&style=none&taskId=ue583a253-101a-4bf5-98b2-e68a1505d26&title=" alt="image.png"><br>根据 class 文件结构分析字节码</p>
<h3 id="1、-魔数-magic"><a href="#1、-魔数-magic" class="headerlink" title="1、 魔数(magic)"></a>1、 魔数(magic)</h3><p>魔数的唯一作用是确定这个文件是否为一个能被虚拟机所接受的 Class 文件。魔数值固定为 0xCAFEBABE，不会改。</p>
<h3 id="2、-版本号-minor-version-major-version"><a href="#2、-版本号-minor-version-major-version" class="headerlink" title="2、 版本号(minor_version, major_version)"></a>2、 版本号(minor_version, major_version)</h3><p>minor_version 和 major_version 的值分别表示 Class 文件的副、主版本号，它们共同构成了 Class 文件的格式版本号。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398732697-4e26a4fb-c6db-4c60-ad03-f163bd119932.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub22a6d8b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=42&originWidth=672&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=4682&status=done&style=none&taskId=ub4c3438e-0909-4a10-933c-0fe27f518e9&title=" alt="image.png"><br>其中，00 00（次版本号），00 31（主版本号），即十进制版本号 49，使用 JDK1.6 编译输出</p>
<h3 id="3、常量池计数器-constant-pool-count"><a href="#3、常量池计数器-constant-pool-count" class="headerlink" title="3、常量池计数器(constant_pool_count)"></a>3、常量池计数器(constant_pool_count)</h3><p>常量池是 class 文件中非常重要的结构，它描述着整个 class 文件的字面量信息。常量池是由一组 constant_pool 结构体数组组成的，而数组的大小则由常量池计数器指定。常量池计数器 constant_pool_count 的值 &#x3D;constant_pool 表中的成员数 + 1。constant_pool 表的索引值只有在大于 0 且小于 constant_pool_count 时才会被认为是有效的。</p>
<h3 id="4、常量池数据区-constant-pool-contstant-pool-count-1"><a href="#4、常量池数据区-constant-pool-contstant-pool-count-1" class="headerlink" title="4、常量池数据区(constant_pool[contstant_pool_count-1])"></a>4、常量池数据区(constant_pool[contstant_pool_count-1])</h3><p>代表常量池个数以及常量池信息，constant_pool 是一种表结构,它包含 Class 文件结构及其子结构中引用的所有字符串常量、 类或接口名、字段名和其它常量。常量池中的每一项都具备相同的格式特征，第一个字节作为类型标记用于识别该项是哪种类型的常量，称为 “tag byte” 。常量池的索引范围是 1 至 constant_pool_count-1。<br>常量池，主要分两种字面常量（Literal）和符号引用（Symbolic reference） 。<br>其中符号引用属于编译原理方面概念，主要包含以下三类常量：</p>
<ol>
<li>类和接口的权限定名</li>
<li>字段的名称和描述符</li>
<li>方法的名称和描述符<br>所有的常量池项都具有如下通用格式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398732717-62f197a3-c22e-40e8-b949-cf7f496100ae.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u64ae0dc0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=168&originWidth=363&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=7210&status=done&style=none&taskId=ufd964a7a-387a-4dde-bbbd-c7e8b599f6d&title=" alt="image.png"><br>常量池中，每个 cp_info 项的格式必须相同，它们都以一个表示 cp_info 类型的单字节“tag”项开头。后面 info[]项的内容 tag 由的类型所决定。tag 有效的类型和对应的取值在表 4.3 列出。每个 tag 项必须跟随 2 个或更多的字节，这些字节用于给定这个常量的信息，附加字节的信息格式由 tag 的值决定。<br>主要有以下类型<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398732745-4d1e9739-464c-4054-9ea6-1853ee3c05f4.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc43c9409&margin=%5Bobject%20Object%5D&name=image.png&originHeight=415&originWidth=545&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=44547&status=done&style=none&taskId=u797a336c-11d2-4a0d-bb12-9e2ae1ea4db&title=" alt="image.png"><br>本主要就 CONSTANT_Class_info 和 CONSTANT_Utf8_info 进行讨论。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398733619-7a66c3bf-4b96-4168-9c6a-d957a8ffa395.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6620cb21&margin=%5Bobject%20Object%5D&name=image.png&originHeight=283&originWidth=1115&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=45631&status=done&style=none&taskId=u745db2b6-cbfe-40ab-883b-bc76e4db1f5&title=" alt="image.png"><br>本例中 class 的常量池为<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398733670-9b15bc64-d471-4102-bbbc-0a3da81990b0.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud55019e9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=550&originWidth=675&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=117763&status=done&style=none&taskId=u40fc202b-5faa-42e2-a9cf-946d72a3b74&title=" alt="image.png"></li>
</ol>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">其中常量池的大小为0x28即为（2*16+8）-1 &#x3D; 39，索引为0不会用到。
07 00 02 (CONSTANT_Class_info)
#1 &#x3D; Class    &#x3D;2 （第一个常量为类信息，name索引为2）
01 00 13 63 6f 6d 2f 63 68 61 72 6c 65 73 2f 43 68 61 72 6c 65 73
00 13 字符串长度为19个字节
63 6f 6d 2f 63 68 61 72 6c 65 73 2f 43 68 61 72 6c 65 73
标示字符串com&#x2F;charles&#x2F;Charles
#2 &#x3D; Utf8     com&#x2F;charles&#x2F;Charles（第二个常量为utf8字符串）</code></pre>

<p>其他的类型可以参考“Java 虚拟机规范(Java_SE_7)”和“深入理解 Java 虚拟机 JVM 高级特性与最佳实践”书籍。</p>
<h3 id="6、类访问标志-access-flags"><a href="#6、类访问标志-access-flags" class="headerlink" title="6、类访问标志(access_flags)"></a>6、类访问标志(access_flags)</h3><p>访问标志，access_flags 是一种掩码标志，用于表示某个类或者接口的访问权限及基础属性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398733921-7bba13f7-7ad1-44a7-bd15-f8f0edfba5cb.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9ed34256&margin=%5Bobject%20Object%5D&name=image.png&originHeight=261&originWidth=628&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=20676&status=done&style=none&taskId=u313c16ca-c3ce-422c-bf98-5fc5aa89447&title=" alt="image.png"></p>
<h3 id="7、类索引-this-class"><a href="#7、类索引-this-class" class="headerlink" title="7、类索引(this_class)"></a>7、类索引(this_class)</h3><p>类索引，this_class 的值必须是对 constant_pool 表中项目的一个有效索引值。constant_pool 表在这个索引处的项必须为 CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类或接口。</p>
<h3 id="8、父类索引-super-class"><a href="#8、父类索引-super-class" class="headerlink" title="8、父类索引(super_class)"></a>8、父类索引(super_class)</h3><p>父类索引，对于类来说，super_class 的值必须为 0 或者是对 constant_pool 表中项目的一个有效索引值。如果它的值不为 0，那 constant_pool 表在这个索引处的项必须为 CONSTANT_Class_info 类型常量，表示这个 Class 文件所定义的类的直接父类。当前类的直接父类，以及它所有间接父类的 access_flag 中都不能带有 ACC_FINAL 标记。对于接口来说，它的 Class 文件的 super_class 项的值必须是对 constant_pool 表中项目的一个有效索引值。constant_pool 表在这个索引处的项必须为代表 java.lang.Object 的 CONSTANT_Class_info 类型常量 。如果 Class 文件的 super_class 的值为 0，那这个 Class 文件只可能是定义的是 java.lang.Object 类，只有它是唯一没有父类的类。</p>
<h3 id="9、接口计数器-interfaces-count"><a href="#9、接口计数器-interfaces-count" class="headerlink" title="9、接口计数器(interfaces_count)"></a>9、接口计数器(interfaces_count)</h3><p>接口计数器，interfaces_count 的值表示当前类或接口的直接父接口数量。</p>
<h3 id="10、接口信息数据区-interfaces-interfaces-count"><a href="#10、接口信息数据区-interfaces-interfaces-count" class="headerlink" title="10、接口信息数据区(interfaces[interfaces_count])"></a>10、接口信息数据区(interfaces[interfaces_count])</h3><p>接口表，interfaces[]数组中的每个成员的值必须是一个对 constant_pool 表中项目的一个有效索引值，它的长度为 interfaces_count。每个成员 interfaces[i] 必须为 CONSTANT_Class_info 类型常量，其中 0 ≤ i &lt;interfaces_count。在 interfaces[]数组中，成员所表示的接口顺序和对应的源代码中给定的接口顺序（从左至右）一样，即 interfaces[0]对应的是源代码中最左边的接口。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398734176-01cb4ca7-9523-4323-8ba0-c3e1a805dbf7.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua0c3d3c4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=65&originWidth=676&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=8716&status=done&style=none&taskId=ufee2647c-2a25-4c24-8068-6408234b6e1&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">flags: ACC_PUBLIC, ACC_SUPER
   #1 &#x3D; Class              #2             &#x2F;&#x2F;  com&#x2F;charles&#x2F;Charles
   #2 &#x3D; Utf8               com&#x2F;charles&#x2F;Charles
   #3 &#x3D; Class              #4             &#x2F;&#x2F;  java&#x2F;lang&#x2F;Object
   #4 &#x3D; Utf8               java&#x2F;lang&#x2F;Object
   #5 &#x3D; Class              #6             &#x2F;&#x2F;  com&#x2F;charles&#x2F;ICharles
   #6 &#x3D; Utf8               com&#x2F;charles&#x2F;ICharles
00 21 标示类访问标示为ACC_PUBLIC, ACC_SUPER
00 01 类为com&#x2F;charles&#x2F;Charles
00 03 父类为java&#x2F;lang&#x2F;Object
00 01 实现了1个接口
00 05 接口为com&#x2F;charles&#x2F;ICharles</code></pre>

<h3 id="11、字段计数器-fields-count"><a href="#11、字段计数器-fields-count" class="headerlink" title="11、字段计数器(fields_count)"></a>11、字段计数器(fields_count)</h3><p>字段计数器，fields_count 的值表示当前 Class 文件 fields[]数组的成员个数。 fields[]数组中每一项都是一个 field_info 结构的数据项，它用于表示该类或接口声明的类字段或者实例字段。</p>
<h3 id="12、字段信息数据区-fields-fields-count"><a href="#12、字段信息数据区-fields-fields-count" class="headerlink" title="12、字段信息数据区(fields[fields_count])"></a>12、字段信息数据区(fields[fields_count])</h3><p>字段表，fields[]数组中的每个成员都必须是一个 fields_info 结构的数据项，用于表示当前类或接口中某个字段的完整描述。 fields[]数组描述当前类或接口声明的所有字段，但不包括从父类或父接口继承的部分。<br>其中字段访问 flag 为<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398734753-1fcd2abb-7059-48f4-801f-9ce33bbb3776.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue45d8e83&margin=%5Bobject%20Object%5D&name=image.png&originHeight=277&originWidth=481&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=20720&status=done&style=none&taskId=u0e4e1bd2-7441-49d9-a380-ae8375e5a30&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398734758-3dd06ec2-cd4f-4c93-9f26-ff4b00b0ea4a.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud31b8499&margin=%5Bobject%20Object%5D&name=image.png&originHeight=255&originWidth=1003&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29267&status=done&style=none&taskId=uc4bff24f-af86-4e14-a839-53178c0ad14&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398734863-fafa7e51-83fd-4569-a73e-137c88d3a8a7.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucdc608de&margin=%5Bobject%20Object%5D&name=image.png&originHeight=36&originWidth=664&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=5030&status=done&style=none&taskId=u1f0798de-4bd8-4ce9-a6bb-9febe2ce98f&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">#7 &#x3D; Utf8               name
#8 &#x3D; Utf8               Ljava&#x2F;lang&#x2F;String;
00 01 类有1个字段
00 02 字段的访问标示为ACC_PRIVATE
00 07 字段名为name
00 08 字段描述符为Ljava&#x2F;lang&#x2F;String;
00 00
没有属性信息数据区</code></pre>

<h3 id="13、方法计数器-methods-count"><a href="#13、方法计数器-methods-count" class="headerlink" title="13、方法计数器(methods_count)"></a>13、方法计数器(methods_count)</h3><p>方法计数器， methods_count 的值表示当前 Class 文件 methods[]数组的成员个数。Methods[]数组中每一项都是一个 method_info 结构的数据项。</p>
<h3 id="14、方法信息数据区-methods-methods-count"><a href="#14、方法信息数据区-methods-methods-count" class="headerlink" title="14、方法信息数据区(methods[methods_count])"></a>14、方法信息数据区(methods[methods_count])</h3><p>方法表，methods[] 数组中的每个成员都必须是一个 method_info 结构的数据项，用于表示当前类或接口中某个方法的完整描述。如果某个 method_info 结构的 access_flags 项既没有设置 ACC_NATIVE 标志也没有设置 ACC_ABSTRACT 标志，那么它所对应的方法体就应当可以被 Java 虚拟机直接从当前类加载，而不需要引用其它类。 method_info 结构可以表示类和接口中定义的所有方法，包括实例方法、类方法、实例初始化方法方法和类或接口初始化方法方法 。methods[]数组只描述当前类或接口中声明的方法，不包括从父类或父接口继承的方法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398735062-35199786-b1c2-4f29-b1c1-5eed2278042d.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc5d3c4dd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=269&originWidth=1006&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=29906&status=done&style=none&taskId=u913c6a82-a82e-4ebe-8254-16f512a8834&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398735524-d63737be-09a7-42d0-be73-e0f4f682ce58.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc8e9b0fa&margin=%5Bobject%20Object%5D&name=image.png&originHeight=349&originWidth=669&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=53293&status=done&style=none&taskId=u727fc0a2-5b46-443f-b308-c448d1d0d7d&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">该类有4个方法，以第2个方法say()为例
00 01 00 12 00 0a 00 01 00 0b
00 01
flags: ACC_PUBLIC
00 12
#18 &#x3D; Utf8               say
00 0a
#10 &#x3D; Utf8               ()V
00 01
1个attriute_info属性
00 0b
#11 &#x3D; Utf8               Code
Code属性</code></pre>

<h3 id="15、属性计数器-attributes-count"><a href="#15、属性计数器-attributes-count" class="headerlink" title="15、属性计数器(attributes_count)"></a>15、属性计数器(attributes_count)</h3><p>属性计数器，attributes_count 的值表示当前 Class 文件 attributes 表的成员个数。attributes 表中每一项都是一个 attribute_info 结构的数据项。</p>
<h3 id="16、属性信息数据区-attributes-attributes-count"><a href="#16、属性信息数据区-attributes-attributes-count" class="headerlink" title="16、属性信息数据区(attributes[attributes_count])"></a>16、属性信息数据区(attributes[attributes_count])</h3><p>java class 文件内部属性信息，和 java 语言定义的属性没有关系，纯粹就是给 java 虚拟机用的。属性表，attributes 表的每个项的值必须是 attribute_info 结构。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398735593-75552d83-a487-48e3-a42f-5208bedc476c.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5ddea03c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=155&originWidth=823&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=11220&status=done&style=none&taskId=u6ba5f3d9-ae6d-4340-98fc-6f817a2ec00&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398736276-5dfbf84f-0434-499f-9c7f-e948109d2303.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uea3f7f46&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=672&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33105&status=done&style=none&taskId=ua00e523f-fac4-4fa7-9917-d377ab482ba&title=" alt="image.png"><br>以第 2 个方法 say()的 code 属性为例<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398736316-a05b49d9-0d2a-42fa-8f53-55c641a1d8fa.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9ed94d19&margin=%5Bobject%20Object%5D&name=image.png&originHeight=520&originWidth=1386&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=66265&status=done&style=none&taskId=ua89e4f00-dd00-460e-a325-017b7ff080d&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398736310-5fb50297-9d97-45c3-8a08-4af805c6eb3a.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u40277943&margin=%5Bobject%20Object%5D&name=image.png&originHeight=146&originWidth=670&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=22486&status=done&style=none&taskId=uc8d1ec58-b69a-4dc8-b548-9f9b2b6b2d6&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">00 0b
#11 &#x3D; Utf8               Code
00 00 00 37
代码属性区的长度为3*16 + 7
00 02
操作数栈最大深度为2
00 01
最大的局部变量数为1
00 00 00 09
方法代码的长度为9
b2 00 13 12 19 b6 00 1b b1
0: getstatic     #19                 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;
3: ldc           #25                 &#x2F;&#x2F; String charles
5: invokevirtual #27                 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V
8: return
00 00
没有异常表
00 02
2个Code属性区的属性
00 0e
行号表属性
#14 &#x3D; Utf8               LineNumberTable
00 0f
本地变量表属性
#15 &#x3D; Utf8               LocalVariableTable</code></pre>

<p><strong>LineNumberTable 属性</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398736334-c14abb13-0cb4-4db4-a139-8ce074f9cf98.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u31cb4098&margin=%5Bobject%20Object%5D&name=image.png&originHeight=421&originWidth=1038&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=39632&status=done&style=none&taskId=u5b8d0de5-add9-4410-885b-a8458fac196&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398736915-24bb6d4d-7997-4d90-b284-100b7cb79c7f.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub12c6a63&margin=%5Bobject%20Object%5D&name=image.png&originHeight=72&originWidth=668&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=8408&status=done&style=none&taskId=u9eecc191-5aea-4b37-9454-de2ffbdcd33&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">LineNumberTable:
  line 18: 0
  line 19: 8</code></pre>

<p><strong>LocalVariableTable 属性</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398737697-7091b332-16b6-4eb1-bcbc-00a9815d4201.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc8d5dfba&margin=%5Bobject%20Object%5D&name=image.png&originHeight=442&originWidth=1016&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=47941&status=done&style=none&taskId=uf86684d7-057f-45da-8024-78a82d36454&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398737685-62f95591-1976-4074-8bdf-6ca37186d261.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3d279806&margin=%5Bobject%20Object%5D&name=image.png&originHeight=67&originWidth=669&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=8656&status=done&style=none&taskId=uc3db514a-9eb4-43e1-83a2-43622881d57&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">LocalVariableTable:
  Start  Length  Slot  Name   Signature
  0       9     0    this     Lcom&#x2F;charles&#x2F;Charles;</code></pre>

<p>在 Java 7 规范里，Class 文件结构中的 attributes 表的项包括下列定义的属性： InnerClasses 、 EnclosingMethod、Synthetic、Signature、SourceFile，SourceDebugExtension 、Deprecated、RuntimeVisibleAntations、RuntimeInvisibleAntations 以及 BootstrapMethods 属性。<br>对于支持 Class 文件格式版本号为 49.0 或更高的 Java 虚拟机实现，必须正确识别并读取 attributes 表中的 Signature、RuntimeVisibleAntations 和 RuntimeInvisibleAntations 属性。对于支持 Class 文件格式版本号为 51.0 或更高的 Java 虚拟机实现，必须正确识别并读取 attributes 表中的 BootstrapMethods 属性。Java 7 规范 要求任一 Java 虚拟机实现可以自动忽略 Class 文件的 attributes 表中的若干 （甚至全部） 它不可识别的属性项。任何本规范未定义的属性不能影响 Class 文件的语义，只能提供附加的描述信息 。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398737761-b07f4139-6c51-4080-b613-8e700c32ff69.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8f399484&margin=%5Bobject%20Object%5D&name=image.png&originHeight=214&originWidth=634&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=17304&status=done&style=none&taskId=u0c1cb6bd-a4e9-4077-9ea2-10198f04b7b&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648398738365-2cf86d60-e78e-4a84-b02d-f9c95adf608e.png#clientId=u0e59f31f-479e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u111c0f1f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=70&originWidth=671&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=7525&status=done&style=none&taskId=u545b2de2-ce69-4d7b-859e-9939af39467&title=" alt="image.png"><br>使用 java -verbose Charles 反编译，查看类信息</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">Last modified Oct 21, 2014; size 743 bytes
  MD5 checksum 98d8dab9aaaeeff70b2e4e77ebfedc53
  Compiled from &quot;Charles.java&quot;
public class com.charles.Charles implements com.charles.ICharles
  SourceFile: &quot;Charles.java&quot;
  minor version: 0
  major version: 49
  flags: ACC_PUBLIC, ACC_SUPER
Constant pool:
   #1 &#x3D; Class              #2             &#x2F;&#x2F;  com&#x2F;charles&#x2F;Charles
   #2 &#x3D; Utf8               com&#x2F;charles&#x2F;Charles
   #3 &#x3D; Class              #4             &#x2F;&#x2F;  java&#x2F;lang&#x2F;Object
   #4 &#x3D; Utf8               java&#x2F;lang&#x2F;Object
   #5 &#x3D; Class              #6             &#x2F;&#x2F;  com&#x2F;charles&#x2F;ICharles
   #6 &#x3D; Utf8               com&#x2F;charles&#x2F;ICharles
   #7 &#x3D; Utf8               name
   #8 &#x3D; Utf8               Ljava&#x2F;lang&#x2F;String;
   #9 &#x3D; Utf8               &lt;init&gt;
  #10 &#x3D; Utf8               ()V
  #11 &#x3D; Utf8               Code
  #12 &#x3D; Methodref          #3.#13         &#x2F;&#x2F;  java&#x2F;lang&#x2F;Object.&quot;&lt;init&gt;&quot;:()V
  #13 &#x3D; NameAndType        #9:#10         &#x2F;&#x2F;  &quot;&lt;init&gt;&quot;:()V
  #14 &#x3D; Utf8               LineNumberTable
  #15 &#x3D; Utf8               LocalVariableTable
  #16 &#x3D; Utf8               this
  #17 &#x3D; Utf8               Lcom&#x2F;charles&#x2F;Charles;
  #18 &#x3D; Utf8               say
  #19 &#x3D; Fieldref           #20.#22        &#x2F;&#x2F;  java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;
  #20 &#x3D; Class              #21            &#x2F;&#x2F;  java&#x2F;lang&#x2F;System
  #21 &#x3D; Utf8               java&#x2F;lang&#x2F;System
  #22 &#x3D; NameAndType        #23:#24        &#x2F;&#x2F;  out:Ljava&#x2F;io&#x2F;PrintStream;
  #23 &#x3D; Utf8               out
  #24 &#x3D; Utf8               Ljava&#x2F;io&#x2F;PrintStream;
  #25 &#x3D; String             #26            &#x2F;&#x2F;  charles
  #26 &#x3D; Utf8               charles
  #27 &#x3D; Methodref          #28.#30        &#x2F;&#x2F;  java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V
  #28 &#x3D; Class              #29            &#x2F;&#x2F;  java&#x2F;io&#x2F;PrintStream
  #29 &#x3D; Utf8               java&#x2F;io&#x2F;PrintStream
  #30 &#x3D; NameAndType        #31:#32        &#x2F;&#x2F;  println:(Ljava&#x2F;lang&#x2F;String;)V
  #31 &#x3D; Utf8               println
  #32 &#x3D; Utf8               (Ljava&#x2F;lang&#x2F;String;)V
  #33 &#x3D; Utf8               getName
  #34 &#x3D; Utf8               ()Ljava&#x2F;lang&#x2F;String;
  #35 &#x3D; Fieldref           #1.#36         &#x2F;&#x2F;  com&#x2F;charles&#x2F;Charles.name:Ljava&#x2F;lang&#x2F;String;
  #36 &#x3D; NameAndType        #7:#8          &#x2F;&#x2F;  name:Ljava&#x2F;lang&#x2F;String;
  #37 &#x3D; Utf8               setName
  #38 &#x3D; Utf8               SourceFile
  #39 &#x3D; Utf8               Charles.java
&#123;
  public com.charles.Charles();
    flags: ACC_PUBLIC
    Code:
      stack#1, locals#1, args_size#1
         0: aload_0
         1: invokespecial #12                 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Object.&quot;&lt;init&gt;&quot;:()V
         4: return
      LineNumberTable:
        line 13: 0
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
          0       5     0  this   Lcom&#x2F;charles&#x2F;Charles;

  public void say();
    flags: ACC_PUBLIC
    Code:
      stack#2, locals#1, args_size#1
         0: getstatic     #19                 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream;
         3: ldc           #25                 &#x2F;&#x2F; String charles
         5: invokevirtual #27                 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V
         8: return
      LineNumberTable:
        line 18: 0
        line 19: 8
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
          0       9     0  this   Lcom&#x2F;charles&#x2F;Charles;

  public java.lang.String getName();
    flags: ACC_PUBLIC
    Code:
      stack#1, locals#1, args_size#1
         0: aload_0
         1: getfield      #35                 &#x2F;&#x2F; Field name:Ljava&#x2F;lang&#x2F;String;
         4: areturn
      LineNumberTable:
        line 22: 0
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
          0       5     0  this   Lcom&#x2F;charles&#x2F;Charles;

  public void setName(java.lang.String);
    flags: ACC_PUBLIC
    Code:
      stack#2, locals#2, args_size#2
         0: aload_0
         1: aload_1
         2: putfield      #35                 &#x2F;&#x2F; Field name:Ljava&#x2F;lang&#x2F;String;
         5: return
      LineNumberTable:
        line 26: 0
        line 27: 5
      LocalVariableTable:
        Start  Length  Slot  Name   Signature
          0       6     0  this   Lcom&#x2F;charles&#x2F;Charles;
          0       6     1  name   Ljava&#x2F;lang&#x2F;String;
&#125;</code></pre>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Java并发编程之锁</title>
    <url>/article/java/java-lock/</url>
    <content><![CDATA[<blockquote>
<p>作为一个 java 开发者，并发编程是不可或缺的，在并发的过程，Lock 是并发的关键，<br>本文主要从排它锁和共享锁的实例来讲解锁的机制。</p>
</blockquote>
<p>本文主要从以下方面来讲解锁的原理及使用：</p>
<ol>
<li><a href="https://alicharles.com/article/java/java-aqs/">AbstractQueuedSynchronizer 分析</a></li>
<li><a href="https://alicharles.com/article/java/java-reentrantlock/">ReentrantLock 独占锁分析</a></li>
<li><a href="https://alicharles.com/article/java/java-countdownlatch/">CountDownLatch 共享锁分析</a></li>
<li><a href="https://alicharles.com/article/java/java-conditionobject/">ConditionObject 分析</a></li>
<li><a href="https://alicharles.com/article/java/java-cyclicbarrier/">CyclicBarrier 分析</a></li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM（七）深入理解java内存模型</title>
    <url>/article/jvm/java-memory-model/</url>
    <content><![CDATA[<blockquote>
<p>java 线程之间的通信对程序员完全透明，内存可见性问题很容易困扰 java 程序员，本文试图揭开 java 内存模型神秘的面纱。</p>
</blockquote>
<p>本文大致分三部分：<br>重排序与顺序一致性；<br>三个同步原语（lock，volatile，final）的内存语义，重排序规则及在处理器中的实现；<br>java 内存模型的设计目标，及其与处理器内存模型和顺序一致性内存模型的关系。</p>
<ul>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-1">深入理解 java 内存模型（一）——基础</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-2">深入理解 java 内存模型（二）——重排序</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-3">深入理解 java 内存模型（三）——顺序一致性</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-4">深入理解 java 内存模型（四）——volatile</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-5">深入理解 java 内存模型（五）——锁</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-6">深入理解 java 内存模型（六）——final</a></li>
<li><a href="http://www.infoq.com/cn/articles/java-memory-model-7">深入理解 java 内存模型（七）——总结</a></li>
</ul>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁（一）AQS分析</title>
    <url>/article/java/java-aqs/</url>
    <content><![CDATA[<blockquote>
<p>作为一个 java 开发者，并发编程是不可或缺的，在并发的过程，Lock 是并发的关键。</p>
</blockquote>
<p>本系列文章主要来讲解锁的原理和机制。<br>在理解 J.U.C 原理以及锁机制之前，我们来介绍 J.U.C 框架最核心也是最复杂的一个基础类：java.util.concurrent.locks.<strong>AbstractQueuedSynchronizer</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649587815459-92075084-6d27-4d80-bc7e-984dee748ce2.png#clientId=u1eb0af4d-8aca-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue584389c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=285&originWidth=592&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=47496&status=done&style=none&taskId=u4176bc44-4be5-4acb-a406-8b58e8ae29b&title=" alt="image.png"><br>上面的继承体系中，AbstractQueuedSynchronizer 是 CountDownLatch&#x2F;Semaphore&#x2F;RenntrantReadWriteLock &#x2F;Worker&#x2F;ReentrantLock 的基础，因此 AbstractQueuedSynchronizer 是 Lock&#x2F;Executor 实现的前提。公平锁、不公平锁、Condition、CountDownLatch、Semaphore 等放到后面的篇幅中说明。AQS 采用模板方法模式，为一个抽象类，但是没抽象方法，每个 sync 子类都需要实现 5 个受保护的方法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649587815456-0f259cd7-755b-4c53-bd45-5edb3de5783c.png#clientId=u1eb0af4d-8aca-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u428e2d8d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=115&originWidth=315&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=6006&status=done&style=none&taskId=ube02c845-fc3a-4add-b72d-faf5bd2cbfd&title=" alt="image.png"><br>这个 5 个方法在 AQS 都抛出 throw new UnsupportedOperationException();<br>完整的设计原理可以参考 Doug Lea 的论文 [java.util.concurrent Synchronizer Framework]（<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf">aqs.pdf</a>），这里做一些简要的分析。</p>
<h2 id="AQS-操作"><a href="#AQS-操作" class="headerlink" title="AQS 操作"></a>AQS 操作</h2><p>基本的思想是表现为一个同步器，支持下面两个操作：</p>
<h3 id="1、AQS-获取锁"><a href="#1、AQS-获取锁" class="headerlink" title="1、AQS 获取锁"></a>1、AQS 获取锁</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F;判断当前状态是否允许获取锁
while(synchronization state does not allow acquire) &#123;
    &#x2F;&#x2F;当前线程入队列
enqueue current thread if not already queued;
&#x2F;&#x2F;阻塞当前线程
    possibly block current thread;
&#125;
&#x2F;&#x2F;状态位允许获取锁时就修改状态, 如果进了队列就从队列中移除
dequeue current thread if it was queued;</code></pre>

<h3 id="2、AQS-释放锁"><a href="#2、AQS-释放锁" class="headerlink" title="2、AQS 释放锁"></a>2、AQS 释放锁</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F;更新同步状态
update synchronization state;
&#x2F;&#x2F;当前状态允许阻塞线程获取，唤醒队列中的一个或者更多线程
if(state may permit a blocked thread to acquire)
    unlock one or more queued threads;</code></pre>

<h2 id="AQS-条件"><a href="#AQS-条件" class="headerlink" title="AQS 条件"></a>AQS 条件</h2><p>要支持上面两个操作就必须有下面的条件：</p>
<ol>
<li>原子操作的同步状态（Atomically managing synchronization state）</li>
<li>阻塞和唤醒线程（Blocking and unblocking threads）</li>
<li>保持队列（Maintaining queues）</li>
</ol>
<h3 id="1、原子操作的同步状态"><a href="#1、原子操作的同步状态" class="headerlink" title="1、原子操作的同步状态"></a>1、原子操作的同步状态</h3><p>AbstractQueuedSynchronizer 中同步状态 volatile int state，使用一个 32 位的整数来描述状态位，并暴露出 getState、setState 以及 compareAndSet 操作来读取和更新这个状态。这些方法都依赖于 j.u.c.atomic 包的支持，这个包提供了兼容 JSR133 中 volatile 在读和写上的语义，并且通过使用本地的 compare-and-swap 或 load-linked&#x2F;store-conditional 指令来实现 compareAndSetState，使得仅当同步状态拥有一个期望值的时候，才会被原子地设置成新值。<br>基于 AQS 的具体实现类必须根据暴露出的状态相关的方法定义 tryAcquire 和 tryRelease 方法，以控制 acquire 和 release 操作。当同步状态满足时，tryAcquire 方法必须返回 true，而当新的同步状态允许后续 acquire 时，tryRelease 方法也必须返回 true。这些方法都接受一个 int 类型的参数用于传递想要的状态。例如：可重入锁中，当某个线程从条件等待中返回，然后重新获取锁时，为了重新建立循环计数的场景。很多同步器并不需要这样一个参数，因此忽略它即可。</p>
<h3 id="2、阻塞和唤醒线程"><a href="#2、阻塞和唤醒线程" class="headerlink" title="2、阻塞和唤醒线程"></a>2、阻塞和唤醒线程</h3><p>标准的 JAVA API 里面是无法挂起（阻塞）一个线程，然后在将来某个时刻再唤醒它的。JDK 1.0 的 API 里面有 Thread.suspend 和 Thread.resume，并且一直延续了下来。但是这些都是过时的 API，而且也是不推荐的做法。在 JDK 5.0 以后利用 JNI 在 LockSupport 类中实现了此特性。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">LockSupport.park()
LockSupport.park(Object)
LockSupport.parkNanos(Object, long)
LockSupport.parkNanos(long)
LockSupport.parkUntil(Object, long)
LockSupport.parkUntil(long)
LockSupport.unpark(Thread)</code></pre>

<p>上面的 API 中 park()是在当前线程中调用，导致线程阻塞，带参数的 Object 是挂起的对象，这样监视的时候就能够知道此线程是因为什么资源而阻塞的。<br>而 park()返回的原因有以下 3 方面：</p>
<ol>
<li>其他某个线程以当前线程作为目标调用 unpark；</li>
<li>其他某个线程中断 interrupt 当前线程；</li>
<li>该调用不合逻辑地（即毫无理由地）返回。</li>
</ol>
<p>由于 park()立即返回，其中第三条就决定了需要循环检测，所以通常情况下需要在循环中去检测竞争资源来决定是否进行下一次阻塞。</p>
<h3 id="3、保持队列"><a href="#3、保持队列" class="headerlink" title="3、保持队列"></a>3、保持队列</h3><p>同步队列的最佳选择是自身没有使用底层锁来构造的非阻塞数据结构，目前，业界对此很少有争议。而其中主要有两个选择：</p>
<ul>
<li>一个是 Mellor-Crummey 和 Scott 锁（MCS 锁）的变体，</li>
<li>另一个是 Craig，Landin 和 Hagersten 锁（CLH 锁）的变体</li>
</ul>
<p>一直以来，CLH 锁仅被用于自旋锁。但是，在这个框架中，<strong>CLH 锁显然比 MCS 锁更合适</strong>。因为 CLH 锁可以更容易地去实现“取消（cancellation）”和“超时”功能，因此我们选择了 CLH 锁作为实现的基础。但是最终的设计已经与原来的 CLH 锁有较大的出入，因此下文将对此做出解释。<br>CLH 队列实际上并不那么像队列，因为它的入队和出队操作都与它的用途（即用作锁）紧密相关。它是一个链表队列，通过两个字段 head 和 tail 来存取，这两个字段是可原子更新的，两者在初始化时都指向了一个空节点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649587815485-2db2f993-be7e-4572-9891-b805219c7081.png#clientId=u1eb0af4d-8aca-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u117765c1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=285&originWidth=694&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=23769&status=done&style=none&taskId=u4150c17c-432c-4bcc-859b-2db30788d31&title=" alt="image.png"><br>AQS 里面有三个核心字段：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">private volatile int state;
private transient volatile Node head;
private transient volatile Node tail;</code></pre>

<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1650856645490-bea8bdec-5243-4d03-a77d-126059800ee9.png#clientId=u8c021430-ecfd-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=397&id=u37b7eb52&margin=%5Bobject%20Object%5D&name=image.png&originHeight=397&originWidth=842&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=62759&status=done&style=none&taskId=u95437ed0-7a5f-45b6-af1c-07fa5d1be41&title=&width=842" alt="image.png"><br>**Sync queue **同步队列，是一个双向列表。包括 head 节点和 tail 节点。head 节点主要用作后续的调度。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1650856674295-e2323641-638c-4e85-bf40-e5d5d3caa624.png#clientId=u8c021430-ecfd-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6eb434c3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=259&originWidth=792&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=13037&status=done&style=none&taskId=u6f9fa3d2-642d-4d08-bac2-dd94dcc375f&title=" alt="image.png"><br>**Condition queue ** 非必须，单向列表。当程序中存在 cindition 的时候才会存在此列表。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1650856674311-4e054d57-e73f-4bf4-950e-ff0bbb7404e2.png#clientId=u8c021430-ecfd-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud3233b96&margin=%5Bobject%20Object%5D&name=image.png&originHeight=236&originWidth=808&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=13578&status=done&style=none&taskId=uf7b0513c-978c-4b4b-9f0e-6d8a99c378d&title=" alt="image.png"></p>
<p>其中 state 描述的有多少个线程取得了锁，对于互斥不可重入锁来说 state⇐1。<br>head&#x2F;tail 加上 CAS 操作就构成了一个 CLH 的 FIFO 队列，队列中的 Node 为一个双向链表。<br>AQS 中入队列(enqueue)，采用 CAS 操作，每次比较尾结点是否一致，然后插入的到尾结点中。<br>出队列(dequeue)，由于每一个节点也缓存了一个状态，决定是否出队列，因此当不满足条件时就需要自旋等待，一旦满足条件就将头结点设置为下一个节点。<br>CLH 锁的优点在于其入队和出队操作是快速、无锁的，以及无障碍的（即使在竞争下，某个线程总会赢得一次插入机会而能继续执行）；且探测是否有线程正在等待也很快（只要测试一下 head 是否与 tail 相等）；同时，“释放”状态是分散的，避免了一些不必要的内存竞争。<br>对于于独占锁和共享锁中，入队列和出队列的具体过程，后续会详细讲解，本文先讲解下同步队列中的 Node 节点的属性和结构。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">static final class Node &#123;
    &#x2F;** 标示节点在共享模式下等待 *&#x2F;
    static final Node SHARED &#x3D; new Node();
    &#x2F;** 标示节点在独占模式下等待 *&#x2F;
    static final Node EXCLUSIVE &#x3D; null;

    &#x2F;** 线程被取消 *&#x2F;
    static final int CANCELLED &#x3D;  1;
    &#x2F;** 后继线程需要被唤醒 *&#x2F;
    static final int SIGNAL    &#x3D; -1;
    &#x2F;** 线程在condition上等待  *&#x2F;
    static final int CONDITION &#x3D; -2;
    &#x2F;**
     * 下一个acquireShared应该无条件传播
     *&#x2F;
    static final int PROPAGATE &#x3D; -3;

    &#x2F;**
     *   CANCELLED:  节点因为超时或者对应的线程被interrupt被取消
     *   SIGNAL:     节点的继任节点是（或者将要成为）BLOCKED状态（例如通过LockSupport.park()操作）。
     *               因此当前节点一旦被释放（解锁）或者取消，就需要唤醒它的后继节点。
     *               为避免竞争，acquire方法必须首先表明他们需要一个信号，然后重试原子acquire方法，
     *               如果失败，就阻塞。
     *   CONDITION:  节点当前是在状态队列中（因为不满足一个条件（Condition）而被阻塞），
     *               直到节点的状态变成0，它才被使用作为一个同步队列节点。
     *   PROPAGATE:  releaseShared应该被传播到其他的节点，它在doReleaseShared方法中被设置（仅头节点）
     *   0:          正常状态，新生的非CONDITION节点都是此状态
     *
     *&#x2F;
    volatile int waitStatus;

    &#x2F;**
     * 前驱节点
     *&#x2F;
    volatile Node prev;

    &#x2F;**
     * 后继节点
     *&#x2F;
    volatile Node next;

    &#x2F;**
     * 节点关联的线程
     *&#x2F;
    volatile Thread thread;

    &#x2F;**
     * 下一个在等待状态（condition）的节点，或者特殊的值 SHARED.
     *&#x2F;
    Node nextWaiter;
&#125;</code></pre>

<p>AQS 在 J.U.C 里面是一个非常核心的工具，而且也非常复杂，里面考虑到了非常多的逻辑实现，本文主要介绍了一些理论背景和相关的数据结构，后续会介绍 AQS 的其他特性和实现。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁（三）CountDownLatch共享锁分析</title>
    <url>/article/java/java-countdownlatch/</url>
    <content><![CDATA[<blockquote>
<p>在开始解读 AQS 的共享功能前，我们再重温一下 CountDownLatch，CountDownLatch 为 java.util.concurrent 包下的计数器工具类，常被用在多线程环境下，它在初始时需要指定一个计数器的大小，然后可被多个线程并发的实现减 1 操作，并在计数器为 0 后调用 await 方法的线程被唤醒，从而实现多线程间的协作。</p>
</blockquote>
<h2 id="1、闭锁使用"><a href="#1、闭锁使用" class="headerlink" title="1、闭锁使用"></a>1、闭锁使用</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">class Driver2 &#123;
    void main() throws InterruptedException &#123;
        CountDownLatch doneSignal &#x3D; new CountDownLatch(N);
        Executor e &#x3D; ...

        for (int i &#x3D; 0; i &lt;N; ++i) &#x2F;&#x2F; create and start threads
        e.execute(new WorkerRunnable(doneSignal, i));
        doneSignal.await(); &#x2F;&#x2F; wait for all to finish
    &#125;
&#125;

class WorkerRunnable implements Runnable &#123;
  private final CountDownLatch doneSignal;
  private final int i;
  WorkerRunnable(CountDownLatch doneSignal, int i) &#123;
    this.doneSignal &#x3D; doneSignal;
    this.i &#x3D; i;
  &#125;
  public void run() &#123;
    try &#123;
      doWork(i);
      doneSignal.countDown();
    &#125; catch (InterruptedException ex) &#123;&#125; &#x2F;&#x2F; return;
  &#125;

  void doWork() &#123; ... &#125;
&#125;</code></pre>

<p>可以看到 CountDownLatch 的作用类似于一个“栏栅”，在 CountDownLatch 的计数为 0 前，调用 await 方法的线程将一直阻塞，直到 CountDownLatch 计数为 0，await 方法才会返回，而 CountDownLatch 的 countDown()方法则一般由各个线程调用，实现 CountDownLatch 计数的减 1。<br>首先，看下 CountDownLatch 的构造方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public CountDownLatch(int count) &#123;
    if (count &lt;0) throw new IllegalArgumentException(&quot;count &lt;0&quot;);
    this.sync &#x3D; new Sync(count);
&#125;</code></pre>

<p>和 ReentrantLock 类似，CountDownLatch 内部也有一个叫做 Sync 的内部类，同样也是用它继承了 AQS，子类需要实现 AQS 的 5 个保护方法。</p>
<h2 id="2、state-状态位"><a href="#2、state-状态位" class="headerlink" title="2、state 状态位"></a>2、state 状态位</h2><p>对于共享锁，需要实现 tryAcquireShared，tryReleaseShared 这 2 个方法。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649589997355-2e0d2412-8dc4-43b5-926e-a0cae309882c.png#clientId=u825d69b5-2259-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uf9bcf6fb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=115&originWidth=315&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=6006&status=done&style=none&taskId=u1bb122c2-e3b3-4fef-b74e-4ba54abb8ae&title=" alt="image.png"><br>setState 方法设定的 state 是 AQS 的一个“状态位”，在不同的场景下，代表不同的含义，比如在 ReentrantLock 中，表示加锁的次数，在 CountDownLatch 中，则表示 CountDownLatch 的计数器的初始大小，任务分为 N 个子线程去执行，同步状态 state 也初始化为 N。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1650856861668-cac26f1c-272f-4b62-99cc-25f3cd132a03.png#clientId=u905e4a7c-27fa-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u59b97447&margin=%5Bobject%20Object%5D&name=image.png&originHeight=472&originWidth=549&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=23052&status=done&style=none&taskId=uad9217c4-28a6-4be9-9569-180ab830a7d&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">private static final class Sync extends AbstractQueuedSynchronizer &#123;
    private static final long serialVersionUID &#x3D; 4982264981922014374L;

    Sync(int count) &#123;
        setState(count);
    &#125;

    int getCount() &#123;
        return getState();
    &#125;

    protected int tryAcquireShared(int acquires) &#123;
        return (getState() &#x3D;&#x3D; 0) ? 1 : -1;
    &#125;

    protected boolean tryReleaseShared(int releases) &#123;
        &#x2F;&#x2F; Decrement count; signal when transition to zero
        for (;;) &#123;
            int c &#x3D; getState();
            if (c &#x3D;&#x3D; 0)
                return false;
            int nextc &#x3D; c-1;
            if (compareAndSetState(c, nextc))
                return nextc &#x3D;&#x3D; 0;
        &#125;
    &#125;
&#125;</code></pre>

<p>设置完计数器大小后 CountDownLatch 的构造方法返回，下面我们再看下 CountDownLatch 的 await()方法。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void await() throws InterruptedException &#123;
    sync.acquireSharedInterruptibly(1);
&#125;</code></pre>

<p>调用了 Sync 的 acquireSharedInterruptibly 方法，因为 Sync 是 AQS 子类的原因，这里其实是直接调用了 AQS 的 acquireSharedInterruptibly 方法。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public final void acquireSharedInterruptibly(int arg)
        throws InterruptedException &#123;
    if (Thread.interrupted())
        throw new InterruptedException();
    if (tryAcquireShared(arg) &lt;0)
        doAcquireSharedInterruptibly(arg);
&#125;</code></pre>

<p>这个方法的调用是响应线程的打断的，所以在前两行会检查下线程是否被打断。接着，尝试着获取共享锁，小于 0，表示获取失败，AQS 在获取锁的思路是，先尝试直接获取锁，如果失败会将当前线程放在队列中，按照 FIFO 的原则等待锁。而对于共享锁也是这个思路，如果和独占锁一致，这里的 tryAcquireShared 应该是个空方法，留给子类去判断。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected int tryAcquireShared(int acquires) &#123;
    return (getState() &#x3D;&#x3D; 0) ? 1 : -1;
&#125;</code></pre>

<p>如果 state 变成 0 了，则返回 1，表示获取成功，否则返回-1 则表示获取失败。</p>
<h2 id="3、获取锁"><a href="#3、获取锁" class="headerlink" title="3、获取锁"></a>3、获取锁</h2><p>看到这里，读者可能会发现，await 方法的获取方式更像是在获取一个独占锁，那为什么这里还会用 tryAcquireShared 呢？<br>回想下 CountDownLatch 的 await 方法是不是只能在主线程中调用？答案是否定的，CountDownLatch 的 await 方法可以在多个线程中调用，当 CountDownLatch 的计数器为 0 后，调用 await 的方法都会依次返回。 也就是说可以多个线程同时在等待 await 方法返回，所以它被设计成了实现 tryAcquireShared 方法，获取的是一个共享锁，锁在所有调用 await 方法的线程间共享，所以叫共享锁。<br>如果获取共享锁失败（返回了-1，说明 state 不为 0，也就是 CountDownLatch 的计数器还不为 0），进入调用 doAcquireSharedInterruptibly 方法中，按照我们上述的猜想，应该是要将当前线程放入到队列中去。<br>在这之前，我们再回顾一下 AQS 队列的数据结构：AQS 是一个双向链表，通过节点中的 next，pre 变量分别指向当前节点后一个节点和前一个节点。其中，每个节点中都包含了一个线程和一个类型变量：表示当前节点是独占节点还是共享节点，头节点中的线程为正在占有锁的线程，而后的所有节点的线程表示为正在等待获取锁的线程。<br>黄色节点为头节点，表示正在获取锁的节点，剩下的蓝色节点（Node1、Node2、Node3）为正在等待锁的节点，他们通过各自的 next、pre 变量分别指向前后节点，形成了 AQS 中的双向链表。每个线程被加上类型（共享还是独占）后便是一个 Node， 也就是本文中说的节点。<br>回到 acquireSharedInterruptibly 方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 在中断模式下获取共享锁
 * @param arg the acquire argument
 *&#x2F;
private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException &#123;
    &#x2F;* 类型为Node.SHARED，标示为共享节点。*&#x2F;
    final Node node &#x3D; addWaiter(Node.SHARED);
    boolean failed &#x3D; true;
    try &#123;
        for (;;) &#123;
            final Node p &#x3D; node.predecessor();
            if (p &#x3D;&#x3D; head) &#123;
                &#x2F;* 头节点获取共享锁 *&#x2F;
                int r &#x3D; tryAcquireShared(arg);
                if (r &gt;&#x3D; 0) &#123;
                    setHeadAndPropagate(node, r);
                    p.next &#x3D; null; &#x2F;&#x2F; help GC
                    failed &#x3D; false;
                    return;
                &#125;
            &#125;
            &#x2F;* 阻塞并判断是否打断，其实这个判断才是自旋锁真正的猥琐点，
             * 意思是如果你的前继节点不是head,
             * 而且当你的前继节点状态是Node.SIGNAL时，
             * 你这个线程将被park()，
             * 直到另外的线程release时,发现head.next是你这个node时，才unpark，
             * 才能继续循环并获取锁
             *&#x2F;
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                throw new InterruptedException();
        &#125;
    &#125; finally &#123;
        if (failed)
            cancelAcquire(node);
    &#125;
&#125;</code></pre>

<p>使用了 CAS 更换了头节点，然后，将当前节点的下一个节点取出来，如果同样是“shared”类型的，再做一个”releaseShared”操作</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 设置队列head节点，检查后继节点是否在共享模式下等待，
 * 如果propagate &gt; 0 或者 节点PROPAGATE状态被设置，状态传播，
 *&#x2F;
private void setHeadAndPropagate(Node node, int propagate) &#123;
    Node h &#x3D; head; &#x2F;&#x2F; 记录老的头节点
    setHead(node);
    &#x2F;*
     * 如果传播propagate被调用者caller标示，或者被前一次操作记录
     * 并且下一个节点在共享模式等待，或者为null，
     * 尝试信号通知队列下一个节点
     *&#x2F;
    if (propagate &gt; 0 || h &#x3D;&#x3D; null || h.waitStatus &lt;0 ||
        (h &#x3D; head) &#x3D;&#x3D; null || h.waitStatus &lt;0) &#123;
        Node s &#x3D; node.next;
        if (s &#x3D;&#x3D; null || s.isShared())
            &#x2F;* 共享模式下的释放动作，信号通知后继节点，保证状态传递 *&#x2F;
            doReleaseShared();
    &#125;
&#125;</code></pre>

<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649589997397-74fdd3d7-a0f1-4993-9f49-71bb562eb720.png#clientId=u825d69b5-2259-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4cee9eb9&margin=%5Bobject%20Object%5D&name=image.png&originHeight=559&originWidth=690&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=53782&status=done&style=none&taskId=u06589832-a1c2-43c5-b5b0-4ace8d7b61c&title=" alt="image.png"></p>
<h2 id="4、释放锁"><a href="#4、释放锁" class="headerlink" title="4、释放锁"></a>4、释放锁</h2><p>看完 await 方法，我们再来看下 countDown()方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void countDown() &#123;
    sync.releaseShared(1);
&#125;

&#x2F;**
 * Releases in shared mode. Implemented by unblocking one or more
 * threads if &#123;@link &#x3D;tryReleaseShared&#125; returns true.
*&#x2F;
public final boolean releaseShared(int arg) &#123;
    if (tryReleaseShared(arg)) &#123;
        doReleaseShared();
        return true;
    &#125;
    return false;
&#125;

protected boolean tryReleaseShared(int releases) &#123;
    &#x2F;&#x2F; Decrement count; signal when transition to zero
    for (;;) &#123;
        int c &#x3D; getState();
        if (c &#x3D;&#x3D; 0)
            return false;
        int nextc &#x3D; c-1;
        if (compareAndSetState(c, nextc))
            return nextc &#x3D;&#x3D; 0;
    &#125;
&#125;

&#x2F;**
 * 共享模式下的释放动作，信号通知后继节点，保证状态传递
 *&#x2F;
private void doReleaseShared() &#123;
    &#x2F;*
     * 确保释放状态的传播，即使有其他在进行中的acquires&#x2F;releases操作的情况下。
     * 如果节点需要等待信号，用常用的方式，
     * 尝试unparkSuccessor将head节点的后继unpark
     * 否则状态被设置成PROPAGATE，来保证在释放的时候，传播能够继续。
     * 另外，当执行这个操作的时候，必须循环，防止新的节点被增加，
     * 此外，不像其他使用unparkSuccessor，我们需要知道CAS是否重置状态失败，
     * 如果失败重新检查。
     *&#x2F;
    for (;;) &#123;
        Node h &#x3D; head;
        if (h !&#x3D; null &amp;&amp; h !&#x3D; tail) &#123;
            int ws &#x3D; h.waitStatus;
            if (ws &#x3D;&#x3D; Node.SIGNAL) &#123;
                &#x2F;* 如果当前节点是SIGNAL意味着，它正在等待一个信号，
                 * 或者说，它在等待被唤醒，因此做两件事，
                 * 1是重置waitStatus标志位，2是重置成功后,唤醒下一个节点。
                 *&#x2F;
                if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))
                    continue;            &#x2F;&#x2F; loop to recheck cases
                unparkSuccessor(h);
            &#125;
            else if (ws &#x3D;&#x3D; 0 &amp;&amp;!compareAndSetWaitStatus(h, 0, Node.PROPAGATE))
                &#x2F;* 如果本身头节点的waitStatus是出于重置状态（waitStatus&#x3D;&#x3D;0）的，
                 * 将其设置为“传播”状态。
                 * 意味着需要将状态向后一个节点传播。
                 *&#x2F;
                continue;                &#x2F;&#x2F; loop on failed CAS &#125;
        if (h &#x3D;&#x3D; head)                   &#x2F;&#x2F; loop if head changed
            break;
    &#125;
&#125;</code></pre>

<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649589997367-5ebefbf7-8bc8-4d93-9d39-f00f3ce8e61b.png#clientId=u825d69b5-2259-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ubd30420a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=592&originWidth=744&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=57023&status=done&style=none&taskId=u26f46c5e-d54d-415b-a2ec-e3fe596ff8f&title=" alt="image.png"><br>闭锁 CountdownLatch 总结</p>
<ol>
<li>与 AQS 的独占功能一样，共享锁是否可以被获取的判断为空方法，交由子类去实现。</li>
<li>与 AQS 的独占功能不同，当共享锁被头节点获取后，独占功能是只有头节点获取锁，其余节点的线程继续沉睡，等待锁被释放后，才会唤醒下一个节点的线程，而共享功能是只要头节点获取锁成功，就在唤醒自身节点对应的线程的同时，继续唤醒 AQS 队列中的下一个节点的线程，每个节点在唤醒自身的同时还会唤醒下一个节点对应的线程，以实现共享状态的“向后传播”，从而实现共享功能。</li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁（五）CyclicBarrier分析</title>
    <url>/article/java/java-cyclicbarrier/</url>
    <content><![CDATA[<p>CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier 默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用 await 方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。</p>
<h2 id="1、CyclicBarrier-使用实例"><a href="#1、CyclicBarrier-使用实例" class="headerlink" title="1、CyclicBarrier 使用实例"></a>1、CyclicBarrier 使用实例</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class CyclicBarrierTest &#123;
    static CyclicBarrier c &#x3D; new CyclicBarrier(2);
    public static void main(String[] args) &#123;
        new Thread(new Runnable() &#123;
            @Override
            public void run() &#123;
                try &#123;
                    c.await();
                &#125; catch (Exception e) &#123;
                &#125;
                System.out.println(1);
            &#125;
        &#125;).start();
        try &#123;
            c.await();
        &#125; catch (Exception e) &#123;
        &#125;
        System.out.println(2);
    &#125;
&#125;</code></pre>

<p>输出 1,2 或者 2,1<br>如果把 new CyclicBarrier(2)修改成 new CyclicBarrier(3)则主线程和子线程会永远等待，因为没有第三个线程执行 await 方法，即没有第三个线程到达屏障，所以之前到达屏障的两个线程都不会继续执行。<br>CyclicBarrier 还提供一个更高级的构造函数 CyclicBarrier(int parties, Runnable barrierAction)，用于在线程到达屏障时，优先执行 barrierAction，方便处理更复杂的业务场景。代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class CyclicBarrierTest2 &#123;
    static CyclicBarrier c &#x3D; new CyclicBarrier(2, new A());
    public static void main(String[] args) &#123;
        new Thread(new Runnable() &#123;

            @Override
            public void run() &#123;
                try &#123;
                    c.await();
                &#125; catch (Exception e) &#123;

                &#125;
                System.out.println(1);
            &#125;
        &#125;).start();

        try &#123;
            c.await();
        &#125; catch (Exception e) &#123;

        &#125;
        System.out.println(2);
    &#125;

    static class A implements Runnable &#123;

        @Override
        public void run() &#123;
            System.out.println(3);
        &#125;

    &#125;
&#125;</code></pre>

<p>输出 1、3、2</p>
<h2 id="2、CyclicBarrier-源码分析"><a href="#2、CyclicBarrier-源码分析" class="headerlink" title="2、CyclicBarrier 源码分析"></a>2、CyclicBarrier 源码分析</h2><p>CyclicBarrier 底层是基于 ReentrantLock、AbstractQueuedSynchronizer，ConditionObject 来实现的，实现相对比较简单。了解前面的 ReentrantLock，对 AQS 的分析中已经指出了其数据结构，在这里不再累赘。<br>CyclicBarrier 的几个标志性的成员变量</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 循环栅栏的当前代
 *&#x2F;
private static class Generation &#123;
    boolean broken &#x3D; false;
&#125;

&#x2F;** 屏障的重入锁 *&#x2F;
private final ReentrantLock lock &#x3D; new ReentrantLock();
&#x2F;** 等待状态直到触发*&#x2F;
private final Condition trip &#x3D; lock.newCondition();
&#x2F;**  parties 数量 *&#x2F;
private final int parties;
&#x2F;** 到达屏障时先触发的操作 *&#x2F;
private final Runnable barrierCommand;

&#x2F;** 一个generation对象代表一代的屏障，
 * 就是说，如果generation对象不同，就代表进入了下一次的屏障，
 * 所以说，这个线程屏障是可循环的(Cyclic)
 *&#x2F;
private Generation generation &#x3D; new Generation();

&#x2F;**
 * count是计数器，如果有线程到达了屏障点，count就减1；
 * 直到count&#x3D;0时，其它线程才可以向下执行
 *&#x2F;
private int count;</code></pre>

<p>线程等待所有线程到达，触发栅栏</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public int await() throws InterruptedException, BrokenBarrierException &#123;
    try &#123;
        return dowait(false, 0L);
    &#125; catch (TimeoutException toe) &#123;
        throw new Error(toe); &#x2F;&#x2F; cannot happen
    &#125;
&#125;

&#x2F;**
 * 主要屏障代码，负责各种策略
 *&#x2F;
private int dowait(boolean timed, long nanos)
    throws InterruptedException, BrokenBarrierException,
           TimeoutException &#123;
    final ReentrantLock lock &#x3D; this.lock;
    lock.lock();
    try &#123;
        &#x2F;&#x2F; 获取屏障的当前代信息
        final Generation g &#x3D; generation;

        if (g.broken)
            throw new BrokenBarrierException();

        &#x2F;&#x2F; 线程中断，中断屏障
        if (Thread.interrupted()) &#123;
            breakBarrier();
            throw new InterruptedException();
        &#125;

        &#x2F;&#x2F; count-1，到达0的时候，所有的线程向下执行
        int index &#x3D; --count;
        if (index &#x3D;&#x3D; 0) &#123;  &#x2F;&#x2F; 触发屏障的栅栏
            boolean ranAction &#x3D; false;
            try &#123;
                &#x2F;&#x2F; 如果设置了barrierCommand，优先执行
                final Runnable command &#x3D; barrierCommand;
                if (command !&#x3D; null)
                    command.run();
                ranAction &#x3D; true;
                &#x2F;&#x2F; 所有线程都到的屏障点
                &#x2F;&#x2F; 更新屏障状态，唤醒其他线程，生成下一代屏障
                nextGeneration();
                return 0;
            &#125; finally &#123;
                if (!ranAction)
                    breakBarrier();
            &#125;
        &#125;

        &#x2F;&#x2F; 循环直到触发屏障栅栏，或者中断，超时
        for (;;) &#123;
            try &#123;
                if (!timed)
                    trip.await();
                else if (nanos &gt; 0L)
                    nanos &#x3D; trip.awaitNanos(nanos);
            &#125; catch (InterruptedException ie) &#123;
                &#x2F;&#x2F; 被中断，设置栅栏中断标志
                if (g &#x3D;&#x3D; generation &amp;&amp; ! g.broken) &#123;
                    &#x2F;&#x2F; 设置broken中断标示
                    breakBarrier();
                    throw ie;
                &#125; else &#123;
                    &#x2F;&#x2F; We&#39;re about to finish waiting even if we had not
                    &#x2F;&#x2F; been interrupted, so this interrupt is deemed to
                    &#x2F;&#x2F; &quot;belong&quot; to subsequent execution.
                    Thread.currentThread().interrupt();
                &#125;
            &#125;

            &#x2F;&#x2F; 屏障被中断，抛出异常
            if (g.broken)
                throw new BrokenBarrierException();

            &#x2F;&#x2F; 不是栅栏的当前代（所有线程都到达，已经生成下一代的generation）
            if (g !&#x3D; generation)
                return index;

            &#x2F;&#x2F; 超时后，中断屏障
            if (timed &amp;&amp; nanos &lt;&#x3D; 0L) &#123;
                breakBarrier();
                throw new TimeoutException();
            &#125;
        &#125;
    &#125; finally &#123;
        lock.unlock();
    &#125;
&#125;

&#x2F;**
 * 中断屏障，唤醒其他线程
 *&#x2F;
private void breakBarrier() &#123;
    generation.broken &#x3D; true;
    count &#x3D; parties;
    trip.signalAll();
&#125;

&#x2F;**
 * 更新屏障状态，唤醒其他线程，生成下一代屏障
 *&#x2F;
private void nextGeneration() &#123;
    &#x2F;&#x2F; signal completion of last generation
    trip.signalAll();
    &#x2F;&#x2F; set up next generation
    count &#x3D; parties;
    generation &#x3D; new Generation();
&#125;</code></pre>

<h2 id="3、CyclicBarrier-和-CountDownLatch-的区别"><a href="#3、CyclicBarrier-和-CountDownLatch-的区别" class="headerlink" title="3、CyclicBarrier 和 CountDownLatch 的区别"></a>3、CyclicBarrier 和 CountDownLatch 的区别</h2><p>CountDownLatch 的计数器只能使用一次。而 CyclicBarrier 的计数器可以使用 reset() 方法重置。所以 CyclicBarrier 能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。<br>CyclicBarrier 还提供其他有用的方法，比如 getNumberWaiting 方法可以获得 CyclicBarrier 阻塞的线程数量。isBroken 方法用来知道阻塞的线程是否被中断。</p>
<h2 id="4、CyclicBarrier-的应用场景"><a href="#4、CyclicBarrier-的应用场景" class="headerlink" title="4、CyclicBarrier 的应用场景"></a>4、CyclicBarrier 的应用场景</h2><p>CyclicBarrier 可以用于多线程计算数据，最后合并计算结果的应用场景。比如我们用一个 Excel 保存了用户所有银行流水，每个 Sheet 保存一个帐户近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个 sheet 里的银行流水，都执行完之后，得到每个 sheet 的日均银行流水，最后，再用 barrierAction 用这些线程的计算结果，计算出整个 Excel 的日均银行流水。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁（二）ReentrantLock独占锁分析</title>
    <url>/article/java/java-reentrantlock/</url>
    <content><![CDATA[<p>ReentrantLock 的功能是实现代码段的并发访问控制，是一种排它锁，也就是通常意义上所说的锁，内部有两种实现 NonfairSync 和 FairSync，公平锁和非公平锁，默认采用非公平锁策略。ReentrantLock 的实现不仅可以替代隐式的 synchronized 关键字，而且能够提供超过关键字本身的多种功能。</p>
<h2 id="1、ReentrantLock-的使用"><a href="#1、ReentrantLock-的使用" class="headerlink" title="1、ReentrantLock 的使用"></a>1、ReentrantLock 的使用</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">class X &#123;
  private final ReentrantLock lock &#x3D; new ReentrantLock();
  &#x2F;&#x2F; ...

  public void m() &#123;
    lock.lock();  &#x2F;&#x2F; block until condition holds
    try &#123;
      &#x2F;&#x2F; ... method body
    &#125; finally &#123;
      lock.unlock()
    &#125;
  &#125;
&#125;</code></pre>

<p><strong>ReentrantLock 会保证 method-body 在同一时间只有一个线程在执行这段代码</strong>，或者说，同一时刻只有一个线程的 lock 方法会返回。其余线程会被挂起，直到获取锁。从这里可以看出，其实 ReentrantLock 实现的就是一个独占锁的功能：有且只有一个线程获取到锁，其余线程全部挂起，直到该拥有锁的线程释放锁，被挂起的线程被唤醒重新开始竞争锁。那现在看下 Doug Lea 怎么去实现 ReentrantLock 重入锁的。首先看下 ReentrantLock 的创建和加锁、解锁过程。</p>
<h2 id="2、ReentrantLock-原理分析"><a href="#2、ReentrantLock-原理分析" class="headerlink" title="2、ReentrantLock 原理分析"></a>2、ReentrantLock 原理分析</h2><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * 默认非公平锁
 *&#x2F;
public ReentrantLock() &#123;
    sync &#x3D; new NonfairSync();
&#125; &#x2F;**
 * 创建ReentrantLock，公平锁or非公平锁
*&#x2F;
public ReentrantLock(boolean fair) &#123;
    sync &#x3D; fair ? new FairSync() : new NonfairSync();
&#125;

&#x2F;**
 *加锁解锁，使用sync完成
*&#x2F;
public void lock() &#123;
    sync.lock();
&#125;
public void unlock() &#123;
    sync.release(1);
&#125;</code></pre>

<p>其中，公平锁中每个线程抢占锁的顺序为先后调用 lock 方法的顺序依次获取锁。非公平锁中每个线程抢占锁的顺序不定，先获取锁，获取不到，然后加入到 queue 中，和调用 lock 方法的先后顺序无关。<br>如果在绝对时间上，先对锁进行获取的请求一定被先满足，那么这个锁是公平的，反之，是不公平的，也就是说等待时间最长的线程最有机会获取锁，也可以说锁的获取是有序的。ReentrantLock 这个锁提供了一个构造函数，能够控制这个锁是否是公平的。而锁的名字也是说明了这个锁具备了重复进入的可能，也就是说能够让当前线程多次的进行对锁的获取操作，这样的最大次数限制是 Integer.MAX_VALUE，约 21 亿次左右。<br>事实上公平的锁机制往往没有非公平的效率高，因为公平的获取锁没有考虑到操作系统对线程的调度因素，这样造成 JVM 对于等待中的线程调度次序和操作系统对线程的调度之间的不匹配。对于锁的快速且重复的获取过程中，连续获取的概率是非常高的，而公平锁会压制这种情况，虽然公平性得以保障，但是响应比却下降了，但是并不是任何场景都是以 TPS 作为唯一指标的，因为公平锁能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。</p>
<h3 id="AQS-的队列操作"><a href="#AQS-的队列操作" class="headerlink" title="AQS 的队列操作"></a>AQS 的队列操作</h3><p>在分析加锁前，先看下 AQS 的入队列操作， head，tail 节点默认为 null，入队列时，当 tail 为 null 时，初始化创建 dummy head 节点，将入队列的 node 插入队尾。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * Creates and enqueues node for given thread and mode.
 * 节点入同步队列，通过CAS比较然后插入队列尾部，
 * @param current the thread
 * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared
 * @return the new node
 *&#x2F;
private Node addWaiter(Node mode) &#123;
    Node node &#x3D; new Node(Thread.currentThread(), mode);
    &#x2F;&#x2F; 快速入队列,tail不为null，通过CAS比较然后插入队列尾部 Node pred &#x3D; tail;
    if (pred !&#x3D; null) &#123;
        node.prev &#x3D; pred;
        if (compareAndSetTail(pred, node)) &#123;
            pred.next &#x3D; node;
            return node;
        &#125;
    &#125;
    &#x2F;&#x2F;快速入队列失败后执行enq方法
    enq(node);
    return node;
&#125;

&#x2F;**
 * 插入节点到队列中，必要的时候初始化头节点，返回该节点前驱
 * @param node the node to insert
 * @return node&#39;s predecessor
 *&#x2F;
private Node enq(final Node node) &#123;
    for (;;) &#123;
        Node t &#x3D; tail;
        if (t &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 初始化，创建Dummy header，thread为null
            if (compareAndSetHead(new Node()))
                tail &#x3D; head;
        &#125; else &#123;
            node.prev &#x3D; t;
            if (compareAndSetTail(t, node)) &#123;
                t.next &#x3D; node;
                return t;
            &#125;
        &#125;
    &#125;
&#125;</code></pre>

<h3 id="AQS-获取锁定-独占锁"><a href="#AQS-获取锁定-独占锁" class="headerlink" title="AQS 获取锁定(独占锁)"></a>AQS 获取锁定(独占锁)</h3><p>调用 acquire 方法，其实这个方法是阻塞的, 获取锁的步骤为：<br>1、 tryAcquire（由子类 Sync 实现）尝试获取锁<br>2、 没有获取到锁，将节点加入到队列尾部中，加入成功 selfInterrupt，中断当前线程。<br>ReentrantLock，state 初始化为 0，表示未锁定状态。A 线程 lock()时，会调用 tryAcquire()独占该锁并将 state+1。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1650856752907-aa48a20e-51da-401f-830d-e940b1b0c650.png#clientId=u47a90b62-dbe9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=344&id=u9774d715&margin=%5Bobject%20Object%5D&name=image.png&originHeight=344&originWidth=595&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=17143&status=done&style=none&taskId=u38557c22-fb44-4ca4-88cb-451b1757914&title=&width=595" alt="image.png"><br><strong>独占模式下的 AQS 是不响应中断的</strong> ，指的是加入到同步队列中的线程，如果因为中断而被唤醒的话，不会立即返回，并且抛出 InterruptedException。而是再次去判断其前驱节点是否为 head 节点，决定是否争抢同步状态。如果其前驱节点不是 head 节点或者争抢同步状态失败，那么再次挂起。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public final void acquire(int arg)  &#123;
    if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
&#125;</code></pre>

<p>没有获取到锁则调用 AQS 的 acquireQueued 方法：<br>1、当 node 的前驱节点是头节点，并且独占时才返回<br>2、前继节点不是 head, 而且当你的前继节点状态是 Node.SIGNAL 时， 你这个线程将被 park()，直到另外的线程 release 时,发现 head.next 是你这个 node 时才 unpark，才能继续循环并获取锁</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">final boolean acquireQueued(final Node node, int arg) &#123;
    boolean failed &#x3D; true;
    try &#123;
        boolean interrupted &#x3D; false;
        for (;;) &#123;
            final Node p &#x3D; node.predecessor();
            &#x2F;* 当node的前驱节点是头节点，并且独占时才返回 *&#x2F;
            if (p &#x3D;&#x3D; head &amp;&amp; tryAcquire(arg)) &#123;
                setHead(node);
                p.next &#x3D; null; &#x2F;&#x2F; help GC，队列中移除头节点p
                failed &#x3D; false;
                return interrupted;
            &#125;
            &#x2F;* 阻塞并判断是否打断，其实这个判断才是自旋锁真正的猥琐点，
             * 意思是如果你的前继节点不是head,
             * 而且当你的前继节点状态是Node.SIGNAL时，
             * 你这个线程将被park()，
             * 直到另外的线程release时,发现head.next是你这个node时，才unpark，
             * 才能继续循环并获取锁
             *&#x2F;
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted &#x3D; true;
        &#125;
    &#125; finally &#123;
        if (failed)
            cancelAcquire(node);
    &#125;
&#125;</code></pre>

<p>shouldParkAfterFailedAcquire 这个方法删除所有 waitStatus&gt;0 也就是 CANCELLED 状态的 Node,并设置前继节点为 signal</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123;
    int ws &#x3D; pred.waitStatus;
    if (ws &#x3D;&#x3D; Node.SIGNAL)
        &#x2F;*
         * 节点已经设置状态Node.SIGNAL，
         * 请求释放使它获取信号，所以它才能安全的park
         *&#x2F;
        return true;
    if (ws &gt; 0) &#123;
        &#x2F;*
         *前驱节点被取消，跳过所有的取消的前驱节点和表明重试
         *&#x2F;
        do &#123;
            node.prev &#x3D; pred &#x3D; pred.prev;
        &#125; while (pred.waitStatus &gt; 0);
        pred.next &#x3D; node;
    &#125; else &#123;
        &#x2F;*
         * waitStatus为0或者PROPAGATE,表明我们需要一个信号，但是还没有park，
         * 调用者需要重试，保证在parking过程中，它不能被获取到
         *&#x2F;
        compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
    &#125;
    return false;
&#125;

&#x2F;* 禁用当前线程，返回是否中断 *&#x2F;
private final boolean parkAndCheckInterrupt() &#123;
    LockSupport.park(this);
    return Thread.interrupted();
&#125;</code></pre>

<p>独占锁 acquire 获取的过程，如下所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649588516655-5cee77db-adfa-4178-b280-d4c73d94135c.png#clientId=u62baf52a-5843-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua0bc3798&margin=%5Bobject%20Object%5D&name=image.png&originHeight=628&originWidth=644&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=49845&status=done&style=none&taskId=u94f0a047-bfa4-4d89-9711-3937c0917a6&title=" alt="image.png"></p>
<h3 id="AQS-释放独占锁"><a href="#AQS-释放独占锁" class="headerlink" title="AQS 释放独占锁"></a>AQS 释放独占锁</h3><p>1、tryRelease 释放锁，没有释放成功，返回 false<br>2、锁释放成功，唤醒 head 的后继节点，返回 true</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public final boolean release(int arg) &#123;
    if (tryRelease(arg)) &#123;
        Node h &#x3D; head;
        if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0)
            unparkSuccessor(h);&#x2F;&#x2F;unblock，唤醒head的后继节点
        return true;
    &#125;
    return false;
&#125;

private void unparkSuccessor(Node node) &#123;
    &#x2F;*
     * 状态为负数，清除信号，设置成0
     *&#x2F;
    int ws &#x3D; node.waitStatus;
    if (ws &lt;0)
        compareAndSetWaitStatus(node, ws, 0);
    &#x2F;*
     * 唤醒后继节点（一般是下一个节点)，如果节点被取消或者为null
     * 反向遍历从尾到头找到实际的非取消的后继节点（问题：为什么不正向遍历）
     *&#x2F;
    Node s &#x3D; node.next;
    if (s &#x3D;&#x3D; null || s.waitStatus &gt; 0) &#123;
        s &#x3D; null;
        for (Node t &#x3D; tail; t !&#x3D; null &amp;&amp; t !&#x3D; node; t &#x3D; t.prev)
            if (t.waitStatus &lt;&#x3D; 0)
                s &#x3D; t;
    &#125;
    if (s !&#x3D; null)
        LockSupport.unpark(s.thread);
&#125;</code></pre>

<p>释放锁的过程如下图所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649588516660-6ebd55d4-9b5c-406b-afac-702d0242a43b.png#clientId=u62baf52a-5843-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u72e622c7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=450&originWidth=507&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=28849&status=done&style=none&taskId=ue26c6f4f-943e-4912-ac16-c067c441718&title=" alt="image.png"></p>
<h2 id="3、公平锁和非公平锁"><a href="#3、公平锁和非公平锁" class="headerlink" title="3、公平锁和非公平锁"></a>3、公平锁和非公平锁</h2><p>两种锁都继承 Sync，而 Sync 又继承 AbstractQueuedSynchronizer ，所以子类必须实现 AQS 的 5 个保护方法。<br>对于独占锁，需要实现 tryAcquire，tryRelease，isHeldExclusively 这 3 个方法，<br>其中 tryRelease，isHeldExclusively 是公平锁和非公平锁共有的，在 Sync 中实现。<br>1、tryRelease 尝试释放锁，每调用 tryRelease(1)一次，将 state 减去 1，当 state 为 0 的时候，释放锁成功，将独占锁的 owner 设为 null。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected final boolean tryRelease(int releases) &#123;
    int c &#x3D; getState() - releases;
    if (Thread.currentThread() !&#x3D; getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free &#x3D; false;
    if (c &#x3D;&#x3D; 0) &#123;
        free &#x3D; true;
        setExclusiveOwnerThread(null);
    &#125;
    setState(c);
    return free;
&#125;</code></pre>

<p>2、isHeldExclusively 判断独占锁的 owner 是不是当前线程</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected final boolean isHeldExclusively() &#123;
    return getExclusiveOwnerThread() &#x3D;&#x3D; Thread.currentThread();
&#125;</code></pre>

<h3 id="非公平锁"><a href="#非公平锁" class="headerlink" title="非公平锁"></a>非公平锁</h3><p>现在我们来看 NonfairSync 加锁的策略<br>1、查看同步队列锁的 state，不通过同步队列，通过 CAS 抢占独占锁，抢占成功，将当前线程设置成独占线程，state 增加 1。<br>2、获取不成功，走普通的获取锁的流程</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">final void lock() &#123;
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
&#125;</code></pre>

<p>其中 NonfairSync 在 acquire 获取锁的过程中，调用 tryAcquire 尝试获取锁。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected final boolean tryAcquire(int acquires) &#123;
    return nonfairTryAcquire(acquires);
&#125;</code></pre>

<p>在看 Sync 的 nonfairTryAcquire 方法实现如下，直接通过 CAS 获取锁</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">final boolean nonfairTryAcquire(int acquires) &#123;
    final Thread current &#x3D; Thread.currentThread();
    int c &#x3D; getState();
    &#x2F;* 锁没有被占用，将当前线程设置成独占锁的owner
    if (c &#x3D;&#x3D; 0) &#123;
        if (compareAndSetState(0, acquires)) &#123;
            setExclusiveOwnerThread(current);
            return true;
        &#125;
    &#125;
    else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123;
        &#x2F;* 增加独占锁的被线程的加锁次数 *&#x2F;
        int nextc &#x3D; c + acquires;
        if (nextc &lt;0) &#x2F;&#x2F; overflow
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);
        return true;
    &#125;
    return false;
&#125;</code></pre>

<h3 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h3><p>了解非公平锁的获取过程，我们再看下公平锁的加锁过程，了解其区别</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">final void lock() &#123;
    acquire(1);
&#125;</code></pre>

<p>通过 acquire 获取锁，没有像非公平锁通过 CAS 操作，直接抢占独占锁。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected final boolean tryAcquire(int acquires) &#123;
    final Thread current &#x3D; Thread.currentThread();
    int c &#x3D; getState();
    if (c &#x3D;&#x3D; 0) &#123;
        &#x2F;* hasQueuedPredecessors判断是否有比当前线程等待更久的线程在等待
         * 没有的话则通过CAS获取锁
         *&#x2F;
        if (!hasQueuedPredecessors() &amp;&amp;
            compareAndSetState(0, acquires)) &#123;
            setExclusiveOwnerThread(current);
            return true;
        &#125;
    &#125;
    else if (current &#x3D;&#x3D; getExclusiveOwnerThread()) &#123;
        int nextc &#x3D; c + acquires;
        if (nextc &lt;0)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        setState(nextc);
        return true;
    &#125;
    return false;
&#125;</code></pre>

<p>从上面的代码可以看出<br>1、公平锁与非公平锁的释放锁步骤是一致的<br>2、获取锁的过程不一致，非公平锁是让当前线程优先独占，而公平锁则是让等待时间最长的线程优先，非公平的可能让其他线程没机会执行，而公平的则可以让等待时间最长的先执行，但是性能上会差点。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Java引用类型</title>
    <url>/article/java/java-reference/</url>
    <content><![CDATA[<h2 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h2><p>每一个 Java 程序中的对象都会占用一定的计算机资源，最常见的，如：每个对象都会在堆空间上申请一定的内存空间。但是除了内存之外，对象还会占用其它资源，如文件句柄，端口，socket 等等。当你创建一个对象的时候，必须保证它在销毁的时候会释放它占用的资源。否则程序将会在 OOM 中结束它的使命。<br>在 Java 中数据内存分配发生在栈和堆中，对于栈中的变量（引用类型，基本类型）会在方法的退出时自动释放，对于 new 出来对象分配到堆中，不需要程序员来管理内存的分配和释放，Java 有自动进行内存管理的神器——垃圾回收器，垃圾回收器会自动回收那些不再使用的对象。那如何判断对象不再使用呢？就是不在被引用的对象。</p>
<h2 id="引用类型"><a href="#引用类型" class="headerlink" title="引用类型"></a>引用类型</h2><p>最早的 JDK 中只存在一个引用类型，这样就对于垃圾收集器来说所有的引用对象回收都是平等的。这样对于开发人员来说无法把控对象回收时机，所有对象回收都交给了垃圾收集器。<br>为了更灵活的控制对象的生命周期，在 JDK1.2 之后，引用被划分为强引用、软引用、弱引用、虚引用四种类型，每种类型有不同的生命周期，它们不同的地方就在于垃圾回收器对待它们会使用不同的处理方式。<strong>这 4 种级别由高到低依次为：强引用、软引用、弱引用和虚引用</strong>。</p>
<h3 id="1、强引用-StrongReference"><a href="#1、强引用-StrongReference" class="headerlink" title="1、强引用 StrongReference"></a>1、强引用 StrongReference</h3><p>就是我们最普遍使用的方式，如</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">Object obj &#x3D; new Object();</code></pre>

<p>这样对于我们，就是创建一个强引用，只要引用存在，jvm 就不会回收引用对应的空间，哪怕是报出内存空间不足的异常，当我们确定<strong>不需要使用 obj 对象时，可以将 obj 置为 null</strong>，这样 jvm 就认为它将不再使用，可以回收，但具体回收的时机还要看 gc 策略。</p>
<h3 id="2、软引用-SoftReference"><a href="#2、软引用-SoftReference" class="headerlink" title="2、软引用 SoftReference"></a>2、软引用 SoftReference</h3><p><strong>内存空间不足时，进行垃圾回收，如果内存空间足时，不会发生回收</strong>。<strong>软引用一般和引用队列结合使用</strong>，当对象回收时，会加入到关联的引用队列中。<br>应用场景，<strong>软引用可以很好的用来实现缓存</strong>，当 JVM 需要内存时，垃圾回收器就会回收这些只有被软引用指向的对象。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class SoftReferenceTest &#123;
    public static void main(String[] args) &#123;
        &#x2F;&#x2F; 原始强引用
        String welcome &#x3D; &quot;hello world&quot;;
        ReferenceQueue&lt;String&gt; refQueue &#x3D; new ReferenceQueue&lt;String&gt;();
        SoftReference&lt;String&gt; welcomeRef &#x3D; new SoftReference&lt;&gt;(welcome,refQueue);

        &#x2F;&#x2F; 置为空，这时可以垃圾回收
        welcome &#x3D; null;
        &#x2F;&#x2F; 这时不一定回收，只有空间不足时，才会回收
        System.gc();
        &#x2F;&#x2F; 这时可能会引用到，也可能引用不到，就看是否空间不足，是否发生了回收
        String welcomeValue &#x3D; welcomeRef.get();
        &#x2F;&#x2F; 如果垃圾回收了，则值不为空，如果还没有回收，则为空
        Reference&lt;? extends String&gt; valueRef &#x3D; refQueue.poll();
    &#125;
&#125;</code></pre>

<h3 id="3、弱引用-WeakReference"><a href="#3、弱引用-WeakReference" class="headerlink" title="3、弱引用 WeakReference"></a>3、弱引用 WeakReference</h3><p>与软引用相似，区别就是<strong>发生垃圾回收时，就会将弱引用对象进行回收，而不用考虑空间是否够用</strong>。<br>应用场景：<strong>弱引用非常适合存储元数据</strong>，例如：存储 ClassLoader 引用。如果没有类被加载，那么也没有指向 ClassLoader 的引用。一旦上一次的强引用被去除，只有弱引用的 ClassLoader 就会被回收</p>
<h3 id="4、虚引用-PhantomReference"><a href="#4、虚引用-PhantomReference" class="headerlink" title="4、虚引用 PhantomReference"></a>4、虚引用 PhantomReference</h3><p>与前面引用不同， <strong>虚引用的对象，在任何时间都可能被垃圾回收，它必须和引用队列联合使用</strong>，<br>当我们回收对象时，发现它还有虚引用，就会在内存回收前，将虛引用增加到引用队列中，<br>这时我们可以通过判断引用队列中，是否有相应的虚引用，然后在对象回收之前采取必须的措施。</p>
<h2 id="引用队列"><a href="#引用队列" class="headerlink" title="引用队列"></a>引用队列</h2><ul>
<li>引用队列由 java.lang.ref.<strong>ReferenceQueue</strong>类来表示，它用于保存被回收后对象的引用。当把软引用、弱引用和引用队列联合使用的时候，系统在回收被引用的对象之后，将把被回收对象对应的应用添加到关联的引用队列中。与软引用和弱引用不同的是，虚引用在对象被释放之后，将把已经回收对象对应的虚引用添加它的关联引用队列中，这是得可以在对象被回收之前采取行动。</li>
<li>软引用和弱引用可以单独使用，但是虚引用不能单独使用，单独使用虚引用没有太大的意义。虚引用的主要作用就是跟踪对象被垃圾回收的状态，程序可以通过检查与虚引用关联的引用队列中是否已经包含了该虚引用，从而了解虚引用所引用对象是否即将被回收。</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li><a href="https://www.jianshu.com/p/7cb6917c0970">强引用</a></li>
<li><a href="https://www.jianshu.com/p/a1872fa4ca7c">软引用</a></li>
<li><a href="https://www.jianshu.com/p/336c8902833b">虚引用</a></li>
</ol>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL B+树深度的了解</title>
    <url>/article/mysql/mysql-btree-depth/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/444448405">https://zhuanlan.zhihu.com/p/444448405</a></p>
</blockquote>
<p>以下从 B+树深度简单模拟计算，有两个主要特征决定了 B 树（或 B+ 树）的深度。</p>
<ol>
<li>数据库中的行数。我们将其称为 N。</li>
<li>索引键的大小。让我们称 B 为适合 B 树节点的键数。（有时 B 用于指代节点大小本身，而不是它持有的键数，但我希望这样看起来更直观。）</li>
</ol>
<p>给定这些数量，B 树的深度是 log B 为下标 N。那只是 (log N )&#x2F;log B。现在我们可以注意到小键意味着更大的 B，这会减少 (log N )&#x2F;log B。如果我们将键的字节大小减半，那么 B 树的深度将从 (log N )&#x2F;log B 到 (log N )&#x2F;log 2 B（适合树节点的键数量的两倍），这就是(log N )&#x2F;(1+log B )。</p>
<p>让我们在那里输入一些数字。假设您有 10 亿行，并且您目前可以在一个节点中容纳 64 个键。那么树的深度是 (log 10^ 9 )&#x2F; log 64 ≈ 30&#x2F;6 &#x3D; 5. 现在你用一半大小的字节的键重建树，你得到 log 10^9 &#x2F; log 128 ≈ 30&#x2F;7 &#x3D; 4.3。假设树的前 3 个级别在内存中，那么您从平均 2 次磁盘搜索到平均 1.3 次磁盘搜索，加速了 35%。</p>
<p>这是一个很好的节省，当然，假设您使用的新的、较小的键对查询同样有用。插入 B 树的时间也同样节省。插入是 O((log N )&#x2F;log B ) — 与点查询大致相同，最多为一个常数，但无论如何，您仍然会获得类似的加速。</p>
<p>范围查询呢？这里对树的深度并不那么敏感。但是在范围查询中，您寻找具有第一行的叶子，然后迭代 所有行，根据需要跳转到兄弟叶子，直到到达结束行。寻找第一片叶子的初始时间——这部分取决于树的深度</p>
<p>然而，这里有一个更微妙的效果。如果您有快速插入（例如，通过使用较小的键），您可以保留更多索引。拥有正确的索引可以对范围查询产生巨大的影响：没有索引可能意味着对少量行的范围查询可能变成全表扫描。一旦添加了正确的索引，我已经在此类查询中看到了 多个数量级的加速。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL死锁分析</title>
    <url>/article/mysql/mysql-deadlock/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>以前接触到的数据库死锁，都是批量更新时加锁顺序不一致而导致的死锁，但是上周却遇到了一个很难理解的死锁。借着这个机会又重新学习了一下 mysql 的死锁知识以及常见的死锁场景。在多方调研以及和同事们的讨论下终于发现了这个死锁问题的成因，收获颇多。虽然是后端程序员，我们不需要像 DBA 一样深入地去分析与锁相关的源码，但是如果我们能够掌握基本的死锁排查方法，对我们的日常开发还是大有裨益的。 PS：本文不会介绍死锁的基本知识，mysql 的加锁原理可以参考本文的参考资料提供的链接。</p>
<h2 id="死锁起因"><a href="#死锁起因" class="headerlink" title="死锁起因"></a>死锁起因</h2><p>先介绍一下数据库和表情况，因为涉及到公司内部真是的数据，所以以下都做了模拟，不会影响具体的分析。 我们采用的是 5.5 版本的 mysql 数据库，事务隔离级别是默认的 RR（Repeatable-Read），采用 innodb 引擎。假设存在 test 表：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">CREATE TABLE &#96;test&#96; (
  &#96;id&#96; int(11) unsigned NOT NULL AUTO_INCREMENT,
  &#96;a&#96; int(11) unsigned DEFAULT NULL,
  PRIMARY KEY (&#96;id&#96;),
  UNIQUE KEY &#96;a&#96; (&#96;a&#96;)
) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;100 DEFAULT CHARSET&#x3D;utf8;</code></pre>

<p>表的结构很简单，一个主键 id，另一个唯一索引 a。表里的数据如下：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; select * from test;
+----+------+
| id | a    |
+----+------+
|  1 |    1 |
|  2 |    2 |
|  4 |    4 |
+----+------+
3 rows in set (0.00 sec)</code></pre>

<p>出现死锁的操作如下：</p>
<table><colgroup><col width="5"></col><col width="30"></col><col width="30"></col></colgroup><thead><tr>
<th></th>
<th><strong>事务 1</strong></th>
<th><strong>事务 2</strong></th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td></td>
<td>begin</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>delete from test where a &#x3D; 2;</td>
</tr>
<tr>
<td>3</td>
<td>begin</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>delete from test where a &#x3D; 2; （事务 1 卡住）</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>提示出现死锁：ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction</td>
<td>insert into test (id, a) values (10, 2);</td>
</tr>
</tbody></table><p>然后我们可以通过 SHOW ENGINE INNODB STATUS;来查看死锁日志：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">------------------------
LATEST DETECTED DEADLOCK
------------------------
170219 13:31:31
*** (1) TRANSACTION:
TRANSACTION 2A8BD, ACTIVE 11 sec starting index read
mysql tables in use 1, locked 1
LOCK WAIT 2 lock struct(s), heap size 376, 1 row lock(s)
MySQL thread id 448218, OS thread handle 0x2abe5fb5d700, query id 18923238 renjun.fangcloud.net 121.41.41.92 root updating
delete from test where a &#x3D; 2
*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BD lock_mode X waiting
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;

*** (2) TRANSACTION:
TRANSACTION 2A8BC, ACTIVE 18 sec inserting
mysql tables in use 1, locked 1
4 lock struct(s), heap size 1248, 3 row lock(s), undo log entries 2
MySQL thread id 448217, OS thread handle 0x2abe5fd65700, query id 18923239 renjun.fangcloud.net 121.41.41.92 root update
insert into test (id,a) values (10,2)
*** (2) HOLDS THE LOCK(S):
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BC lock_mode X locks rec but not gap
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;

*** (2) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BC lock mode S waiting
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;

*** WE ROLL BACK TRANSACTION (1)</code></pre>

<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><h3 id="阅读死锁日志"><a href="#阅读死锁日志" class="headerlink" title="阅读死锁日志"></a>阅读死锁日志</h3><p>遇到死锁，第一步就是阅读死锁日志。死锁日志通常分为两部分，上半部分说明了事务 1 在等待什么锁：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">170219 13:31:31
*** (1) TRANSACTION:
TRANSACTION 2A8BD, ACTIVE 11 sec starting index read
mysql tables in use 1, locked 1
LOCK WAIT 2 lock struct(s), heap size 376, 1 row lock(s)
MySQL thread id 448218, OS thread handle 0x2abe5fb5d700, query id 18923238 renjun.fangcloud.net 121.41.41.92 root updating
delete from test where a &#x3D; 2
*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BD lock_mode X waiting
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;</code></pre>

<p>从日志里我们可以看到事务 1 当前正在执行 delete from test where a &#x3D; 2，该条语句正在申请索引 a 的 X 锁，所以提示 lock_mode X waiting。 然后日志的下半部分说明了事务 2 当前持有的锁以及等待的锁：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">*** (2) TRANSACTION:
TRANSACTION 2A8BC, ACTIVE 18 sec inserting
mysql tables in use 1, locked 1
4 lock struct(s), heap size 1248, 3 row lock(s), undo log entries 2
MySQL thread id 448217, OS thread handle 0x2abe5fd65700, query id 18923239 renjun.fangcloud.net 121.41.41.92 root update
insert into test (id,a) values (10,2)
*** (2) HOLDS THE LOCK(S):
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BC lock_mode X locks rec but not gap
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;

*** (2) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 0 page no 923 n bits 80 index &#96;a&#96; of table &#96;oauthdemo&#96;.&#96;test&#96; trx id 2A8BC lock mode S waiting
Record lock, heap no 3 PHYSICAL RECORD: n_fields 2; compact format; info bits 32
 0: len 4; hex 00000002; asc     ;;
 1: len 4; hex 00000002; asc     ;;</code></pre>

<p>从日志的 HOLDS THE LOCKS(S)块中我们可以看到事务 2 持有索引 a 的 X 锁，并且是记录锁（Record Lock）。该锁是通过事务 2 在步骤 2 执行的 delete 语句申请的。由于是 RR 隔离模式下的基于唯一索引的等值查询（Where a &#x3D; 2），所以会申请一个记录锁，而非 next-key 锁。</p>
<p>从日志的 WAITING FOR THIS LOCK TO BE GRANTED 块中我们可以看到事务 2 正在申请 S 锁，也就是共享锁。该锁是 insert into test (id,a) values (10,2)语句申请的。<strong>insert 语句在普通情况下是会申请排他锁，也就是 X 锁，但是这里出现了 S 锁。这是因为 a 字段是一个唯一索引，所以 insert 语句会在插入前进行一次 duplicate key 的检查，为了使这次检查成功，需要申请 S 锁防止其他事务对 a 字段进行修改。</strong></p>
<p>那么为什么该 S 锁会失败呢？这是对同一个字段的锁的申请是需要排队的。S 锁前面还有一个未申请成功的 X 锁，所以 S 锁必须等待，所以形成了循环等待，死锁出现了。通过阅读死锁日志，我们可以清楚地知道两个事务形成了怎样的循环等待，再加以分析，就可以逆向推断出循环等待的成因，也就是死锁形成的原因。</p>
<h3 id="死锁形成流程图"><a href="#死锁形成流程图" class="headerlink" title="死锁形成流程图"></a>死锁形成流程图</h3><p>为了让大家更好地理解死锁形成的原因，我们再通过表格的形式阐述死锁形成的流程：</p>
<table><colgroup><col width="5"></col><col width="30"></col><col width="30"></col></colgroup><thead><tr>
<th></th>
<th><strong>事务 1</strong></th>
<th><strong>事务 2</strong></th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td></td>
<td>begin</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>delete from test where a &#x3D; 2; 执行成功，事务 2 占有 a&#x3D;2 下的 X 锁，类型为记录锁。</td>
</tr>
<tr>
<td>3</td>
<td>begin</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>delete from test where a &#x3D; 2; 事务 1 希望申请 a&#x3D;2 下的 X 锁，但是由于事务 2 已经申请了一把 X 锁，两把 X 锁互斥，所以 X 锁申请进入锁请求队列。</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>出现死锁，事务 1 权重较小，所以被选择回滚（成为牺牲品）。</td>
<td>insert into test (id, a) values (10, 2); 由于 a 字段建立了唯一索引，所以需要申请 S 锁以便检查 duplicate key，由于插入的 a 的值还是 2，所以排在 X 锁后面。但是前面的 X 锁的申请只有在事务 2commit 或者 rollback 之后才能成功，此时形成了循环等待，死锁产生。</td>
</tr>
</tbody></table><p>‘id 41 page no 433805’</p>
<table><colgroup><col width="5"></col><col width="30"></col><col width="30"></col></colgroup><thead><tr>
<th></th>
<th><strong>事务 1</strong></th>
<th><strong>事务 2</strong></th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td></td>
<td>开始事务</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>delete from fdc_fulfil_net_line_agg WHERE uk_fulfil_net &#x3D; ‘433805’; 执行成功，事务 2 占有 uk_fulfil_net &#x3D; ‘433805’下的 X No Gap 锁(lock_mode X locks rec but not gap)，类型为记录锁。</td>
</tr>
<tr>
<td>3</td>
<td>开始事务</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>delete from fdc_fulfil_net_line_agg WHERE uk_fulfil_net &#x3D; ‘433805’; 事务 1 希望申请 uk_fulfil_net &#x3D; ‘433805’下的 X No Gap 锁，但是由于事务 2 已经申请了一把 X No Gap 锁，两把 X 锁互斥，所以 X 锁申请进入锁请求队列。</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>出现死锁，事务 1 权重较小，所以被选择回滚（成为牺牲品）。</td>
<td>insert into fdc_fulfil_net_line_agg (id, uk_fulfil_net) values (xx, ‘433805’); 由于 uk_fulfil_net 字段建立了唯一索引，所以需要申请 S 锁以便检查 duplicate key，由于插入的 uk_fulfil_net 的值还是 433805，所以排在 X 锁后面。但是前面的 X 锁的申请只有在事务 2commit 或者 rollback 之后才能成功，此时形成了循环等待，死锁产生。</td>
</tr>
</tbody></table><h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><p>在排查死锁的过程中，有个同事还发现了上述场景会产生另一种死锁，该场景无法通过手工复现，只有高并发场景下才有可能复现。<br>该死锁对应的日志这里就不贴出了，与上一个死锁的核心差别是事务 2 等待的锁从 S 锁换成了 X 锁，也就是 lock_mode X locks gap before rec insert intention waiting。我们还是通过表格来详细说明该死锁产生的流程：</p>
<table><colgroup><col width="5"></col><col width="30"></col><col width="30"></col></colgroup><thead><tr>
<th></th>
<th><strong>事务 1</strong></th>
<th><strong>事务 2</strong></th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td></td>
<td>begin</td>
</tr>
<tr>
<td>2</td>
<td></td>
<td>delete from test where a &#x3D; 2; 执行成功，事务 2 占有 a&#x3D;2 下的 X 锁，类型为记录锁。</td>
</tr>
<tr>
<td>3</td>
<td>begin</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td></td>
<td>【insert 第 1 阶段】insert into test (id, a) values (10, 2); 事务 2 申请 S 锁进行 duplicate key 进行检查。检查成功。</td>
</tr>
<tr>
<td>5</td>
<td>delete from test where a &#x3D; 2; 事务 1 希望申请 a&#x3D;2 下的 X 锁，但是由于事务 2 已经申请了一把 X 锁，两把 X 锁互斥，所以 X 锁申请进入锁请求队列。</td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>出现死锁，事务 1 权重较小，所以被选择回滚（成为牺牲品）。</td>
<td>【insert 第 2 阶段】insert into test (id, a) values (10, 2); 事务 2 开始插入数据，S 锁升级为 X 锁，类型为 insert intention。同理，X 锁进入队列排队，形成循环等待，死锁产生。</td>
</tr>
</tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>排查死锁时，首先需要根据死锁日志分析循环等待的场景，然后根据当前各个事务执行的 SQL 分析出加锁类型以及顺序，逆向推断出如何形成循环等待，这样就能找到死锁产生的原因了。<br>PS：上述分析都是基于经验的推断，希望其他小伙伴们能够指出当中的错误以及不足指出，谢谢！</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>Mysql 加锁处理分析<br>一个最不可思议的 Mysql 死锁分析<br>Innodb 锁系统之如何阅读死锁日志<br>源码分析 insert 和 delete 操作的加锁<br>Innodb 锁相关源码翻译</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Deadlock</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL事务和隔离级别</title>
    <url>/article/mysql/mysql-transaction/</url>
    <content><![CDATA[<h2 id="1、数据库事务-ACID-特性"><a href="#1、数据库事务-ACID-特性" class="headerlink" title="1、数据库事务 ACID 特性"></a>1、数据库事务 ACID 特性</h2><p>数据库事务的 4 个特性：</p>
<ul>
<li><strong>原子性(Atomicity)</strong></li>
</ul>
<p>事务中的多个操作，不可分割，要么都成功，要么都失败，事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做。</p>
<ul>
<li><strong>一致性(Consistency)</strong></li>
</ul>
<p>事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是不一致的状态。</p>
<ul>
<li><strong>隔离性(Isolation)</strong></li>
</ul>
<p>多个事务之间就像是串行执行一样，不相互影响，一个事务的执行不能其它事务干扰。即一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。</p>
<ul>
<li><strong>持续性(Durability)</strong></li>
</ul>
<p>事务提交后被持久化到永久存储，也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。</p>
<h2 id="2、隔离性"><a href="#2、隔离性" class="headerlink" title="2、隔离性"></a>2、隔离性</h2><p>其中 隔离性 分为了四种：</p>
<ul>
<li><strong>READ UNCOMMITTED</strong></li>
</ul>
<p>可以读取未提交的数据，未提交的数据称为脏数据，所以又称脏读。此时：幻读，不可重复读和脏读均允许；</p>
<ul>
<li><strong>READ COMMITTED</strong></li>
</ul>
<p>只能读取已经提交的数据；此时：允许幻读和不可重复读，但不允许脏读，所以 RC 隔离级别要求解决脏读；</p>
<ul>
<li><strong>REPEATABLE READ</strong></li>
</ul>
<p>同一个事务中多次执行同一个 select,读取到的数据没有发生改变；此时允许幻读，但不允许不可重复读和脏读，所以 RR 隔离级别要求解决不可重复读；事务 A 读取与搜索条件相匹配的若干行。事务 B 以插入或删除行等方式来修改事务 A 的结果集，然后再提交。事务 A 再读取时，却发现数据发生了变化，造成了幻读（MySQL 默认的隔离级别）。</p>
<ul>
<li><strong>SERIALIZABLE</strong></li>
</ul>
<p>Serializable 是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。</p>
<h2 id="3、几个概念"><a href="#3、几个概念" class="headerlink" title="3、几个概念"></a>3、几个概念</h2><p><strong>脏读</strong>：可以读取未提交的数据。RC 要求解决脏读；<br><strong>不可重复读</strong>：同一个事务中多次执行同一个 select, 读取到的数据发生了改变(被其它事务 update 并且提交)；<br><strong>可重复读</strong>：同一个事务中多次执行同一个 select, 读取到的数据没有发生改变(一般使用 MVCC 实现)；RR 各级级别要求达到可重复读的标准；<br><strong>幻读</strong>：同一个事务中多次执行同一个 select, 读取到的数据行发生改变。也就是行数减少或者增加了(被其它事务 delete&#x2F;insert 并且提交)。SERIALIZABLE 要求解决幻读问题；</p>
<p><strong>读提交，在读取一条记录时会出现不可重复读；</strong><br><strong>可重复读，通过对事务里面的读写操作加锁解决了读提交的问题，但是对统计某个范围内的记录数量，还是会产生幻读。</strong><br><strong>避免不可重复读需要锁行</strong>，<strong>避免幻影读则需要锁表。</strong></p>
<p>这里一定要区分 <strong>不可重复读 和 幻读：</strong></p>
<ul>
<li><strong>不可重复读重点在于 update 和 delete</strong>： 同样的条件的 select, 你读取过的数据, 再次读取出来发现值不一样了</li>
<li>幻读的重点在于<strong>新增或者删除</strong>： 同样的条件的 select, 第 1 次和第 2 次读出来的记录数不一样</li>
</ul>
<p>从结果上来看, 两者都是为多次读取的结果不一致。但如果你从实现的角度来看, 它们的区别就比较大： 对于前者, 在 RC 下只需要锁住满足条件的记录，就可以避免被其它事务修改，也就是 select for update, select in share mode; RR 隔离下使用 MVCC 实现可重复读； 对于后者, 要锁住满足条件的记录及所有这些记录之间的 gap，也就是需要 gap lock。</p>
<h3 id="数据库锁"><a href="#数据库锁" class="headerlink" title="数据库锁"></a>数据库锁</h3><p>对于解决<strong>可重复读</strong>需要锁行；对于解决<strong>幻影读</strong>则需要锁表。目前主要使用<strong>悲观锁和乐观锁</strong>来实现这两种隔离级别。<strong>可重复读</strong>，第一次读取到数据后，就将这些数据加锁，其它事务无法修改这些数据；<strong>幻影读，</strong>读用读锁，写用写锁，读锁和写锁互斥，可有效的避免幻读、不可重复读、脏读等问题，但会极大的降低数据库的并发能力。<br><strong>1）悲观锁</strong><br>对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。<br><strong>悲观锁</strong>的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。<br>在<strong>悲观锁</strong>的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据，来保证操作最大程度的独占性。但随之而来的就是<strong>数据库性能的大量开销</strong>，特别是对长事务而言，这样的开销往往无法承受。<br><strong>2）乐观锁</strong><br><strong>乐观锁</strong>机制采取了更加宽松的加锁机制，在一定程度上解决了这个问题。<br>乐观锁大多是基于数据版本（Version）记录机制实现，为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个“version”字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。要说明的是，MVCC 的实现没有固定的规范，每个数据库都会有不同的实现方式（这里讨论的是 InnoDB 的 MVCC）。</p>
<p>目前 MySQL、ORACLE、PostgreSQL 等成熟的数据库，出于性能考虑，都是使用了以<strong>乐观锁</strong>为理论基础的 MVCC（多版本并发控制）来避免这两种问题。</p>
<h3 id="隔离级别"><a href="#隔离级别" class="headerlink" title="隔离级别"></a>隔离级别</h3><table><thead><tr>
<th>隔离级别</th>
<th>脏读（Dirty Read）</th>
<th>不可重复（NonRepeatable Read）</th>
<th>幻读 （Phantom Read）</th>
</tr>
</thead><tbody><tr>
<td>未提交读（Read uncommitted）</td>
<td>可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>已提交读（Read committed）</td>
<td>不可能</td>
<td>可能</td>
<td>可能</td>
</tr>
<tr>
<td>可重复读（Repeatable read）</td>
<td>不可能</td>
<td>不可能</td>
<td>可能</td>
</tr>
<tr>
<td>可串行化（Serializable ）</td>
<td>不可能</td>
<td>不可能</td>
<td>不可能</td>
</tr>
</tbody></table><h2 id="4、实例"><a href="#4、实例" class="headerlink" title="4、实例"></a>4、实例</h2><p>除了 MySQL 默认采用 RR 隔离级别之外，其它几大数据库都是采用 RC 隔离级别。</p>
<p>但是他们的实现也是极其不一样的。Oracle 仅仅实现了 RC 和 SERIALIZABLE 隔离级别。默认采用 RC 隔离级别，解决了脏读。但是允许不可重复读和幻读。其 SERIALIZABLE 则解决了脏读、不可重复读、幻读。</p>
<p>MySQL 的实现：MySQL 默认采用 RR 隔离级别，SQL 标准是要求 RR 解决不可重复读的问题，但是因为 MySQL 采用了<strong>gap lock</strong>，所以<strong>实际上 MySQL 的 RR 隔离级别也解决了幻读的问题</strong>。<br>那么 MySQL 的 SERIALIZABLE 是怎么回事呢？其实 MySQL 的 SERIALIZABLE 采用了经典的实现方式，对读和写都加锁。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">create table &#96;test_trx&#96; (
&#96;id&#96; int(11) NOT NULL AUTO_INCREMENT,
&#96;value&#96; int(11) NOT NULL DEFAULT 0,
PRIMARY KEY(&#96;id&#96;)
) ENGINE&#x3D;InnoDB AUTO_INCREMENT&#x3D;1 DEFAULT  CHARSET&#x3D;utf8;

insert into test_trx(value) value(1),(2),(3),(4),(5);</code></pre>

<p>下面以例子来说明上面上面的情况</p>
<h3 id="1-脏读"><a href="#1-脏读" class="headerlink" title="1) 脏读"></a>1) 脏读</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648310234100-5c0a65d1-3b81-47ce-a200-2e7006f6f49b.png#clientId=u7c1ec514-fc0d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=497&id=u2cb52a02&margin=%5Bobject%20Object%5D&name=image.png&originHeight=994&originWidth=1544&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=98969&status=done&style=none&taskId=u2963e192-f7fb-4450-983b-b1d9b98a6b8&title=&width=772" alt="image.png"></p>
<blockquote>
<p>未提交隔离级别, 事务 1 中更新的 value,未提交,事务 2 中可以看到、造成脏读</p>
</blockquote>
<h3 id="2-虚读-不可重复读"><a href="#2-虚读-不可重复读" class="headerlink" title="2) 虚读(不可重复读)"></a>2) 虚读(不可重复读)</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648310714617-0253ccac-7317-4a0c-bd13-877ff146983a.png#clientId=u7c1ec514-fc0d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=957&id=uafea7c26&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1914&originWidth=1544&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=171359&status=done&style=none&taskId=u74adf793-a0d9-4ed3-a8a3-83903a081a2&title=&width=772" alt="image.png"></p>
<blockquote>
<p>读提交隔离级别,事务 2 在同一个事务中,读取事务 1 提交后的 update 更改</p>
</blockquote>
<h3 id="3-幻读"><a href="#3-幻读" class="headerlink" title="3) 幻读"></a>3) 幻读</h3><p>看下大部分 mysql 所说的幻读现象<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648311001789-6023982f-c8fb-459e-8aa2-09095e18c719.png#clientId=u7c1ec514-fc0d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=1132&id=ue0a170e1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=2264&originWidth=1544&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=223126&status=done&style=none&taskId=u5365eae2-34c4-4f1f-a33b-e8956a94bf3&title=&width=772" alt="image.png"></p>
<blockquote>
<p>事务 2,查询记录里面没有记录 7,插入 7 的时候提示主键重复,幻读.</p>
</blockquote>
<p>RR 事务隔离级别号称可以解决幻读的问题（通过当前读加锁来实现）</p>
<h2 id="5、gap-锁（当前读）解决幻读问题"><a href="#5、gap-锁（当前读）解决幻读问题" class="headerlink" title="5、gap 锁（当前读）解决幻读问题"></a>5、gap 锁（当前读）解决幻读问题</h2><p>mysql 说对数据加锁不管共享锁还是互斥锁就能解决幻读的问题</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">select * from test_trx where id between 1 and 7 lock in share mode;

select * from test_trx where id between 1 and 7 for update;</code></pre>

<p>通过 gap 锁+当前读解决幻读问题,但是 lock in share mode 和 for update 不是标准的 sql 语法.</p>
<h2 id="6、RR-没有解决的幻读"><a href="#6、RR-没有解决的幻读" class="headerlink" title="6、RR 没有解决的幻读"></a>6、RR 没有解决的幻读</h2><p>场景：我们知道 grap 锁能够将右边的记录进行加锁，因此我要统计表记录的数量，我只需要对最大记录加锁就行了</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>MVCC多版本并发控制</title>
    <url>/article/mysql/mysql-mvcc/</url>
    <content><![CDATA[<p><a href="https://cloud.tencent.com/developer/article/1488871">https://cloud.tencent.com/developer/article/1488871</a><br><a href="https://zhuanlan.zhihu.com/p/40208895">https://zhuanlan.zhihu.com/p/40208895</a><br><a href="https://blog.csdn.net/u014532775/article/details/107018538">https://blog.csdn.net/u014532775/article/details/107018538</a><br><a href="https://www.jianshu.com/p/0ef46997c300">https://www.jianshu.com/p/0ef46997c300</a></p>
<p><a href="https://blog.csdn.net/fuzhongmin05/article/details/91351933">https://blog.csdn.net/fuzhongmin05/article/details/91351933</a><br>redolog 和 undolog<br><a href="https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html">https://www.cnblogs.com/f-ck-need-u/archive/2018/05/08/9010872.html</a></p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Java锁（四）ConditionObject分析</title>
    <url>/article/java/java-conditionobject/</url>
    <content><![CDATA[<p>在讲 ConditionObject 之前，先讲解下条件队列。条件队列能够使得一组线程能够通过某种方式来等待特定的条件变成真，条件队列中的成员是一个个正在等待状态的线程。条件队列提供了一种挂起方式，当现场等待的条件非真时，挂起自己并释放锁，一旦等待条件为真，则立即醒来。</p>
<h2 id="条件队列主要功能"><a href="#条件队列主要功能" class="headerlink" title="条件队列主要功能"></a>条件队列主要功能</h2><h3 id="1、隐式锁对应的条件队列"><a href="#1、隐式锁对应的条件队列" class="headerlink" title="1、隐式锁对应的条件队列"></a>1、隐式锁对应的条件队列</h3><p>对象的内置锁（synchronized 语义对应的同步机制），关联着一个内置的条件队列。Object 的 wait&#x2F;notify&#x2F;notifyAll 等方法构成了内部条件队列的 API（即将内部锁与内部条件队列关联的机制）。 内部条件队列是需要内置锁保护的，需要调用对象 X 中的条件队列，必须持有对象 X 上的锁。这是因为状态处于并发环境下，“等待依赖状态的某个条件”与“维护状态的一致性”是绑定在一起的。</p>
<h3 id="2、显式锁对应的条件队列"><a href="#2、显式锁对应的条件队列" class="headerlink" title="2、显式锁对应的条件队列"></a>2、显式锁对应的条件队列</h3><p>与内置锁对应的是显式锁，显式锁关联的条件队列是显式条件队列。内置锁的局限是每个内置锁只能关联一个条件队列，当线程需要等待多个条件时，则需要同时获取多个内置锁。 显式锁可以与多个条件队列关联，Condition 是显式锁的条件队列，它是 Object 的 wait&#x2F;notify&#x2F;notifyAll 等方法的扩展。提供了在一个对象上设置多个等待集合的功能，即一个对象上设置多个等待条件。</p>
<h3 id="3、condition-使用"><a href="#3、condition-使用" class="headerlink" title="3、condition 使用"></a>3、condition 使用</h3><p>Condition 也称为条件队列，与内置锁关联的条件队列类似，它是一种广义的内置条件队列。它提供给线程一种方式使得该线程在调用 wait 方法后执行挂起操作，直到线程的等待的某个条件为真时被唤醒。 条件队列必须跟锁一起使用的，因为对共享状态变量的访问发生在多线程环境下，原理与内部条件队列一样。一个 Condition 的实例必须跟一个 Lock 绑定， Condition 一般作为 Lock 的内部类现。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">class BoundedBuffer &#123;
  final Lock lock &#x3D; new ReentrantLock();
  final Condition notFull  &#x3D; lock.newCondition();
  final Condition notEmpty &#x3D; lock.newCondition();

  final Object[] items &#x3D; new Object[100];
  int putptr, takeptr, count;

  public void put(Object x) throws InterruptedException &#123;
    lock.lock();
    try &#123;
      while (count &#x3D;&#x3D; items.length)
        notFull.await();
      items[putptr] &#x3D; x;
      if (++putptr &#x3D;&#x3D; items.length) putptr &#x3D; 0;
      ++count;
      notEmpty.signal();
    &#125; finally &#123;
      lock.unlock();
    &#125;
  &#125;

  public Object take() throws InterruptedException &#123;
    lock.lock();
    try &#123;
      while (count &#x3D;&#x3D; 0)
        notEmpty.await();
      Object x &#x3D; items[takeptr];
      if (++takeptr &#x3D;&#x3D; items.length) takeptr &#x3D; 0;
      --count;
      notFull.signal();
      return x;
    &#125; finally &#123;
      lock.unlock();
    &#125;
  &#125;

&#125;</code></pre>

<h3 id="4、AQS-对条件队列类图"><a href="#4、AQS-对条件队列类图" class="headerlink" title="4、AQS 对条件队列类图"></a>4、AQS 对条件队列类图</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649590734865-739bf34e-78fb-4a01-8c21-2dbedd5a0aa8.png#clientId=ueca12249-0176-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7fcdf467&margin=%5Bobject%20Object%5D&name=image.png&originHeight=556&originWidth=656&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=57897&status=done&style=none&taskId=ufc51b264-532e-4873-aaac-2848a6b76ea&title=" alt="image.png"></p>
<h3 id="5、条件队列的节点状态"><a href="#5、条件队列的节点状态" class="headerlink" title="5、条件队列的节点状态"></a>5、条件队列的节点状态</h3><p>调用条件队列的等待操作，会设置节点的 waitingStatus 为 Condition，标识当前节点正处于条件队列中。状态转换图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649590734907-8867f1f1-95be-438f-bc78-1eb6a9e72484.png#clientId=ueca12249-0176-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue8d1fd2b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=469&originWidth=1186&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=76862&status=done&style=none&taskId=ucb02a0ae-ca4e-483b-8600-af99a1423cc&title=" alt="image.png"><br>Node 的各个状态的主要作用，Cancelled 主要是解决线程在持有锁时被外部中断的逻辑，AQS 的可中断锁获取方法 lockInterrutible()是基于该状态实现的，显示锁必须手动释放锁，尤其是有中断的环境中，一个线程被中断可能仍然持有锁，所以必须注意在 finally 中 unlock。Condition 则是条件队列的等待操作，是 Lock 与条件队列关联的基础。Signal 是阻塞后继线程的标识。</p>
<h3 id="6、条件队列的等待和唤醒操作"><a href="#6、条件队列的等待和唤醒操作" class="headerlink" title="6、条件队列的等待和唤醒操作"></a>6、条件队列的等待和唤醒操作</h3><p>条件队列上的等待和唤醒操作，本质上是节点在 AQS 线程等待队列和条件队列之间相互转移的过程，当需要等待某个条件时，线程会将当前节点添加到条件队列中，并释放锁；当某个线程执行条件队列的唤醒操作，则会将条件队列的节点转移到 AQS 等待队列。每个 Condition 就是一个条件队列，可以通过 Lock 的 newCondition 创建多个等待条件。操作流程如下：<br>条件队列等待 await 如下所示</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public final void await() throws InterruptedException &#123;
    if (Thread.interrupted())
        throw new InterruptedException();
    &#x2F;&#x2F; 将当前线程所在的节点添加到条件等待队列里面
    Node node &#x3D; addConditionWaiter();
    &#x2F;&#x2F; 释放并唤醒后续节点
    int savedState &#x3D; fullyRelease(node);
    int interruptMode &#x3D; 0;
    &#x2F;&#x2F; node不在同步队列中，挂起当前线程，
    while (!isOnSyncQueue(node)) &#123;
        LockSupport.park(this);
        &#x2F;&#x2F; 检查在等待时是否中断，如果中断，返回中断模式
        if ((interruptMode &#x3D; checkInterruptWhileWaiting(node)) !&#x3D; 0)
            break;
    &#125;
    &#x2F;&#x2F; 当前节点进入到队列中，并自旋
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode !&#x3D; THROW_IE)
        interruptMode &#x3D; REINTERRUPT;
    &#x2F;&#x2F; 当前节点的下一个等待者，不为空，移除所有取消的
    if (node.nextWaiter !&#x3D; null)
        unlinkCancelledWaiters();
    if (interruptMode !&#x3D; 0)
        reportInterruptAfterWait(interruptMode);
&#125;

&#x2F;**
 * 添加一个新的等待者到条件等待队列里面
 *&#x2F;
private Node addConditionWaiter() &#123;
    Node t &#x3D; lastWaiter;
    &#x2F;&#x2F; 如果lastWaiter不为状态节点，移除
    if (t !&#x3D; null &amp;&amp; t.waitStatus !&#x3D; Node.CONDITION) &#123;
        unlinkCancelledWaiters();
        t &#x3D; lastWaiter;
    &#125;
    &#x2F;&#x2F; 将当前线程关联的node添加到条件队列中
    Node node &#x3D; new Node(Thread.currentThread(), Node.CONDITION);
    if (t &#x3D;&#x3D; null)
        firstWaiter &#x3D; node;
    else
        t.nextWaiter &#x3D; node;
    lastWaiter &#x3D; node;
    return node;
&#125;

&#x2F;**
 * 使用当前的state值调用release方法，返回保存的state值
 * 失败时抛出异常，并将节点设置成在Node.CANCELLED，
 * @param node 等待的状态节点
 * @return 返回上一次同步队列的state状态
 *&#x2F;
final int fullyRelease(Node node) &#123;
    boolean failed &#x3D; true;
    try &#123;
        &#x2F;&#x2F; 获取当前AQS的状态值state
        int savedState &#x3D; getState();
        &#x2F;&#x2F; 释放，并唤醒后继节点
        if (release(savedState)) &#123;
            failed &#x3D; false;
            return savedState;
        &#125; else &#123;
            &#x2F;&#x2F; 释放失败，抛出异常，并且在finally中将节点设置成在Node.CANCELLED
            throw new IllegalMonitorStateException();
        &#125;
    &#125; finally &#123;
        if (failed)
            node.waitStatus &#x3D; Node.CANCELLED;
    &#125;
&#125;

public final boolean release(int arg) &#123;
    if (tryRelease(arg)) &#123;
        Node h &#x3D; head;
        if (h !&#x3D; null &amp;&amp; h.waitStatus !&#x3D; 0)
            unparkSuccessor(h);&#x2F;&#x2F;unblock，唤醒head的后继节点
        return true;
    &#125;
    return false;
&#125;</code></pre>

<p>await 等待的流程如下图所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649590734932-a81a3a72-c37b-4bff-939b-216b5627c773.png#clientId=ueca12249-0176-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u3164b185&margin=%5Bobject%20Object%5D&name=image.png&originHeight=919&originWidth=692&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=90215&status=done&style=none&taskId=u54118d76-26e9-4148-ad0f-073d21c68ba&title=" alt="image.png"></p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * Moves the longest-waiting thread, if one exists, from the
 * wait queue for this condition to the wait queue for the
 * owning lock.
 *
 * @throws IllegalMonitorStateException if &#123;@link &#x3D;isHeldExclusively&#125;
 *         returns &#123;@code false&#125;
 *&#x2F;
public final void signal() &#123;
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first &#x3D; firstWaiter;
    if (first !&#x3D; null)
        doSignal(first);
&#125;

&#x2F;**
 * Moves all threads from the wait queue for this condition to
 * the wait queue for the owning lock.
 *
 * @throws IllegalMonitorStateException if &#123;@link &#x3D;isHeldExclusively&#125;
 *         returns &#123;@code false&#125;
 *&#x2F;
public final void signalAll() &#123;
    if (!isHeldExclusively())
        throw new IllegalMonitorStateException();
    Node first &#x3D; firstWaiter;
    if (first !&#x3D; null)
        doSignalAll(first);
&#125;

&#x2F;**
 * Removes and transfers nodes until hit non-cancelled one or
 * null. Split out from signal in part to encourage compilers
 * to inline the case of no waiters.
 * @param first (non-null) the first node on condition queue
 *&#x2F;
private void doSignal(Node first) &#123;
    do &#123;
        if ( (firstWaiter &#x3D; first.nextWaiter) &#x3D;&#x3D; null)
            lastWaiter &#x3D; null;
        first.nextWaiter &#x3D; null;
    &#125; while (!transferForSignal(first) &amp;&amp;
             (first &#x3D; firstWaiter) !&#x3D; null);
&#125;

&#x2F;**
 * Removes and transfers all nodes.
 * @param first (non-null) the first node on condition queue
 *&#x2F;
private void doSignalAll(Node first) &#123;
    lastWaiter &#x3D; firstWaiter &#x3D; null;
    do &#123;
        Node next &#x3D; first.nextWaiter;
        first.nextWaiter &#x3D; null;
        transferForSignal(first);
        first &#x3D; next;
    &#125; while (first !&#x3D; null);
&#125;

&#x2F;**
 * 将节点从条件队列转到同步队列中
 * 成功，返回true
 * 否则节点被取消，在收到信号前
 *&#x2F;
final boolean transferForSignal(Node node) &#123;
    &#x2F;*
     * 节点被取消，不能改变waitStatus
     *&#x2F;
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;

    &#x2F;*
     * 将节点粘到队列中，尝试设置前驱节点的waitStatus，表明线程可能正在等待
     * 如果取消或者尝试设置waitStatus失败，唤醒重新同步
     * 在这种情况下waitStatus会出错，但是是瞬时无害的
     *&#x2F;
    Node p &#x3D; enq(node);
    int ws &#x3D; p.waitStatus;
    if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
        LockSupport.unpark(node.thread);
    return true;
&#125;</code></pre>

<p>signal 通知条件等待<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649590734733-d11f6304-b1ff-4ca4-9a96-05c753d436f8.png#clientId=ueca12249-0176-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua9bda77d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=270&originWidth=466&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=20651&status=done&style=none&taskId=u00f9d5b8-b2cf-4cad-951e-ad13f639c9e&title=" alt="image.png"><br>显式条件队列弥补内置条件队列只能关联一个条件的缺陷，同时继承了 Lock 对象的公平性。在 Condition 对象中，与 Object 的 wait&#x2F;notify&#x2F;notifyAll 对应的扩展方法是 await&#x2F;signal&#x2F;signallAll，同时也具有 Object 的这三个方法，所以使用的时候需要注意使用版本的正确。另外，显式锁必须遵从特定的使用规范，先 lock 在 finally 中 unlock，以确保锁必然会被正确释放。<br>此外，AQS 的两个队列都是链表队列，关联类的方法的都相当简洁，尤其是节点移除队列操作过程中，都及时释放了所占内存。读源码，可以学习到一种编码的严谨性，锻炼自己关注 GC 的意识。这是我见到过的第三处及时释放 GC 的的代码了。从最初的 ArrayList 的元素 remove 中，然后是 HashMap 的动态扩容数组转移操作，最近看 AQS 的元素唤醒和锁释放操作。关注 GC 的确是最近开始形成的一种编程意识。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Lock</tag>
      </tags>
  </entry>
  <entry>
    <title>Nacos2动态配置</title>
    <url>/article/nacos/nacos-config/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/375912272">https://zhuanlan.zhihu.com/p/375912272</a> &gt; <a href="https://www.pianshen.com/article/4989271413/">https://www.pianshen.com/article/4989271413/</a><br>Nacos 配置实时更新原理分析<br><a href="https://www.jianshu.com/p/acb9b1093a54">https://www.jianshu.com/p/acb9b1093a54</a></p>
</blockquote>
<h2 id="动态配置场景"><a href="#动态配置场景" class="headerlink" title="动态配置场景"></a>动态配置场景</h2><p>了解了动态配置管理的效果之后，我们知道了大概的原理了，Nacos 服务端保存了配置信息，客户端连接到服务端之后，根据 dataID，group 可以获取到具体的配置信息，当服务端的配置发生变更时，客户端会收到通知。当客户端拿到变更后的最新配置信息后，就可以做自己的处理了，这非常有用，所有需要使用配置的场景都可以通过 Nacos 来进行管理。<br>可以说 Nacos 有很多的适用场景，包括但不限于以下这些情况：</p>
<ul>
<li>数据库连接信息</li>
<li>限流规则和降级开关</li>
<li>流量的动态调度</li>
</ul>
<p>看过我的 Sentinel 系列文章的同学可能知道，其中有一篇专门介绍集群限流环境搭建的文章，就是通过 Nacos 来创建动态规则的。</p>
<h2 id="推还是拉"><a href="#推还是拉" class="headerlink" title="推还是拉"></a>推还是拉</h2><p>现在我们了解了 Nacos 的配置管理的功能了，但是有一个问题我们需要弄明白，那就是 Nacos 客户端是怎么实时获取到 Nacos 服务端的最新数据的。<br>其实客户端和服务端之间的数据交互，无外乎两种情况：</p>
<ul>
<li>服务端推数据给客户端</li>
<li>客户端从服务端拉数据</li>
</ul>
<p>那到底是推还是拉呢，从 Nacos 客户端通过 Listener 来接收最新数据的这个做法来看，感觉像是服务端推的数据，但是不能想当然，要想知道答案，最快最准确的方法就是从源码中去寻找。</p>
<h3 id="创建-ConfigService"><a href="#创建-ConfigService" class="headerlink" title="创建 ConfigService"></a>创建 ConfigService</h3><p>从我们的 demo 中可以知道，首先是创建了一个 ConfigService。而 ConfigService 是通过 ConfigFactory 类创建的，createConfigService 如下图所示：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
 * Create Config.
 *
 * @param properties init param
 * @return ConfigService
 * @throws NacosException Exception
 *&#x2F;
public static ConfigService createConfigService(Properties properties) throws NacosException &#123;
    try &#123;
        Class&lt;?&gt; driverImplClass &#x3D; Class.forName(&quot;com.alibaba.nacos.client.config.NacosConfigService&quot;);
        Constructor constructor &#x3D; driverImplClass.getConstructor(Properties.class);
        ConfigService vendorImpl &#x3D; (ConfigService) constructor.newInstance(properties);
        return vendorImpl;
    &#125; catch (Throwable e) &#123;
        throw new NacosException(NacosException.CLIENT_INVALID_PARAM, e);
    &#125;
&#125;</code></pre>

<p>可以看到实际是通过反射调用了 NacosConfigService 的构造方法来创建 ConfigService 的，而且是有一个 Properties 参数的构造方法。<br>需要注意的是，这里并没有通过单例或者缓存技术，也就是说每次调用都会重新创建一个 ConfigService 的实例。</p>
<h3 id="实例化-ConfigService"><a href="#实例化-ConfigService" class="headerlink" title="实例化 ConfigService"></a>实例化 ConfigService</h3><p>现在我们来看 NacosConfigService 的构造方法，看看 ConfigService 是怎么实例化的，如下图所示：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
* will be deleted in 2.0 later versions
*&#x2F;
@Deprecated
ServerHttpAgent agent &#x3D; null;

&#x2F;**
* long polling.
*&#x2F;
private final ClientWorker worker;

private String namespace;

private final ConfigFilterChainManager configFilterChainManager;

public NacosConfigService(Properties properties) throws NacosException &#123;
    ValidatorUtils.checkInitParam(properties);

    initNamespace(properties);
    this.configFilterChainManager &#x3D; new ConfigFilterChainManager(properties);
    ServerListManager serverListManager &#x3D; new ServerListManager(properties);
    serverListManager.start();

    this.worker &#x3D; new ClientWorker(this.configFilterChainManager, serverListManager, properties);
    &#x2F;&#x2F; will be deleted in 2.0 later versions
    agent &#x3D; new ServerHttpAgent(serverListManager);
&#125;</code></pre>

<p>实例化时主要是初始化了两个对象，他们分别是：</p>
<ul>
<li>HttpAgent</li>
<li>ClientWorker</li>
</ul>
<h4 id="HttpAgent"><a href="#HttpAgent" class="headerlink" title="HttpAgent"></a>HttpAgent</h4><p>其中 agent 是通过装饰着模式实现的，ServerHttpAgent 是实际工作的类，MetricsHttpAgent 在内部也是调用了 ServerHttpAgent 的方法，另外加上了一些统计操作，所以我们只需要关心 ServerHttpAgent 的功能就可以了，在 Nacos 2.0 版本后被废弃掉。<br>agent 实际是在 ClientWorker 中发挥能力的，下面我们来看下 ClientWorker 类。</p>
<h4 id="ClientWorker"><a href="#ClientWorker" class="headerlink" title="ClientWorker"></a>ClientWorker</h4><p>以下是 ClientWorker 的构造方法，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647169498445-bd7e4397-af99-4076-84bc-193ade747221.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=488&id=u74b0ca9c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=976&originWidth=2148&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=232410&status=done&style=none&taskId=u482d0220-9bac-4c47-bf1a-2d5d62c1270&title=&width=1074" alt="image.png"><br>可以看到 ClientWorker 除了将 HttpAgent 维持在自己内部，还创建了两个线程池：<br>第一个线程池是只拥有一个线程用来执行定时任务的 executor，executor 每隔 10ms 就会执行一次 checkConfigInfo() 方法，从方法名上可以知道是每 10 ms 检查一次配置信息。<br>第二个线程池是一个普通的线程池，从 ThreadFactory 的名称可以看到这个线程池是做长轮询的。<br>现在让我们来看下 executor 每 10ms 执行的方法到底是干什么的，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166498308-989b5501-2372-437a-94ab-45db6ba5df94.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5f90fb22&margin=%5Bobject%20Object%5D&name=image.png&originHeight=379&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=354860&status=done&style=none&taskId=u4e3c4ccd-f9f7-4fba-9cbc-180bd700d0a&title=" alt="image.png"><br>可以看到，checkConfigInfo 方法是取出了一批任务，然后提交给 executorService 线程池去执行，执行的任务就是 LongPollingRunnable，每个任务都有一个 taskId。<br>现在我们来看看 LongPollingRunnable 做了什么，主要分为两部分，第一部分是检查本地的配置信息，第二部分是获取服务端的配置信息然后更新到本地。 1.本地检查<br>首先取出与该 taskId 相关的 CacheData，然后对 CacheData 进行检查，包括本地配置检查和监听器的 md5 检查，本地检查主要是做一个故障容错，当服务端挂掉后，Nacos 客户端可以从本地的文件系统中获取相关的配置信息，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166497617-080a8eed-7e3f-4805-a717-c0197a20fef9.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u02bd781c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=658&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=400882&status=done&style=none&taskId=u9e744f9e-3b83-49ca-be2c-808a285ce73&title=" alt="image.png"><br>通过跟踪 checkLocalConfig 方法，可以看到 Nacos 将配置信息保存在了<br>~&#x2F;nacos&#x2F;config&#x2F;fixed-{address}8848nacos&#x2F;snapshot&#x2F;DEFAULT_GROUP&#x2F;{dataId}<br>这个文件中，我们看下这个文件中保存的内容，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166500335-ec2d1d2d-4686-4214-8b40-4dc58b93ad99.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u33489ba4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=105&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=151312&status=done&style=none&taskId=ue71e5bdf-3228-4ff3-bdec-2b1d6c2cd2a&title=" alt="image.png"> 2.服务端检查<br>然后通过 checkUpdateDataIds() 方法从服务端获取那些值发生了变化的 dataId 列表，<br>通过 getServerConfig 方法，根据 dataId 到服务端获取最新的配置信息，接着将最新的配置信息保存到 CacheData 中。<br>最后调用 CacheData 的 checkListenerMd5 方法，可以看到该方法在第一部分也被调用过，我们需要重点关注一下。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166500685-1e1b87fd-b617-4aea-9c68-2bc8fc3b2a23.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uab50115e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=910&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=653957&status=done&style=none&taskId=u016b6723-d719-4cc9-94cd-ec692d0119a&title=" alt="image.png"><br>可以看到，在该任务的最后，也就是在 finally 中又重新通过 executorService 提交了本任务。</p>
<h3 id="添加-Listener"><a href="#添加-Listener" class="headerlink" title="添加 Listener"></a>添加 Listener</h3><p>好了现在我们可以为 ConfigService 来添加一个 Listener 了，最终是调用了 ClientWorker 的 addTenantListeners 方法，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166500080-1cabaf8b-d711-4d30-8cc7-403dbbdb188b.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue298a71c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=249&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=187438&status=done&style=none&taskId=u81093d7f-6987-4bfd-b002-ecb7889f488&title=" alt="image.png"><br>该方法分为两个部分，首先根据 dataId，group 和当前的场景获取一个 CacheData 对象，然后将当前要添加的 listener 对象添加到 CacheData 中去。<br>也就是说 listener 最终是被这里的 CacheData 所持有了，那 listener 的回调方法 receiveConfigInfo 就应该是在 CacheData 中触发的。<br>我们发现 CacheData 是出现频率非常高的一个类，在 LongPollingRunnable 的任务中，几乎所有的方法都围绕着 CacheData 类，现在添加 Listener 的时候，实际上该 Listener 也被委托给了 CacheData，那我们要重点关注下 CacheData 类了。</p>
<h3 id="CacheData"><a href="#CacheData" class="headerlink" title="CacheData"></a>CacheData</h3><p>首先让我们来看一下 CacheData 中的成员变量，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166500657-fe7fedda-0597-4422-9049-51552de5283a.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uea79af23&margin=%5Bobject%20Object%5D&name=image.png&originHeight=690&originWidth=1036&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=598849&status=done&style=none&taskId=u4c6ac89f-cfa4-4e13-ba21-027552d31a4&title=" alt="image.png"><br>可以看到除了 dataId，group，content，taskId 这些跟配置相关的属性，还有两个比较重要的属性：listeners、md5。<br>listeners 是该 CacheData 所关联的所有 listener，不过不是保存的原始的 Listener 对象，而是包装后的 ManagerListenerWrap 对象，该对象除了持有 Listener 对象，还持有了一个 lastCallMd5 属性。<br>另外一个属性 md5 就是根据当前对象的 content 计算出来的 md5 值。</p>
<h3 id="触发回调"><a href="#触发回调" class="headerlink" title="触发回调"></a>触发回调</h3><p>现在我们对 ConfigService 有了大致的了解了，现在剩下最后一个重要的问题还没有答案，那就是 ConfigService 的 Listener 是在什么时候触发回调方法 receiveConfigInfo 的。<br>现在让我们回过头来想一下，在 ClientWorker 中的定时任务中，启动了一个长轮询的任务：LongPollingRunnable，该任务多次执行了 cacheData.checkListenerMd5() 方法，那现在就让我们来看下这个方法到底做了些什么，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166500423-0d405470-1b43-4942-bdec-4ec9cbaf1520.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6902e04e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=292&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=182088&status=done&style=none&taskId=u20958255-8bf1-4e6e-bde0-c000064a91c&title=" alt="image.png"><br>到这里应该就比较清晰了，该方法会检查 CacheData 当前的 md5 与 CacheData 持有的所有 Listener 中保存的 md5 的值是否一致，如果不一致，就执行一个安全的监听器的通知方法：safeNotifyListener，通知什么呢？我们可以大胆的猜一下，应该是通知 Listener 的使用者，该 Listener 所关注的配置信息已经发生改变了。现在让我们来看一下 safeNotifyListener 方法，如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166501511-88a94338-2166-49fd-9180-8490ab897d8a.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u0cb4c1a3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=718&originWidth=1080&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=612490&status=done&style=none&taskId=u6dd3b964-229e-4488-aad6-90a8ed1e642&title=" alt="image.png"><br>可以看到在 safeNotifyListener 方法中，重点关注下红框中的三行代码：获取最新的配置信息，调用 Listener 的回调方法，将最新的配置信息作为参数传入，这样 Listener 的使用者就能接收到变更后的配置信息了，最后更新 ListenerWrap 的 md5 值。和我们猜测的一样， Listener 的回调方法就是在该方法中触发的。</p>
<h3 id="Md5-何时变更"><a href="#Md5-何时变更" class="headerlink" title="Md5 何时变更"></a>Md5 何时变更</h3><p>那 CacheData 的 md5 值是何时发生改变的呢？我们可以回想一下，在上面的 LongPollingRunnable 所执行的任务中，在获取服务端发生变更的配置信息时，将最新的 content 数据写入了 CacheData 中，我们可以看下该方法如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647166501511-7d8fd815-f6e6-41da-9a1f-e6c1a42be6af.png#clientId=ue06f4bca-f00b-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue2cc5a3e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=192&originWidth=826&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=118794&status=done&style=none&taskId=u5d8acd12-74e5-483b-b215-31adfcf7d0b&title=" alt="image.png"><br>可以看到是在长轮询的任务中，当服务端配置信息发生变更时，客户端将最新的数据获取下来之后，保存在了 CacheData 中，同时更新了该 CacheData 的 md5 值，所以当下次执行 checkListenerMd5 方法时，就会发现当前 listener 所持有的 md5 值已经和 CacheData 的 md5 值不一样了，也就意味着服务端的配置信息发生改变了，这时就需要将最新的数据通知给 Listener 的持有者。<br>至此配置中心的完整流程已经分析完毕了，可以发现，Nacos 并不是通过推的方式将服务端最新的配置信息发送给客户端的，而是客户端维护了一个长轮询的任务，定时去拉取发生变更的配置信息，然后将最新的数据推送给 Listener 的持有者。</p>
<h3 id="拉的优势"><a href="#拉的优势" class="headerlink" title="拉的优势"></a>拉的优势</h3><p>客户端拉取服务端的数据与服务端推送数据给客户端相比，优势在哪呢，为什么 Nacos 不设计成主动推送数据，而是要客户端去拉取呢？如果用推的方式，服务端需要维持与客户端的长连接，这样的话需要耗费大量的资源，并且还需要考虑连接的有效性，例如需要通过心跳来维持两者之间的连接。而用拉的方式，客户端只需要通过一个无状态的 http 请求即可获取到服务端的数据。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Nacos 服务端创建了相关的配置项后，客户端就可以进行监听了。<br>客户端是通过一个定时任务来检查自己监听的配置项的数据的，一旦服务端的数据发生变化时，客户端将会获取到最新的数据，并将最新的数据保存在一个 CacheData 对象中，然后会重新计算 CacheData 的 md5 属性的值，此时就会对该 CacheData 所绑定的 Listener 触发 receiveConfigInfo 回调。<br>考虑到服务端故障的问题，客户端将最新数据获取后会保存在本地的 snapshot 文件中，以后会优先从文件中获取配置信息的值。</p>
<p><strong>NotifyCenter.registerSubscriber</strong><br>NotifyCenter.registerToPublisher<br>com.alibaba.nacos.config.server.service.LongPollingService#LongPollingService<br>长轮询</p>
]]></content>
      <categories>
        <category>nacos</category>
      </categories>
      <tags>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title>Nacos2架构设计</title>
    <url>/article/nacos/nacos-architecture/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://blog.csdn.net/alisystemsoftware/article/details/111934889">https://blog.csdn.net/alisystemsoftware/article/details/111934889</a></p>
</blockquote>
<p>Nacos 在阿里巴巴起源于 2008 年五彩石项目，该项目完成了微服务拆分和业务中台建设，随着云计算和开源环境的兴起，2018 年我们深刻感受到开源软件行业的影响，因此决定将 Nacos 开源，输出阿里十年关于服务发现和配管管理的沉淀，推动微服务行业发展，加速企业数字化转型。<br>目前 Nacos 支持主流微服务开发语言 &amp; 主流服务框架和配置管理框架，比如支持 Duboo 和 SCA， 还对接了一些云原生的组件比如 coreDNS 和 sentinel 等。<br>客户端语言方面支持诸如 Java、go python 等主流语言，还有近期刚发布正式版本的 C# 和 C++，在此感谢所有社区贡献者的支持。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647186852933-dd5d6331-5782-4838-818c-709e076d62fb.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=454&id=ueb87fee0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=908&originWidth=1950&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=506718&status=done&style=none&taskId=uba88d0b8-0039-4e54-8c8a-177738ba7ef&title=&width=975" alt="image.png"><br>Nacos 开源 2 年多以来，共发布了 34 个版本，其中有一些比较重要的里程碑版本；Nacos 还非常年轻，有很大的进步空间，欢迎社区及各界大佬一起共同建设。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647186884814-fe768519-de4e-4630-a9e6-0c0cb13c2797.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=462&id=ud918b33a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=924&originWidth=2018&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=267048&status=done&style=none&taskId=u3c384325-8783-4712-ac3d-56cbb32d224&title=&width=1009" alt="image.png"></p>
<h2 id="Nacos-1-X-架构及问题"><a href="#Nacos-1-X-架构及问题" class="headerlink" title="Nacos 1.X 架构及问题"></a>Nacos 1.X 架构及问题</h2><p>接下来我们看一下 nacos1.x 架构及其分析一下存在的比较重要的问题。首先来看一下架构简图。</p>
<h3 id="Nacos-1-X-架构层次"><a href="#Nacos-1-X-架构层次" class="headerlink" title="Nacos 1.X 架构层次"></a>Nacos 1.X 架构层次</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647186916107-cbb155cf-e62a-4df0-be16-ca62d32f6c2c.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=448&id=uc689c6cf&margin=%5Bobject%20Object%5D&name=image.png&originHeight=896&originWidth=1822&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=618566&status=done&style=none&taskId=ub3dd0f13-5e44-4423-80d7-1ad53690dd8&title=&width=911" alt="image.png">Nacos 1.X 大致分为 5 层， 分别是接入、通信、功能、同步和持久化。<br>接入层是用户最直接交互的层面，主要有 Nacos 客户端，以及依赖客户端的 Dubbo 和 SCA 以及用户操作的控制台 Console 组成。客户端和 Console 进行服务和配置操作，统一通过 HTTP 的 OpenAPI 发起通信请求。<br>通信层主要基于 HTTP 的短连接请求模型进行，部分推送功能通过 UDP 进行通信。<br>功能目前有服务发现和配置管理，这层也就是实际管理服务和配置的业务层。<br>同步层有数据同步的 AP 模式 Distro 和 CP 模式 Raft，还有有一个最简易的水平通知 Notify，用处各不相同：</p>
<ul>
<li>Distro：非持久化服务的同步模式。</li>
<li>Raft：持久化服务的同步模式、以及使用 Derby 作为配置的存储时同步配置操作。</li>
<li>Notify：使用 MySQL 作为配置的存储时，通知其他节点更新缓存及发起配置推送。</li>
</ul>
<p>持久化层 Nacos 使用 MySQL、Derby 和本地文件系统来进行数据的持久化 配置信息，用户信息，权限信息存储在 MySQL 或 Derby 数据库中， 持久化服务信息及服务和实例元数据信息存储在本地文件系统。</p>
<h3 id="Nacos-1-X-架构下的服务模型"><a href="#Nacos-1-X-架构下的服务模型" class="headerlink" title="Nacos 1.X 架构下的服务模型"></a>Nacos 1.X 架构下的服务模型</h3><p>我们通过一个服务发现的流程，再深入熟悉一下 Nacos 1.X 架构和基于当前架构的 Nacos 服务发现模型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647186965908-53f94599-34de-45bb-a432-56ac7eabf141.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=488&id=u115c4e2b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=976&originWidth=1752&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=733696&status=done&style=none&taskId=uada5818f-3c98-4d40-a36a-ed7988fb6eb&title=&width=876" alt="image.png"></p>
<p>Nacos 客户端注册服务会通过 OpenAPI 发送 Http 注册服务的请求，请求内容会带上服务信息及实例信息，通常这个步骤是由微服务框架 SCA 和 dubbo 完成。<br>服务端收到请求后，会先在 Contoller 中进行数据的读取和校验，比如 IP 是否合法，服务名是否正确等等。校验通过后，如果这个服务是第一次注册，Nacos 会在服务端生成一个 Service 对象，然后把这次注册的实例信息存入这个 Service 对象中；如果 Nacos 服务端已经有了这个 Service 对象，那么就会直接把新注册的实例信息存入对象。这个 Service 对象通过 命名空间+Group+Service 的组合来保证唯一性。<br>完成实例存入 Service 的同时，会触发两个事件，其中一个事件是用于数据同步的，Nacos 服务端会根据这个服务是否是临时对象的信息，使用 Distro 或者 Raft 协议进行同步，通知其他的 Nacos 节点该服务发生了变更；另一个事件则通知在该 Nacos 服务节点上订阅了该服务的订阅者，并根据订阅者信息，通过 UDP 的方式，把最新的服务列表推送到订阅者客户端上。这就完成了一次服务注册流程。<br>另外，对于那些被定义为持久化的服务的所有信息，都会通过 raft 协议，保证能够写入到文件系统中被持久化。<br>最后，其他的 Nacos 节点，在通过同步而进行 Service 变更的时候也会触发通知订阅者的事件，从而使在其他 Nacos 服务节点上订阅该服务的订阅者也能收到推送。</p>
<h3 id="1-X-架构存在的问题"><a href="#1-X-架构存在的问题" class="headerlink" title="1.X 架构存在的问题"></a>1.X 架构存在的问题</h3><p>粗略介绍了下 Nacos1.X 的架构和服务发现模型，接下来分析一下 Nacos1.X 架构所面临的几个比较重要的问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647187004205-6be23bea-d969-4551-8b8f-21ab6748c3cf.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=381&id=uc8f19a83&margin=%5Bobject%20Object%5D&name=image.png&originHeight=762&originWidth=1148&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=543022&status=done&style=none&taskId=u4fca4d8e-a3ca-47ac-baaa-f3a5a387c80&title=&width=574" alt="image.png"><br>一句话总结，心跳多，无效查询多，心跳续约感知变化慢，连接消耗大，资源空耗严重。</p>
<ul>
<li><p>心跳数量多，导致 TPS 居高不下</p>
<blockquote>
<p>通过心跳续约，当服务规模上升时，特别是类似 Dubbo 的接口级服务较多时，心跳及配置元数据的轮询数量众多，导致集群 TPS 很高，系统资源高度空耗。</p>
</blockquote>
</li>
<li><p>通过心跳续约感知服务变化，时延长</p>
<blockquote>
<p>心跳续约需要达到超时时间才会移除并通知订阅者，默认为 15s，时延较长，时效性差。若改短超时时间，当网络抖动时，会频繁触发变更推送，对客户端服务端都有更大损耗。</p>
</blockquote>
</li>
<li><p>UDP 推送不可靠，导致 QPS 居高不下</p>
<blockquote>
<p>由于 UDP 不可靠，因此客户端测需要每隔一段时间进行对账查询，保证客户端缓存的服务列表的状态正确，当订阅客户端规模上升时，集群 QPS 很高，但大多数服务列表其实不会频繁改变，造成无效查询，从而存在资源空耗。</p>
</blockquote>
</li>
<li><p>基于 HTTP 短连接模型，TIME_WAIT 状态连接过多</p>
<blockquote>
<p>HTTP 短连接模型，每次客户端请求都会创建和销毁 TCP 链接，TCP 协议销毁的链接状态是 WAIT_TIME，完全释放还需要一定时间，当 TPS 和 QPS 较高时，服务端和客户端可能有大量的 WAIT_TIME 状态链接，从而会导致 connect time out 错误或者 Cannot assign requested address 的问题。</p>
</blockquote>
</li>
<li><p>配置模块的 30 秒长轮询引起的频繁 GC</p>
<blockquote>
<p>配置模块使用 HTTP 短连接阻塞模型来模拟长连接通信，但是由于并非真实的长连接模型，因此每 30 秒需要进行一次请求和数据的上下文切换，每一次切换都有引起造成一次内存浪费，从而导致服务端频繁 GC。</p>
</blockquote>
</li>
</ul>
<h2 id="Nacos-2-0-架构及新模型"><a href="#Nacos-2-0-架构及新模型" class="headerlink" title="Nacos 2.0 架构及新模型"></a>Nacos 2.0 架构及新模型</h2><h3 id="Nacos-2-0-架构层次"><a href="#Nacos-2-0-架构层次" class="headerlink" title="Nacos 2.0 架构层次"></a>Nacos 2.0 架构层次</h3><p>Nacos 2.X 在 1.X 的架构基础上 新增了对长连接模型的支持，同时保留对旧客户端和 openAPI 的核心功能支持。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647187106644-8785b9d8-2b78-4f86-bc27-ba0a88d031e8.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=453&id=ue365d5bc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=906&originWidth=1640&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=727769&status=done&style=none&taskId=ub6aaff50-3f24-4656-b096-ed3ab2a0976&title=&width=820" alt="image.png"><br>通信层目前通过 gRPC 和 Rsocket 实现了长连接 RPC 调用和推送能力。<br>在服务端测，新增一个链接层，用来将不同类型的 Request 请求，将来自不同客户端的不同类型请求，转化为相同语意的功能数据结构，复用业务处理逻辑。同时，将来的流量控制和负载均衡等功能也会在链接层处理。<br>其他架构分层在大体上保持不变。</p>
<h3 id="Nacos-2-0-新服务模型"><a href="#Nacos-2-0-新服务模型" class="headerlink" title="Nacos 2.0 新服务模型"></a>Nacos 2.0 新服务模型</h3><p>虽然 Nacos2.0 的在架构层次上并未做太大的变化，但是具体的模型细节却有不小的改动，依旧使用注册服务的流程，再深入了解一下 Nacos2.0 服务模型的变化。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647187142467-84067a03-cc99-4723-b3e9-bcb0eeadf041.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=441&id=u4ac18cfb&margin=%5Bobject%20Object%5D&name=image.png&originHeight=882&originWidth=1624&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=836035&status=done&style=none&taskId=ud8f7b0c8-426b-49a5-baf8-18fb08b2ccd&title=&width=812" alt="image.png"><br>由于通信使用了 RPC 方式，因此某一客户端的所有请求（无论是注册还是订阅）都通过同一个链接和同一个服务节点进行，不像之前通过 HTTP 连接可能每次请求都请求在不同的 Nacos 节点上，这就导致了服务发现的数据内容由原来的无状态化变为了与连接状态绑定的一种有状态数据。为了适应这种变化，需要改变一下数据模型，因此抽象了一个新数据结构，将同一个客户端通过该链接发布和订阅的内容关联起来，暂命名为 Client。这个 Client 不是客户端的意思，而是这个客户端所相关的数据内容，一个链接与一个 Client 对应。<br>当客户端发布了服务时，该客户端所发布的所有服务与订阅者信息会被更新到与该客户端链接相对应的 Client 对象中，然后通过事件机制触发对索引信息的更新。这个索引信息是客户端链接和服务的索引，方便快速聚合生成需要推送的服务纬度的数据。<br>索引信息更新完成后，会触发推送事件，此时会将所有和该服务有关的 Client 对象，通过刚产生的索引信息聚合起来，当数据聚合完成后，再从客户端链接中筛选出订阅该服务的订阅者的客户端链接，将推送数据通过该链接，推送回去。这样一次发布变更的主链路就完成了。<br>回过头看数据同步，客户端发布了服务时实际更新的对象从原来的 Service 变成 Client 对象，所以需要同步的内容也变成了 Client 对象；同时服务端间的通信方式也会换成 RPC。这里只有真正被客户端更新的 Client 对象会触发同步，如果是通过同步而更新的 Client 对象不会再次触发同步。<br>最后看 Metadata，Metadata 是从 1.X 版本中的 Service 对象和 Instance 对象中分离出来的一些属性：比如服务的元数据 label 标签，实例的上下线状态、权重和元数据 label 标签等。这些元数据可以被 openAPI 单独修改，在聚合数据时生效。之所以将元数据拆分出来，区别于基础数据，原因是基础数据比如：ip 端口，服务名等一经发布不应该被修改，而且应当以发布时的信息为准；但其他的原数据，比如上下线状态和权重，通常是在运行过程中动态调节的，因此拆分开之后，分为两条不同的处理工作流应该更加合理。</p>
<h3 id="Nacos-2-0-架构的优缺点"><a href="#Nacos-2-0-架构的优缺点" class="headerlink" title="Nacos 2.0 架构的优缺点"></a>Nacos 2.0 架构的优缺点</h3><p>前面简要介绍了 Nacos 2.0 的架构和新模型的工作方式，接下来我们分析一下这样的改动有哪些优缺点。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647187199068-efc7d1d5-451c-4d57-9f70-9f5283ac1bcc.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=413&id=uabd7a682&margin=%5Bobject%20Object%5D&name=image.png&originHeight=826&originWidth=1106&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=694419&status=done&style=none&taskId=u86a6c9d4-1942-4731-98e1-9edcd21fbeb&title=&width=553" alt="image.png"></p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>客户端不再需要定时发送实例心跳，只需要有一个维持连接可用 keepalive 消息即可。重复 TPS 可以大幅降低。</li>
<li>TCP 连接断开可以被快速感知到，提升反应速度。</li>
<li>长连接的流式推送，比 UDP 更加可靠；nio 的机制具有更高的吞吐量，而且由于可靠推送，可以加长客户端用于对账服务列表的时间，甚至删除相关的请求。重复的无效 QPS 可以大幅降低。</li>
<li>长连接避免频繁连接开销，可以大幅缓解 TIME_ WAIT 问题。</li>
<li>真实的长连接，解决配置模块 GC 问题。</li>
<li>更细粒度的同步内容，减少服务节点间的通信压力。</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>没有银弹的方案，新架构也会引入一些新问题：</li>
<li>内部结构复杂度上升，管理连接状态，连接的负载均衡需要管理。</li>
<li>数据又原来的无状态，变为与连接绑定的有状态数据，流程链路更长。</li>
<li>RPC 协议的观测性不如 HTTP。即使 gRPC 基于 HTTP2.0Stream 实现，仍然不如直接使用 HTTP 协议来的直观。</li>
</ul>
<h2 id="Nacos-2-X-规划"><a href="#Nacos-2-X-规划" class="headerlink" title="Nacos 2.X 规划"></a>Nacos 2.X 规划</h2><p>接下来简单分享下 Nacos 2.X 的后期规划，主要分为文档、质量和 Roadmap。<br>在文档和质量方面，Nacos 1.X 都做的不是很好。文档内容较少，仅有简单使用文档；和版本有一定脱节，更新不及时；没有对技术内容的说明，参与贡献难度高。代码质量及测试质量也不是很高，虽然已经使用 checkstyle 进行了 codeStyle 的校验以及开启了社区协作 review。但是这还远远不够。Nacos 2.X 将会逐步更新、细化官网使用文档；通过电子书对技术细节进行解析；通过 Github 展示技术方案，促进讨论及贡献；并且对代码进行大量重构及 UT 和 IT 的治理工作，在未来将 Benchmark 也会开源出来，方便给开源用户进行压测。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647187260940-7947ba57-e15b-4bff-b40a-53f5636d684a.png#clientId=u3381db7b-bd5f-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=413&id=ue56cd15f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=826&originWidth=1800&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=490103&status=done&style=none&taskId=u11aa0ade-115c-4b4b-afda-9ff959e6697&title=&width=900" alt="image.png">而 RoadMap 方面，Nacos 2.X 会对项目做大幅度的重构，完成初步插件化，并对刚才 2.0 架构的一些缺点，如负载均衡，可观测性进行提升。</p>
]]></content>
      <categories>
        <category>nacos</category>
      </categories>
      <tags>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title>Nacos简介</title>
    <url>/article/nacos/nacos/</url>
    <content><![CDATA[<blockquote>
<p><a href="https://zhuanlan.zhihu.com/p/375912272">https://zhuanlan.zhihu.com/p/375912272</a> &gt; <a href="https://www.cnblogs.com/crazymakercircle/p/14231815.html">https://www.cnblogs.com/crazymakercircle/p/14231815.html</a></p>
</blockquote>
<h2 id="1、Nacos-优势"><a href="#1、Nacos-优势" class="headerlink" title="1、Nacos 优势"></a>1、Nacos 优势</h2><p>问题，既然有了 Eureka ，为啥还要用 Nacos？<br>而 Nacos 作为微服务核心的服务注册与发现中心，让大家在 Eureka 和 Consule 之外有了新的选择，开箱即用，上手简洁，暂时也没发现有太大的坑。</p>
<h3 id="1-1、与-eureka-对比"><a href="#1-1、与-eureka-对比" class="headerlink" title="1.1、与 eureka 对比"></a>1.1、与 eureka 对比</h3><ul>
<li>eureka 2.0 闭源码了</li>
<li>从官网来看 nacos 的注册的实例数是大于 eureka 的</li>
<li>因为 nacos 使用的 raft 协议,nacos 集群的一致性要远大于 eureka 集群</li>
</ul>
<p>分布式一致性协议 Raft，自 2013 年论文发表，之后就受到了技术领域的热捧，与其他的分布式一致性算法比，Raft 相对比较简单并且易于实现，这也是 Raft 能异军突起的主要因素。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647146414817-3e1648bd-2623-4690-bf28-9e42a3d67114.png#clientId=ued4b6436-aafe-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=236&id=ud337bae4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=766&originWidth=1864&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=180596&status=done&style=none&taskId=ue131811e-f697-4ada-ab96-a532ee5bbcd&title=&width=574" alt="image.png"><br>Raft 的数据一致性策略<br>Raft 协议强依赖 Leader 节点来确保集群数据一致性。即 client 发送过来的数据均先到达 Leader 节点，Leader 接收到数据后，先将数据标记为 uncommitted 状态，随后 Leader 开始向所有 Follower 复制数据并等待响应，在获得集群中大于 N&#x2F;2 个 Follower 的已成功接收数据完毕的响应后，Leader 将数据的状态标记为 committed，随后向 client 发送数据已接收确认，在向 client 发送出已数据接收后，再向所有 Follower 节点发送通知表明该数据状态为 committed。</p>
<h3 id="1-2、与-spring-cloud-config-对比"><a href="#1-2、与-spring-cloud-config-对比" class="headerlink" title="1.2、与 spring cloud config 对比"></a>1.2、与 spring cloud config 对比</h3><p>三大优势：</p>
<ul>
<li>springcloud config 大部分场景结合 git 使用, 动态变更还需要依赖 Spring Cloud Bus 消息总线来通过所有的客户端变化</li>
<li>springcloud config 不提供可视化界面</li>
<li>nacos config 使用长连接更新配置, 一旦配置有变动后，通知 Provider 的过程非常的迅速, 从速度上秒杀 spring cloud 原来的 config 几条街</li>
</ul>
<h2 id="2、Spring-Cloud-Alibaba-套件"><a href="#2、Spring-Cloud-Alibaba-套件" class="headerlink" title="2、Spring Cloud Alibaba 套件"></a>2、Spring Cloud Alibaba 套件</h2><p>目前 Spring Cloud Alibaba 主要有三个组件：</p>
<ul>
<li>Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。</li>
<li>Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。</li>
<li>AliCloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。</li>
</ul>
<p>Spring Cloud Alibaba 套件 和 Spring Cloud Netflix 套件类比<br>仔细看看各组件的功能描述，<br>Spring Cloud Alibaba 套件和 Spring Cloud Netflix 套件大致的对应关系：</p>
<ul>
<li>Nacos &#x3D; Eureka&#x2F;Consule + Config + Admin</li>
<li>Sentinel &#x3D; Hystrix + Dashboard + Turbine</li>
<li>Dubbo &#x3D; Ribbon + Feign</li>
<li>RocketMQ &#x3D; RabbitMQ</li>
<li>Schedulerx &#x3D; Quartz</li>
<li>AliCloud OSS、AliCloud SLS 这三个应该是独有的</li>
</ul>
<p>链路跟踪（Sleuth、Zipkin）不知道会不会在 Sentinel 里<br>以上只是猜测，待我从坑里爬出来之后再回来更新。也欢迎大家一起交流探讨~<br>这里我就先试试 Nacos。</p>
<h2 id="3、Nacos-的架构和安装"><a href="#3、Nacos-的架构和安装" class="headerlink" title="3、Nacos 的架构和安装"></a>3、Nacos 的架构和安装</h2><h3 id="3-1、Nacos-的架构"><a href="#3-1、Nacos-的架构" class="headerlink" title="3.1、Nacos 的架构"></a>3.1、Nacos 的架构</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647146632603-f0389671-a4b1-481c-9ead-1871422c593e.png#clientId=ued4b6436-aafe-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=250&id=u4d3e389c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=500&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=208181&status=done&style=none&taskId=udfc84aec-adb9-4cae-9349-11426a58d84&title=&width=550" alt="image.png"><br>这是 Nacos 的架构图，可以看到它确实是融合了服务注册发现中心、配置中心、服务管理等功能，类似于 Eureka&#x2F;Consule + Config + Admin 的合体。<br>另外通过官方文档发现，Nacos 除了可以和 Spring Cloud 集成，还可以和 Spring、SpringBoot 进行集成。不过我们只关注于 Spring Cloud，别的就略过了，直接上手实战吧。</p>
<h3 id="3-2、Nacos-Server-的下载和安装"><a href="#3-2、Nacos-Server-的下载和安装" class="headerlink" title="3.2、Nacos Server 的下载和安装"></a>3.2、Nacos Server 的下载和安装</h3><p>在使用 Nacos 之前，需要先下载 Nacos 并启动 Nacos Server。<br>安装的参考教程：<br><a href="https://www.cnblogs.com/crazymakercircle/p/11992539.html">https://www.cnblogs.com/crazymakercircle/p/11992539.html</a></p>
<h2 id="4、Nacos-Server-的运行"><a href="#4、Nacos-Server-的运行" class="headerlink" title="4、Nacos Server 的运行"></a>4、Nacos Server 的运行</h2><h3 id="4-1、两种模式"><a href="#4-1、两种模式" class="headerlink" title="4.1、两种模式"></a>4.1、两种模式</h3><p>Nacos Server 有两种运行模式：</p>
<ul>
<li><p>standalone</p>
</li>
<li></li>
<li><p>cluster</p>
</li>
</ul>
<h3 id="4-2、standalone-模式"><a href="#4-2、standalone-模式" class="headerlink" title="4.2、standalone 模式"></a>4.2、standalone 模式</h3><p>此模式一般用于 demo 和测试，不用改任何配置，直接敲以下命令执行<br><code>sh bin/startup.sh -m standalone </code><br>Windows 的话就是<br><code>cmd bin/startup.cmd -m standalone </code><br>然后从 <a href="http://cdh1:8848/nacos/index.html">http://cdh1:8848/nacos/index.html</a> 进入控制台就能看到如下界面了<br><a href="https://img-blog.csdnimg.cn/20190329154915102.png"><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647101731578-6fa3b395-c472-471e-8678-93d3bdce7aea.png#clientId=u7f5edb5f-179e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucbab9220&margin=%5Bobject%20Object%5D&name=image.png&originHeight=426&originWidth=1240&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=67704&status=done&style=none&taskId=ucbc9e81e-8cda-4413-9ca9-4a43b84f3d8&title=" alt="image.png"></a><br>默认账号和密码为：nacos nacos</p>
<h3 id="4-3、cluster-模式"><a href="#4-3、cluster-模式" class="headerlink" title="4.3、cluster 模式"></a>4.3、cluster 模式</h3><p>测试环境，可以先用 standalone 模式撸起来，享受 coding 的快感，但是，生产环境可以使用 cluster 模式。<br>cluster 模式需要依赖 MySQL，然后改两个配置文件：<br>conf&#x2F;cluster.conf<br>conf&#x2F;application.properties<br>大致如下：<br>1、cluster.conf，填入要运行 Nacos Server 机器的 ip<br>192.168.100.155<br>192.168.100.156<br>2、修改 NACOS_PATH&#x2F;conf&#x2F;application.properties，加入 MySQL 配置</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">db.num&#x3D;1
db.url.0&#x3D;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;nacos_config?characterEncoding&#x3D;utf8&amp;connectTimeout&#x3D;1000&amp;socketTimeout&#x3D;3000&amp;autoReconnect&#x3D;true
db.user&#x3D;root
db.password&#x3D;root</code></pre>

<p>创建一个名为 nacos_config 的 database，将 NACOS_PATH&#x2F;conf&#x2F;nacos-mysql.sql 中的表结构导入刚才创建的库中，这几张表的用途就自己研究吧</p>
<h3 id="4-4、Nacos-Server-的配置数据是存在哪里呢？"><a href="#4-4、Nacos-Server-的配置数据是存在哪里呢？" class="headerlink" title="4.4、Nacos Server 的配置数据是存在哪里呢？"></a>4.4、Nacos Server 的配置数据是存在哪里呢？</h3><p>问题来了： Nacos Server 的配置数据是存在哪里呢？<br>我们没有对 Nacos Server 做任何配置，那么数据只有两个位置可以存储：</p>
<ul>
<li>内存</li>
<li>本地数据库</li>
</ul>
<p>如果我们现在重启刚刚在运行的 Nacos Server，会发现刚才加的 nacos.properties 配置还在，说明不是内存存储的。<br>这时候我们打开 NACOS_PATH&#x2F;data，会发现里边有个 derby-data 目录，我们的配置数据现在就存储在这个库中。</p>
<blockquote>
<p>Derby 是 Java 编写的数据库，属于 Apache 的一个开源项目</p>
</blockquote>
<p>如果将数据源改为我们熟悉的 MySQL 呢？当然可以。</p>
<blockquote>
<p>注意：不支持 MySQL 8.0 版本</p>
</blockquote>
<p>这里有两个坑：</p>
<blockquote>
<p>Nacos Server 的数据源是用 Derby 还是 MySQL 完全是由其运行模式决定的：</p>
</blockquote>
<p>standalone 的话仅会使用 Derby，即使在 application.properties 里边配置 MySQL 也照样无视； cluster 模式会自动使用 MySQL，这时候如果没有 MySQL 的配置，是会报错的。<br>官方提供的 cluster.conf 示例如下</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#it is ip
#example
10.10.109.214
11.16.128.34
11.16.128.36</code></pre>

<p>以上配置结束后，运行 Nacos Server 就能看到效果了。</p>
<h2 id="5、配置的隔离"><a href="#5、配置的隔离" class="headerlink" title="5、配置的隔离"></a>5、配置的隔离</h2><p>在实际的应用中，存在着以下几种环境隔离的要求：<br>1、开发环境、测试环境、准生产环境和生产环境需要隔离<br>2、不同项目需要隔离<br>3、同一项目，不同的模块需要隔离<br>可以通过三种方式来进行配置隔离：Nacos 的服务器、namespace 命名空间、group 分组，在 bootstrap.yml 文件中可以通过配置 Nacos 的 server-addr、namespace 和 group 来区分不同的配置信息。</p>
<ul>
<li>Nacos 的服务器 spring.cloud.nacos.config.server-addr</li>
<li>Nacos 的命名空间 spring.cloud.nacos.config.namespace，注意，这里使用命名空间的 ID 不是名称</li>
<li>Nacos 的分组 spring.cloud.nacos.config.group</li>
</ul>
<h2 id="6、nacos-集群搭建"><a href="#6、nacos-集群搭建" class="headerlink" title="6、nacos 集群搭建"></a>6、nacos 集群搭建</h2><p>如果我们要搭建集群的话，那么肯定是不能用内嵌的数据库，不然数据无法共享。所以，集群搭建的时候我们需要将 Nacos 对接 Mysql 进行数据存储。<br>集群模式跟我们平时进行扩容是一样的，可以通过 Nginx 转发到多个节点，最前面挂一个域名即可，如下图：<a href="https://img-blog.csdnimg.cn/20190807114946379.png"><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647101735764-f1376194-ae1a-442b-b723-ca0ebfd2b150.png#clientId=u7f5edb5f-179e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uca2877fe&margin=%5Bobject%20Object%5D&name=image.png&originHeight=476&originWidth=1098&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=39460&status=done&style=none&taskId=u19bfb715-4a35-4204-b23d-f66450a2c6e&title=" alt="image.png"></a></p>
<h3 id="IP-规划"><a href="#IP-规划" class="headerlink" title="IP 规划"></a>IP 规划</h3><p>通常如果我们只是为了体验的话，直接在本地起动 3 个实例就可以了，没必要真的去搞三台服务器，下面我们就以在本地的方式来搭建集群。 将 Nacos 的解压包复制分成 3 份，分别是:<br>nacos<br>nacos1<br>nacos2<br>进入 nacos 的 conf 目录，编辑 application.properties 文件，增加数据库配置</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># 指定数据源为Mysql
spring.datasource.platform&#x3D;mysql

# 数据库实例数量
db.num&#x3D;1
db.url.0&#x3D;jdbc:mysql:&#x2F;&#x2F;localhost:3306&#x2F;nacos?characterEncoding&#x3D;utf8&amp;connectTimeout&#x3D;1000&amp;socketTimeout&#x3D;3000&amp;autoReconnect&#x3D;true
db.user&#x3D;root
db.password&#x3D;123456</code></pre>

<p>复制代码同样的步骤进入 nacos1 和 nacos2 操作一遍，唯一需要修改的就是 application.properties 文件中的 server.port，默认 nacos 的 server.port&#x3D;8848，<br>我们在本地启动三个实例，那么端口肯定会冲突，所以其他 2 个实例的端口我们需要进行修改，比如 nacos1 修改成 8847，nacos2 修改成 8846。<br>数据库配置信息好了后，我们需要将对应的数据库和表进行初始化，数据库脚本在 conf 目录下的 nacos-mysql.sql 中，执行即可。<br>最后一步需要配置一份集群节点信息，配置文件在 conf 目录下的 cluster.conf.example 文件，我们进行重命名成 cluster.conf。 然后编辑 cluster.conf 文件，增加 3 个节点的信息，格式为 IP:PORT，三个目录都一致即可。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">127.0.0.1:8848
127.0.0.1:8847
127.0.0.1:8846</code></pre>

<p>启动的话直接到 bin 目录下，执行.&#x2F;startup.sh 就可以了，默认就是集群模式，不需要加任何参数。</p>
<h3 id="集群的使用"><a href="#集群的使用" class="headerlink" title="集群的使用"></a>集群的使用</h3><p>上面的集群，虽然可用， 但仍不是真正的集群， 我们一般不会这么用。nacos 集群的使用一般有 4 种方式：</p>
<ul>
<li><a href="http://ip1:port/openAPI">http://ip1:port/openAPI</a> 直连 ip 模式，不同的节点，则需要修改 ip 才可以使用。</li>
<li><a href="http://VIP:port/openAPI">http://VIP:port/openAPI</a> VIP 模式高可用，客户端 vip 即可，VIP 下面挂 server 真实 ip，部署比较麻烦，需要部署 vip（keepalive）。</li>
<li><a href="http://nacos.com:port/openAPI">http://nacos.com:port/openAPI</a> 域名模式，可读性好，而且换 ip 方便，在 host 文件配置本地域名即可。</li>
<li>http:&#x2F;&#x2F;反向代理:port&#x2F;openAPI 反向代理模式</li>
</ul>
<p>这里介绍一下反向代理模式。<br>关于 Nginx 的安装和配置，本文就不进行讲解了，不会的可以自己去尝试下，反向代理模式 核心配置如下：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">upstream nacos_server &#123;
  server 127.0.0.1:8848;
  server 127.0.0.1:8847;
  server 127.0.0.1:8846;
&#125;

server &#123;
listen 8648;
   server_name localhost;
  #charset koi8-r;
  #access_log logs&#x2F;host.access.log main;
  location &#x2F; &#123;
     proxy_pass http:&#x2F;&#x2F;nacos_server;
     index index.html index.htm;
   &#125;
&#125;</code></pre>

<p>整体来说，nacos 的集群搭建方式还是挺简单的，没什么特别要注意的，最好是能通过域名的方式来进行访问，另外数据库这块如果上生产环境，也需要考虑高可用问题，至少也得有个主从。<br>8648 的 nginx 提供的 nacos 服务接口，可以自定义。 我们访问<br><a href="http://localhost:8648/nacos/#/clusterManagement?dataId=&amp;group=&amp;appName=&amp;namespace=&amp;serverId=">http://localhost:8648/nacos/#/clusterManagement?dataId=&amp;group=&amp;appName=&amp;namespace=&amp;serverId=</a><br>，就可以看到：<br><a href="https://img2018.cnblogs.com/blog/493842/201907/493842-20190717151826015-620927747.png"><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647101735813-7e09f91a-e566-44dc-84c1-1ee7fd5362f3.png#clientId=u7f5edb5f-179e-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ude292ffd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=616&originWidth=1419&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=54160&status=done&style=none&taskId=u04ec9c2b-0562-442d-9fba-e72db88e109&title=" alt="image.png"></a><br>我们可以简单测试一下，杀掉 一个的 nacos ，看服务是否正常。 后面，我们对微服务提供 nacos 服务的时候，只要配置这个 nginx 端口就好了！！</p>
<h3 id="新版本部署"><a href="#新版本部署" class="headerlink" title="新版本部署"></a>新版本部署</h3><p>Nacos2.0 版本相比 1.X 新增了 gRPC 的通信方式，因此需要增加 2 个端口。新增端口是在配置的主端口(server.port)基础上，进行一定偏移量自动生成。</p>
<table><thead><tr>
<th><strong>端口</strong></th>
<th><strong>与主端口的偏移量</strong></th>
<th><strong>描述</strong></th>
</tr>
</thead><tbody><tr>
<td>9848</td>
<td>1000</td>
<td>客户端 gRPC 请求服务端端口，用于客户端向服务端发起连接和请求</td>
</tr>
<tr>
<td>9849</td>
<td>1001</td>
<td>服务端 gRPC 请求服务端端口，用于服务间同步等</td>
</tr>
</tbody></table><p>使用 VIP&#x2F;nginx 请求时，需要配置成 TCP 转发，不能配置 http2 转发，否则连接会被 nginx 断开。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1647149978462-a0be9d46-22fa-44d9-b96f-6a8861c93f51.png#clientId=ud9238c9c-8bab-4&crop=0&crop=0.0867&crop=1&crop=0.794&from=paste&height=1125&id=u33618615&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1125&originWidth=2000&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=108422&status=done&style=none&taskId=u1b99182e-30dd-4d07-8b92-e0f135109da&title=&width=2000" alt="image.png"><br>客户端拥有相同的计算逻辑，用户如同 1.X 的使用方式，配置主端口(默认 8848)，通过相同的偏移量，计算对应 gRPC 端口(默认 9848)。<br>因此如果客户端和服务端之前存在端口转发，或防火墙时，需要对端口转发配置和防火墙配置做相应的调整。其余部署参考<a href="https://nacos.io/zh-cn/docs/deployment.html">Nacos 部署手册</a> ，将版本相关替换成 2.0.0。</p>
]]></content>
      <categories>
        <category>nacos</category>
      </categories>
      <tags>
        <tag>Nacos</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty（一）网络IO基础</title>
    <url>/article/netty/netty-io-basic/</url>
    <content><![CDATA[<p>在讨论 IO 的时候，参与者通常有两个角色：系统内核和用户进程。用户进程发送 IO 请求过后，系统内核在准备好 IO 数据后，会通过内存拷贝的方式，将准备好的缓存 IO 数据共享给用户进程缓存。</p>
<h2 id="网络-I-x2F-O-模型简介"><a href="#网络-I-x2F-O-模型简介" class="headerlink" title="网络 I&#x2F;O 模型简介"></a>网络 I&#x2F;O 模型简介</h2><p>根据 UNIX 网络编程对 I&#x2F;O 模型的分类，提供了阻塞 I&#x2F;O 模型、非阻塞 I&#x2F;O 模型、I&#x2F;O 复用模型、信号驱动 I&#x2F;O 模型、异步 I&#x2F;O 这 5 种 I&#x2F;O 模型。</p>
<h3 id="1、阻塞-I-x2F-O-模型"><a href="#1、阻塞-I-x2F-O-模型" class="headerlink" title="1、阻塞 I&#x2F;O 模型"></a>1、阻塞 I&#x2F;O 模型</h3><p>最常用的模型，所有文件操作都是阻塞的。套接字 socket 在进程空间中调用 recvfrom，其系统调用直到数据包到达，且被复制到应用进程的缓冲区或者发生错误的时候才返回，在此期间一直会等待，进程从调用 recvfrom 开始到它返回的整段时间内都是被阻塞的，因此被称为阻塞 I&#x2F;O 模型。常用 IO 模型交互图如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649522297797-a008ac08-3d0a-4496-b71c-859877a8f126.png#clientId=ub2077674-f022-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u615c264e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=371&originWidth=651&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=25891&status=done&style=none&taskId=u93741eac-ecb5-4749-938e-320cc6521af&title=" alt="image.png"><br>首先应用程序调用 recvfrom()转入内核，注意内核有 2 个过程，等待数据就绪和拷贝内核数据到用户空间，直到最后复制完成后，recvfrom()才返回，此过程一直是阻塞的。</p>
<h3 id="2、非阻塞-I-x2F-O-模型"><a href="#2、非阻塞-I-x2F-O-模型" class="headerlink" title="2、非阻塞 I&#x2F;O 模型"></a>2、非阻塞 I&#x2F;O 模型</h3><p>recvfrom 从应用层到内核的时候，如果该缓冲区没有数据的话，就直接返回一个 EWOULDBLOCK 错误，一般都对非阻塞 I&#x2F;O 模型进行轮询检查这个状态，看内核是不是有数据到来，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649522297809-96fbb845-1f64-40b3-81a3-7555b3ce6dad.png#clientId=ub2077674-f022-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5190db18&margin=%5Bobject%20Object%5D&name=image.png&originHeight=409&originWidth=644&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33416&status=done&style=none&taskId=u4bef8f22-7374-4e98-93ba-b421a70499b&title=" alt="image.png"></p>
<h3 id="3、I-x2F-O-复用模型"><a href="#3、I-x2F-O-复用模型" class="headerlink" title="3、I&#x2F;O 复用模型"></a>3、I&#x2F;O 复用模型</h3><p>Linux 提供 select&#x2F;poll，进程通过将一个或者多个 fd 传递给 select 或者 poll 系统调用，阻塞在 select 操作上，这样 select&#x2F;poll 可以帮我们侦测多个文件描述符 fd 是否处于就绪状态。select&#x2F;poll 是顺序扫描 fd 是否就绪，而且支持的 fd 数量有限，因此它的使用受到一些限制。Linux 还提供了一个 epoll 系统调用，epoll 基于事件驱动方式代替顺序扫描，性能更高，当有 fd 就绪时，立即回调函数 rollback，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649522297845-994a9ff3-7d25-4bb7-be1b-57edd48ed76f.png#clientId=ub2077674-f022-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u83c97bf2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=371&originWidth=679&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=31919&status=done&style=none&taskId=u3f714429-101e-49b6-974f-52e54aa8635&title=" alt="image.png"><br>select 先阻塞，有活动套接字才返回。与 blocking I&#x2F;O 相比，select 会有两次系统调用，但是 select 能处理多个套接字。</p>
<h3 id="4、信号驱动-I-x2F-O-模型"><a href="#4、信号驱动-I-x2F-O-模型" class="headerlink" title="4、信号驱动 I&#x2F;O 模型"></a>4、信号驱动 I&#x2F;O 模型</h3><p>首先开启套接字信号驱动 I&#x2F;O 功能，并通过系统调用 sigaction 执行一个信号处理函数（此系统调用立即返回，进程继续工作，它是非阻塞的）。当数据准备就绪时，就为该进程生成一个 SIGIO 信号，通过信号回调通知应用程序调用 recvfrom 来读取数据，并通知主循环函数处理数据，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649522297987-78a42b20-0dee-437e-bf35-c57ef1ca2622.png#clientId=ub2077674-f022-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucf548bc6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=639&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=30623&status=done&style=none&taskId=ubdaab16a-9e8a-4b97-939a-95fff3cd504&title=" alt="image.png"><br>只有 Unix 系统支持，与 I&#x2F;O multiplexing (select and poll)相比，它的优势是，免去了 select 的阻塞与轮询，当有活跃套接字时，由注册的 handler 处理。</p>
<h3 id="5、异步-I-x2F-O"><a href="#5、异步-I-x2F-O" class="headerlink" title="5、异步 I&#x2F;O"></a>5、异步 I&#x2F;O</h3><p>告知内核启动某个操作，并让内核在整个操作完成之后（包括将数据从内核复制到用户自己的缓冲区）通知我们。这种模型与信号驱动模型的主要区别就是：信号驱动 I&#x2F;O 由内核通知我们何时可以开始一个 I&#x2F;O 操作；异步 I&#x2F;O 模型由内核通知我们 I&#x2F;O 操作何时已经完成。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649522297970-c0f9e82a-847f-4ccd-bb03-5cfaf3343269.png#clientId=ub2077674-f022-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc03fda2f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=380&originWidth=633&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=26816&status=done&style=none&taskId=u52f71716-8357-4e07-937c-a8672a14a66&title=" alt="image.png"><br>很少有 Linux&#x2F;Unix 系统支持，Windows 的 IOCP 则是此模型，完全异步的 I&#x2F;O 复用机制，纵观上面其它四种模型，至少都会在由 kernel copy data to appliction 时阻塞。而该模型是当 copy 完成后才通知 application，可见是纯异步的，好像只有 Windows 的完成端口是这个模型，效率也很出色。</p>
<h2 id="I-x2F-O-多路复用技术"><a href="#I-x2F-O-多路复用技术" class="headerlink" title="I&#x2F;O 多路复用技术"></a>I&#x2F;O 多路复用技术</h2><p>I&#x2F;O 多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源，主要应用场景如下：<br>1、服务器需要同时处理多个处于监听状态或者多个连接状态的套接字。<br>2、服务器需要同时处理多种网络协议的套接字。<br>目前支持 I&#x2F;O 多路复用的系统调用有 select、pselect、poll,、epoll（linux）、kqueue（FreeBSD）、iocp(Windows)，由于 select&#x2F; poll 的一些固有缺陷导致了它的应用受到了很大的限制，Linux 中最终选择了 epoll，来克服 select 的缺点。</p>
<h3 id="select-模型缺点"><a href="#select-模型缺点" class="headerlink" title="select 模型缺点"></a>select 模型缺点</h3><p>1、最大并发数限制问题，select 中一个进程所打开的 FD（文件描述符）是有限制的，由 FD_SETSIZE 设置，默认值是 1024，对于需要支持上万个 TCP 连接的大型服务器来说显然太少了。<br>2、I&#x2F;O 效率问题，select 每次调用都会线性扫描全部的 FD 集合，效率就会呈现线性下降。<br>3、内存拷贝问题，select 采取了内存拷贝方法，将内核中的 FD 消息通知给用户空间。<br>poll 基本上效率和 select 是相同的，select 缺点的 2 和 3 它都没有改掉。</p>
<h3 id="epoll-的改进和提升"><a href="#epoll-的改进和提升" class="headerlink" title="epoll 的改进和提升"></a>epoll 的改进和提升</h3><p>1、没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大，1G 内存的机器上大约有 10 万个句柄左右，具体数目可以 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max 察看。<br>2、I&#x2F;O 效率提升，不会随着 FD 数目的增加而线性下降，它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，epoll 的效率就会远远高于 select 和 poll。<br>3、使用 mmap 共享内存加速内核与用户空间的消息传递，内核和用户空间 mmap 共用一块内存来实现，省去了内存拷贝。</p>
<h2 id="Java-的-I-x2F-O-的演进"><a href="#Java-的-I-x2F-O-的演进" class="headerlink" title="Java 的 I&#x2F;O 的演进"></a>Java 的 I&#x2F;O 的演进</h2><p>从 JDK1.0 到 JDK1.3，Java 的 I&#x2F;O 类库都非常原始，基于 Java 的所有 Socket 通信都采用了同步阻塞模式（BIO），在性能和可靠性方面存在着巨大的瓶颈。<br>2002 年 JDK1.4 发布，NIO 以 JSR-51 的身份随 JDK 发布，增加了 java.nio 包，提供了很多非阻塞 I&#x2F;O 开发的类库，在 JDK1.4 和 1.5 update 10 版本之前，JDK 的 selector 基于 select&#x2F;poll 模型，基于 I&#x2F;O 复用的非阻塞 I&#x2F;O，不是异步 I&#x2F;O。在 JDK1.5 update 10 和 Linux core2.6 以上版本，优化了 selector 的实现，在底层使用 epoll 替换了 select&#x2F;poll，上层 API 没有变化，可认为是 JDK NIO 的一次性能优化。<br>2011 年 JDK1.7 发布，将原来的 NIO 进行了升级，通过 JSR-203 演进而来，称为 NIO2.0，提供异步 I&#x2F;O 开发类库。</p>
<h3 id="1、Java-同步阻塞-I-x2F-O"><a href="#1、Java-同步阻塞-I-x2F-O" class="headerlink" title="1、Java 同步阻塞 I&#x2F;O"></a>1、Java 同步阻塞 I&#x2F;O</h3><p>在 java 中调用 InputStream.read()或者 OutputStream.write()时，用户进程会阻塞住直到数据就绪，相当于一个线程一个连接的方式。所以在采用 Java IO 时，在 Server 端通常会采用对于每个新连接，起一个新的线程去处理，这样后来的连接就不用等到之前的完成才能操作。但也带来了问题，毕竟线程是系统的稀缺资源，数量上会有瓶颈，达到一定数量后，性能急剧下降，内存崩溃。不能应对大量连接的情况，而且线程切换很耗费系统资源。</p>
<h3 id="2、Java-NIO-同步非阻塞-IO"><a href="#2、Java-NIO-同步非阻塞-IO" class="headerlink" title="2、Java NIO 同步非阻塞 IO"></a>2、Java NIO 同步非阻塞 IO</h3><p>基于 Java IO 的缺点，NIO 采用了新的设计方式，核心在 ServerSocketChannel, SocketChannel, FileChannel, ByteBuffer, Pipe, Selector。非阻塞主要依靠 Selector，Channel 在 Selector 上注册自己感兴趣的事件，然后 Selector 线程会轮询注册在自己身上的 Channel，当有数据准备就绪时，就通知相应的 Channel。这样一个 Selector 可以管理多个 Channel，但实际上还是阻塞的，现在不阻塞 IO 层面了，阻塞在 Selector 线程上了。而且采用轮询的方式，效率比较低。</p>
<h3 id="3、Java-AIO-异步非阻塞-IO"><a href="#3、Java-AIO-异步非阻塞-IO" class="headerlink" title="3、Java AIO 异步非阻塞 IO"></a>3、Java AIO 异步非阻塞 IO</h3><p>在 Java NIO 的基础上，增加了 AsynchronousServerSocketChannel, AsynchronousSocketChannel, AsynchronousChannelGroup, CompletionHandler，其中 AsynchronousChannelGroup 起到了事件收集和任务分发的作用，而 CompletionHandler 是绑定在事件上回调机制，从而达到异步。能否真正实现异步，关键还要看系统底层的实现，当前来看只有 window 的 iocp 实现了真正的异步，linux 上还是通过 epoll 来模拟，是一种伪异步。<br>是否异步主要在<strong>系统内核数据拷贝到用户进程这个步骤来区分</strong>，同步的话是通知用户进程数据准备好了，可以拷贝了，然后用户进程阻塞去拷贝数据；异步的话是操作系统帮你把数据拷贝后，然后通知你数据好了，可以直接用了。</p>
]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis大Value</title>
    <url>/article/cache/redis-large-value/</url>
    <content><![CDATA[<p>大 key 和大 value 的危害，如何处理</p>
<p>Redis 的大 key 有什么危害？<br>一个 key 的 value 较大时的情况，比如：</p>
<ul>
<li>内存不均：单 value 较大时，可能会导致节点之间的内存使用不均匀，间接地影响 key 的部分和负载不均匀；</li>
<li>阻塞请求：redis 为单线程，单 value 较大读写需要较长的处理时间，会阻塞后续的请求处理；</li>
<li>阻塞网络：单 value 较大时会占用服务器网卡较多带宽，可能会影响该服务器上的其他 Redis 实例或者应用。</li>
</ul>
<p>虽说答的是挺好的，但是我又随之产生了另一个疑惑，如果 redis 的 key 较长时，会产生什么样的影响呢？查了很多文章，说的都不是特别清楚。所以我决心探究一下这个问题。</p>
<p>我们需要知道 Redis 是如何存储 key 和 value 的：<br>根结构为 RedisServer，其中包含 RedisDB（数据库）。<br>而 RedisDB 实际上是使用 Dict（字典）结构对 Redis 中的 kv 进行存储的。这里的 key 即字符串，value 可以是 string&#x2F;hash&#x2F;list&#x2F;set&#x2F;zset 这五种对象之一。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648744552730-c003770c-2f09-4054-8f06-ea9f281aab67.png#clientId=u2aa5eb80-caf6-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9ed9ae81&margin=%5Bobject%20Object%5D&name=image.png&originHeight=728&originWidth=1560&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=305690&status=done&style=none&taskId=u8557ca20-7bae-4532-bbec-ad03e3b9faa&title=" alt="image.png"></p>
<p>Dict 字典结构中，存储数据的主题为 DictHt，即哈希表。而哈希表本质上是一个 DictEntry（哈希表节点）的数组，并且使用链表法解决哈希冲突问题（关于哈希冲突的解决方法可以参考大佬的文章 <a href="https://www.jianshu.com/p/4d3cb99d7580">解决哈希冲突的常用方法分析</a>）。<br>所以在这里实际存储时，key 和 value 都是存储在 DictEntry 中的。<br>所以基本上来说，<strong>大 key 和大 value 带来的内存不均和网络 IO 压力都是一致的，只是 key 相较于 value 还多一个做 hashcode 和比较的过程（链表中进行遍历比较 key），会有更多的内存相关开销。</strong><br>结论：</p>
<ol>
<li>大 key 和大 value 的危害是一致的：内存不均、阻塞请求、阻塞网络。</li>
<li><strong>key 由于比 value 需要做更多的操作如 hashcode、链表中比较等操作，所以会比 value 更多一些内存相关开销。</strong></li>
</ol>
<p>如何处理？<br>Redis 大 key<br>Redis 使用过程中经常会有各种大 key 的情况， 比如：</p>
<ol>
<li>单个简单的 key 存储的 value 很大</li>
<li>hash， set，zset，list 中存储过多的元素（以万为单位）</li>
</ol>
<p>由于 redis 是单线程运行的，如果一次操作的 value 很大会对整个 redis 的响应时间造成负面影响，所以，业务上能拆则拆，下面举几个典型的分拆方案。</p>
<p>业务场景：<br>即通过 hash 的方式来存储每一天用户订单次数。那么 key &#x3D; order_20200102, field &#x3D; order_id, value &#x3D; 10。那么如果一天有百万千万甚至上亿订单的时候，key 后面的值是很多，存储空间也很大，造成所谓的大 key。</p>
<p>大 key 的风险： 1.读写大 key 会导致超时严重，甚至阻塞服务。 2.如果删除大 key，DEL 命令可能阻塞 Redis 进程数十秒，使得其他请求阻塞，对应用程序和 Redis 集群可用性造成严重的影响。</p>
<p>redis 使用会出现大 key 的场景： 1.单个简单 key 的存储的 value 过大；<br>2.hash、set、zset、list 中存储过多的元素。</p>
<p>解决问题： 1.单个简单 key 的存储的 value 过大的解决方案：<br>将大 key 拆分成对个 key-value，使用 multiGet 方法获得值，这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的 IO 操作。<br>2.hash、set、zset、list 中存储过多的元素的解决方案：</p>
<ol>
<li>类似于第一种场景，使用第一种方案拆分;</li>
<li>以 hash 为例，将原先的 hget、hset 方法改成（加入固定一个 hash 桶的数量为 10000），先计算 field 的 hash 值模取 10000，确定该 field 在哪一个 key 上。<br>将大 key 进行分割，为了均匀分割，可以对 field 进行 hash 并通过质数 N 取余，将余数加到 key 上面，我们取质数 N 为 997。<br>那么新的 key 则可以设置为：<br>newKey &#x3D; order_20200102_String.valueOf( Math.abs(order_id.hashcode() % 997) )<br>field &#x3D; order_id<br>value &#x3D; 10<br>hset (newKey, field, value) ;<br>hget(newKey, field)</li>
</ol>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL表碎片</title>
    <url>/article/mysql/mysql-table-fragmentation/</url>
    <content><![CDATA[<blockquote>
<p>原文链接：<br><a href="https://www.percona.com/blog/2020/06/24/mysql-table-fragmentation-beware-of-bulk-insert-with-failure-or-rollback/">https://www.percona.com/blog/2020/06/24/mysql-table-fragmentation-beware-of-bulk-insert-with-failure-or-rollback/</a></p>
</blockquote>
<p><strong>当心批量插入失败或者回滚时带来的 MySQL 表碎片</strong>，通常，DBA 都了解使用 DELETE 语句会产生表碎片。在大多数情况下，当执行大量的删除时，DBA 总会重新构建表以回收磁盘空间。但是，您是否认为只有删除才会导致表碎片？（答案：并不是）。<br>在这篇博文中，我将解释插入如何会带来碎片。</p>
<p>在讨论这个主题之前，我们需要了解 MySQL，有两种碎片：</p>
<ul>
<li>在表中的 InnoDB 页完全空闲引起的碎片。</li>
<li>InnoDB 页未填充满（页中还有一些空闲空间）引起的碎片。</li>
</ul>
<p>主要有三种由插入引起的碎片场景：</p>
<ul>
<li>插入，然后回滚</li>
<li>插入语句失败</li>
<li>页分裂引起的碎片</li>
</ul>
<h2 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h2><p>我创建了自己的测试环境来测试这些案例。</p>
<ul>
<li>DB：Percona 版分支</li>
<li>Table：frag，ins_frag，frag_page_spl</li>
<li>表大小：2G</li>
</ul>
<h2 id="场景-1：插入后回滚"><a href="#场景-1：插入后回滚" class="headerlink" title="场景 1：插入后回滚"></a>场景 1：插入后回滚</h2><p>首先，我创建了一个新表”ins_flag”。然后我开启一个事务（使用 BEGIN）,如下所示开始拷贝”frag”表中数据到”ins_flag”中。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; create table ins_frag like frag;
Query OK, 0 rows affected (0.01 sec)

mysql&gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; insert into ins_frag select * from frag;
Query OK, 47521280 rows affected (3 min 7.45 sec)
Records: 47521280  Duplicates: 0  Warnings: 0

#Linux shell
sakthi-3.2# ls -lrth
total 8261632
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 03:00 ins_frag.ibd</code></pre>

<p>如上所示，您可以看到已经执行了插入，但是我还没有提交或者回滚插入操作。您注意到 2 张表都已经占用 2G 磁盘空间。</p>
<p>现在我将回滚插入操作。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; select count(*) from ins_frag;
+----------+
| count(*) |
+----------+
| 47521280 |
+----------+
1 row in set (1.87 sec)

mysql&gt; rollback;
Query OK, 0 rows affected (5 min 45.21 sec)

mysql&gt; select count(*) from ins_frag;
+----------+
| count(*) |
+----------+
|        0 |
+----------+
1 row in set (0.00 sec)


#Linux shell
sakthi-3.2# ls -lrth
total 8261632
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 03:09 ins_frag.ibd</code></pre>

<p>当插入回滚后，”ins_frag”表仍然占有相同的 2GB 的磁盘空间。让我们在 MySQL 客户端看看碎片空间。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; SELECT
-&gt; table_schema as &#39;DATABASE&#39;,
-&gt; table_name as &#39;TABLE&#39;,
-&gt; CONCAT(ROUND(( data_length + index_length ) &#x2F; ( 1024 * 1024 * 1024 ), 2), &#39;G&#39;) &#39;TOTAL&#39;,
-&gt; CONCAT(ROUND(data_free &#x2F; ( 1024 * 1024 * 1024 ), 2), &#39;G&#39;) &#39;DATAFREE&#39;
-&gt; FROM information_schema.TABLES
-&gt; where table_schema&#x3D;&#39;percona&#39; and table_name&#x3D;&#39;ins_frag&#39;;
+----------+----------+-------+----------+
| DATABASE | TABLE.   | TOTAL | DATAFREE |
+----------+----------+-------+----------+
| percona  | ins_frag | 0.00G | 1.96G    |
+----------+----------+-------+----------+
1 row in set (0.01 sec)</code></pre>

<p>这清楚的显示了插入之后回滚会产生碎片。我们需要重建表来回收磁盘空间。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; alter table ins_frag engine&#x3D;innodb;
Query OK, 0 rows affected (2.63 sec)
Records: 0  Duplicates: 0  Warnings: 0

#Linux shell

sakthi-3.2# ls -lrth
total 4131040
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   112K Jun 17 03:11 ins_frag.ibd</code></pre>

<h2 id="场景-2-插入语句失败"><a href="#场景-2-插入语句失败" class="headerlink" title="场景 2: 插入语句失败"></a>场景 2: 插入语句失败</h2><p>在会话 1 中，我将在事务中执行相同的插入语句。但是这次我会在会话 2 中中断并杀掉这个插入语句。<br><strong>会话 1</strong></p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">#Linux shell

sakthi-3.2# ls -lrth
total 4131040
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   112K Jun 17 04:02 ins_frag.ibd

#MySQL shell

mysql&gt; begin;
Query OK, 0 rows affected (0.00 sec)

mysql&gt; insert into ins_frag select * from frag;   #is running</code></pre>

<p><strong>会话 2</strong></p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; pager grep -i insert ; show processlist;
PAGER set to &#39;grep -i insert&#39;
| 33 | root            | localhost | percona | Query   |    14 | executing              | insert into ins_frag select * from frag |
4 rows in set (0.00 sec)

mysql&gt; kill 33;
Query OK, 0 rows affected (0.00 sec)</code></pre>

<p>插入中断并失败了。<strong>在会话 1 查看：</strong></p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; insert into ins_frag select * from frag;
ERROR 2013 (HY000): Lost connection to MySQL server during query

#Linux shell

sakthi-3.2# ls -lrth
total 4591616
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   212M Jun 17 04:21 ins_frag.ibd

#MySQL shell

mysql&gt; select count(*) from ins_frag;
+----------+
| count(*) |
+----------+
|        0 |
+----------+
1 row in set (0.10 sec)</code></pre>

<p>插入并未完成，表中无数据。但是仍然，这个表的 ibd 文件已经涨到 212M。通过 MySQL 客户端查看表空间碎片。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; SELECT
-&gt; table_schema as &#39;DATABASE&#39;,
-&gt; table_name as &#39;TABLE&#39;,
-&gt; CONCAT(ROUND(( data_length + index_length ) &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) &#39;TOTAL&#39;,
-&gt; CONCAT(ROUND(data_free &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) &#39;DATAFREE&#39;
-&gt; FROM information_schema.TABLES
-&gt; where table_schema&#x3D;&#39;percona&#39; and table_name&#x3D;&#39;ins_frag&#39;;
+----------+----------+---------+----------+
| DATABASE | TABLE    | TOTAL   | DATAFREE |
+----------+----------+---------+----------+
| percona  | ins_frag | 0.03M   | 210.56M  |
+----------+----------+---------+----------+
1 row in set (0.01 sec)</code></pre>

<p>表中有碎片，需要重建表回收这些空间。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; alter table ins_frag engine&#x3D;&#39;innodb&#39;;
Query OK, 0 rows affected (0.03 sec)
Records: 0  Duplicates: 0  Warnings: 0

#Linux shell

sakthi-3.2# ls -lrth
total 4131040
-rw-r-----  1 _mysql  _mysql   2.0G Jun 17 02:43 frag.ibd
-rw-r-----  1 _mysql  _mysql   112K Jun 17 04:32 ins_frag.ibd</code></pre>

<h2 id="场景-3-页分裂引起的碎片"><a href="#场景-3-页分裂引起的碎片" class="headerlink" title="场景 3: 页分裂引起的碎片"></a>场景 3: 页分裂引起的碎片</h2><p>我们知道，InnoDB 记录存储在 InnoDB 页中。默认情况下，每个页大小是 16K，但是您可以选择更改页大小。</p>
<p>如果 InnoDB 页没有足够的空间容纳新的记录或索引条目，它将被分成 2 页，每页约占 50%。这意味着，即使对表只有插入，没有回滚和删除，最终也可能只有平均 75%的页利用率——因此这种页内部损失为 25%。</p>
<p>当按排序建立索引，它们会有更多的拥塞，如果表很多插入到索引中随机位置，就会导致页分裂。</p>
<p>参阅 Marco Tusa 写的博客 InnoDB Page Merging and Page Splitting，详细介绍了页分裂和 InnoDB 页结构&#x2F;操作。</p>
<p>为了实验，我创建了一个具有排序索引的表（降序）</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; show create table frag_page_splG
*************************** 1. row ***************************
Table: frag_page_spl
Create Table: CREATE TABLE &#96;frag_page_spl&#96; (
&#96;id&#96; int NOT NULL AUTO_INCREMENT,
&#96;name&#96; varchar(16) DEFAULT NULL,
&#96;messages&#96; varchar(600) DEFAULT NULL,
PRIMARY KEY (&#96;id&#96;),
KEY &#96;idx_spl&#96; (&#96;messages&#96; DESC)
) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 COLLATE&#x3D;utf8mb4_0900_ai_ci
1 row in set (0.07 sec)</code></pre>

<p>我们可以通过表 INFORMATION_SCHEMA.INNODB_METRICS 监控页分裂情况。对此，您需要启用 InnoDB monitor。</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; SET GLOBAL innodb_monitor_enable&#x3D;all;
Query OK, 0 rows affected (0.09 sec)</code></pre>

<p>我写了一个 6 个并发随机插入的脚本。脚本执行结束后：</p>
<pre class="line-numbers language-sql" data-language="sql"><code class="language-sql">mysql&gt; select name,count,type,status,comment from information_schema.innodb_metrics where name like &#39;%index_page_spl%&#39;G
*************************** 1. row ***************************
name: index_page_splits
count: 52186
type: counter
status: enabled
comment: Number of index page splits
1 row in set (0.05 sec)

mysql&gt; SELECT
-&gt; table_schema as &#39;DATABASE&#39;,
-&gt; table_name as &#39;TABLE&#39;,
-&gt; CONCAT(ROUND(( data_length + index_length ) &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) &#39;TOTAL&#39;,
-&gt; CONCAT(ROUND(data_free &#x2F; ( 1024 * 1024 ), 2), &#39;M&#39;) &#39;DATAFREE&#39;
-&gt; FROM information_schema.TABLES
-&gt; where table_schema&#x3D;&#39;percona&#39; and table_name&#x3D;&#39;frag_page_spl&#39;;
+----------+---------------+----------+----------+
| DATABASE | TABLE.        | TOTAL    | DATAFREE |
+----------+---------------+----------+----------+
| percona  | frag_page_spl | 2667.55M | 127.92M  |
+----------+---------------+----------+----------+
1 row in set (0.00 sec)</code></pre>

<p>从指标上看，我们看到页分裂次数在增加。输出显示有 52186 次页分裂，产生了 127.92MB 的碎片。<br>一旦发生页分裂，唯一的方法是将创建的页降至合并阈值之下。当这种情况发生时，InnoDB 通过合并操作将数据从分裂的页中移出。对表和特定的索引合并阈值是可配置的。<br>另一种重新组织数据的方法是 OPTIMIZE TABLE。这是一个非常重和漫长的过程，但通常这是解决过多页比较稀疏的唯一方法。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>前面两种情况很少见。因为大多数应用程序都不会设计在表中写入大量数据。</li>
<li>在执行批量插入时（INSERT INTO SELECT * FROM, 加载 mysqldump 的数据, INSERT with huge data 等）需要注意这些问题。</li>
<li>碎片占用的磁盘空间始终是可重用的。</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>InnoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis分布式锁</title>
    <url>/article/cache/redis-lock/</url>
    <content><![CDATA[<blockquote>
<p>分布式锁为解决<strong>分布式系统中多个应用同时访问同一个资源的问题</strong>。</p>
</blockquote>
<h2 id="分布式锁的使用场景"><a href="#分布式锁的使用场景" class="headerlink" title="分布式锁的使用场景"></a>分布式锁的使用场景</h2><p>一般是在两个场景下会防止对同一个资源的重复访问</p>
<ul>
<li><strong>提升效率</strong></li>
</ul>
<p>比如多个节点计算同一批任务，如果某个任务已经有节点在计算了，那其他节点就不用重复计算了，以免浪费计算资源。不过重复计算也没事，不会造成其他更大的损失，<strong>允许偶尔的失败</strong>。</p>
<ul>
<li><strong>保证正确性</strong></li>
</ul>
<p>这种情况对锁的要求就很高了，如果重复计算，会对正确性造成影响，<strong>不允许失败</strong>。</p>
<h2 id="分布式锁支持的特性"><a href="#分布式锁支持的特性" class="headerlink" title="分布式锁支持的特性"></a>分布式锁支持的特性</h2><p>在这个技术不断更新迭代的情况下，分布式这个概念，在企业中的权重越来越高。谈及分布式时，不可避免一定会提到分布式锁，现阶段分布式锁的实现方式主流的有几种实现方式，Zookeeper、Mysql、Redis，Etcd，分布式锁需要保证锁的<strong>要互斥、防死锁、高性能、可重入</strong>。<br>本篇文章以 Redis 为例，从我们的角度来看，下面的三个属性是有效使用分布式锁所需的最低保证。</p>
<ul>
<li>安全特性：<strong>互斥</strong></li>
</ul>
<p>在任何给定时刻，只有一个客户端可以持有锁。</p>
<ul>
<li>活力属性：<strong>无死锁</strong></li>
</ul>
<p>最终，即使锁定资源的客户端崩溃或分区，也始终可以获得锁。</p>
<ul>
<li>活动性：<strong>容错能力</strong></li>
</ul>
<p>只要大多数 Redis 节点都处于运行状态，客户端就可以获取和释放锁。</p>
<p>一般分布式锁需要支持以下功能，才能满足大多数场景的需求</p>
<table><thead><tr>
<th>**功能 **</th>
<th><strong>是否必须</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead><tbody><tr>
<td>失效时间</td>
<td>是</td>
<td>防止 Java 应用忽然挂掉 或 网络动荡 而产生死锁</td>
</tr>
<tr>
<td>自动续租</td>
<td>是</td>
<td>支持分布式锁过期，自动续租</td>
</tr>
<tr>
<td>可重入性</td>
<td>是</td>
<td>单线程调用的多个函数或地方可能会锁住同一把锁 (不支持调用服务化接口)</td>
</tr>
<tr>
<td>阻塞、公平锁</td>
<td>是</td>
<td>第三方的介质实现分布式锁，非公平的锁竞争并不会提高性能</td>
</tr>
<tr>
<td>接入动态配置</td>
<td>是</td>
<td>可自动配置 etcd 等锁的配置中心地址，通知 client 端进行切换</td>
</tr>
<tr>
<td>尝试锁</td>
<td>可选</td>
<td>tryLock ， 超过指定时间没有获得锁则抛出异常，由使用方捕获异常</td>
</tr>
</tbody></table><h2 id="Redis-实现分布式锁的几种方式"><a href="#Redis-实现分布式锁的几种方式" class="headerlink" title="Redis 实现分布式锁的几种方式"></a>Redis 实现分布式锁的几种方式</h2><h3 id="1、单机"><a href="#1、单机" class="headerlink" title="1、单机"></a>1、单机</h3><p>直接单机上锁，这台机器挂了就 GG 了，整个业务系统都获取不到锁了，单点故障。</p>
<h3 id="2、哨兵"><a href="#2、哨兵" class="headerlink" title="2、哨兵"></a>2、哨兵</h3><p>既然单点故障，那我搞个哨兵，Sentinel，自动主从切换。但是会有如下新问题：<br>锁写到 Master 后，还没同步到 Slave 呢，Master 挂了。Slave 选举成了 Master，但是 Slave 里没有锁，其他线程再次能上锁了，不安全。</p>
<h3 id="3、集群"><a href="#3、集群" class="headerlink" title="3、集群"></a>3、集群</h3><p>集群只是做了 slot 分片，锁还是只写到一个 Master 上，所以和 Sentinel 哨兵模式有同样的问题。</p>
<h3 id="4、红锁"><a href="#4、红锁" class="headerlink" title="4、红锁"></a>4、红锁</h3><p>也称 RedLock，非常著名，是 Redis 实现分布式锁相对最安全可靠的一种手段。<br>核心思路是：搞几个独立的 Master，比如 5 个。然后挨着个的加锁，只要超过一半以上（这里是 5 &#x2F; 2 + 1 &#x3D; 3 个）那就代表加锁成功，然后释放锁的时候也逐台释放。这样的好处在于一台 Master 挂了的话，还有其他的，所以不耽误，看起来好像完美解决了上面的问题，但是并不是 100%安全。</p>
<p>不管用 Redis 的哪种方式来实现分布式锁，都不是 100%安全的，那就不用 Redis 做分布式锁了吗？不然，我觉得取决于业务吧，如果你业务要求必须，<strong>100%不能出问题，那用 zk&#x2F;etcd 来实现吧</strong>。但是据我了解，<strong>至少 80%的互联网公司都不这么强烈要求，大对数还是 Redis 分布式锁</strong>，即使用 zk 来实现的也可能不是业务上 100%要求不能出现问题。比如你项目就没用 zk，只用了 Redis，那完全没必要搭建一套 zk 来做分布式锁，Redis 的红锁也能保证高可用，几乎不会出现问题的。</p>
<h2 id="Redis-多节点实现分布式锁带来的挑战"><a href="#Redis-多节点实现分布式锁带来的挑战" class="headerlink" title="Redis 多节点实现分布式锁带来的挑战"></a>Redis 多节点实现分布式锁带来的挑战</h2><p>我们使用 Redis 锁定资源的最简单方法是：</p>
<blockquote>
<ul>
<li>在实例中创建锁。</li>
<li>锁通常使用 Redis 过期功能，在有限时间存在，最终将被释放，超过给定时间会被删除。</li>
<li>当客户端需要释放资源时，它将删除锁。</li>
</ul>
</blockquote>
<p>乍一看，似乎并没有什么问题。但是不妨我们深究一下，这种实现方案在 redis 单机环境下似乎并没有什么问题。但是如果节点坏了呢？好吧，那么让我们添加一个 slave 节点。如果主服务器宕机了，就使用这个节点。但是我们不妨来看看她真的能保证可用吗？在谈论这个的致命缺陷时，我们需要了解一个知识点，<strong>Redis 复制是异步的</strong>。<br><strong>1、客户端 A 获取主服务器中的锁</strong><br><strong>2、在将锁复制传输到从机之前，主机崩溃</strong><br><strong>3、slave 晋升为 master</strong><br><strong>4、客户端 B 获取锁，因为从机并没有该锁的对象，获取成功</strong><br>显然，这样是不对的，<strong>主节点因为没来得及同步数据就宕机了</strong>，所以从节点没有该数据，从而造成分布式锁的失效</p>
<h2 id="Redlock-红锁"><a href="#Redlock-红锁" class="headerlink" title="Redlock 红锁"></a><strong>Redlock 红锁</strong></h2><p>作者认为，我们应该使用多个 Redis，这些节点是完全独立的，不需要使用复制或者任何协调数据的系统。</p>
<h3 id="RedLock-多个-redis-系统获取锁过程"><a href="#RedLock-多个-redis-系统获取锁过程" class="headerlink" title="RedLock 多个 redis 系统获取锁过程"></a>RedLock 多个 redis 系统获取锁过程</h3><ol>
<li>以毫秒 ms 为单位获取当前的服务器时间</li>
<li>尝试使用相同的 key 和随机值来获取锁，对每一个机器获取锁时都应该有一个超时时间，比如锁的过期时间为 10s，那么获取单个节点锁的超时时间就应该为 5 到 50 毫秒左右，他这样做的目的是为了保证客户端与故障的机器连接，耗费多余的时间。超时间时间内未获取数据就放弃该节点，从而去下一个节点获取，直至将所有节点全部获取一遍。</li>
<li>获取完成后，获取当前时间减去步骤一获取的时间，当且仅当客户端半数以上获取成功且获取锁的时间小于锁额超时时间，则证明该锁生效。</li>
<li>获取锁之后，锁的超时时间等于设置的有效时间-获取锁花费的时间</li>
<li>如果 获取锁的机器不满足半数以上，或者锁的超时时间计算完毕后为负数 等异常操作，则系统会尝试解锁所有实例，即使有些实例没有获取锁成功，依旧会被尝试解锁。</li>
<li>释放锁，只需在所有实例中释放锁，无论客户端是否认为它能够成功锁定给定的实例。</li>
</ol>
<h3 id="Redlock-真能够解决问题吗"><a href="#Redlock-真能够解决问题吗" class="headerlink" title="Redlock 真能够解决问题吗"></a>Redlock 真能够解决问题吗</h3><p>Martin Kleppmann 发表<a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">文章</a>，<strong>Redlock 并不能保证该锁的安全性，分布式锁用途有下面 2 种：</strong></p>
<blockquote>
<p><strong>1、提升效率</strong>，用锁来保证一个任务没有必要被执行两次，比如（很昂贵的计算）。<br>2、<strong>保证正确性</strong>，使用锁来保证任务按照正常的步骤执行，防止两个节点同时操作一份数据，造成文件冲突，数据丢失。</p>
</blockquote>
<p><strong>提升效率，允许偶尔的失败。</strong>对锁是有一定宽容度的，就算发生了两个节点同时工作，对系统的影响也仅仅是多付出了一些计算的成本，没什么额外的影响。<strong>使用单点的 Redis 就能很好的解决问题，没有必要使用 RedLock，维护那么多的 Redis 实例，提升系统的维护成本。</strong></p>
<h3 id="分布式锁的超时性，所带来的缺点"><a href="#分布式锁的超时性，所带来的缺点" class="headerlink" title="分布式锁的超时性，所带来的缺点"></a>分布式锁的超时性，所带来的缺点</h3><p>但是对于第二种场景<strong>保证正确性</strong>来说，就比较慎重了，因为很可能涉及到一些金钱交易，如果锁定失败，并且两个节点同时处理同一数据，则结果将导致文件损坏，数据丢失，永久性不一致，或者金钱方面的损失。</p>
<p>我们假设一种场景，我们有两个客户端，每一个客户端必须拿到锁之后才能去保存数据到数据库，我们使用 RedLock 算法实现会出现什么问题呢？RedLock 中，为了防止死锁，锁是具有过期时间的，但是 Martin 认为这是不安全的。该流程图类似于这样。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648715500983-f2e3ee2a-3144-46dc-ac75-19814c643102.png#clientId=ue2c0d7c5-aca3-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=400&id=u2c02c07f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=400&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=40923&status=done&style=none&taskId=u040b413b-dd5f-4ba8-9ee1-03d3164367d&title=&width=1100" alt="image.png"></p>
<p>客户端 1 获取到锁成功后，开始执行，执行到一半系统发生 Full GC ,系统服务被挂起，过段时间锁超时了。客户端 2 等待客户端 1 的锁超时后，成功的获取到锁，开始执行入库操作，完成后，客户端 1 完成了 Full GC,又做了一次入库操作。这是不安全的。如何解决呢？</p>
<p>Martin 提出来一种<strong>类似乐观锁的实现机制</strong>，示例图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648715529584-8e43c9ec-e9ed-4eac-9f82-0a570402ccb3.png#clientId=ue2c0d7c5-aca3-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=400&id=u6689a039&margin=%5Bobject%20Object%5D&name=image.png&originHeight=400&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=42930&status=done&style=none&taskId=u7ce5607d-a74a-443b-8222-477b16071c6&title=&width=1100" alt="image.png"><br>客户端 1 长时间被挂起后，客户端 2 获取到锁，开始写库操作，同时携带令牌 34，写库完成后，客户端 1 苏醒，开始进行入库操作，但是因为携带的令牌为 33 小于最新令牌，该次提交就被拒绝。<br>这个想法听起来似乎时很完备的思路，这样即使系统因为某些原因被挂起，数据也能够被正确的处理。但是仔细想一下：</p>
<blockquote>
<p>如果仅当您的令牌大于所有过去的令牌时，数据存储区才能始终接受写入，则它是可线性化的存储区，<strong>相当与使用数据库来实现一个 分布式锁系统，那么 RedLock 的作用就变的微乎其微</strong>。甚至不在需要使用 redis 保证分布式锁。</p>
</blockquote>
<h3 id="RedLock-对于系统时钟强依赖"><a href="#RedLock-对于系统时钟强依赖" class="headerlink" title="RedLock 对于系统时钟强依赖"></a>RedLock 对于系统时钟强依赖</h3><p>回想一下 Redlock 算法获取锁的几个步骤，你会发现锁的有效性是与当前的系统时钟强依赖，我们假设，我们有，A、B、C、D、E 五个 redis 节点：</p>
<ul>
<li>客户端 1 获取节点 A，B，C 的锁定。由于网络问题，无法访问 D 和 E。</li>
<li>节点 C 上的时钟向前跳，导致锁过期。</li>
<li>客户端 2 获取节点 C，D，E 的锁定。由于网络问题，无法访问 A 和 B。</li>
<li>现在，客户 1 和 2 都认为他们持有该锁。</li>
</ul>
<p>如果 C 在将锁持久保存到磁盘之前崩溃并立即重新启动，则可能会发生类似的问题。<br>Martin 认为系统时间的阶跃主要来自两个方面（以及作者给出的解决方案）：</p>
<ul>
<li><strong>人为修改</strong></li>
</ul>
<p>对于人为修改，能说啥呢？人要搞破坏没办法避免。</p>
<ul>
<li><strong>从 NTP 服务收到了一个跳跃时时钟更新</strong></li>
</ul>
<p>NTP 网络时间协议(Network Time Protocol)受到一个阶跃时钟更新，对于这个问题，需要通过运维来保证。需要将阶跃的时间更新到服务器的时候，应当采取小步快跑的方式。多次修改，每次更新时间尽量小。</p>
<h2 id="分布式锁需要注意的问题"><a href="#分布式锁需要注意的问题" class="headerlink" title="分布式锁需要注意的问题"></a>分布式锁需要注意的问题</h2><h3 id="1、加锁成功的客户端挂掉或网络动荡，可能产生死锁"><a href="#1、加锁成功的客户端挂掉或网络动荡，可能产生死锁" class="headerlink" title="1、加锁成功的客户端挂掉或网络动荡，可能产生死锁"></a>1、加锁成功的客户端挂掉或网络动荡，可能产生死锁</h3><p>对于加的分布式锁，需要<strong>设置 expire 过期时间</strong>，锁过期后进行释放</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">SET key value [EX seconds] [PX milliseconds] NX</code></pre>

<h3 id="2、业务未执行完，分布式锁超时，需要进行锁续期"><a href="#2、业务未执行完，分布式锁超时，需要进行锁续期" class="headerlink" title="2、业务未执行完，分布式锁超时，需要进行锁续期"></a>2、业务未执行完，分布式锁超时，需要进行锁续期</h3><p>Redisson 实现了一种保证锁失效时间绝对大于业务程序执行时间的机制。官方叫做看门狗机制（Watchdog），主要原理是，在程序成功获取锁之后，启动一个 Watchdog，会 fork 一条子线程去不断的给该锁续期，直至该锁释放为止。原理图大概如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648918542273-8da12f6b-9ecb-41a9-9721-38789a7733d3.png#clientId=u6a12c7db-de06-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=332&id=u11e98e06&margin=%5Bobject%20Object%5D&name=image.png&originHeight=664&originWidth=1354&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=56357&status=done&style=none&taskId=u4219fc59-3e1c-421e-986e-533cac48f1c&title=&width=677" alt="image.png"><br><strong>Redisson 使用守护线程来进行锁的续期</strong>（守护线程的作用：当主线程销毁，会和主线程一起销毁）防止程序宕机后，线程依旧不断续命，造成死锁。<br>RedissonLock 加锁续期</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">RLock lock &#x3D; redisson.getLock(&quot;myLock&quot;);
lock.lock();

@Override
public void lock() &#123;
    try &#123;
        lockInterruptibly();
    &#125; catch (InterruptedException e) &#123;
        Thread.currentThread().interrupt();
    &#125;
&#125;

@Override
public void lockInterruptibly() throws InterruptedException &#123;
    lockInterruptibly(-1, null);
&#125;

public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123;
    long threadId &#x3D; Thread.currentThread().getId();
    &#x2F;&#x2F; 尝试获取锁，leaseTime为-1，开启看门狗续期
    Long ttl &#x3D; tryAcquire(leaseTime, unit, threadId);
    &#x2F;&#x2F; lock acquired
    if (ttl &#x3D;&#x3D; null) &#123;
        return;
    &#125;

    RFuture&lt;RedissonLockEntry&gt; future &#x3D; subscribe(threadId);
    commandExecutor.syncSubscription(future);

    try &#123;
        &#x2F;&#x2F; 加锁失败，while(true)等待重试
        while (true) &#123;
            ttl &#x3D; tryAcquire(leaseTime, unit, threadId);
            &#x2F;&#x2F; lock acquired
            if (ttl &#x3D;&#x3D; null) &#123;
                break;
            &#125;

            &#x2F;&#x2F; waiting for message
            if (ttl &gt;&#x3D; 0) &#123;
                getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
            &#125; else &#123;
                getEntry(threadId).getLatch().acquire();
            &#125;
        &#125;
    &#125; finally &#123;
        unsubscribe(future, threadId);
    &#125;
&#125;

private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123;
    return get(tryAcquireAsync(leaseTime, unit, threadId));
&#125;

&#x2F;&#x2F; threadId,当前的线程id
private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123;
    if (leaseTime !&#x3D; -1) &#123;
        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    &#125;

    &#x2F;&#x2F; leaseTime &#x3D;&#x3D; -1 就 scheduleExpirationRenewal 开启看门狗续期，
    &#x2F;&#x2F; leaseTime !&#x3D; -1 就不续期，只是把 internalLockLeaseTime 时间变成传进来的时间。
    &#x2F;&#x2F; lockWatchdogTimeout 看门狗 默认超时时间 30 秒
    RFuture&lt;Long&gt; ttlRemainingFuture &#x3D; tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
    ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123;
        @Override
        public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123;
            if (!future.isSuccess()) &#123;
                return;
            &#125;

            Long ttlRemaining &#x3D; future.getNow();
            &#x2F;&#x2F; lock acquired
            if (ttlRemaining &#x3D;&#x3D; null) &#123;
                &#x2F;&#x2F; 当前线程 threadId 是否要续租
                scheduleExpirationRenewal(threadId);
            &#125;
        &#125;
    &#125;);
    return ttlRemainingFuture;
&#125;

private void scheduleExpirationRenewal(final long threadId) &#123;
    if (expirationRenewalMap.containsKey(getEntryName())) &#123;
        return;
    &#125;

    Timeout task &#x3D; commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123;
        @Override
        public void run(Timeout timeout) throws Exception &#123;
            &#x2F;&#x2F; 当前线程 threadId 是否要续租
            RFuture&lt;Boolean&gt; future &#x3D; renewExpirationAsync(threadId);
            future.addListener(new FutureListener&lt;Boolean&gt;() &#123;
                @Override
                public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123;
                    expirationRenewalMap.remove(getEntryName());
                    if (!future.isSuccess()) &#123;
                        log.error(&quot;Can&#39;t update lock &quot; + getName() + &quot; expiration&quot;, future.cause());
                        return;
                    &#125;
                    if (future.getNow()) &#123;
                        &#x2F;&#x2F; reschedule itself
                        scheduleExpirationRenewal(threadId);
                    &#125;
                &#125;
            &#125;);
        &#125;
        &#x2F;&#x2F; 这里是个知识点，续期线程在过期时间达到三分之一的时候工作，比如9s过期时间，那么续期会在第3秒的时候工作，也就是还剩余6s的时候进行续期
    &#125;, internalLockLeaseTime &#x2F; 3, TimeUnit.MILLISECONDS);

    if (expirationRenewalMap.putIfAbsent(getEntryName(), new ExpirationEntry(threadId, task)) !&#x3D; null) &#123;
        task.cancel();
    &#125;
&#125;

protected RFuture&lt;Boolean&gt; renewExpirationAsync(long threadId) &#123;
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
                                          &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1) then &quot; +
                                          &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                                          &quot;return 1; &quot; +
                                          &quot;end; &quot; +
                                          &quot;return 0;&quot;,
                                          Collections.&lt;Object&gt;singletonList(getName()),
                                          internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>很简单，就是看当前线程有没有加锁 hexists, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1，有加锁的话就代表业务线程还没执行完，就给他的锁重新续期 pexpire’, KEYS[1], ARGV[1]，然后返回 1，也就是 true，没加锁的话返回 0，也就是 false。那就是返回 1 就调用自己准备下一次续期 scheduleExpirationRenewal(threadId)，返回 0 就调用在删除后不做处理。</p>
<p>这里有几个关键点：</p>
<ul>
<li>要使 watchLog 机制生效，lock 时不要设置过期时间</li>
<li>续期核心 lua 脚本在 renewExpirationAsync 里</li>
<li>Watchdog 通过类似 netty 的 Future 功能来实现<strong>异步延时</strong></li>
<li><strong>续期的开始时间是超过过期时间的三分之一，比如 9s 过期时间，那么第 3s 的时候开始续期</strong></li>
<li><strong>续期成功自己调用自己，也就是为下一次续期做准备，</strong>续期失败不做后续处理</li>
</ul>
<blockquote>
<p>因为分布式锁的续期是在客户端执行的，所以如果 client 宕机了，续期线程就不能工作了，也就不能续期了，<strong>只能等到超时时间后锁被自动删除</strong>。这时应该把分布式锁删除，让其他客户端来获取。<br>如果要立刻删除，<strong>需要增加额外的工作，比如增加哨兵机制</strong>，让哨兵来维护所有 redis 客户端的列表。哨兵定时监控客户端是否宕机，如果检测到宕机，立刻删除这个客户端的锁。</p>
</blockquote>
<p>另外，Redisson 定时器使用的是 netty-common 包中的 HashedWheelTime 来实现的，Redisson 还实现并且优化了 <strong>RedLock 算法、公平锁、可重入锁、连锁</strong>等操作，使 Redis 分布式锁的实现方式更加简便高效。</p>
<h3 id="3、对于要保证正确的分布式锁，需要注意原子性"><a href="#3、对于要保证正确的分布式锁，需要注意原子性" class="headerlink" title="3、对于要保证正确的分布式锁，需要注意原子性"></a>3、对于要保证正确的分布式锁，需要注意原子性</h3><h4 id="Redisson-加锁"><a href="#Redisson-加锁" class="headerlink" title="Redisson 加锁"></a>Redisson 加锁</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123;
    internalLockLeaseTime &#x3D; unit.toMillis(leaseTime);
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
              &quot;if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 0) then &quot; +
                  &quot;redis.call(&#39;hset&#39;, KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1) then &quot; +
                  &quot;redis.call(&#39;hincrby&#39;, KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;return redis.call(&#39;pttl&#39;, KEYS[1]);&quot;,
                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>加锁 lua 脚本解释</p>
<pre class="line-numbers language-lua" data-language="lua"><code class="language-lua">lock入参：
keys[1]:自定义锁的key  RLock lock &#x3D; redissonClient.getLock(lockKey);
argv[1]&#x3D;锁的租期，默认30s
argv[2]&#x3D;锁的名称(UUID:threadId)

&#x2F;&#x2F; 1.不存在key锁
if(exists keys[1]&#x3D;&#x3D;0) then
  &#x2F;&#x2F; 赋值 key field value --&gt;1.1 尝试获取锁
  hset keys[1] argv[2] 1
  &#x2F;&#x2F; 过期 expire key time --&gt;1.2 设置锁过期时间
  pexpire keys[1] argv[1]
  return 空；
end

&#x2F;&#x2F; 存在Key name 的锁 --&gt; 2.当前线程已获取锁
if(hexists keys[1] argv[2]&#x3D;&#x3D;1) then
  &#x2F;&#x2F; --&gt;2.1 原子计数器+1  锁重入！！！
  hincrby keys[1] argv[2] 1
  &#x2F;&#x2F; 过期 --&gt;2.2 重置锁过期时间
  pexpire keys[1] argv[1]
  return 空；
end

&#x2F;&#x2F; --&gt;3.返回剩余过期时间
return pttl keys[1]</code></pre>

<blockquote>
<p>注意：lua 脚本数组下标从 1 开始</p>
</blockquote>
<h4 id="Redisson-释放锁"><a href="#Redisson-释放锁" class="headerlink" title="Redisson 释放锁"></a>Redisson 释放锁</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123;
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
            &quot;if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 0) then &quot; +
                &quot;redis.call(&#39;publish&#39;, KEYS[2], ARGV[1]); &quot; +
                &quot;return 1; &quot; +
            &quot;end;&quot; +
            &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[3]) &#x3D;&#x3D; 0) then &quot; +
                &quot;return nil;&quot; +
            &quot;end; &quot; +
            &quot;local counter &#x3D; redis.call(&#39;hincrby&#39;, KEYS[1], ARGV[3], -1); &quot; +
            &quot;if (counter &gt; 0) then &quot; +
                &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[2]); &quot; +
                &quot;return 0; &quot; +
            &quot;else &quot; +
                &quot;redis.call(&#39;del&#39;, KEYS[1]); &quot; +
                &quot;redis.call(&#39;publish&#39;, KEYS[2], ARGV[1]); &quot; +
                &quot;return 1; &quot;+
            &quot;end; &quot; +
            &quot;return nil;&quot;,
            Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>释放 lua 脚本解释</p>
<pre class="line-numbers language-lua" data-language="lua"><code class="language-lua">unlock入参：
keys[1]:自定义锁的key  RLock lock &#x3D; redissonClient.getLock(lockKey);
keys[2]：通道名称  redisson_lock__channel:&#123;UUID:threadId&#125;
argv[1]&#x3D; publish unlock消息&#x3D;0
argv[2]&#x3D;锁的租期，默认30s
argv[3]&#x3D;锁的名称(UUID:threadId)

&#x2F;&#x2F; --&gt;1.不存在key锁，直接返回
if(hexists keys[1] argv[3]&#x3D;&#x3D;0) then
return 空

&#x2F;&#x2F; --&gt;2.存在锁，原子计数器-1
counter&#x3D;hincrby keys[1] argv[3] -1

if(counter&gt;0) then
  &#x2F;&#x2F; --&gt;2.1 计数器&gt;0,还有锁没释放，重置锁过期时间
  pexpire KEYS[1] ARGV[2]
  return 0;
else
  &#x2F;&#x2F; --&gt;2.2计数器&#x3D;0，锁已经全部释放完毕。
  &#x2F;&#x2F; --&gt;删除key
  del KEYS[1]
  &#x2F;&#x2F; --&gt;发布消息 publish channel message
  publish KEYS[2] ARGV[1]
  return 1；
end

return 空；</code></pre>

<blockquote>
<p>实现原理的学习可参考 <a href="https://bbs.huaweicloud.com/blogs/238821">https://bbs.huaweicloud.com/blogs/238821</a></p>
</blockquote>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（一）基础数据类型</title>
    <url>/article/redis/redis-introduce/</url>
    <content><![CDATA[<p>REmote DIctionary Server(Redis) 是一个由 Salvatore Sanfilippo 写的 key-value 存储系统。Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API。它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648982520740-f6e21a86-02bd-4c4c-a013-923a2155cdde.png#clientId=ua941ba02-f1a4-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5b38cb6e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=197&originWidth=513&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=13923&status=done&style=none&taskId=ua56b85db-8bdf-48ec-a02e-785402d29d7&title=" alt="image.png"></p>
<h2 id="Redis-简介"><a href="#Redis-简介" class="headerlink" title="Redis 简介"></a>Redis 简介</h2><p>Redis 是完全开源免费的，遵守 BSD 协议，是一个高性能的 key-value 数据库,与其他 key-value 缓存产品有以下三个特点：</p>
<ul>
<li>Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li>
<li>Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。</li>
<li>Redis 支持数据的备份，即 master-slave 模式的数据备份。</li>
</ul>
<h2 id="Redis-优势"><a href="#Redis-优势" class="headerlink" title="Redis 优势"></a>Redis 优势</h2><ol>
<li>性能极高，**Redis 能读的速度是 110000 次&#x2F;s，写的速度是 81000 次&#x2F;s **。</li>
<li>丰富的数据类型，Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。</li>
<li>原子性，Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作全并后的原子性执行。</li>
<li>丰富的特性 ，Redis 还支持 publish&#x2F;subscribe, 通知, key 过期等等特性。</li>
</ol>
<h2 id="Redis-与其他-key-value-存储差异"><a href="#Redis-与其他-key-value-存储差异" class="headerlink" title="Redis 与其他 key-value 存储差异"></a>Redis 与其他 key-value 存储差异</h2><ol>
<li>Redis 有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。</li>
<li>Redis 的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。</li>
<li>Redis 运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样 Redis 可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。</li>
</ol>
<h2 id="Redis-数据类型"><a href="#Redis-数据类型" class="headerlink" title="Redis 数据类型"></a>Redis 数据类型</h2><p>Redis 支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及 zset(sorted set：有序集合)。</p>
<h3 id="String（字符串）"><a href="#String（字符串）" class="headerlink" title="String（字符串）"></a>String（字符串）</h3><p>string 是 redis 最基本的类型，你可以理解成与 Memcached 一模一样的类型，一个 key 对应一个 value。string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象 。<br>s<strong>tring 类型是 Redis 最基本的数据类型，一个键最大能存储 512MB。</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">redis 127.0.0.1:6379&gt; SET name &quot;charles&quot;
OK
redis 127.0.0.1:6379&gt; GET name
&quot;charles&quot;</code></pre>

<p>在以上实例中我们使用了 Redis 的 SET 和 GET 命令。键为 name，对应的值为 charles。<br>注意：一个键最大能存储 512MB。</p>
<h3 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h3><p>Redis hash 是一个键值对集合。<br>Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">127.0.0.1:6379&gt; HMSET user:1 username charles password charles points 200
OK
127.0.0.1:6379&gt; HGETALL user:1
1) &quot;username&quot;
2) &quot;charles&quot;
3) &quot;password&quot;
4) &quot;charles&quot;
5) &quot;points&quot;
6) &quot;200&quot;</code></pre>

<p>以上实例中 hash 数据类型存储了包含用户脚本信息的用户对象。 实例中我们使用了 Redis HMSET, HGETALL 命令，user:1 为键值。<br>每个 hash 可以存储 232 -1 键值对（40 多亿）。</p>
<h3 id="List（列表）"><a href="#List（列表）" class="headerlink" title="List（列表）"></a>List（列表）</h3><p>Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">redis 127.0.0.1:6379&gt; lpush charles redis
(integer) 1
redis 127.0.0.1:6379&gt; lpush charles mongodb
(integer) 2
redis 127.0.0.1:6379&gt; lpush charles rabitmq
(integer) 3
redis 127.0.0.1:6379&gt; lrange charles 0 10
1) &quot;rabitmq&quot;
2) &quot;mongodb&quot;
3) &quot;redis&quot;</code></pre>

<p>列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储 40 多亿)。</p>
<h3 id="Set（集合）"><a href="#Set（集合）" class="headerlink" title="Set（集合）"></a>Set（集合）</h3><p>Redis 的 Set 是 string 类型的无序集合。<br>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。<br>sadd 命令<br>添加一个 string 元素到,key 对应的 set 集合中，成功返回 1,如果元素已经在集合中返回 0,key 对应的 set 不存在返回错误。<br>sadd key member</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">redis 127.0.0.1:6379&gt; sadd charles redis
(integer) 1
redis 127.0.0.1:6379&gt; sadd charles mongodb
(integer) 1
redis 127.0.0.1:6379&gt; sadd charles rabitmq
(integer) 1
redis 127.0.0.1:6379&gt; sadd charles rabitmq
(integer) 0
redis 127.0.0.1:6379&gt; smembers charles
1) &quot;rabitmq&quot;
2) &quot;mongodb&quot;
3) &quot;redis&quot;</code></pre>

<p>注意：以上实例中 rabitmq 添加了两次，但根据集合内元素的唯一性，第二次插入的元素将被忽略。<br>集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储 40 多亿个成员)。</p>
<h3 id="zset（sorted-set：有序集合）"><a href="#zset（sorted-set：有序集合）" class="headerlink" title="zset（sorted set：有序集合）"></a>zset（sorted set：有序集合）</h3><p>Redis zset 和 set 一样也是 string 类型元素的集合,且不允许重复的成员。<br>不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。<br>zset 的成员是唯一的,但分数(score)却可以重复。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">redis 127.0.0.1:6379&gt; zadd charles 0 redis
(integer) 1
redis 127.0.0.1:6379&gt; zadd charles 0 mongodb
(integer) 1
redis 127.0.0.1:6379&gt; zadd charles 0 rabitmq
(integer) 1
redis 127.0.0.1:6379&gt; zadd charles 0 rabitmq
(integer) 0
redis 127.0.0.1:6379&gt; ZRANGEBYSCORE charles0 1000
1) &quot;redis&quot;
2) &quot;mongodb&quot;
3) &quot;rabitmq&quot;</code></pre>

<p>上面主要介绍了 Redis 相关的基础信息和支持的数据类型，关于 redis 的实现原理后续会逐步讲解。</p>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（七）大key和大value</title>
    <url>/article/redis/redis-large-value/</url>
    <content><![CDATA[<p>大 key 和大 value 的危害，如何处理</p>
<p>Redis 的大 key 有什么危害？<br>一个 key 的 value 较大时的情况，比如：</p>
<ul>
<li>内存不均：单 value 较大时，可能会导致节点之间的内存使用不均匀，间接地影响 key 的部分和负载不均匀；</li>
<li>阻塞请求：redis 为单线程，单 value 较大读写需要较长的处理时间，会阻塞后续的请求处理；</li>
<li>阻塞网络：单 value 较大时会占用服务器网卡较多带宽，可能会影响该服务器上的其他 Redis 实例或者应用。</li>
</ul>
<p>虽说答的是挺好的，但是我又随之产生了另一个疑惑，如果 redis 的 key 较长时，会产生什么样的影响呢？查了很多文章，说的都不是特别清楚。所以我决心探究一下这个问题。</p>
<p>我们需要知道 Redis 是如何存储 key 和 value 的：<br>根结构为 RedisServer，其中包含 RedisDB（数据库）。<br>而 RedisDB 实际上是使用 Dict（字典）结构对 Redis 中的 kv 进行存储的。这里的 key 即字符串，value 可以是 string&#x2F;hash&#x2F;list&#x2F;set&#x2F;zset 这五种对象之一。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648744552730-c003770c-2f09-4054-8f06-ea9f281aab67.png#clientId=u2aa5eb80-caf6-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9ed9ae81&margin=%5Bobject%20Object%5D&name=image.png&originHeight=728&originWidth=1560&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=305690&status=done&style=none&taskId=u8557ca20-7bae-4532-bbec-ad03e3b9faa&title=" alt="image.png"></p>
<p>Dict 字典结构中，存储数据的主题为 DictHt，即哈希表。而哈希表本质上是一个 DictEntry（哈希表节点）的数组，并且使用链表法解决哈希冲突问题（关于哈希冲突的解决方法可以参考大佬的文章 <a href="https://www.jianshu.com/p/4d3cb99d7580">解决哈希冲突的常用方法分析</a>）。<br>所以在这里实际存储时，key 和 value 都是存储在 DictEntry 中的。<br>所以基本上来说，<strong>大 key 和大 value 带来的内存不均和网络 IO 压力都是一致的，只是 key 相较于 value 还多一个做 hashcode 和比较的过程（链表中进行遍历比较 key），会有更多的内存相关开销。</strong><br>结论：</p>
<ol>
<li>大 key 和大 value 的危害是一致的：内存不均、阻塞请求、阻塞网络。</li>
<li><strong>key 由于比 value 需要做更多的操作如 hashcode、链表中比较等操作，所以会比 value 更多一些内存相关开销。</strong></li>
</ol>
<p>如何处理？<br>Redis 大 key<br>Redis 使用过程中经常会有各种大 key 的情况， 比如：</p>
<ol>
<li>单个简单的 key 存储的 value 很大</li>
<li>hash， set，zset，list 中存储过多的元素（以万为单位）</li>
</ol>
<p>由于 redis 是单线程运行的，如果一次操作的 value 很大会对整个 redis 的响应时间造成负面影响，所以，业务上能拆则拆，下面举几个典型的分拆方案。</p>
<p>业务场景：<br>即通过 hash 的方式来存储每一天用户订单次数。那么 key &#x3D; order_20200102, field &#x3D; order_id, value &#x3D; 10。那么如果一天有百万千万甚至上亿订单的时候，key 后面的值是很多，存储空间也很大，造成所谓的大 key。</p>
<p>大 key 的风险： 1.读写大 key 会导致超时严重，甚至阻塞服务。 2.如果删除大 key，DEL 命令可能阻塞 Redis 进程数十秒，使得其他请求阻塞，对应用程序和 Redis 集群可用性造成严重的影响。</p>
<p>redis 使用会出现大 key 的场景： 1.单个简单 key 的存储的 value 过大；<br>2.hash、set、zset、list 中存储过多的元素。</p>
<p>解决问题： 1.单个简单 key 的存储的 value 过大的解决方案：<br>将大 key 拆分成对个 key-value，使用 multiGet 方法获得值，这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的 IO 操作。<br>2.hash、set、zset、list 中存储过多的元素的解决方案：</p>
<ol>
<li>类似于第一种场景，使用第一种方案拆分;</li>
<li>以 hash 为例，将原先的 hget、hset 方法改成（加入固定一个 hash 桶的数量为 10000），先计算 field 的 hash 值模取 10000，确定该 field 在哪一个 key 上。<br>将大 key 进行分割，为了均匀分割，可以对 field 进行 hash 并通过质数 N 取余，将余数加到 key 上面，我们取质数 N 为 997。<br>那么新的 key 则可以设置为：<br>newKey &#x3D; order_20200102_String.valueOf( Math.abs(order_id.hashcode() % 997) )<br>field &#x3D; order_id<br>value &#x3D; 10<br>hset (newKey, field, value) ;<br>hget(newKey, field)</li>
</ol>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis存储结构</title>
    <url>/article/cache/redis-storage-structure/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Redis 作为一款高性能数据库，表现在：它接收到一个键值对操作后， 能以微秒级别的速度找到数据，并快速完成操作。其高性能得奥秘来缘于以下两点：</p>
<ul>
<li>Redis 是内存数据库， 所有操作都在内存上完成，内存的访问速度本身就很快</li>
<li>Reids 通过高效的数据结构来组织数据。</li>
</ul>
<p>本章节可以让你在最短的时间了解如下内容：</p>
<ul>
<li>Redis 支持五大数据类型</li>
<li>Redis 组织 Key-Value 数据结构</li>
<li>Redis5 大值类型数据存储结构</li>
</ul>
<h2 id="一、五大数据类型"><a href="#一、五大数据类型" class="headerlink" title="一、五大数据类型"></a>一、五大数据类型</h2><ul>
<li>String(字符串)</li>
<li>List(列表)</li>
<li>Set(集合)</li>
<li>Hash（哈希）</li>
<li>Zset（有序集合）</li>
</ul>
<h2 id="二、组织-Key-Value-数据结构"><a href="#二、组织-Key-Value-数据结构" class="headerlink" title="二、组织 Key-Value 数据结构"></a>二、组织 Key-Value 数据结构</h2><p>在 redis 中无论什么数据类型，在数据库中都是以 key-value 形式保存，通过进行对 Redis-key 的操作，来完成对数据库中数据的操作。</p>
<h3 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h3><p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。<br>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一 个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。<br>哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。在下图中，可以看到，_哈希桶中的 entry 元素中保存了 key 和_value 指针<strong>，分别指向了 实际的键和值<br>因为这个哈希表保存了所有的键值对，所以，我也把它称为</strong>全局哈希表**。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779832457-c09e705a-bf33-4cf0-b9b4-411792c87aef.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=566&id=u136f6d07&margin=%5Bobject%20Object%5D&name=image.png&originHeight=566&originWidth=1056&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=207909&status=done&style=none&taskId=u2ae3c090-ef92-4b9c-ad82-c7d159475cf&title=&width=1056" alt="image.png"></p>
<h4 id="哈希表优势"><a href="#哈希表优势" class="headerlink" title="哈希表优势"></a>哈希表优势</h4><p>让我们可以用 O(1) 的时间复杂度来快速查找到键值对——我们只需要计算 键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说， 不管哈希表里有 10 万个键还是 100 万个键，我们只需要一次计算就能找到相应的键。</p>
<h4 id="哈希表劣势"><a href="#哈希表劣势" class="headerlink" title="哈希表劣势"></a>哈希表劣势</h4><p>当往哈希表写入大量数据后，就可能发现操作有时候会突然变慢了，这其实是因为你忽略了一个潜在 的风险点，那就是<strong>哈希冲突</strong>问题和 <strong>rehash</strong> 可能带来的操作阻塞。</p>
<h3 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h3><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。<br>哈希冲突，也就是 指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。毕竟，哈希桶的个数通常要少于 key 的数量，这也就是说，难免会有一些 key 的哈希值对 应到了同一个哈希桶中。</p>
<h4 id="链式哈希"><a href="#链式哈希" class="headerlink" title="链式哈希"></a>链式哈希</h4><p>链式哈希也很容易理解，就是指同一个哈希 桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779889129-ec383f85-181f-4e98-b070-ba902f0d2c4d.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=692&id=ud220931d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=692&originWidth=794&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=250853&status=done&style=none&taskId=u0cdb692f-9f75-4de4-923a-68fc2d282e8&title=&width=794" alt="image.png"><br>如上图所示：entry1、entry2 和 entry3 都需要保存在哈希桶 3 中，导致了哈希冲突。此 时，entry1 元素会通 过一个_next 指针指向 entry2，同样，entry2 也会通过_next 指针 指向 entry3。这样一来，即使哈希桶 3 中的元素有 100 个，我们也可以通过 entry 元素 中的指针，把它们连起来。这就形成了一个链表，也叫作哈希冲突链。</p>
<h3 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h3><p>哈希冲突链上的元素只能通过指针逐一查找再操作。如果 哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链 过长，进而导致这个链上的元素查找耗时长，效率降低。<br>Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐 增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个 桶中的冲突。</p>
<h4 id="简单-rehash"><a href="#简单-rehash" class="headerlink" title="简单 rehash"></a>简单 rehash</h4><p>为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希 表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空 间。随着数据逐步增多，Redis 开始执行 rehash,这个过程分为三步：</p>
<ul>
<li>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；</li>
<li>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中</li>
<li>释放哈希表 1 的空间</li>
</ul>
<p>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来 的哈希表 1 留作下一次 rehash 扩容备用。（有点类似 JVM 年轻代复制回收）</p>
<h4 id="渐进式-rehash"><a href="#渐进式-rehash" class="headerlink" title="渐进式 rehash"></a>渐进式 rehash</h4><p>简单 rehash 过程中最大的问题在于第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都 迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据 了。为了避免这个问题，Redis 采用了渐进式 rehash。<br>渐进式 rehash 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求 时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝 到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。<br>这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操 作，保证了数据的快速访问。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779914591-e4c4c721-7f22-4a94-96bb-e424742d1f2a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=650&id=ueecd49e3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=650&originWidth=999&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=327606&status=done&style=none&taskId=u6dd9ec86-ebe2-484d-bb62-8c9dd78d3d8&title=&width=999" alt="image.png"></p>
<h3 id="内存使用大小"><a href="#内存使用大小" class="headerlink" title="内存使用大小"></a>内存使用大小</h3><p>哈希表的每一项是 一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针， 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节。<br>但这里需要注意的是这里 Redis 使用的内 存分配库 jemalloc 了。<br>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。<br>举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字 节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，<strong>dictEntry 结构就占 用了 32 字节</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780229010-3120360f-507a-4c46-b6e1-7b229dc38f13.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=156&id=ued930961&margin=%5Bobject%20Object%5D&name=image.png&originHeight=623&originWidth=1056&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=194203&status=done&style=none&taskId=ube66eb53-78ef-4e48-8235-458252f0166&title=&width=264" alt="image.png"></p>
<h2 id="三、不同数据类型存储结构"><a href="#三、不同数据类型存储结构" class="headerlink" title="三、不同数据类型存储结构"></a>三、不同数据类型存储结构</h2><p>Redis 底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈 希表、跳表和整数数组。它们和数据类型的对应关系如下图所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780246131-132be37e-abc1-4b14-a54b-cbf87e1904a6.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=305&id=u6f02ecf5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=305&originWidth=994&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=151661&status=done&style=none&taskId=u5e069a5c-7cb4-4dad-a0b6-9223b3b09f1&title=&width=994" alt="image.png"></p>
<h3 id="简单动态字符串（SDS）"><a href="#简单动态字符串（SDS）" class="headerlink" title="简单动态字符串（SDS）"></a>简单动态字符串（SDS）</h3><p>Redis String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存。</p>
<h4 id="Redis-SDS-数据结构"><a href="#Redis-SDS-数据结构" class="headerlink" title="Redis SDS 数据结构"></a>Redis SDS 数据结构</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780289412-e0046012-68e4-48e6-8bd4-3837c90d3a99.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=758&id=u00197c7c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=758&originWidth=1050&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=148199&status=done&style=none&taskId=uf419e644-49bb-4e7b-90f8-dd32520d17a&title=&width=1050" alt="image.png"></p>
<h5 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h5><p>Redis 简单字符串可以存储数据类型有很多，而且，不同数据类型都有些相同的元数据要记录，这其中包括：</p>
<ul>
<li>最后一次访问的时间</li>
<li>被引用的次数</li>
<li>….</li>
</ul>
<p>其中元数据占用 8 个字节。</p>
<h5 id="PRT"><a href="#PRT" class="headerlink" title="PRT"></a>PRT</h5><p>表示一个指针，指针再进一步指向具体 数据类型的实际数据所在。如果存储类型是 String 类型，那么指针指向的是的 SDS 结构所在的内存地址。<br>其中 PRT 指针占用 8 个字节。</p>
<h5 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h5><p>SDS 存储结构负责存储具体数据。其中包括了三层结构：</p>
<h6 id="buf"><a href="#buf" class="headerlink" title="buf"></a>buf</h6><ul>
<li>字节数组，保存实际数据。</li>
<li>为了表示字节数组的结束，Redis 会自动在数组最后加 一个“\0”，这就会额外占用 1 个字节的开销。</li>
</ul>
<h6 id="len"><a href="#len" class="headerlink" title="len"></a>len</h6><ul>
<li>占 4 个字节，表示 buf 的已用长度。</li>
</ul>
<h6 id="alloc"><a href="#alloc" class="headerlink" title="alloc"></a>alloc</h6><ul>
<li>也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。</li>
</ul>
<p>[图片上传失败…(image-ec3716-1611492954707)]</p>
<h4 id="Redis-SDS-内存优化"><a href="#Redis-SDS-内存优化" class="headerlink" title="Redis SDS 内存优化"></a>Redis SDS 内存优化</h4><p>为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。</p>
<h5 id="Long-类型整数"><a href="#Long-类型整数" class="headerlink" title="Long 类型整数"></a>Long 类型整数</h5><p>当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据 了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。</p>
<h5 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h5><h6 id="当字符串小于-44-字节时"><a href="#当字符串小于-44-字节时" class="headerlink" title="当字符串小于 44 字节时"></a>当字符串小于 44 字节时</h6><p>RedisObject 中的元 数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被 称为 embstr 编码方式。</p>
<h6 id="当字符串大于-44-字节时"><a href="#当字符串大于-44-字节时" class="headerlink" title="当字符串大于 44 字节时"></a>当字符串大于 44 字节时</h6><p>SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。 这种布局方式被称为 raw 编码模式。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780346574-992aa687-ba7f-4fc5-ad31-7556b50ad899.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=739&id=u2582c374&margin=%5Bobject%20Object%5D&name=image.png&originHeight=739&originWidth=1014&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=178694&status=done&style=none&taskId=u5fba1ee8-a340-49cf-9ece-0718c9677d0&title=&width=1014" alt="image.png"></p>
<h4 id="Redis-SDS-优势"><a href="#Redis-SDS-优势" class="headerlink" title="Redis SDS 优势"></a>Redis SDS 优势</h4><p>SDS 这种数据结构相对于 C 字符串有以下优点：</p>
<ul>
<li>杜绝缓冲区溢出</li>
<li>减少字符串操作中的内存重分配次数</li>
<li>二进制安全</li>
<li>由于 SDS 遵循以空字符结尾的惯例，因此兼容部门 C 字符串函数</li>
</ul>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><table><thead><tr>
<th>操作</th>
<th>时间复杂度</th>
</tr>
</thead><tbody><tr>
<td>获取 SDS 长度</td>
<td>由于 SDS 中提供了 len 属性，因此我们可以直接获取时间复杂度为 O(1),C 字符串为 O(n)。</td>
</tr>
<tr>
<td>获取 SDS 未使用空间长度</td>
<td>O(1)</td>
</tr>
<tr>
<td>清除 SDS 保存的内容</td>
<td>由于惰性分配策略，O(1)</td>
</tr>
<tr>
<td>创建一个长度为 N 字符串</td>
<td>O(n)</td>
</tr>
<tr>
<td>拼接一个长度为 N 的 C 字符串</td>
<td>O(n)</td>
</tr>
<tr>
<td>拼接一个长度为 N 的 SDS 字符串</td>
<td>O(n)</td>
</tr>
</tbody></table><h3 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h3><h4 id="数据结构-链表"><a href="#数据结构-链表" class="headerlink" title="数据结构-链表"></a>数据结构-链表</h4><p>相比数组，链表是一种稍微复杂一点的数据结构。数组需要一块连续的内存空间来存储，对内存的要求比较高。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780372496-d0edb5de-d6a1-4de7-8539-820e2fb62b57.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=699&id=uc6849a5a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=699&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=274491&status=done&style=none&taskId=u5a96a5a3-c6af-4bad-a787-caf4933822a&title=&width=1142" alt="image.png"><br>链表结构五花八门，其中三种最常见的链表结构，它们分别是：<strong>单链表</strong>、<strong>双向链表</strong>和<strong>循环链表</strong>。</p>
<h5 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h5><p>链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作后继指针 next。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780382346-7e852ee4-6a21-4d27-9bee-5e4b5f0f9ace.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=399&id=u30fbfc37&margin=%5Bobject%20Object%5D&name=image.png&originHeight=399&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=148863&status=done&style=none&taskId=ubd3f3538-7eb0-41a6-9354-20aa6f9f563&title=&width=1142" alt="image.png"><br>其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。</p>
<h6 id="插入-amp-删除"><a href="#插入-amp-删除" class="headerlink" title="插入&amp;删除"></a>插入&amp;删除</h6><p>而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780393549-1666cf4f-3954-424c-b1b6-662573a8a72a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=650&id=ud3c02b32&margin=%5Bobject%20Object%5D&name=image.png&originHeight=650&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=215444&status=done&style=none&taskId=u615ac002-3f9e-46a4-a278-2287b313cdc&title=&width=1142" alt="image.png"></p>
<h6 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h6><p>但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点<br>你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。</p>
<h5 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h5><p>循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780405398-4c31b4eb-f4a0-4f6a-8fd2-16ac48cb814f.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=399&id=uba73997a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=399&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=146326&status=done&style=none&taskId=u96c32cac-6a3c-4c6e-a81a-1160217d084&title=&width=1142" alt="image.png"></p>
<p>和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。</p>
<h5 id="双向链表-1"><a href="#双向链表-1" class="headerlink" title="双向链表"></a>双向链表</h5><p>单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。<br>双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。</p>
<h6 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h6><p>双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。如删除某个结点 q 需要知道其前驱结点<br><strong>删除某个结点前驱结点</strong><br>我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next&#x3D;q，说明 p 是 q 的前驱结点。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针， 不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了。<br><strong>某个指定结点前面插入</strong><br>同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。<br><strong>查询某个节点</strong><br>除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。<br>Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。</p>
<h6 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h6><p>这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。</p>
<h5 id="双向循环链表"><a href="#双向循环链表" class="headerlink" title="双向循环链表"></a>双向循环链表</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780423996-14ad8829-63a6-435c-8c73-28991bd46931.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=500&id=uf11ba9af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=500&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=228581&status=done&style=none&taskId=uff6cd8ff-b47a-4ffe-a058-1560829d9b0&title=&width=1142" alt="image.png"></p>
<h5 id="链表-VS-数组性能"><a href="#链表-VS-数组性能" class="headerlink" title="链表 VS 数组性能"></a>链表 VS 数组性能</h5><p>数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。</p>
<h6 id="数组优势"><a href="#数组优势" class="headerlink" title="数组优势"></a><strong>数组优势</strong></h6><p>数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。</p>
<h6 id="数组劣势"><a href="#数组劣势" class="headerlink" title="数组劣势"></a><strong>数组劣势</strong></h6><p>数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。</p>
<h6 id="取舍"><a href="#取舍" class="headerlink" title="取舍"></a><strong>取舍</strong></h6><p>如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。</p>
<h4 id="Redis-链表结构"><a href="#Redis-链表结构" class="headerlink" title="Redis 链表结构"></a>Redis 链表结构</h4><p>Redis 链表使用双向链表结构<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780439047-c93a6e28-9ed3-4863-9cb7-028181e193df.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=653&id=u20485c50&margin=%5Bobject%20Object%5D&name=image.png&originHeight=653&originWidth=1146&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=280270&status=done&style=none&taskId=u3178c682-0adc-46b5-be58-814860e460e&title=&width=1146" alt="image.png"></p>
<ul>
<li>双向：链表节点带有前驱、后继指针获取某个节点的前驱、后继节点的时间复杂度为 0(1)。</li>
<li>无环: 链表为非循环链表表头节点的前驱指针和表尾节点的后继指针都指向 NULL，对链表的访问以 NULL 为终点。</li>
<li>带表头指针和表尾指针：通过 list 结构中的 head 和 tail 指针，获取表头和表尾节点的时间复杂度都为 O(1)。</li>
<li>带链表长度计数器:通过 list 结构的 len 属性获取节点数量的时间复杂度为 O(1)。</li>
<li>多态：链表节点使用 void*指针保存节点的值，并且可以通过 list 结构的 dup、free、match 三个属性为节点值设置类型特定函数，所以链表可以用来保存各种不同类型的值。</li>
</ul>
<h3 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h3><p>压缩列表(zip1ist)是列表和哈希的底层实现之一。</p>
<ul>
<li>当一个列表只包含少量列表项,并且每个列表项要么就是小整数值,要么就是长度比较短的字符串,那么 Redis 就会使用压缩列表来做列表的底层实现。</li>
<li>当一个哈希只包含少量键值对,比且每个键值对的键和值要么就是小整数值,要么就是长度比较短的字符串,那么 Redis 就会使用压缩列表来做哈希的底层实现。</li>
</ul>
<h4 id="数据结构-压缩列表"><a href="#数据结构-压缩列表" class="headerlink" title="数据结构-压缩列表"></a>数据结构-压缩列表</h4><p>听到“压缩”两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存,是相较于数组的存储思路而言的。我们知道,数组要求每个元素的大小相同,如果我们要存储不同长度的字符串,那我们就需要用最大长度的字符串大小作为元素的大小(假设是 20 个字节)。存储小于 20 个字节长度的字符串的时候，便会浪费部分存储空间。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780454355-cbd5dd1a-727f-446f-b18f-36ca360171ae.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=246&id=u619cc6f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=246&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=65335&status=done&style=none&taskId=u8488eda2-eb22-4b8f-a664-b88c7accfee&title=&width=1200" alt="image.png"><br>数组的优势占用一片连续的空间可以很好的利用 CPU 缓存访问数据。如果我们想要保留这种优势，又想节省存储空间我们可以对数组进行压缩。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780467106-0c83a678-28ed-47af-8672-316dd2d0d4d9.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=289&id=ua0fd48b0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=854&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=72717&status=done&style=none&taskId=u9939bcc3-55fa-490c-8987-15b181db90c&title=&width=854" alt="image.png"><br>是这样有一个问题，我们在遍历它的时候由于不知道每个元素的大小是多少，因此也就无法计算出下一个节点的具体位置。这个时候我们可以给每个节点增加一个 lenght 的属性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780486188-d17fc325-6f0d-442d-a36c-a200458f6ec1.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=380&id=u47fb909b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=380&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=110718&status=done&style=none&taskId=ue9f201c5-e21b-4036-b0fe-6c19e2bbb89&title=&width=1200" alt="image.png"><br>如此。我们在遍历节点的之后就知道每个节点的长度(占用内存的大小)，就可以很容易计算出下一个节点再内存中的位置。这种结构就像一个简单的压缩列表了。</p>
<h4 id="Redis-压缩列表结构"><a href="#Redis-压缩列表结构" class="headerlink" title="Redis 压缩列表结构"></a>Redis 压缩列表结构</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780502069-e09aedf4-9ee5-4c76-adbd-144055c2221a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=339&id=u4cb75eb1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=339&originWidth=1060&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=108377&status=done&style=none&taskId=u45806980-2ab9-4b4c-856b-449384af80c&title=&width=1060" alt="image.png"></p>
<h5 id="zlbytes"><a href="#zlbytes" class="headerlink" title="zlbytes"></a>zlbytes</h5><ul>
<li>记录整个压缩列表占用的内存字节数；</li>
<li>在对压缩列表进行重新内存分配，或者计算 zlleng 的位置时使用；</li>
<li>占用 4 个字节；</li>
</ul>
<h5 id="zltail"><a href="#zltail" class="headerlink" title="zltail"></a>zltail</h5><ul>
<li>记录压缩列表表尾节点(entryN)起始偏移量距离压缩列表的起始地址有多少字节；</li>
<li>通过这个偏移量，程序无须遍历整个压缩列表就可以确认压缩列表尾节点的地址；</li>
<li>占用 4 个字节；</li>
</ul>
<h5 id="zllen"><a href="#zllen" class="headerlink" title="zllen"></a>zllen</h5><ul>
<li>记录压缩列表包含了节点(entryN)数量；</li>
<li>当这个属性的小于 65535 时，这个属性的值就是压缩列表包含节点的数量；</li>
<li>当这个属性的大于等于 65535 时，节点的真实数量需要遍历整个压缩列表才能计算获得；</li>
<li>占用 2 个字节；</li>
</ul>
<h5 id="zlend"><a href="#zlend" class="headerlink" title="zlend"></a>zlend</h5><ul>
<li>特殊值 OxFF,用于记录压缩列表的未端；</li>
<li>占用 1 个字节；</li>
</ul>
<h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780517323-ffa1704a-7d35-48ed-9332-39408e37262f.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=299&id=u51195243&margin=%5Bobject%20Object%5D&name=image.png&originHeight=299&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=100794&status=done&style=none&taskId=u581807bc-fd85-4ec7-8792-62a10ca4b92&title=&width=1200" alt="image.png"></p>
<ul>
<li>zllen 表示当前压缩列表有 3 个节点；</li>
<li>zltail 表示压缩列表表尾节点(entryN)起始偏移量距离压缩列表的起始地址有 60 个字节，因此如果表示 P 指向了压缩列表开始偏移量，那么 entry3 节点开始偏移量为 P+60；</li>
<li>zlbytes 表示整个压缩列表占用的内存字节数，因此通过计算可以知道 entry3 大小为 19&#x3D;80-60-1；</li>
</ul>
<h5 id="entry-数据结构"><a href="#entry-数据结构" class="headerlink" title="entry 数据结构"></a>entry 数据结构</h5><p>列表节点</p>
<h6 id="prev-len"><a href="#prev-len" class="headerlink" title="prev_len"></a>prev_len</h6><p>表示前一个 entry 的长度。<br><strong>表示上一个 entry 的长度小于 254 字节</strong></p>
<ul>
<li>占用 1 字节</li>
<li>前一节点的长度就保存在这一个字节里面</li>
</ul>
<p><strong>表示上一个 entry 的长度大于 254 字节</strong></p>
<ul>
<li>占用 5 字节</li>
<li>第一字节会被设置为 0xFE</li>
<li>之后的四个字节则用于保存前一节点的长度</li>
</ul>
<h6 id="encoding"><a href="#encoding" class="headerlink" title="encoding"></a>encoding</h6><ul>
<li>表示数据的类型和长度</li>
<li>占用 1 字节</li>
</ul>
<h6 id="len-1"><a href="#len-1" class="headerlink" title="len"></a>len</h6><ul>
<li>表示自身长度</li>
<li>占用 4 字节</li>
</ul>
<h6 id="key"><a href="#key" class="headerlink" title="key"></a>key</h6><ul>
<li>保存实际数据</li>
</ul>
<h4 id="时间复杂度-1"><a href="#时间复杂度-1" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><table><thead><tr>
<th>操作</th>
<th>时间复杂度</th>
</tr>
</thead><tbody><tr>
<td>创建一个压缩列表</td>
<td>O(1)</td>
</tr>
<tr>
<td>创建一个包含给定值的新节点，并将这个新节点添加到压缩列表的表头或者表尾</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新)</td>
</tr>
<tr>
<td>将包含给定值的新节点插入到给定节点之后</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>返回压缩列表给定索引上的节点</td>
<td>O(N)</td>
</tr>
<tr>
<td>在压缩列表中查找并返回包含了给定值的节点</td>
<td>因为节点的值可能是一个字节数组，所以检查节点值和给定值是否相同的复杂度为 O(N)，而查找整个泪飙的复杂度则(N^2)</td>
</tr>
<tr>
<td>返回给定节点的下一个节点</td>
<td>O(1)</td>
</tr>
<tr>
<td>返回给定节点的前一个节点</td>
<td>O(1)</td>
</tr>
<tr>
<td>获取给定节点所保存的值</td>
<td>O(1)</td>
</tr>
<tr>
<td>从压缩列表中删除给定的节点</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>删除压缩列表在给定索引上的连续多个</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>返回压缩列表目前占用的内存字节数</td>
<td>O(1)</td>
</tr>
<tr>
<td>返回压缩列表目前包含的节点数量</td>
<td>点数量小于 65535 时为 O(1)，大于 65535 时为 O(N)</td>
</tr>
</tbody></table><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780537452-e936d830-7f57-49df-adbc-69e5874c5849.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=550&id=ue6e6b33e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=550&originWidth=987&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=244526&status=done&style=none&taskId=u068db4c3-e323-4683-983e-26e2a3e5c04&title=&width=987" alt="image.png"></p>
<h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><h3 id="整数数组"><a href="#整数数组" class="headerlink" title="整数数组"></a>整数数组</h3><h3 id="不同操作的复杂度"><a href="#不同操作的复杂度" class="headerlink" title="不同操作的复杂度"></a>不同操作的复杂度</h3><p>集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元 素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作， 它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。<br>我总结了一个“四句口诀”，希望能帮助你快速记住集合常见操作的复杂度。这样你在使 用过程中，就可以提前规避高复杂度操作了</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
<h5 id="单元素操作"><a href="#单元素操作" class="headerlink" title="单元素操作"></a>单元素操作</h5><p>第一，<strong>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作</strong>。例如，Hash 类 型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。<strong>这些操 作的复杂度由集合采用的数据结构决定</strong>，例如，HGET、HSET 和 HDEL 是对哈希表做操 作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、 SREM、SRANDMEMBER 复杂度也是 O(1)。<br>这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操 作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元 素时，复杂度就从 O(1) 变成 O(M) 了。</p>
<h5 id="范围操作"><a href="#范围操作" class="headerlink" title="范围操作"></a>范围操作</h5><p>第二，<strong>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据</strong>，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。<strong>这类操作的复杂度一般是 O(N)，比较耗时， 我们应该尽量避免</strong>。<br>不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻 塞。</p>
<h5 id="统计操作"><a href="#统计操作" class="headerlink" title="统计操作"></a>统计操作</h5><p>第三，统计操作，是指<strong>集合类型对集合中所有元素个数的记录</strong>，例如 LLEN 和 SCARD。这 类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数 据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
<h5 id="例外情况"><a href="#例外情况" class="headerlink" title="例外情况"></a>例外情况</h5><p>第四，例外情况，是指某些数据结构的特殊记录，例如<strong>压缩列表和双向链表都会记录表头 和表尾的偏移量</strong>。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操 作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂 度也只有 O(1)，可以实现快速操作</p>
<h2 id="四、经典案例"><a href="#四、经典案例" class="headerlink" title="四、经典案例"></a>四、经典案例</h2><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系 统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查 找到图片存储对象 ID。<br>因为图片数量巨大，所以我们就用 10 位数来表示图片 ID 和图片存储对象 ID，例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">photo_id: 1101000051
photo_obj_id: 3301000051</code></pre>

<p>可以看到，图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。所谓 的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供 的“一个键对应一个值的数据”的保存形式刚好契合。</p>
<h3 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h3><h4 id="使用-String-类型"><a href="#使用-String-类型" class="headerlink" title="使用 String 类型"></a>使用 String 类型</h4><p>使用 String 保存数据。我们把图片 ID 和图片存储对象 ID 分别 作为键值对的 key 和 value 来保存，其中，图片存储对象 ID 用了 String 类型。</p>
<h4 id="String-类型内存开销大"><a href="#String-类型内存开销大" class="headerlink" title="String 类型内存开销大"></a>String 类型内存开销大</h4><p>随着图片数据量的不断 增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。<br>当我们使用 String 类型时，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等 信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较 大了，有点“喧宾夺主”的意思。</p>
<ul>
<li>1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和 图片存储对象 ID 的记录平均用了 64 字节。</li>
<li>但问题是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。</li>
</ul>
<h4 id="计算-String-内存大小"><a href="#计算-String-内存大小" class="headerlink" title="计算 String 内存大小"></a>计算 String 内存大小</h4><p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码 的 RedisObject 保存<br>根据下图计算一共 64 字节。</p>
<table><thead><tr>
<th>结构</th>
<th>大小</th>
</tr>
</thead><tbody><tr>
<td>key-value 哈希表 dictEntry</td>
<td>32 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 SDS 元数据</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 PRT</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片存储对象 ID 简单字符串 SDS 元数据</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 PRT 简单字符串 PRT</td>
<td>8 字节</td>
</tr>
</tbody></table>]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis线程模型</title>
    <url>/article/cache/redis-thread-model/</url>
    <content><![CDATA[<h1 id="一、Redis-有多快？"><a href="#一、Redis-有多快？" class="headerlink" title="一、Redis 有多快？"></a>一、Redis 有多快？</h1><p>Redis 是基于内存运行的高性能 K-V 数据库，官方提供的测试报告是单机可以支持约 10w&#x2F;s 的 QPS<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780707278-e20636e0-ebfa-40c3-8f71-64535ead4337.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=453&id=ufd62af17&margin=%5Bobject%20Object%5D&name=image.png&originHeight=453&originWidth=754&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=80647&status=done&style=none&taskId=ud8e8b5e1-4735-4254-b416-c9d4c4bb91f&title=&width=754" alt="image.png"></p>
<h1 id="二、Redis-为什么这么快？"><a href="#二、Redis-为什么这么快？" class="headerlink" title="二、Redis 为什么这么快？"></a>二、Redis 为什么这么快？</h1><p>（1）完全基于内存，数据存在内存中，绝大部分请求是纯粹的内存操作，非常快速，跟传统的磁盘文件数据存储相比，避免了通过磁盘 IO 读取到内存这部分的开销。<br>（2）数据结构简单，对数据操作也简单。Redis 中的数据结构是专门进行设计的，每种数据结构都有一种或多种数据结构来支持。Redis 正是依赖这些灵活的数据结构，来提升读取和写入的性能。<br>（3）采用单线程，省去了很多上下文切换的时间以及 CPU 消耗，不存在竞争条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，也不会出现死锁而导致的性能消耗。<br>（4）使用基于 IO 多路复用机制的线程模型，可以处理并发的链接。<br>Redis 基于 Reactor 模式开发了自己的网络事件处理器，这个处理器被称为文件事件处理器 file event handler。由于这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型，但是它采用 IO 多路复用机制同时监听多个 Socket，并根据 Socket 上的事件来选择对应的事件处理器进行处理。文件事件处理器的结构包含 4 个部分，线程模型如下图：</p>
<blockquote>
<p>多个 Socket<br>IO 多路复用程序<br>文件事件分派器<br>事件处理器（命令请求处理器、命令回复处理器、连接应答处理器）</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780718941-c3cd8bfa-de3a-45a8-a964-0d0d76db7078.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=728&id=u2a474487&margin=%5Bobject%20Object%5D&name=image.png&originHeight=728&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=262381&status=done&style=none&taskId=u7ef7b622-16d1-4dbb-9ca7-a01e5b79759&title=&width=1200" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780739146-4ee96535-2123-4803-a72b-836ce89e31b1.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=581&id=ude40546d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=581&originWidth=1497&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=332800&status=done&style=none&taskId=u29caaf54-2bb2-4536-b04f-8bebbb6439b&title=&width=1497" alt="image.png"><br>多个 Socket 可能会产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。<br>Redis 客户端对服务端的每次调用都经历了发送命令，执行命令，返回结果三个过程。其中执行命令阶段，由于 Redis 是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个队列中，然后逐个被执行。并且多个客户端发送的命令的执行顺序是不确定的。但是可以确定的是不会有两条命令被同时执行，不会产生并发问题，这就是 Redis 的单线程基本模型。</p>
<blockquote>
<p>多路 I&#x2F;O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I&#x2F;O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I&#x2F;O 事件时，就从阻塞态中唤醒，然后程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且依次顺序<typo id="typo-1053" data-origin="的" ignoretag="true">的</typo>处理就绪的流，这种做法就避免了大量的无用操作。<br>这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I&#x2F;O 复用技术可以让单个线程高效的处理多个客户端的网络 IO 连接请求（尽量减少网络 IO 的时间消耗）</p>
</blockquote>
<p>（5）Redis 直接自己构建了 VM 机制 ，避免调用系统函数的时候，浪费时间去移动和请求</p>
<h1 id="三、为什么-Redis-是单线程？"><a href="#三、为什么-Redis-是单线程？" class="headerlink" title="三、为什么 Redis 是单线程？"></a>三、为什么 Redis 是单线程？</h1><p>这里我们强调的单线程，指的是网络请求模块使用一个线程来处理，即一个线程处理所有网络请求，其他模块仍用了多个线程。<br>那为什么使用单线程呢？官方答案是：因为 CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。<br>但是，我们使用单线程的方式是无法发挥多核 CPU 性能，不过我们可以通过在单机开多个 Redis 实例来解决这个问题</p>
<h1 id="四、Redis6-0-的多线程？"><a href="#四、Redis6-0-的多线程？" class="headerlink" title="四、Redis6.0 的多线程？"></a>四、Redis6.0 的多线程？</h1><p>1、Redis6.0 之前为什么一直不使用多线程？<br>Redis 使用单线程的可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。<br>2、Redis6.0 为什么要引入多线程呢？<br>因为 Redis 的瓶颈不在内存，而是在网络 I&#x2F;O 模块带来 CPU 的耗时，所以 Redis6.0 的多线程是用来处理网络 I&#x2F;O 这部分，充分利用 CPU 资源，减少网络 I&#x2F;O 阻塞带来的性能损耗。<br>3、Redis6.0 如何开启多线程？<br>默认情况下 Redis 是关闭多线程的，可以在 conf 文件进行配置开启：<br>io-threads-do-reads yes<br>io-threads 线程数<br>“##”官方建议的线程数设置：4 核的机器建议设置为 2 或 3 个线程，8 核的建议设置为 6 个线程，线程数一定要小于机器核数，尽量不超过 8 个。<br><strong>4、多线程模式下，是否<typo id="typo-1890" data-origin="存在" ignoretag="true">存在</typo>线程并发安全问题？</strong><br>如图，一次 redis 请求，要建立连接，然后获取操作的命令，然后执行命令，最后将响应的结果写到 socket 上。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780790005-7feadbae-0815-49ce-82e5-652dde050548.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=312&id=u457be10d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=312&originWidth=646&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=76699&status=done&style=none&taskId=u3cfd9d4b-b573-440e-9586-facf1e78153&title=&width=646" alt="image.png"><br>在 redis 的多线程模式下，获取、解析命令，以及输出结果<typo id="typo-1988" data-origin="着" ignoretag="true">着</typo>两个过程，可以配置成多线程执行的，因为它毕竟是我们定位到的主要耗时点，但是命令的执行，也就是内存操作，依然是单线程运行的。所以，Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行，也就不存在并发安全问题。</p>
<h3 id="Redis-为什么用单线程"><a href="#Redis-为什么用单线程" class="headerlink" title="Redis 为什么用单线程"></a>Redis 为什么用单线程</h3><h4 id="Redis-单线程指的什么"><a href="#Redis-单线程指的什么" class="headerlink" title="Redis 单线程指的什么"></a>Redis 单线程指的什么</h4><p>Redis 是单线程，主要是指 <strong>Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程</strong>。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。</p>
<h4 id="多线程提高系统吞吐率"><a href="#多线程提高系统吞吐率" class="headerlink" title="多线程提高系统吞吐率"></a>多线程提高系统吞吐率</h4><p>日常写程序时，我们经常会听到一种说法：“<strong>使用多线程，可以增加系统吞吐率，或是可 以增加系统扩展性</strong>。”的确，对于一个多线程的系统来说，在有合理的资源分配的情况 下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即 吞吐率。下面的左图是我们采用多线程时所期待的结果。<br>但是，请你注意，通常情况下，<strong>在我们采用多线程后，如果没有良好的系统设计，实际得 到的结果，其实是右图所展示的那样。我们刚开始增加线程数时，系统吞吐率会增加，但 是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780858223-46203b98-d9af-429f-a64c-624e63499ea5.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=458&id=u80f98f2a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=458&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=102025&status=done&style=none&taskId=u8d644773-1c56-48fb-8946-3700895ff40&title=&width=1100" alt="image.png"></p>
<h4 id="多线程共享资源"><a href="#多线程共享资源" class="headerlink" title="多线程共享资源"></a>多线程共享资源</h4><p>为什么会出现这种情况呢？一个关键的瓶颈在于,系统中通常会存在被多线程同时访问的 共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共 享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开 销。</p>
<h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p>拿 Redis 来说，Redis 有 List 的数据类型，并提供出队（LPOP） 和入队（LPUSH）操作。假设 Redis 采用多线程设计，如下图所示，现在有两个线程 A 和 B，线程 A 对一个 List 做 LPUSH 操作，并对队列长度加 1。同时，线程 B 对该 List 执行 LPOP 操作，并对队列长度减 1。为了保证队列长度的正确性，Redis 需要让线程 A 和 B 的 LPUSH 和 LPOP 串行执行，这样一来，Redis 可以无误地记录它们对 List 长度的修 改。否则，我们可能就会得到错误的长度结果。这就是多线程编程模式面临的共享资源的 并发访问控制问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780868651-b8a7673b-5b94-4382-ab1f-cc726493e5d1.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=725&id=ue4264bb6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=725&originWidth=1064&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=124110&status=done&style=none&taskId=u84165546-44e8-493f-920f-78d94a38511&title=&width=1064" alt="image.png"><br>并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，<strong>只是 简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也 在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增 加。甚至减少，因为多线程会存在多线程频繁切换开销</strong><br>采用<strong>多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统 代码的易调试性和可维护性</strong>。为了避免这些问题，Redis 直接采用了单线程模式。</p>
<h4 id="Redis-使用单线程小结"><a href="#Redis-使用单线程小结" class="headerlink" title="Redis 使用单线程小结"></a>Redis 使用单线程小结</h4><ul>
<li>使用多线程，可以增加系统吞吐率，如果没有良好的系统设计，实际得 到的结果我们刚开始增加线程数时，系统吞吐率会增加，但 是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况</li>
<li>出现上述情况的原因是 redis 在使用多线程时同样会存在多线程同时访问的 共享资源的问题，为了保证共 享资源的正确性，就需要有额外的机制进行保证。</li>
<li>在没有良好的系统设计，这个额外的机制，就会带来额外的开 销。这种开销有时不但无法增加系统吞吐率，反而会降低系统吞吐率</li>
<li>多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统 代码的易调试性和可维护性</li>
</ul>
<h3 id="单线程-Redis-为什么快"><a href="#单线程-Redis-为什么快" class="headerlink" title="单线程 Redis 为什么快"></a>单线程 Redis 为什么快</h3><h4 id="多路复用-IO"><a href="#多路复用-IO" class="headerlink" title="多路复用 IO"></a>多路复用 IO</h4>]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（二）ShardedJedis一致性哈希</title>
    <url>/article/redis/redis-consistent-hashing/</url>
    <content><![CDATA[<p>本文主要介绍一致性哈希的概念，以及在 Redis 中的 ShardedJedis 一致性哈希实现原理</p>
<h2 id="1、非一致性哈希"><a href="#1、非一致性哈希" class="headerlink" title="1、非一致性哈希"></a>1、非一致性哈希</h2><p>在讨论一致性哈希之前，先认识下”非一致性哈希”，例如 HashMap。<br>当使用 HashMap 时，key 被均匀地映射到数组之上，映射方法就是利用 key 的 hash 与数组长度取模(通过&amp;运算)。<br>当 put 的数据超过负载因子 loadFactor×2Len 时，HashMap 会按照 2 被的容量扩容。<br>新 put 进来的数据会通过与新数组的长度取模的方式进行映射。那之前已经映射的数据该怎么办？<br>通过查看 HashMap 代码的 resize 方法会发现，每次扩容都会把之前的 key 重新映射。<br>所以对 HashMap 而言要想获得较好的性能必须要提前估计所放数据集合的大小，以设计合适的初始化容量和负载因子。</p>
<h2 id="2、一致性哈希"><a href="#2、一致性哈希" class="headerlink" title="2、一致性哈希"></a>2、一致性哈希</h2><p>不是每个场景都像 HashMap 这么简单，比如在大型的 P2P 网络中存在上百万台 Server，资源与 Server 的关系是以 Key 的形式映射而成，也就是说是一个大的 HashMap，维护着每个 Key 在哪个 Server 之上，如果有新的节点加入或退出 P2P 网络，跟 HashMap 一样，也会导致映射关系的变化，显然不可能把所有的 Key 与 Server 的映射关系都调整一遍。这就需要一种方法，在哈希项发生变化是，不需要调整所有的节点，而达到继续维护哈希映射的关系。下面来看下<a href="%5Bhttp://en.wikipedia.org/wiki/Consistent_hashing">一致性</a>的定义。](<a href="http://en.wikipedia.org/wiki/Consistent_hashing)%E7%9A%84%E5%AE%9A%E4%B9%89%E3%80%82">http://en.wikipedia.org/wiki/Consistent_hashing)%E7%9A%84%E5%AE%9A%E4%B9%89%E3%80%82</a>)</p>
<blockquote>
<p>Consistent hashing is a special kind of hashing such that when a hash table is resized, only K&#x2F;n keys need to be remapped on average, where K is the number of keys, and n is the number of slots. In contrast, in most traditional hash tables, a change in the number of array slots causes nearly all keys to be remapped because the mapping between the keys and the slots is defined by a modular operation.</p>
</blockquote>
<p>一致性哈希是一种特殊类型的的哈希，当哈希表改变大小的时候，平均只有 K&#x2F;n 的 keys 需要被重新映射，其中 k 为 keys 的数量，n 为槽 slots 的数量。相比之下，在传统的哈希表中，因为 key 和 slot 的映射是通过取模操作定义的，槽 slot 的数量改变会引起几乎所有的 key 都被重新映射。一致性哈希当节点加入、退出时，只影响加入退出的节点和其邻居节点或者其他节点只有少量的 Key 受影响，需要满足下面几个条件：</p>
<ul>
<li>平衡性(Balance)：就是指哈希算法要均匀分布，不能有明显的映射规律，这对一般的哈希实现也是必须的；</li>
<li>单调性(Monotonicity)：就是指有新节点加入时，已经存在的映射关系不能发生变化；</li>
<li>分散性(Spread)：就是避免不同的内容映射到相同的位置和相同的内容映射到不同的位置。</li>
</ul>
<p>其实一致性哈希（哈希）有个明显的优点就是负载均衡，只要哈希函数设计得当，每个点就是对等的可以均匀地分布系统负载。</p>
<h2 id="3、ShardedJedis-一致性哈希"><a href="#3、ShardedJedis-一致性哈希" class="headerlink" title="3、ShardedJedis 一致性哈希"></a>3、ShardedJedis 一致性哈希</h2><p>Shared 一致性哈希采用以下方案：</p>
<ol>
<li>Redis 服务器节点划分：将每台服务器节点采用 hash 算法划分为 160 个虚拟节点(可以配置划分权重)</li>
<li>将划分虚拟节点采用 TreeMap 存储</li>
<li>对每个 Redis 服务器的物理连接采用 LinkedHashMap 存储</li>
<li>对 Key or KeyTag 采用同样的 hash 算法，然后从 TreeMap 获取大于等于键 hash 值得节点，取最邻近节点存储；</li>
</ol>
<p>当 key 的 hash 值大于虚拟节点 hash 值得最大值时，存入第一个虚拟节点。<br>Sharded 采用的 hash 算法：MD5 和 MurmurHash 两种；默认采用 64 位的 MurmurHash 算法，<br>Sharded 类维护了一致性哈希后的物理机器和虚拟节点的映射关系。<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648982930385-16ad72be-62d7-4f89-a727-d5e14dfb9ca2.png#clientId=u019c0c6b-a681-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub18ca8ff&margin=%5Bobject%20Object%5D&name=image.png&originHeight=410&originWidth=688&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=38474&status=done&style=none&taskId=u747618ef-6aa3-4345-b95e-8c3dcb18635&title=" alt="image.png"></p>
<h3 id="3-1-Sharded-的实现定义"><a href="#3-1-Sharded-的实现定义" class="headerlink" title="3.1 Sharded 的实现定义"></a>3.1 Sharded 的实现定义</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">public class Sharded&lt;R, S extends ShardInfo&lt;R&gt;&gt; &#123;

    public static final int DEFAULT_WEIGHT &#x3D; 1;
    private TreeMap&lt;Long, S&gt; nodes;
    private final Hashing algo;
    private final Map&lt;ShardInfo&lt;R&gt;, R&gt; resources &#x3D; new LinkedHashMap&lt;ShardInfo&lt;R&gt;, R&gt;();

    &#x2F;**
     * The default pattern used for extracting a key tag. The pattern must have a group (between
     * parenthesis), which delimits the tag to be hashed. A null pattern avoids applying the regular
     * expression for each lookup, improving performance a little bit is key tags aren&#39;t being used.
     *&#x2F;
    private Pattern tagPattern &#x3D; null;
    &#x2F;&#x2F; the tag is anything between &#123;&#125;
    public static final Pattern DEFAULT_KEY_TAG_PATTERN &#x3D; Pattern.compile(&quot;\\&#123;(.+?)\\&#125;&quot;);
    ......

&#125;</code></pre>

<p>其中 TreeMap&lt;Long, S&gt; nodes，存储的是虚拟节点和 key 的映射关系。有了虚拟节点，还要找到真正的存储位置。<br>Map&lt;ShardInfo<R>, R&gt; resources 维护了虚拟节点和真正的存储位置的映射关系。<br>也是说，hash(key) → virtual node → real node;<br>jedis 划分虚拟节点的逻辑代码，在 Sharded 类中，方法是 initialize。这是在实例化对象池 ShardedJedisPool 过程中执行的划分虚拟节点。<br>其中 ShardedJedis、BinaryShardedJedis 和 Sharded 的关系如下图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648982930200-543d6cdd-b007-4653-afdc-3de50a477aae.png#clientId=u019c0c6b-a681-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ud990d154&margin=%5Bobject%20Object%5D&name=image.png&originHeight=371&originWidth=569&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=19894&status=done&style=none&taskId=ue4304c8e-087b-48f0-95eb-2c81cb47c88&title=" alt="image.png"></div></p>
<h3 id="3-2-ShardedJedis-初始化"><a href="#3-2-ShardedJedis-初始化" class="headerlink" title="3.2 ShardedJedis 初始化"></a>3.2 ShardedJedis 初始化</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">public ShardedJedis(List&lt;JedisShardInfo&gt; shards) &#123;
    super(shards);
&#125;

public BinaryShardedJedis(List&lt;JedisShardInfo&gt; shards, Hashing algo) &#123;
    super(shards, algo);
&#125;

public Sharded(List&lt;S&gt; shards) &#123;
    this(shards, Hashing.MURMUR_HASH); &#x2F;&#x2F; MD5 is really not good as we works
    &#x2F;&#x2F; with 64-bits not 128
&#125;

public Sharded(List&lt;S&gt; shards, Hashing algo) &#123;
    this.algo &#x3D; algo;
    initialize(shards);
&#125;</code></pre>

<p>通过 initialize 来看，节点的划分和初始化</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">private void initialize(List&lt;S&gt; shards) &#123;
    nodes &#x3D; new TreeMap&lt;Long, S&gt;();

    for (int i &#x3D; 0; i !&#x3D; shards.size(); ++i) &#123;
        final S shardInfo &#x3D; shards.get(i);
        if (shardInfo.getName() &#x3D;&#x3D; null) for (int n &#x3D; 0; n &lt;160 * shardInfo.getWeight(); n++) &#123;
            nodes.put(this.algo.hash(&quot;SHARD-&quot; + i + &quot;-NODE-&quot; + n), shardInfo);
        &#125;
        else for (int n &#x3D; 0; n &lt;160 * shardInfo.getWeight(); n++) &#123;
            nodes.put(this.algo.hash(shardInfo.getName() + &quot;*&quot; + shardInfo.getWeight() + n), shardInfo);
        &#125;
        resources.put(shardInfo, shardInfo.createResource());
    &#125;
&#125;</code></pre>

<p>以上代码就是 Sharded 划分虚拟节点的逻辑，初始化 TreeMap&lt;Long, S&gt; nodes 虚拟节点和 key 的映射关系，以及 Map&lt;ShardInfo<R>, R&gt; resources 虚拟节点和真正的存储位置的映射关系。</p>
<h3 id="3-3-ShardedJedis-中的-set-和-get-操作"><a href="#3-3-ShardedJedis-中的-set-和-get-操作" class="headerlink" title="3.3 ShardedJedis 中的 set 和 get 操作"></a>3.3 ShardedJedis 中的 set 和 get 操作</h3><p>先看 ShardedJedis 的 set 操作（get 操作类似）</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">public String set(String key, String value) &#123;
    &#x2F;&#x2F; 1、获取ShardedJedis的实例
    Jedis j &#x3D; getShard(key);
    return j.set(key, value);
&#125;

public R getShard(String key) &#123;
    &#x2F;&#x2F; 2、首先需要通过getShardInfo(key)的获取到JedisShardInfo信息，通过resources.get获取到ShardedJedis实例
    return resources.get(getShardInfo(key));
&#125;

public S getShardInfo(String key) &#123;
    &#x2F;&#x2F; 3、SafeEncoder.encode(getKeyTag(key))获取hash后的byte[]
    &#x2F;&#x2F; 4、通过getShardInfo(byte[] key)获取到JedisShardInfo信息
    return getShardInfo(SafeEncoder.encode(getKeyTag(key)));
&#125;

public S getShardInfo(byte[] key) &#123;
    &#x2F;&#x2F; 5、获取大于等于当前algo.hash(key)的升序SortedMap
    SortedMap&lt;Long, S&gt; tail &#x3D; nodes.tailMap(algo.hash(key));
    if (tail.isEmpty()) &#123;
        &#x2F;&#x2F; 6、为空，说明当前的hash值比所有的都大，返回nodes的第一个ShardInfo
        return nodes.get(nodes.firstKey());
    &#125;
    &#x2F;&#x2F; 7、否则返回大于等于当前hash值的第一个ShardInfo
    return tail.get(tail.firstKey());
&#125;</code></pre>

<p>上面的代码中大体的逻辑，首先通过 key 得到 ShardInfo，然后通过 ShardInfo 得到泛型 Jedis 客户端实例，进行 set 和 get 操作。通过上面的代码保证了 redis 的哈希一致性。</p>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（六）分布式锁</title>
    <url>/article/redis/redis-lock/</url>
    <content><![CDATA[<blockquote>
<p>分布式锁为解决<strong>分布式系统中多个应用同时访问同一个资源的问题</strong>。</p>
</blockquote>
<h2 id="分布式锁的使用场景"><a href="#分布式锁的使用场景" class="headerlink" title="分布式锁的使用场景"></a>分布式锁的使用场景</h2><p>一般是在两个场景下会防止对同一个资源的重复访问</p>
<ul>
<li><strong>提升效率</strong></li>
</ul>
<p>比如多个节点计算同一批任务，如果某个任务已经有节点在计算了，那其他节点就不用重复计算了，以免浪费计算资源。不过重复计算也没事，不会造成其他更大的损失，<strong>允许偶尔的失败</strong>。</p>
<ul>
<li><strong>保证正确性</strong></li>
</ul>
<p>这种情况对锁的要求就很高了，如果重复计算，会对正确性造成影响，<strong>不允许失败</strong>。</p>
<h2 id="分布式锁支持的特性"><a href="#分布式锁支持的特性" class="headerlink" title="分布式锁支持的特性"></a>分布式锁支持的特性</h2><p>在这个技术不断更新迭代的情况下，分布式这个概念，在企业中的权重越来越高。谈及分布式时，不可避免一定会提到分布式锁，现阶段分布式锁的实现方式主流的有几种实现方式，Zookeeper、Mysql、Redis，Etcd，分布式锁需要保证锁的<strong>要互斥、防死锁、高性能、可重入</strong>。<br>本篇文章以 Redis 为例，从我们的角度来看，下面的三个属性是有效使用分布式锁所需的最低保证。</p>
<ul>
<li>安全特性：<strong>互斥</strong></li>
</ul>
<p>在任何给定时刻，只有一个客户端可以持有锁。</p>
<ul>
<li>活力属性：<strong>无死锁</strong></li>
</ul>
<p>最终，即使锁定资源的客户端崩溃或分区，也始终可以获得锁。</p>
<ul>
<li>活动性：<strong>容错能力</strong></li>
</ul>
<p>只要大多数 Redis 节点都处于运行状态，客户端就可以获取和释放锁。</p>
<p>一般分布式锁需要支持以下功能，才能满足大多数场景的需求</p>
<table><thead><tr>
<th>**功能 **</th>
<th><strong>是否必须</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead><tbody><tr>
<td>失效时间</td>
<td>是</td>
<td>防止 Java 应用忽然挂掉 或 网络动荡 而产生死锁</td>
</tr>
<tr>
<td>自动续租</td>
<td>是</td>
<td>支持分布式锁过期，自动续租</td>
</tr>
<tr>
<td>可重入性</td>
<td>是</td>
<td>单线程调用的多个函数或地方可能会锁住同一把锁 (不支持调用服务化接口)</td>
</tr>
<tr>
<td>阻塞、公平锁</td>
<td>是</td>
<td>第三方的介质实现分布式锁，非公平的锁竞争并不会提高性能</td>
</tr>
<tr>
<td>接入动态配置</td>
<td>是</td>
<td>可自动配置 etcd 等锁的配置中心地址，通知 client 端进行切换</td>
</tr>
<tr>
<td>尝试锁</td>
<td>可选</td>
<td>tryLock ， 超过指定时间没有获得锁则抛出异常，由使用方捕获异常</td>
</tr>
</tbody></table><h2 id="Redis-实现分布式锁的几种方式"><a href="#Redis-实现分布式锁的几种方式" class="headerlink" title="Redis 实现分布式锁的几种方式"></a>Redis 实现分布式锁的几种方式</h2><h3 id="1、单机"><a href="#1、单机" class="headerlink" title="1、单机"></a>1、单机</h3><p>直接单机上锁，这台机器挂了就 GG 了，整个业务系统都获取不到锁了，单点故障。</p>
<h3 id="2、哨兵"><a href="#2、哨兵" class="headerlink" title="2、哨兵"></a>2、哨兵</h3><p>既然单点故障，那我搞个哨兵，Sentinel，自动主从切换。但是会有如下新问题：<br>锁写到 Master 后，还没同步到 Slave 呢，Master 挂了。Slave 选举成了 Master，但是 Slave 里没有锁，其他线程再次能上锁了，不安全。</p>
<h3 id="3、集群"><a href="#3、集群" class="headerlink" title="3、集群"></a>3、集群</h3><p>集群只是做了 slot 分片，锁还是只写到一个 Master 上，所以和 Sentinel 哨兵模式有同样的问题。</p>
<h3 id="4、红锁"><a href="#4、红锁" class="headerlink" title="4、红锁"></a>4、红锁</h3><p>也称 RedLock，非常著名，是 Redis 实现分布式锁相对最安全可靠的一种手段。<br>核心思路是：搞几个独立的 Master，比如 5 个。然后挨着个的加锁，只要超过一半以上（这里是 5 &#x2F; 2 + 1 &#x3D; 3 个）那就代表加锁成功，然后释放锁的时候也逐台释放。这样的好处在于一台 Master 挂了的话，还有其他的，所以不耽误，看起来好像完美解决了上面的问题，但是并不是 100%安全。</p>
<p>不管用 Redis 的哪种方式来实现分布式锁，都不是 100%安全的，那就不用 Redis 做分布式锁了吗？不然，我觉得取决于业务吧，如果你业务要求必须，<strong>100%不能出问题，那用 zk&#x2F;etcd 来实现吧</strong>。但是据我了解，<strong>至少 80%的互联网公司都不这么强烈要求，大对数还是 Redis 分布式锁</strong>，即使用 zk 来实现的也可能不是业务上 100%要求不能出现问题。比如你项目就没用 zk，只用了 Redis，那完全没必要搭建一套 zk 来做分布式锁，Redis 的红锁也能保证高可用，几乎不会出现问题的。</p>
<h2 id="Redis-多节点实现分布式锁带来的挑战"><a href="#Redis-多节点实现分布式锁带来的挑战" class="headerlink" title="Redis 多节点实现分布式锁带来的挑战"></a>Redis 多节点实现分布式锁带来的挑战</h2><p>我们使用 Redis 锁定资源的最简单方法是：</p>
<blockquote>
<ul>
<li>在实例中创建锁。</li>
<li>锁通常使用 Redis 过期功能，在有限时间存在，最终将被释放，超过给定时间会被删除。</li>
<li>当客户端需要释放资源时，它将删除锁。</li>
</ul>
</blockquote>
<p>乍一看，似乎并没有什么问题。但是不妨我们深究一下，这种实现方案在 redis 单机环境下似乎并没有什么问题。但是如果节点坏了呢？好吧，那么让我们添加一个 slave 节点。如果主服务器宕机了，就使用这个节点。但是我们不妨来看看她真的能保证可用吗？在谈论这个的致命缺陷时，我们需要了解一个知识点，<strong>Redis 复制是异步的</strong>。<br><strong>1、客户端 A 获取主服务器中的锁</strong><br><strong>2、在将锁复制传输到从机之前，主机崩溃</strong><br><strong>3、slave 晋升为 master</strong><br><strong>4、客户端 B 获取锁，因为从机并没有该锁的对象，获取成功</strong><br>显然，这样是不对的，<strong>主节点因为没来得及同步数据就宕机了</strong>，所以从节点没有该数据，从而造成分布式锁的失效</p>
<h2 id="Redlock-红锁"><a href="#Redlock-红锁" class="headerlink" title="Redlock 红锁"></a><strong>Redlock 红锁</strong></h2><p>作者认为，我们应该使用多个 Redis，这些节点是完全独立的，不需要使用复制或者任何协调数据的系统。</p>
<h3 id="RedLock-多个-redis-系统获取锁过程"><a href="#RedLock-多个-redis-系统获取锁过程" class="headerlink" title="RedLock 多个 redis 系统获取锁过程"></a>RedLock 多个 redis 系统获取锁过程</h3><ol>
<li>以毫秒 ms 为单位获取当前的服务器时间</li>
<li>尝试使用相同的 key 和随机值来获取锁，对每一个机器获取锁时都应该有一个超时时间，比如锁的过期时间为 10s，那么获取单个节点锁的超时时间就应该为 5 到 50 毫秒左右，他这样做的目的是为了保证客户端与故障的机器连接，耗费多余的时间。超时间时间内未获取数据就放弃该节点，从而去下一个节点获取，直至将所有节点全部获取一遍。</li>
<li>获取完成后，获取当前时间减去步骤一获取的时间，当且仅当客户端半数以上获取成功且获取锁的时间小于锁额超时时间，则证明该锁生效。</li>
<li>获取锁之后，锁的超时时间等于设置的有效时间-获取锁花费的时间</li>
<li>如果 获取锁的机器不满足半数以上，或者锁的超时时间计算完毕后为负数 等异常操作，则系统会尝试解锁所有实例，即使有些实例没有获取锁成功，依旧会被尝试解锁。</li>
<li>释放锁，只需在所有实例中释放锁，无论客户端是否认为它能够成功锁定给定的实例。</li>
</ol>
<h3 id="Redlock-真能够解决问题吗"><a href="#Redlock-真能够解决问题吗" class="headerlink" title="Redlock 真能够解决问题吗"></a>Redlock 真能够解决问题吗</h3><p>Martin Kleppmann 发表<a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">文章</a>，<strong>Redlock 并不能保证该锁的安全性，分布式锁用途有下面 2 种：</strong></p>
<blockquote>
<p><strong>1、提升效率</strong>，用锁来保证一个任务没有必要被执行两次，比如（很昂贵的计算）。<br>2、<strong>保证正确性</strong>，使用锁来保证任务按照正常的步骤执行，防止两个节点同时操作一份数据，造成文件冲突，数据丢失。</p>
</blockquote>
<p><strong>提升效率，允许偶尔的失败。</strong>对锁是有一定宽容度的，就算发生了两个节点同时工作，对系统的影响也仅仅是多付出了一些计算的成本，没什么额外的影响。<strong>使用单点的 Redis 就能很好的解决问题，没有必要使用 RedLock，维护那么多的 Redis 实例，提升系统的维护成本。</strong></p>
<h3 id="分布式锁的超时性，所带来的缺点"><a href="#分布式锁的超时性，所带来的缺点" class="headerlink" title="分布式锁的超时性，所带来的缺点"></a>分布式锁的超时性，所带来的缺点</h3><p>但是对于第二种场景<strong>保证正确性</strong>来说，就比较慎重了，因为很可能涉及到一些金钱交易，如果锁定失败，并且两个节点同时处理同一数据，则结果将导致文件损坏，数据丢失，永久性不一致，或者金钱方面的损失。</p>
<p>我们假设一种场景，我们有两个客户端，每一个客户端必须拿到锁之后才能去保存数据到数据库，我们使用 RedLock 算法实现会出现什么问题呢？RedLock 中，为了防止死锁，锁是具有过期时间的，但是 Martin 认为这是不安全的。该流程图类似于这样。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648715500983-f2e3ee2a-3144-46dc-ac75-19814c643102.png#clientId=ue2c0d7c5-aca3-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=400&id=u2c02c07f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=400&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=40923&status=done&style=none&taskId=u040b413b-dd5f-4ba8-9ee1-03d3164367d&title=&width=1100" alt="image.png"></p>
<p>客户端 1 获取到锁成功后，开始执行，执行到一半系统发生 Full GC ,系统服务被挂起，过段时间锁超时了。客户端 2 等待客户端 1 的锁超时后，成功的获取到锁，开始执行入库操作，完成后，客户端 1 完成了 Full GC,又做了一次入库操作。这是不安全的。如何解决呢？</p>
<p>Martin 提出来一种<strong>类似乐观锁的实现机制</strong>，示例图如下：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648715529584-8e43c9ec-e9ed-4eac-9f82-0a570402ccb3.png#clientId=ue2c0d7c5-aca3-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=400&id=u6689a039&margin=%5Bobject%20Object%5D&name=image.png&originHeight=400&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=42930&status=done&style=none&taskId=u7ce5607d-a74a-443b-8222-477b16071c6&title=&width=1100" alt="image.png"><br>客户端 1 长时间被挂起后，客户端 2 获取到锁，开始写库操作，同时携带令牌 34，写库完成后，客户端 1 苏醒，开始进行入库操作，但是因为携带的令牌为 33 小于最新令牌，该次提交就被拒绝。<br>这个想法听起来似乎时很完备的思路，这样即使系统因为某些原因被挂起，数据也能够被正确的处理。但是仔细想一下：</p>
<blockquote>
<p>如果仅当您的令牌大于所有过去的令牌时，数据存储区才能始终接受写入，则它是可线性化的存储区，<strong>相当与使用数据库来实现一个 分布式锁系统，那么 RedLock 的作用就变的微乎其微</strong>。甚至不在需要使用 redis 保证分布式锁。</p>
</blockquote>
<h3 id="RedLock-对于系统时钟强依赖"><a href="#RedLock-对于系统时钟强依赖" class="headerlink" title="RedLock 对于系统时钟强依赖"></a>RedLock 对于系统时钟强依赖</h3><p>回想一下 Redlock 算法获取锁的几个步骤，你会发现锁的有效性是与当前的系统时钟强依赖，我们假设，我们有，A、B、C、D、E 五个 redis 节点：</p>
<ul>
<li>客户端 1 获取节点 A，B，C 的锁定。由于网络问题，无法访问 D 和 E。</li>
<li>节点 C 上的时钟向前跳，导致锁过期。</li>
<li>客户端 2 获取节点 C，D，E 的锁定。由于网络问题，无法访问 A 和 B。</li>
<li>现在，客户 1 和 2 都认为他们持有该锁。</li>
</ul>
<p>如果 C 在将锁持久保存到磁盘之前崩溃并立即重新启动，则可能会发生类似的问题。<br>Martin 认为系统时间的阶跃主要来自两个方面（以及作者给出的解决方案）：</p>
<ul>
<li><strong>人为修改</strong></li>
</ul>
<p>对于人为修改，能说啥呢？人要搞破坏没办法避免。</p>
<ul>
<li><strong>从 NTP 服务收到了一个跳跃时时钟更新</strong></li>
</ul>
<p>NTP 网络时间协议(Network Time Protocol)受到一个阶跃时钟更新，对于这个问题，需要通过运维来保证。需要将阶跃的时间更新到服务器的时候，应当采取小步快跑的方式。多次修改，每次更新时间尽量小。</p>
<h2 id="分布式锁需要注意的问题"><a href="#分布式锁需要注意的问题" class="headerlink" title="分布式锁需要注意的问题"></a>分布式锁需要注意的问题</h2><h3 id="1、加锁成功的客户端挂掉或网络动荡，可能产生死锁"><a href="#1、加锁成功的客户端挂掉或网络动荡，可能产生死锁" class="headerlink" title="1、加锁成功的客户端挂掉或网络动荡，可能产生死锁"></a>1、加锁成功的客户端挂掉或网络动荡，可能产生死锁</h3><p>对于加的分布式锁，需要<strong>设置 expire 过期时间</strong>，锁过期后进行释放</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">SET key value [EX seconds] [PX milliseconds] NX</code></pre>

<h3 id="2、业务未执行完，分布式锁超时，需要进行锁续期"><a href="#2、业务未执行完，分布式锁超时，需要进行锁续期" class="headerlink" title="2、业务未执行完，分布式锁超时，需要进行锁续期"></a>2、业务未执行完，分布式锁超时，需要进行锁续期</h3><p>Redisson 实现了一种保证锁失效时间绝对大于业务程序执行时间的机制。官方叫做看门狗机制（Watchdog），主要原理是，在程序成功获取锁之后，启动一个 Watchdog，会 fork 一条子线程去不断的给该锁续期，直至该锁释放为止。原理图大概如下所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648918542273-8da12f6b-9ecb-41a9-9721-38789a7733d3.png#clientId=u6a12c7db-de06-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=332&id=u11e98e06&margin=%5Bobject%20Object%5D&name=image.png&originHeight=664&originWidth=1354&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=56357&status=done&style=none&taskId=u4219fc59-3e1c-421e-986e-533cac48f1c&title=&width=677" alt="image.png"><br><strong>Redisson 使用守护线程来进行锁的续期</strong>（守护线程的作用：当主线程销毁，会和主线程一起销毁）防止程序宕机后，线程依旧不断续命，造成死锁。<br>RedissonLock 加锁续期</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">RLock lock &#x3D; redisson.getLock(&quot;myLock&quot;);
lock.lock();

@Override
public void lock() &#123;
    try &#123;
        lockInterruptibly();
    &#125; catch (InterruptedException e) &#123;
        Thread.currentThread().interrupt();
    &#125;
&#125;

@Override
public void lockInterruptibly() throws InterruptedException &#123;
    lockInterruptibly(-1, null);
&#125;

public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123;
    long threadId &#x3D; Thread.currentThread().getId();
    &#x2F;&#x2F; 尝试获取锁，leaseTime为-1，开启看门狗续期
    Long ttl &#x3D; tryAcquire(leaseTime, unit, threadId);
    &#x2F;&#x2F; lock acquired
    if (ttl &#x3D;&#x3D; null) &#123;
        return;
    &#125;

    RFuture&lt;RedissonLockEntry&gt; future &#x3D; subscribe(threadId);
    commandExecutor.syncSubscription(future);

    try &#123;
        &#x2F;&#x2F; 加锁失败，while(true)等待重试
        while (true) &#123;
            ttl &#x3D; tryAcquire(leaseTime, unit, threadId);
            &#x2F;&#x2F; lock acquired
            if (ttl &#x3D;&#x3D; null) &#123;
                break;
            &#125;

            &#x2F;&#x2F; waiting for message
            if (ttl &gt;&#x3D; 0) &#123;
                getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);
            &#125; else &#123;
                getEntry(threadId).getLatch().acquire();
            &#125;
        &#125;
    &#125; finally &#123;
        unsubscribe(future, threadId);
    &#125;
&#125;

private Long tryAcquire(long leaseTime, TimeUnit unit, long threadId) &#123;
    return get(tryAcquireAsync(leaseTime, unit, threadId));
&#125;

&#x2F;&#x2F; threadId,当前的线程id
private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123;
    if (leaseTime !&#x3D; -1) &#123;
        return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);
    &#125;

    &#x2F;&#x2F; leaseTime &#x3D;&#x3D; -1 就 scheduleExpirationRenewal 开启看门狗续期，
    &#x2F;&#x2F; leaseTime !&#x3D; -1 就不续期，只是把 internalLockLeaseTime 时间变成传进来的时间。
    &#x2F;&#x2F; lockWatchdogTimeout 看门狗 默认超时时间 30 秒
    RFuture&lt;Long&gt; ttlRemainingFuture &#x3D; tryLockInnerAsync(commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);
    ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123;
        @Override
        public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123;
            if (!future.isSuccess()) &#123;
                return;
            &#125;

            Long ttlRemaining &#x3D; future.getNow();
            &#x2F;&#x2F; lock acquired
            if (ttlRemaining &#x3D;&#x3D; null) &#123;
                &#x2F;&#x2F; 当前线程 threadId 是否要续租
                scheduleExpirationRenewal(threadId);
            &#125;
        &#125;
    &#125;);
    return ttlRemainingFuture;
&#125;

private void scheduleExpirationRenewal(final long threadId) &#123;
    if (expirationRenewalMap.containsKey(getEntryName())) &#123;
        return;
    &#125;

    Timeout task &#x3D; commandExecutor.getConnectionManager().newTimeout(new TimerTask() &#123;
        @Override
        public void run(Timeout timeout) throws Exception &#123;
            &#x2F;&#x2F; 当前线程 threadId 是否要续租
            RFuture&lt;Boolean&gt; future &#x3D; renewExpirationAsync(threadId);
            future.addListener(new FutureListener&lt;Boolean&gt;() &#123;
                @Override
                public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123;
                    expirationRenewalMap.remove(getEntryName());
                    if (!future.isSuccess()) &#123;
                        log.error(&quot;Can&#39;t update lock &quot; + getName() + &quot; expiration&quot;, future.cause());
                        return;
                    &#125;
                    if (future.getNow()) &#123;
                        &#x2F;&#x2F; reschedule itself
                        scheduleExpirationRenewal(threadId);
                    &#125;
                &#125;
            &#125;);
        &#125;
        &#x2F;&#x2F; 这里是个知识点，续期线程在过期时间达到三分之一的时候工作，比如9s过期时间，那么续期会在第3秒的时候工作，也就是还剩余6s的时候进行续期
    &#125;, internalLockLeaseTime &#x2F; 3, TimeUnit.MILLISECONDS);

    if (expirationRenewalMap.putIfAbsent(getEntryName(), new ExpirationEntry(threadId, task)) !&#x3D; null) &#123;
        task.cancel();
    &#125;
&#125;

protected RFuture&lt;Boolean&gt; renewExpirationAsync(long threadId) &#123;
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
                                          &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1) then &quot; +
                                          &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                                          &quot;return 1; &quot; +
                                          &quot;end; &quot; +
                                          &quot;return 0;&quot;,
                                          Collections.&lt;Object&gt;singletonList(getName()),
                                          internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>很简单，就是看当前线程有没有加锁 hexists, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1，有加锁的话就代表业务线程还没执行完，就给他的锁重新续期 pexpire’, KEYS[1], ARGV[1]，然后返回 1，也就是 true，没加锁的话返回 0，也就是 false。那就是返回 1 就调用自己准备下一次续期 scheduleExpirationRenewal(threadId)，返回 0 就调用在删除后不做处理。</p>
<p>这里有几个关键点：</p>
<ul>
<li>要使 watchLog 机制生效，lock 时不要设置过期时间</li>
<li>续期核心 lua 脚本在 renewExpirationAsync 里</li>
<li>Watchdog 通过类似 netty 的 Future 功能来实现<strong>异步延时</strong></li>
<li><strong>续期的开始时间是超过过期时间的三分之一，比如 9s 过期时间，那么第 3s 的时候开始续期</strong></li>
<li><strong>续期成功自己调用自己，也就是为下一次续期做准备，</strong>续期失败不做后续处理</li>
</ul>
<blockquote>
<p>因为分布式锁的续期是在客户端执行的，所以如果 client 宕机了，续期线程就不能工作了，也就不能续期了，<strong>只能等到超时时间后锁被自动删除</strong>。这时应该把分布式锁删除，让其他客户端来获取。<br>如果要立刻删除，<strong>需要增加额外的工作，比如增加哨兵机制</strong>，让哨兵来维护所有 redis 客户端的列表。哨兵定时监控客户端是否宕机，如果检测到宕机，立刻删除这个客户端的锁。</p>
</blockquote>
<p>另外，Redisson 定时器使用的是 netty-common 包中的 HashedWheelTime 来实现的，Redisson 还实现并且优化了 <strong>RedLock 算法、公平锁、可重入锁、连锁</strong>等操作，使 Redis 分布式锁的实现方式更加简便高效。</p>
<h3 id="3、对于要保证正确的分布式锁，需要注意原子性"><a href="#3、对于要保证正确的分布式锁，需要注意原子性" class="headerlink" title="3、对于要保证正确的分布式锁，需要注意原子性"></a>3、对于要保证正确的分布式锁，需要注意原子性</h3><h4 id="Redisson-加锁"><a href="#Redisson-加锁" class="headerlink" title="Redisson 加锁"></a>Redisson 加锁</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123;
    internalLockLeaseTime &#x3D; unit.toMillis(leaseTime);
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,
              &quot;if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 0) then &quot; +
                  &quot;redis.call(&#39;hset&#39;, KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1) then &quot; +
                  &quot;redis.call(&#39;hincrby&#39;, KEYS[1], ARGV[2], 1); &quot; +
                  &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +
                  &quot;return nil; &quot; +
              &quot;end; &quot; +
              &quot;return redis.call(&#39;pttl&#39;, KEYS[1]);&quot;,
                Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>加锁 lua 脚本解释</p>
<pre class="line-numbers language-lua" data-language="lua"><code class="language-lua">lock入参：
keys[1]:自定义锁的key  RLock lock &#x3D; redissonClient.getLock(lockKey);
argv[1]&#x3D;锁的租期，默认30s
argv[2]&#x3D;锁的名称(UUID:threadId)

&#x2F;&#x2F; 1.不存在key锁
if(exists keys[1]&#x3D;&#x3D;0) then
  &#x2F;&#x2F; 赋值 key field value --&gt;1.1 尝试获取锁
  hset keys[1] argv[2] 1
  &#x2F;&#x2F; 过期 expire key time --&gt;1.2 设置锁过期时间
  pexpire keys[1] argv[1]
  return 空；
end

&#x2F;&#x2F; 存在Key name 的锁 --&gt; 2.当前线程已获取锁
if(hexists keys[1] argv[2]&#x3D;&#x3D;1) then
  &#x2F;&#x2F; --&gt;2.1 原子计数器+1  锁重入！！！
  hincrby keys[1] argv[2] 1
  &#x2F;&#x2F; 过期 --&gt;2.2 重置锁过期时间
  pexpire keys[1] argv[1]
  return 空；
end

&#x2F;&#x2F; --&gt;3.返回剩余过期时间
return pttl keys[1]</code></pre>

<blockquote>
<p>注意：lua 脚本数组下标从 1 开始</p>
</blockquote>
<h4 id="Redisson-释放锁"><a href="#Redisson-释放锁" class="headerlink" title="Redisson 释放锁"></a>Redisson 释放锁</h4><pre class="line-numbers language-java" data-language="java"><code class="language-java">protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123;
    return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,
            &quot;if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 0) then &quot; +
                &quot;redis.call(&#39;publish&#39;, KEYS[2], ARGV[1]); &quot; +
                &quot;return 1; &quot; +
            &quot;end;&quot; +
            &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[3]) &#x3D;&#x3D; 0) then &quot; +
                &quot;return nil;&quot; +
            &quot;end; &quot; +
            &quot;local counter &#x3D; redis.call(&#39;hincrby&#39;, KEYS[1], ARGV[3], -1); &quot; +
            &quot;if (counter &gt; 0) then &quot; +
                &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[2]); &quot; +
                &quot;return 0; &quot; +
            &quot;else &quot; +
                &quot;redis.call(&#39;del&#39;, KEYS[1]); &quot; +
                &quot;redis.call(&#39;publish&#39;, KEYS[2], ARGV[1]); &quot; +
                &quot;return 1; &quot;+
            &quot;end; &quot; +
            &quot;return nil;&quot;,
            Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));
&#125;</code></pre>

<p>释放 lua 脚本解释</p>
<pre class="line-numbers language-lua" data-language="lua"><code class="language-lua">unlock入参：
keys[1]:自定义锁的key  RLock lock &#x3D; redissonClient.getLock(lockKey);
keys[2]：通道名称  redisson_lock__channel:&#123;UUID:threadId&#125;
argv[1]&#x3D; publish unlock消息&#x3D;0
argv[2]&#x3D;锁的租期，默认30s
argv[3]&#x3D;锁的名称(UUID:threadId)

&#x2F;&#x2F; --&gt;1.不存在key锁，直接返回
if(hexists keys[1] argv[3]&#x3D;&#x3D;0) then
return 空

&#x2F;&#x2F; --&gt;2.存在锁，原子计数器-1
counter&#x3D;hincrby keys[1] argv[3] -1

if(counter&gt;0) then
  &#x2F;&#x2F; --&gt;2.1 计数器&gt;0,还有锁没释放，重置锁过期时间
  pexpire KEYS[1] ARGV[2]
  return 0;
else
  &#x2F;&#x2F; --&gt;2.2计数器&#x3D;0，锁已经全部释放完毕。
  &#x2F;&#x2F; --&gt;删除key
  del KEYS[1]
  &#x2F;&#x2F; --&gt;发布消息 publish channel message
  publish KEYS[2] ARGV[1]
  return 1；
end

return 空；</code></pre>

<blockquote>
<p>实现原理的学习可参考 <a href="https://bbs.huaweicloud.com/blogs/238821">https://bbs.huaweicloud.com/blogs/238821</a></p>
</blockquote>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（三）部署Sentinel高可用集群</title>
    <url>/article/redis/redis-sentinel/</url>
    <content><![CDATA[<blockquote>
<p>大家一定非常熟悉如何利用 Docker 启动单个 Redis 容器用于开发环境，本文将介绍如何利用 Docker Compose 模板在本机和云端部署基于 Sentinel 的高可用 Redis 3 集群。</p>
</blockquote>
<p>Redis 集群可以在一组 redis 节点之间实现高可用性和 sharding。今天我们重点围绕 master-slave 的高可用模式来进行讨论，在集群中会有 1 个 master 和多个 slave 节点。当 master 节点失效时，应选举出一个 slave 节点作为新的 master。然而 Redis 本身(包括它的很多客户端)没有实现自动故障发现并进行主备切换的能力，需要外部的监控方案来实现自动故障恢复。<br>Redis Sentinel 是官方推荐的高可用性解决方案。它是 Redis 集群的监控管理工具，可以提供节点监控、通知、自动故障恢复和客户端配置发现服务。<br>今天我们的部署模型是 Redis Sentinel 介绍的实例二，也是实战中比较常见的一种部署模式：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648983154309-7449cd0f-c64f-4578-848d-263536a9267d.png#clientId=u8949e708-224a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u099a1b8b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=266&originWidth=660&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=132746&status=done&style=none&taskId=u87031afb-c083-4c11-8d60-f2093d5e8ae&title=" alt="image.png"><br>本文所有示例代码都可以从 <a href="https://github.com/AliyunContainerService/redis-cluster">https://github.com/AliyunContainerService/redis-cluster</a> 获得<br>本文采用的 Redis 镜像全部基于 Docker 提供的 Redis 官方镜像 3.2.1</p>
<h2 id="单机部署-Redis-集群"><a href="#单机部署-Redis-集群" class="headerlink" title="单机部署 Redis 集群"></a>单机部署 Redis 集群</h2><p>下面的测试需要本地环境已经安装 Docker Engine 和 Docker Compose，推荐使用 Docker for Mac&#x2F;Windows。想在云端部署的同学可以直接跳到下一节</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">git clone https:&#x2F;&#x2F;github.com&#x2F;AliyunContainerService&#x2F;redis-cluster
cd redis-cluster</code></pre>

<p>目录下面的 docker-compose.yml 模板定义 Redis 集群的服务组成</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">master:
  image: redis:3
slave:
  image: redis:3
  command: redis-server --slaveof redis-master 6379
  links:
    - master:redis-master
sentinel:
  build: sentinel
  environment:
    - SENTINEL_DOWN_AFTER&#x3D;5000
    - SENTINEL_FAILOVER&#x3D;5000
  links:
    - master:redis-master
    - slave</code></pre>

<p>在模板中定义了下面一系列服务 - master: Redis master - slave: Redis slave - sentinel: Redis Sentinel<br>其中 sentinel 服务的 Docker 镜像是由 “.&#x2F;sentinel” 目录中的 Dockerfile 构建完成，只是在官方 Redis 镜像上添加了 sentinel.conf 配置文件，并以 sentinel 模式启动容器。其配置文件如下，其中包含了 sentinel 对名为”mymaster”的集群的监控配置：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sentinel monitor mymaster redis-master 6379 2
sentinel down-after-milliseconds mymaster 5000
sentinel parallel-syncs mymaster 1
sentinel failover-timeout mymaster 5000</code></pre>

<p>细节请参见 sentinel.conf 配置自身。<br>注意： - slave 和 sentinel 容器初始化配置的 Redis master 节点主机名为”redis-master”，这里我们利用了 Docker 容器连接的别名机制来连接 master 和 sentinel&#x2F;slave 容器实例 - 由于我们会部署 3 个 Sentinel，我们把 sentinel 的”quorum”设置为 2，只有两个 sentinel 同意故障切换，才会真正切换相应的 redis master 节点。 下面我们先构建 sentinel 服务所需 Docker image</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose build</code></pre>

<p>一键部署并启动 Redis 集群</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose up -d</code></pre>

<p>这时我们可以检查集群状态，应该是包含 3 个容器，1 个 master, 1 个 slave，和 1 个 sentinel</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose ps</code></pre>

<p>显示结果如下</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">  Name                        Command               State          Ports
--------------------------------------------------------------------------------------
rediscluster_master_1     docker-entrypoint.sh redis ...   Up      6379&#x2F;tcp
rediscluster_sentinel_1   docker-entrypoint.sh redis ...   Up      26379&#x2F;tcp, 6379&#x2F;tcp
rediscluster_slave_1      docker-entrypoint.sh redis ...   Up      6379&#x2F;tcp</code></pre>

<p>我们可以伸缩 sentinel 的实例数量到 3 个</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose scale sentinel&#x3D;3</code></pre>

<p>伸缩 slave 的实例数量到 2 个，这样我们就有 3 个 redis 实例了（包含一个 master)</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose scale slave&#x3D;2</code></pre>

<p>检查集群状态，结果如下</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">docker-compose ps

         Name                        Command               State          Ports
--------------------------------------------------------------------------------------
rediscluster_master_1     docker-entrypoint.sh redis ...   Up      6379&#x2F;tcp
rediscluster_sentinel_1   docker-entrypoint.sh redis ...   Up      26379&#x2F;tcp, 6379&#x2F;tcp
rediscluster_sentinel_2   docker-entrypoint.sh redis ...   Up      26379&#x2F;tcp, 6379&#x2F;tcp
rediscluster_sentinel_3   docker-entrypoint.sh redis ...   Up      26379&#x2F;tcp, 6379&#x2F;tcp
rediscluster_slave_1      docker-entrypoint.sh redis ...   Up      6379&#x2F;tcp
rediscluster_slave_2      docker-entrypoint.sh redis ...   Up      6379&#x2F;tcp</code></pre>

<p>我们可以利用下面的测试脚本来模拟 master 节点失效，并验证 Redis 集群的自动主从切换。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">.&#x2F;test.sh</code></pre>

<p>这个测试脚本实际上利用 docker pause 命令将 Redis master 容器暂停，sentinel 会发现这个故障并将 master 切换到其他一个备用的 slave 上面。<br>执行结果如下</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">Redis master: 172.17.0.2
Redis Slave: 172.17.0.3
------------------------------------------------
Initial status of sentinel
------------------------------------------------
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;172.17.0.2:6379,slaves&#x3D;2,sentinels&#x3D;3
Current master is
172.17.0.2
6379
------------------------------------------------
Stop redis master
rediscluster_master_1
Wait for 10 seconds
Current infomation of sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;172.17.0.3:6379,slaves&#x3D;2,sentinels&#x3D;3
Current master is
172.17.0.3
6379
------------------------------------------------
Restart Redis master
rediscluster_master_1
Current infomation of sentinel
# Sentinel
sentinel_masters:1
sentinel_tilt:0
sentinel_running_scripts:0
sentinel_scripts_queue_length:0
sentinel_simulate_failure_flags:0
master0:name&#x3D;mymaster,status&#x3D;ok,address&#x3D;172.17.0.3:6379,slaves&#x3D;2,sentinels&#x3D;3
Current master is
172.17.0.3
6379</code></pre>

<p>我们可以利用 Docker Compose 方便地在本地验证 Redis 集群的部署和故障恢复，但是这还不是一个分布式的高可用部署。我们下面会利用阿里云容器服务来进行验证</p>
<h2 id="云端部署高可用-Redis-集群"><a href="#云端部署高可用-Redis-集群" class="headerlink" title="云端部署高可用 Redis 集群"></a>云端部署高可用 Redis 集群</h2><p>阿里云容器服务 在兼容 Docker Compose 编排模板的基础上，做了大量的扩展。能够更好地帮助我们在 Docker 集群中部署分布式应用。<br>首先您需要创建一个包含至少三个节点的集群（否则您需要注释掉相应的”affinity:service”部署约束）<br>然后我们利用下面的 docker compose 模板部署高可用 Redis 集群</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">master:
  image: redis:3
  environment:
    - affinity:service!&#x3D;slave
  restart: always
slave:
  image: redis:3
  command: redis-server --slaveof redis-master 6379
  environment:
    - affinity:service!&#x3D;master
    - affinity:service!&#x3D;slave
  labels:
    aliyun.scale: &quot;2&quot;
  restart: always
  links:
    - master:redis-master
sentinel:
  image: registry.aliyuncs.com&#x2F;acs-sample&#x2F;redis-sentinel:3
  environment:
    - affinity:service!&#x3D;sentinel
  labels:
    aliyun.scale: &quot;3&quot;
  restart: always
  links:
    - master:redis-master
    - slave</code></pre>

<p>这里使用了预编译的 sentinel 镜像”registry.aliyuncs.com&#x2F;acs-sample&#x2F;redis-sentinel:3”<br>更重要是，引入了一些阿里云扩展使得对分布式应用更好地控制容器在宿主机节点的部署<br>aliyun.scale 标签：描述了服务的实例数量 affinity:service 环境变量描述了服务的部署约束：比如对于 Redis slave 而言，我们不希望在一个宿主机节点上同时部署 master 和 slave，或多个 slave，我们可以方便用示例中的方法描述这些约束。 关于这些的详尽解释请参见帮助文档<br>一键部署之后，我们就已经有一个真正高可用的 Redis 集群了</p>
<ul>
<li>在这里 master 和 2 个 slave 部署到不同的宿主机节点中</li>
<li>3 个 sentinel 部署到不同的宿主机节点中</li>
</ul>
<p>这样任何一个宿主机节点失效，都不会导致 Redis 集群失败</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>文章介绍了如何在本地部署一个 Redis 集群，并利用 Redis Sentinel 实现自动化的主从切换。并在此基础上利用阿里云容器服务扩展，一键部署一个真正的高可用分布式 Redis 集群。<br>对于 Redis 而言，阿里云提供了云数据库 Redis 版，对于大部分对 SLA 有要求的客户我们建议在生产环境使用 Redis 云服务。但是如果大家对版本、配置有特殊要求的时候，使用 Docker 部署 Redis 也是非常方便的。<br>出于性能考虑，在 Docker 容器中运行 Redis 不建议采用 bridge 网络对外提供访问，如需对外部 VM 或应用提供服务建议采用 host 网络模式，并注意安全保护；如果只是对集群中容器提供 redis 访问，则容器服务默认提供的跨宿主机容器网络会提供优化而安全的网络配置。同时建议在 Docker 容器设置中，给 Redis 容器配置合适的内存设置。<br>本文也给大家提供了一个示例，如何采用 Docker 的方式开发分布式应用并在云端部署生产级别环境。阿里云容器服务不但支持 docker-compose 模板提供的容器功能，使得本地开发的 Docker 镜像和编排模板可以轻松上云；更提供了灵活的部署约束描述，使得对分布式应用的部署和控制变得非常方便。</p>
]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（四）存储结构</title>
    <url>/article/redis/redis-storage-structure/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Redis 作为一款高性能数据库，表现在：它接收到一个键值对操作后， 能以微秒级别的速度找到数据，并快速完成操作。其高性能得奥秘来缘于以下两点：</p>
<ul>
<li>Redis 是内存数据库， 所有操作都在内存上完成，内存的访问速度本身就很快</li>
<li>Reids 通过高效的数据结构来组织数据。</li>
</ul>
<p>本章节可以让你在最短的时间了解如下内容：</p>
<ul>
<li>Redis 支持五大数据类型</li>
<li>Redis 组织 Key-Value 数据结构</li>
<li>Redis5 大值类型数据存储结构</li>
</ul>
<h2 id="一、五大数据类型"><a href="#一、五大数据类型" class="headerlink" title="一、五大数据类型"></a>一、五大数据类型</h2><ul>
<li>String(字符串)</li>
<li>List(列表)</li>
<li>Set(集合)</li>
<li>Hash（哈希）</li>
<li>Zset（有序集合）</li>
</ul>
<h2 id="二、组织-Key-Value-数据结构"><a href="#二、组织-Key-Value-数据结构" class="headerlink" title="二、组织 Key-Value 数据结构"></a>二、组织 Key-Value 数据结构</h2><p>在 redis 中无论什么数据类型，在数据库中都是以 key-value 形式保存，通过进行对 Redis-key 的操作，来完成对数据库中数据的操作。</p>
<h3 id="全局哈希表"><a href="#全局哈希表" class="headerlink" title="全局哈希表"></a>全局哈希表</h3><p>为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。<br>一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶。所以，我们常说，一 个哈希表是由多个哈希桶组成的，每个哈希桶中保存了键值对数据。<br>哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。在下图中，可以看到，_哈希桶中的 entry 元素中保存了 key 和_value 指针<strong>，分别指向了 实际的键和值<br>因为这个哈希表保存了所有的键值对，所以，我也把它称为</strong>全局哈希表**。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779832457-c09e705a-bf33-4cf0-b9b4-411792c87aef.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=566&id=u136f6d07&margin=%5Bobject%20Object%5D&name=image.png&originHeight=566&originWidth=1056&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=207909&status=done&style=none&taskId=u2ae3c090-ef92-4b9c-ad82-c7d159475cf&title=&width=1056" alt="image.png"></p>
<h4 id="哈希表优势"><a href="#哈希表优势" class="headerlink" title="哈希表优势"></a>哈希表优势</h4><p>让我们可以用 O(1) 的时间复杂度来快速查找到键值对——我们只需要计算 键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素。这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说， 不管哈希表里有 10 万个键还是 100 万个键，我们只需要一次计算就能找到相应的键。</p>
<h4 id="哈希表劣势"><a href="#哈希表劣势" class="headerlink" title="哈希表劣势"></a>哈希表劣势</h4><p>当往哈希表写入大量数据后，就可能发现操作有时候会突然变慢了，这其实是因为你忽略了一个潜在 的风险点，那就是<strong>哈希冲突</strong>问题和 <strong>rehash</strong> 可能带来的操作阻塞。</p>
<h3 id="哈希冲突"><a href="#哈希冲突" class="headerlink" title="哈希冲突"></a>哈希冲突</h3><p>当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。<br>哈希冲突，也就是 指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。毕竟，哈希桶的个数通常要少于 key 的数量，这也就是说，难免会有一些 key 的哈希值对 应到了同一个哈希桶中。</p>
<h4 id="链式哈希"><a href="#链式哈希" class="headerlink" title="链式哈希"></a>链式哈希</h4><p>链式哈希也很容易理解，就是指同一个哈希 桶中的多个元素用一个链表来保存，它们之间依次用指针连接。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779889129-ec383f85-181f-4e98-b070-ba902f0d2c4d.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=692&id=ud220931d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=692&originWidth=794&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=250853&status=done&style=none&taskId=u0cdb692f-9f75-4de4-923a-68fc2d282e8&title=&width=794" alt="image.png"><br>如上图所示：entry1、entry2 和 entry3 都需要保存在哈希桶 3 中，导致了哈希冲突。此 时，entry1 元素会通 过一个_next 指针指向 entry2，同样，entry2 也会通过_next 指针 指向 entry3。这样一来，即使哈希桶 3 中的元素有 100 个，我们也可以通过 entry 元素 中的指针，把它们连起来。这就形成了一个链表，也叫作哈希冲突链。</p>
<h3 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h3><p>哈希冲突链上的元素只能通过指针逐一查找再操作。如果 哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链 过长，进而导致这个链上的元素查找耗时长，效率降低。<br>Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让逐渐 增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个 桶中的冲突。</p>
<h4 id="简单-rehash"><a href="#简单-rehash" class="headerlink" title="简单 rehash"></a>简单 rehash</h4><p>为了使 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希 表 2。一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空 间。随着数据逐步增多，Redis 开始执行 rehash,这个过程分为三步：</p>
<ul>
<li>给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍；</li>
<li>把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中</li>
<li>释放哈希表 1 的空间</li>
</ul>
<p>到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来 的哈希表 1 留作下一次 rehash 扩容备用。（有点类似 JVM 年轻代复制回收）</p>
<h4 id="渐进式-rehash"><a href="#渐进式-rehash" class="headerlink" title="渐进式 rehash"></a>渐进式 rehash</h4><p>简单 rehash 过程中最大的问题在于第二步涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都 迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据 了。为了避免这个问题，Redis 采用了渐进式 rehash。<br>渐进式 rehash 简单来说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求 时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝 到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。<br>这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操 作，保证了数据的快速访问。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648779914591-e4c4c721-7f22-4a94-96bb-e424742d1f2a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=650&id=ueecd49e3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=650&originWidth=999&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=327606&status=done&style=none&taskId=u6dd9ec86-ebe2-484d-bb62-8c9dd78d3d8&title=&width=999" alt="image.png"></p>
<h3 id="内存使用大小"><a href="#内存使用大小" class="headerlink" title="内存使用大小"></a>内存使用大小</h3><p>哈希表的每一项是 一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构中有三个 8 字节的指针， 分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节。<br>但这里需要注意的是这里 Redis 使用的内 存分配库 jemalloc 了。<br>jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数。<br>举个例子。如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字 节空间，jemalloc 则会分配 32 字节。所以，在我们刚刚说的场景里，<strong>dictEntry 结构就占 用了 32 字节</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780229010-3120360f-507a-4c46-b6e1-7b229dc38f13.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=156&id=ued930961&margin=%5Bobject%20Object%5D&name=image.png&originHeight=623&originWidth=1056&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=194203&status=done&style=none&taskId=ube66eb53-78ef-4e48-8235-458252f0166&title=&width=264" alt="image.png"></p>
<h2 id="三、不同数据类型存储结构"><a href="#三、不同数据类型存储结构" class="headerlink" title="三、不同数据类型存储结构"></a>三、不同数据类型存储结构</h2><p>Redis 底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈 希表、跳表和整数数组。它们和数据类型的对应关系如下图所示<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780246131-132be37e-abc1-4b14-a54b-cbf87e1904a6.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=305&id=u6f02ecf5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=305&originWidth=994&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=151661&status=done&style=none&taskId=u5e069a5c-7cb4-4dad-a0b6-9223b3b09f1&title=&width=994" alt="image.png"></p>
<h3 id="简单动态字符串（SDS）"><a href="#简单动态字符串（SDS）" class="headerlink" title="简单动态字符串（SDS）"></a>简单动态字符串（SDS）</h3><p>Redis String 类型就会用简单动态字符串（Simple Dynamic String，SDS）结构体来保存。</p>
<h4 id="Redis-SDS-数据结构"><a href="#Redis-SDS-数据结构" class="headerlink" title="Redis SDS 数据结构"></a>Redis SDS 数据结构</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780289412-e0046012-68e4-48e6-8bd4-3837c90d3a99.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=758&id=u00197c7c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=758&originWidth=1050&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=148199&status=done&style=none&taskId=uf419e644-49bb-4e7b-90f8-dd32520d17a&title=&width=1050" alt="image.png"></p>
<h5 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h5><p>Redis 简单字符串可以存储数据类型有很多，而且，不同数据类型都有些相同的元数据要记录，这其中包括：</p>
<ul>
<li>最后一次访问的时间</li>
<li>被引用的次数</li>
<li>….</li>
</ul>
<p>其中元数据占用 8 个字节。</p>
<h5 id="PRT"><a href="#PRT" class="headerlink" title="PRT"></a>PRT</h5><p>表示一个指针，指针再进一步指向具体 数据类型的实际数据所在。如果存储类型是 String 类型，那么指针指向的是的 SDS 结构所在的内存地址。<br>其中 PRT 指针占用 8 个字节。</p>
<h5 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h5><p>SDS 存储结构负责存储具体数据。其中包括了三层结构：<br>buf</p>
<ul>
<li>字节数组，保存实际数据。</li>
<li>为了表示字节数组的结束，Redis 会自动在数组最后加 一个“\0”，这就会额外占用 1 个字节的开销。</li>
</ul>
<p>len</p>
<ul>
<li>占 4 个字节，表示 buf 的已用长度。</li>
</ul>
<p>alloc</p>
<ul>
<li>也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。</li>
</ul>
<p>[图片上传失败…(image-ec3716-1611492954707)]</p>
<h4 id="Redis-SDS-内存优化"><a href="#Redis-SDS-内存优化" class="headerlink" title="Redis SDS 内存优化"></a>Redis SDS 内存优化</h4><p>为了节省内存空间，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计。</p>
<h5 id="Long-类型整数"><a href="#Long-类型整数" class="headerlink" title="Long 类型整数"></a>Long 类型整数</h5><p>当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据 了，这样就不用额外的指针再指向整数了，节省了指针的空间开销。</p>
<h5 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h5><p>当字符串小于 44 字节时<br>RedisObject 中的元 数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被 称为 embstr 编码方式。<br>当字符串大于 44 字节时<br>SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。 这种布局方式被称为 raw 编码模式。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780346574-992aa687-ba7f-4fc5-ad31-7556b50ad899.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=739&id=u2582c374&margin=%5Bobject%20Object%5D&name=image.png&originHeight=739&originWidth=1014&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=178694&status=done&style=none&taskId=u5fba1ee8-a340-49cf-9ece-0718c9677d0&title=&width=1014" alt="image.png"></p>
<h4 id="Redis-SDS-优势"><a href="#Redis-SDS-优势" class="headerlink" title="Redis SDS 优势"></a>Redis SDS 优势</h4><p>SDS 这种数据结构相对于 C 字符串有以下优点：</p>
<ul>
<li>杜绝缓冲区溢出</li>
<li>减少字符串操作中的内存重分配次数</li>
<li>二进制安全</li>
<li>由于 SDS 遵循以空字符结尾的惯例，因此兼容部门 C 字符串函数</li>
</ul>
<h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><table><thead><tr>
<th>操作</th>
<th>时间复杂度</th>
</tr>
</thead><tbody><tr>
<td>获取 SDS 长度</td>
<td>由于 SDS 中提供了 len 属性，因此我们可以直接获取时间复杂度为 O(1),C 字符串为 O(n)。</td>
</tr>
<tr>
<td>获取 SDS 未使用空间长度</td>
<td>O(1)</td>
</tr>
<tr>
<td>清除 SDS 保存的内容</td>
<td>由于惰性分配策略，O(1)</td>
</tr>
<tr>
<td>创建一个长度为 N 字符串</td>
<td>O(n)</td>
</tr>
<tr>
<td>拼接一个长度为 N 的 C 字符串</td>
<td>O(n)</td>
</tr>
<tr>
<td>拼接一个长度为 N 的 SDS 字符串</td>
<td>O(n)</td>
</tr>
</tbody></table><h3 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h3><h4 id="数据结构-链表"><a href="#数据结构-链表" class="headerlink" title="数据结构-链表"></a>数据结构-链表</h4><p>相比数组，链表是一种稍微复杂一点的数据结构。数组需要一块连续的内存空间来存储，对内存的要求比较高。而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780372496-d0edb5de-d6a1-4de7-8539-820e2fb62b57.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=699&id=uc6849a5a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=699&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=274491&status=done&style=none&taskId=u5a96a5a3-c6af-4bad-a787-caf4933822a&title=&width=1142" alt="image.png"><br>链表结构五花八门，其中三种最常见的链表结构，它们分别是：<strong>单链表</strong>、<strong>双向链表</strong>和<strong>循环链表</strong>。</p>
<h5 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h5><p>链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作后继指针 next。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780382346-7e852ee4-6a21-4d27-9bee-5e4b5f0f9ace.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=399&id=u30fbfc37&margin=%5Bobject%20Object%5D&name=image.png&originHeight=399&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=148863&status=done&style=none&taskId=ubd3f3538-7eb0-41a6-9354-20aa6f9f563&title=&width=1142" alt="image.png"><br>其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。<br><strong>插入&amp;删除</strong><br>而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780393549-1666cf4f-3954-424c-b1b6-662573a8a72a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=650&id=ud3c02b32&margin=%5Bobject%20Object%5D&name=image.png&originHeight=650&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=215444&status=done&style=none&taskId=u615ac002-3f9e-46a4-a278-2287b313cdc&title=&width=1142" alt="image.png"><br><strong>查询</strong><br>但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点<br>你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。</p>
<h5 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h5><p>循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780405398-4c31b4eb-f4a0-4f6a-8fd2-16ac48cb814f.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=399&id=uba73997a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=399&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=146326&status=done&style=none&taskId=u96c32cac-6a3c-4c6e-a81a-1160217d084&title=&width=1142" alt="image.png"></p>
<p>和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。</p>
<h5 id="双向链表-1"><a href="#双向链表-1" class="headerlink" title="双向链表"></a>双向链表</h5><p>单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。<br>双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。</p>
<h6 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h6><p>双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。如删除某个结点 q 需要知道其前驱结点<br><strong>删除某个结点前驱结点</strong><br>我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p-&gt;next&#x3D;q，说明 p 是 q 的前驱结点。但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针， 不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了。<br><strong>某个指定结点前面插入</strong><br>同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。<br><strong>查询某个节点</strong><br>除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。<br>Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。</p>
<h6 id="设计思想"><a href="#设计思想" class="headerlink" title="设计思想"></a>设计思想</h6><p>这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。</p>
<h5 id="双向循环链表"><a href="#双向循环链表" class="headerlink" title="双向循环链表"></a>双向循环链表</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780423996-14ad8829-63a6-435c-8c73-28991bd46931.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=500&id=uf11ba9af&margin=%5Bobject%20Object%5D&name=image.png&originHeight=500&originWidth=1142&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=228581&status=done&style=none&taskId=uff6cd8ff-b47a-4ffe-a058-1560829d9b0&title=&width=1142" alt="image.png"></p>
<h5 id="链表-VS-数组性能"><a href="#链表-VS-数组性能" class="headerlink" title="链表 VS 数组性能"></a>链表 VS 数组性能</h5><p>数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。</p>
<h6 id="数组优势"><a href="#数组优势" class="headerlink" title="数组优势"></a><strong>数组优势</strong></h6><p>数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。</p>
<h6 id="数组劣势"><a href="#数组劣势" class="headerlink" title="数组劣势"></a><strong>数组劣势</strong></h6><p>数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。</p>
<h6 id="取舍"><a href="#取舍" class="headerlink" title="取舍"></a><strong>取舍</strong></h6><p>如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。</p>
<h4 id="Redis-链表结构"><a href="#Redis-链表结构" class="headerlink" title="Redis 链表结构"></a>Redis 链表结构</h4><p>Redis 链表使用双向链表结构<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780439047-c93a6e28-9ed3-4863-9cb7-028181e193df.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=653&id=u20485c50&margin=%5Bobject%20Object%5D&name=image.png&originHeight=653&originWidth=1146&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=280270&status=done&style=none&taskId=u3178c682-0adc-46b5-be58-814860e460e&title=&width=1146" alt="image.png"></p>
<ul>
<li>双向：链表节点带有前驱、后继指针获取某个节点的前驱、后继节点的时间复杂度为 0(1)。</li>
<li>无环: 链表为非循环链表表头节点的前驱指针和表尾节点的后继指针都指向 NULL，对链表的访问以 NULL 为终点。</li>
<li>带表头指针和表尾指针：通过 list 结构中的 head 和 tail 指针，获取表头和表尾节点的时间复杂度都为 O(1)。</li>
<li>带链表长度计数器:通过 list 结构的 len 属性获取节点数量的时间复杂度为 O(1)。</li>
<li>多态：链表节点使用 void*指针保存节点的值，并且可以通过 list 结构的 dup、free、match 三个属性为节点值设置类型特定函数，所以链表可以用来保存各种不同类型的值。</li>
</ul>
<h3 id="压缩列表"><a href="#压缩列表" class="headerlink" title="压缩列表"></a>压缩列表</h3><p>压缩列表(zip1ist)是列表和哈希的底层实现之一。</p>
<ul>
<li>当一个列表只包含少量列表项,并且每个列表项要么就是小整数值,要么就是长度比较短的字符串,那么 Redis 就会使用压缩列表来做列表的底层实现。</li>
<li>当一个哈希只包含少量键值对,比且每个键值对的键和值要么就是小整数值,要么就是长度比较短的字符串,那么 Redis 就会使用压缩列表来做哈希的底层实现。</li>
</ul>
<h4 id="数据结构-压缩列表"><a href="#数据结构-压缩列表" class="headerlink" title="数据结构-压缩列表"></a>数据结构-压缩列表</h4><p>听到“压缩”两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存,是相较于数组的存储思路而言的。我们知道,数组要求每个元素的大小相同,如果我们要存储不同长度的字符串,那我们就需要用最大长度的字符串大小作为元素的大小(假设是 20 个字节)。存储小于 20 个字节长度的字符串的时候，便会浪费部分存储空间。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780454355-cbd5dd1a-727f-446f-b18f-36ca360171ae.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=246&id=u619cc6f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=246&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=65335&status=done&style=none&taskId=u8488eda2-eb22-4b8f-a664-b88c7accfee&title=&width=1200" alt="image.png"><br>数组的优势占用一片连续的空间可以很好的利用 CPU 缓存访问数据。如果我们想要保留这种优势，又想节省存储空间我们可以对数组进行压缩。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780467106-0c83a678-28ed-47af-8672-316dd2d0d4d9.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=289&id=ua0fd48b0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=289&originWidth=854&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=72717&status=done&style=none&taskId=u9939bcc3-55fa-490c-8987-15b181db90c&title=&width=854" alt="image.png"><br>是这样有一个问题，我们在遍历它的时候由于不知道每个元素的大小是多少，因此也就无法计算出下一个节点的具体位置。这个时候我们可以给每个节点增加一个 lenght 的属性。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780486188-d17fc325-6f0d-442d-a36c-a200458f6ec1.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=380&id=u47fb909b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=380&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=110718&status=done&style=none&taskId=ue9f201c5-e21b-4036-b0fe-6c19e2bbb89&title=&width=1200" alt="image.png"><br>如此。我们在遍历节点的之后就知道每个节点的长度(占用内存的大小)，就可以很容易计算出下一个节点再内存中的位置。这种结构就像一个简单的压缩列表了。</p>
<h4 id="Redis-压缩列表结构"><a href="#Redis-压缩列表结构" class="headerlink" title="Redis 压缩列表结构"></a>Redis 压缩列表结构</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780502069-e09aedf4-9ee5-4c76-adbd-144055c2221a.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=339&id=u4cb75eb1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=339&originWidth=1060&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=108377&status=done&style=none&taskId=u45806980-2ab9-4b4c-856b-449384af80c&title=&width=1060" alt="image.png"><br><strong>zlbytes</strong></p>
<ul>
<li>记录整个压缩列表占用的内存字节数；</li>
<li>在对压缩列表进行重新内存分配，或者计算 zlleng 的位置时使用；</li>
<li>占用 4 个字节；</li>
</ul>
<p><strong>zltail</strong></p>
<ul>
<li>记录压缩列表表尾节点(entryN)起始偏移量距离压缩列表的起始地址有多少字节；</li>
<li>通过这个偏移量，程序无须遍历整个压缩列表就可以确认压缩列表尾节点的地址；</li>
<li>占用 4 个字节；</li>
</ul>
<p><strong>zllen</strong></p>
<ul>
<li>记录压缩列表包含了节点(entryN)数量；</li>
<li>当这个属性的小于 65535 时，这个属性的值就是压缩列表包含节点的数量；</li>
<li>当这个属性的大于等于 65535 时，节点的真实数量需要遍历整个压缩列表才能计算获得；</li>
<li>占用 2 个字节；</li>
</ul>
<p><strong>zlend</strong></p>
<ul>
<li>特殊值 OxFF,用于记录压缩列表的未端；</li>
<li>占用 1 个字节；</li>
</ul>
<h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780517323-ffa1704a-7d35-48ed-9332-39408e37262f.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=299&id=u51195243&margin=%5Bobject%20Object%5D&name=image.png&originHeight=299&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=100794&status=done&style=none&taskId=u581807bc-fd85-4ec7-8792-62a10ca4b92&title=&width=1200" alt="image.png"></p>
<ul>
<li>zllen 表示当前压缩列表有 3 个节点；</li>
<li>zltail 表示压缩列表表尾节点(entryN)起始偏移量距离压缩列表的起始地址有 60 个字节，因此如果表示 P 指向了压缩列表开始偏移量，那么 entry3 节点开始偏移量为 P+60；</li>
<li>zlbytes 表示整个压缩列表占用的内存字节数，因此通过计算可以知道 entry3 大小为 19&#x3D;80-60-1；</li>
</ul>
<h5 id="entry-数据结构"><a href="#entry-数据结构" class="headerlink" title="entry 数据结构"></a>entry 数据结构</h5><p>列表节点<br>prev_len<br>表示前一个 entry 的长度。<br><strong>表示上一个 entry 的长度小于 254 字节</strong></p>
<ul>
<li>占用 1 字节</li>
<li>前一节点的长度就保存在这一个字节里面</li>
</ul>
<p><strong>表示上一个 entry 的长度大于 254 字节</strong></p>
<ul>
<li>占用 5 字节</li>
<li>第一字节会被设置为 0xFE</li>
<li>之后的四个字节则用于保存前一节点的长度</li>
</ul>
<p>encoding</p>
<ul>
<li>表示数据的类型和长度</li>
<li>占用 1 字节</li>
</ul>
<p>len</p>
<ul>
<li>表示自身长度</li>
<li>占用 4 字节</li>
</ul>
<p>key</p>
<ul>
<li>保存实际数据</li>
</ul>
<h4 id="时间复杂度-1"><a href="#时间复杂度-1" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><table><thead><tr>
<th>操作</th>
<th>时间复杂度</th>
</tr>
</thead><tbody><tr>
<td>创建一个压缩列表</td>
<td>O(1)</td>
</tr>
<tr>
<td>创建一个包含给定值的新节点，并将这个新节点添加到压缩列表的表头或者表尾</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新)</td>
</tr>
<tr>
<td>将包含给定值的新节点插入到给定节点之后</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>返回压缩列表给定索引上的节点</td>
<td>O(N)</td>
</tr>
<tr>
<td>在压缩列表中查找并返回包含了给定值的节点</td>
<td>因为节点的值可能是一个字节数组，所以检查节点值和给定值是否相同的复杂度为 O(N)，而查找整个泪飙的复杂度则(N^2)</td>
</tr>
<tr>
<td>返回给定节点的下一个节点</td>
<td>O(1)</td>
</tr>
<tr>
<td>返回给定节点的前一个节点</td>
<td>O(1)</td>
</tr>
<tr>
<td>获取给定节点所保存的值</td>
<td>O(1)</td>
</tr>
<tr>
<td>从压缩列表中删除给定的节点</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>删除压缩列表在给定索引上的连续多个</td>
<td>平均 O(N),最坏 O(N^2)(可能发生连锁更新</td>
</tr>
<tr>
<td>返回压缩列表目前占用的内存字节数</td>
<td>O(1)</td>
</tr>
<tr>
<td>返回压缩列表目前包含的节点数量</td>
<td>点数量小于 65535 时为 O(1)，大于 65535 时为 O(N)</td>
</tr>
</tbody></table><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780537452-e936d830-7f57-49df-adbc-69e5874c5849.png#clientId=u7897f90e-c8d9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=550&id=ue6e6b33e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=550&originWidth=987&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=244526&status=done&style=none&taskId=u068db4c3-e323-4683-983e-26e2a3e5c04&title=&width=987" alt="image.png"></p>
<h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><h3 id="整数数组"><a href="#整数数组" class="headerlink" title="整数数组"></a>整数数组</h3><h3 id="不同操作的复杂度"><a href="#不同操作的复杂度" class="headerlink" title="不同操作的复杂度"></a>不同操作的复杂度</h3><p>集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元 素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作， 它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。<br>我总结了一个“四句口诀”，希望能帮助你快速记住集合常见操作的复杂度。这样你在使 用过程中，就可以提前规避高复杂度操作了</p>
<ul>
<li>单元素操作是基础；</li>
<li>范围操作非常耗时；</li>
<li>统计操作通常高效；</li>
<li>例外情况只有几个。</li>
</ul>
<h5 id="单元素操作"><a href="#单元素操作" class="headerlink" title="单元素操作"></a>单元素操作</h5><p>第一，<strong>单元素操作，是指每一种集合类型对单个数据实现的增删改查操作</strong>。例如，Hash 类 型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。<strong>这些操 作的复杂度由集合采用的数据结构决定</strong>，例如，HGET、HSET 和 HDEL 是对哈希表做操 作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、 SREM、SRANDMEMBER 复杂度也是 O(1)。<br>这里，有个地方你需要注意一下，集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操 作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元 素时，复杂度就从 O(1) 变成 O(M) 了。</p>
<h5 id="范围操作"><a href="#范围操作" class="headerlink" title="范围操作"></a>范围操作</h5><p>第二，<strong>范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据</strong>，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。<strong>这类操作的复杂度一般是 O(N)，比较耗时， 我们应该尽量避免</strong>。<br>不过，Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻 塞。</p>
<h5 id="统计操作"><a href="#统计操作" class="headerlink" title="统计操作"></a>统计操作</h5><p>第三，统计操作，是指<strong>集合类型对集合中所有元素个数的记录</strong>，例如 LLEN 和 SCARD。这 类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数 据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。</p>
<h5 id="例外情况"><a href="#例外情况" class="headerlink" title="例外情况"></a>例外情况</h5><p>第四，例外情况，是指某些数据结构的特殊记录，例如<strong>压缩列表和双向链表都会记录表头 和表尾的偏移量</strong>。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操 作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂 度也只有 O(1)，可以实现快速操作</p>
<h2 id="四、经典案例"><a href="#四、经典案例" class="headerlink" title="四、经典案例"></a>四、经典案例</h2><h3 id="需求分析"><a href="#需求分析" class="headerlink" title="需求分析"></a>需求分析</h3><p>当时，我们要开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片在存储系 统中保存时的 ID（可以直接叫作图片存储对象 ID）。同时，还要能够根据图片 ID 快速查 找到图片存储对象 ID。<br>因为图片数量巨大，所以我们就用 10 位数来表示图片 ID 和图片存储对象 ID，例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">photo_id: 1101000051
photo_obj_id: 3301000051</code></pre>

<p>可以看到，图片 ID 和图片存储对象 ID 正好一一对应，是典型的“键 - 单值”模式。所谓 的“单值”，就是指键值对中的值就是一个值，而不是一个集合，这和 String 类型提供 的“一个键对应一个值的数据”的保存形式刚好契合。</p>
<h4 id="使用-String-类型"><a href="#使用-String-类型" class="headerlink" title="使用 String 类型"></a>使用 String 类型</h4><p>使用 String 保存数据。我们把图片 ID 和图片存储对象 ID 分别 作为键值对的 key 和 value 来保存，其中，图片存储对象 ID 用了 String 类型。</p>
<h4 id="String-类型内存开销大"><a href="#String-类型内存开销大" class="headerlink" title="String 类型内存开销大"></a>String 类型内存开销大</h4><p>随着图片数据量的不断 增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。<br>当我们使用 String 类型时，除了记录实际数据，String 类型还需要额外的内存空间记录数据长度、空间使用等 信息，这些信息也叫作元数据。当实际保存的数据较小时，元数据的空间开销就显得比较 大了，有点“喧宾夺主”的意思。</p>
<ul>
<li>1 亿张图片的信息，用了约 6.4GB 的内存，一个图片 ID 和 图片存储对象 ID 的记录平均用了 64 字节。</li>
<li>但问题是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了。</li>
</ul>
<h4 id="计算-String-内存大小"><a href="#计算-String-内存大小" class="headerlink" title="计算 String 内存大小"></a>计算 String 内存大小</h4><p>因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码 的 RedisObject 保存，根据下图计算一共 64 字节。</p>
<table><thead><tr>
<th><strong>结构</strong></th>
<th><strong>大小</strong></th>
</tr>
</thead><tbody><tr>
<td>key-value 哈希表 dictEntry</td>
<td>32 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 SDS 元数据</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 PRT</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片存储对象 ID 简单字符串 SDS 元数据</td>
<td>8 字节</td>
</tr>
<tr>
<td>图片 ID 简单字符串 PRT 简单字符串 PRT</td>
<td>8 字节</td>
</tr>
</tbody></table>]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Sentinel与Hystrix的对比</title>
    <url>/article/stability/sentinel-hystrix/</url>
    <content><![CDATA[<p>Sentinel 是阿里中间件团队研发的面向分布式服务架构的轻量级高可用流量控制组件，已开源。Sentinel 主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。</p>
<p>大家可能会问：Sentinel 和之前常用的熔断降级库 Netflix Hystrix 有什么异同呢？本文将从多个角度对 Sentinel 和 Hystrix 进行对比，帮助大家进行技术选型。先来看一下 Hystrix 的官方介绍：</p>
<blockquote>
<p>Hystrix is a library that helps you control the interactions between these distributed services by adding latency tolerance and fault tolerance logic. Hystrix does this by isolating points of access between the services, stopping cascading failures across them, and providing fallback options, all of which improve your system’s overall resiliency.</p>
</blockquote>
<p>Hystrix 是一个库，通过添加延迟容忍和容错逻辑，帮助您控制这些分布式服务之间的交互。Hystrix 通过隔离服务之间的访问点、阻止跨服务的级联故障以及提供回退选项来实现这一点，所有这些都可以提高系统的整体弹性。</p>
<h2 id="关注点差异"><a href="#关注点差异" class="headerlink" title="关注点差异"></a>关注点差异</h2><p>1、Hystrix 的关注点<br>以 <strong>隔离 和 熔断 <strong>为主的容错机制，</strong>超时或被熔断的调用将会快速失败</strong>，并可以提供 <strong>fallback</strong> 机制。<br>2、Sentinel 的侧重点在于</p>
<ul>
<li>多样化的流量控制</li>
<li>熔断降级</li>
<li>系统负载保护</li>
<li>实时监控和控制台</li>
</ul>
<p>可以看到两者解决的问题还是有比较大的不同的，下面我们来分别对比一下。</p>
<h2 id="共同特性"><a href="#共同特性" class="headerlink" title="共同特性"></a>共同特性</h2><h3 id="资源模型和执行模型对比"><a href="#资源模型和执行模型对比" class="headerlink" title="资源模型和执行模型对比"></a>资源模型和执行模型对比</h3><p>1、Hystrix 的资源模型设计上采用<strong>命令模式</strong><br>将对外部资源的调用和 fallback 逻辑封装成一个命令对象（<strong>HystrixCommand</strong> &#x2F; <strong>HystrixObservableCommand</strong>），其底层的执行是基于 RxJava 实现的。每个 Command 创建时都要指定** commandKey** 和 <strong>groupKey</strong>（用于区分资源）以及对应的隔离策略（线程池隔离 or 信号量隔离）。</p>
<p><strong>线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超时等）</strong>，然后 Command 就会在指定的线程池按照指定的容错策略执行；<strong>信号量隔离模式下需要配置最大并发数</strong>，执行 Command 时 Hystrix 就会限制其并发调用。</p>
<p>2、Sentinel 的设计则更为简单<br>相比 Hystrix Command <strong>强依赖隔离规则</strong>，Sentinel 的资源定义与规则配置的耦合度更低。<strong>Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响 Command 的执行</strong>。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单包装成当前线程执行的 Scheduler。</p>
<p>而 Sentinel 并不指定执行模型，也不关注应用是如何执行的。Sentinel 的原则非常简单：根据对应资源配置的规则来为资源执行相应的限流&#x2F;降级&#x2F;负载保护策略。在 <strong>Sentinel 中资源定义和规则配置是分离</strong>的。用户先通过 Sentinel API 给对应的业务逻辑定义资源（埋点），然后可以在需要的时候配置规则，埋点方式有两种：</p>
<ul>
<li>try-catch 方式（通过 <strong>SphU</strong>.entry(…))，用户在 catch 块中执行异常处理 &#x2F; fallback</li>
<li>if-else 方式（通过 <strong>SphO</strong>.entry(…)），当返回 false 时执行异常处理 &#x2F; fallback</li>
</ul>
<p>未来 Sentinel 还会引入基于注解的资源定义方式，同时可以通过注解参数指定异常处理函数和 fallback 函数。</p>
<p>Sentinel 提供多样化的规则配置方式。除了直接通过 loadRules API 将规则注册到内存态之外，用户还可以注册各种外部数据源来提供动态的规则。用户可以根据系统当前的实时情况去动态地变更规则配置，数据源会将变更推送至 Sentinel 并即时生效。</p>
<h3 id="隔离设计上的对比"><a href="#隔离设计上的对比" class="headerlink" title="隔离设计上的对比"></a>隔离设计上的对比</h3><p><strong>1、Hystrix 隔离策略</strong><br>隔离是 Hystrix 的核心功能之一。<strong>Hystrix 提供两种隔离策略：线程池隔离（Bulkhead Pattern）和信号量隔离</strong>，其中最推荐也是最常用的是线程池隔离。Hystrix 的线程池隔离针对不同的资源分别创建不同的线程池，不同服务调用都发生在不同的线程池中，在线程池排队、超时等阻塞情况时可以快速失败，并可以提供 fallback 机制。线程池隔离的好处是隔离度比较高，可以针对某个资源的线程池去进行处理而不影响其它资源，但是代价就是线程上下文切换的 overhead 比较大，特别是对低延时的调用有比较大的影响。</p>
<p>但是，实际情况下，线程池隔离并没有带来非常多的好处。首先就是过多的<strong>线程池会非常影响性能</strong>。考虑这样一个场景，在 Tomcat 之类的 Servlet 容器使用 Hystrix，本身 Tomcat 自身的线程数目就非常多了（可能到几十或一百多），如果加上 Hystrix 为各个资源创建的线程池，总共线程数目会非常多（几百个线程），这样上下文切换会有非常大的损耗。另外，线程池模式比较彻底的隔离性使得 Hystrix 可以针对不同资源线程池的排队、超时情况分别进行处理，但这其实是超时熔断和流量控制要解决的问题，如果组件具备了超时熔断和流量控制的能力，线程池隔离就显得没有那么必要了。</p>
<p><strong>2、Sentinel 隔离策略</strong><br><strong>Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能</strong>。这样的隔离非常轻量级，仅限制对某个资源调用的并发数，而不是显式地去创建线程池，所以 overhead 比较小，但是效果不错。并且结合基于响应时间的熔断降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，影响整个系统。而 Hystrix 的信号量隔离比较简单，无法对慢调用自动进行降级，只能等待客户端自己超时，因此仍然可能会出现级联阻塞的情况。</p>
<h3 id="熔断降级对比"><a href="#熔断降级对比" class="headerlink" title="熔断降级对比"></a>熔断降级对比</h3><p>Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式（Circuit Breaker Pattern）。Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后才启发性地恢复。上面提到过，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。</p>
<h3 id="实时指标统计实现对比"><a href="#实时指标统计实现对比" class="headerlink" title="实时指标统计实现对比"></a>实时指标统计实现对比</h3><p>Hystrix 和 Sentinel 的实时指标数据统计实现都是基于<strong>滑动窗口</strong>的。</p>
<ul>
<li>Hystrix 1.5 之前的版本是通过环形数组实现的滑动窗口，通过锁配合 CAS 的操作对每个桶的统计信息进行更新。Hystrix 1.5 开始对实时指标统计的实现进行了重构，将指标统计数据结构抽象成了响应式流（reactive stream）的形式，方便消费者去利用指标信息。同时底层改造成了基于 RxJava 的事件驱动模式，在服务调用成功&#x2F;失败&#x2F;超时的时候发布相应的事件，通过一系列的变换和聚合最终得到实时的指标统计数据流，可以被熔断器或 Dashboard 消费。</li>
<li>Sentinel 目前抽象出了 Metric 指标统计接口，底层可以有不同的实现，目前默认的实现是基于 <strong>LeapArray</strong> 的滑动窗口，后续根据需要可能会引入 <strong>reactive</strong> <strong>stream</strong> 等实现。</li>
</ul>
<h2 id="Sentinel-的特色"><a href="#Sentinel-的特色" class="headerlink" title="Sentinel 的特色"></a>Sentinel 的特色</h2><p>除了之前提到的两者的共同特性之外，Sentinel 还提供以下的特色功能：</p>
<h3 id="轻量级、高性能"><a href="#轻量级、高性能" class="headerlink" title="轻量级、高性能"></a>轻量级、高性能</h3><p>Sentinel 作为一个功能完备的高可用流量管控组件，其核心 sentinel-core 没有任何多余依赖，打包后只有不到 200 KB，非常轻量级。开发者可以放心地引入 sentinel-core 而不需担心依赖问题。同时，Sentinel 提供了多种扩展点，用户可以很方便地根据需求去进行扩展，并且无缝地切合到 Sentinel 中。<br>引入 Sentinel 带来的性能损耗非常小。只有在业务单机量级超过 25W QPS 的时候才会有一些显著的影响（5% - 10% 左右），单机 QPS 不太大的时候损耗几乎可以忽略不计。</p>
<h3 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h3><p>Sentinel 可以针对不同的调用关系，以不同的运行指标（如 QPS、并发调用数、系统负载等）为基准，对资源调用进行流量控制，将随机的请求调整成合适的形状。<br>Sentinel 支持多样化的流量整形策略，在 QPS 过高的时候可以自动将流量调整成合适的形状。常用的有：</p>
<ul>
<li><strong>直接拒绝模式</strong>：即超出的请求直接拒绝。</li>
<li><strong>慢启动预热模式</strong>：当流量激增的时候，控制流量通过的速率，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648092157855-7f16f5f1-5859-492a-a1d7-69930c547e0d.png#clientId=u54d46c2c-7e67-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=489&id=u578fce8b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=489&originWidth=567&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=51718&status=done&style=none&taskId=u3c1a7e4a-7ab0-47e5-8d25-9fb6ec48922&title=&width=567" alt="image.png"></p>
<ul>
<li><strong>匀速器模式</strong>：利用 Leaky Bucket 算法实现的匀速模式，严格控制了请求通过的时间间隔，同时堆积的请求将会排队，超过超时时长的请求直接被拒绝。</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648092917274-de7029ed-78a7-4cb3-bc71-dcc1720e7946.png#clientId=u54d46c2c-7e67-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=422&id=ubf8b4131&margin=%5Bobject%20Object%5D&name=image.png&originHeight=422&originWidth=1250&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=44005&status=done&style=none&taskId=u9a4683b1-92c9-4729-903e-f542bb03a88&title=&width=1250" alt="image.png"></p>
<p>Sentinel 还支持基于调用关系的限流，包括基于调用方限流、基于调用链入口限流、关联流量限流等，依托于 Sentinel 强大的调用链路统计信息，可以提供精准的不同维度的限流。<br>目前 Sentinel 对异步调用链路的支持还不是很好，后续版本会着重改善支持异步调用。</p>
<h3 id="系统负载保护"><a href="#系统负载保护" class="headerlink" title="系统负载保护"></a>系统负载保护</h3><p>Sentinel 对系统的维度提供保护，负载保护算法借鉴了 TCP BBR 的思想。当系统负载较高的时候，如果仍持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648093267714-9c7a3d8a-ff3e-4362-9ad1-e5beffc6102e.png#clientId=u54d46c2c-7e67-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=137&id=u35838e37&margin=%5Bobject%20Object%5D&name=image.png&originHeight=137&originWidth=871&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=25235&status=done&style=none&taskId=u648a729d-1288-4672-8778-80df67c9e60&title=&width=871" alt="image.png"></p>
<h3 id="实时监控与控制面板"><a href="#实时监控与控制面板" class="headerlink" title="实时监控与控制面板"></a>实时监控与控制面板</h3><p>Sentinel 提供 HTTP API 用于获取实时的监控信息，如调用链路统计信息、簇点信息、规则信息等。如果用户正在使用 Spring Boot&#x2F;Spring Cloud 并使用了 Sentinel Spring Cloud Starter，还可以方便地通过其暴露的 Actuator Endpoint 来获取运行时的一些信息，如动态规则等。未来 Sentinel 还会支持标准化的指标监控 API，可以方便地整合各种监控系统和可视化系统，如 Prometheus、Grafana 等。</p>
<p>Sentinel 控制台（Dashboard）提供了机器发现、配置规则、查看实时监控、查看调用链路信息等功能，使得用户可以非常方便地去查看监控和进行配置。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648093287021-622cf832-4136-4de2-8609-2cabcdb832ff.png#clientId=u54d46c2c-7e67-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=1586&id=ua3d1786b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1586&originWidth=2428&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=367092&status=done&style=none&taskId=uc321d861-3fa3-4b4f-81d9-6c47b351213&title=&width=2428" alt="image.png"></p>
<h3 id="生态"><a href="#生态" class="headerlink" title="生态"></a>生态</h3><p>Sentinel 目前已经针对 Servlet、Dubbo、Spring Boot&#x2F;Spring Cloud、gRPC 等进行了适配，用户只需引入相应依赖并进行简单配置即可非常方便地享受 Sentinel 的高可用流量防护能力。未来 Sentinel 还会对更多常用框架进行适配，并且会为 Service Mesh 提供集群流量防护的能力。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后用表格来进行对比</p>
<table><thead><tr>
<th></th>
<th>Sentinel</th>
<th>Hystrix</th>
</tr>
</thead><tbody><tr>
<td>隔离策略</td>
<td>基于并发数</td>
<td>线程池隔离&#x2F;信号量隔离</td>
</tr>
<tr>
<td>熔断降级策略</td>
<td>基于响应时间或失败比率</td>
<td>基于失败比率</td>
</tr>
<tr>
<td>实时指标实现</td>
<td>滑动窗口</td>
<td>滑动窗口（基于 RxJava）</td>
</tr>
<tr>
<td>规则配置</td>
<td>支持多种数据源</td>
<td>支持多种数据源</td>
</tr>
<tr>
<td>扩展性</td>
<td>多个扩展点</td>
<td>插件的形式</td>
</tr>
<tr>
<td>基于注解的支持</td>
<td>即将发布</td>
<td>支持</td>
</tr>
<tr>
<td>调用链路信息</td>
<td>支持同步调用</td>
<td>不支持</td>
</tr>
<tr>
<td>限流</td>
<td>基于 QPS &#x2F; 并发数，支持基于调用关系的限流</td>
<td>不支持</td>
</tr>
<tr>
<td>流量整形</td>
<td>支持慢启动、匀速器模式</td>
<td>不支持</td>
</tr>
<tr>
<td>系统负载保护</td>
<td>支持</td>
<td>不支持</td>
</tr>
<tr>
<td>实时监控 API</td>
<td>各式各样</td>
<td>较为简单</td>
</tr>
<tr>
<td>控制台</td>
<td>开箱即用，可配置规则、查看秒级监控、机器发现等</td>
<td>不完善</td>
</tr>
<tr>
<td>常见框架的适配</td>
<td>Servlet、Spring Cloud、Dubbo、gRPC 等</td>
<td>Servlet、Spring Cloud Netflix</td>
</tr>
</tbody></table>]]></content>
      <categories>
        <category>stability</category>
      </categories>
      <tags>
        <tag>Stability</tag>
        <tag>Sentinel</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Service Mesh概述</title>
    <url>/article/cncf/service-mesh/</url>
    <content><![CDATA[<blockquote>
<p>关于 ServiceMesh 相关知识和进展，推荐资深大牛敖小剑的相关文章 <a href="https://skyao.io/">https://skyao.io/</a><br>ServiceMesh 的社区网站 <a href="http://www.servicemesher.com/">http://www.servicemesher.com/</a><br>最近蚂蚁金服开源了分布式框架 SOFA，项目地址 <a href="https://github.com/alipay/">Alipay</a>，具体文档可见 <a href="http://www.sofastack.tech/">Sofa</a><br>关于 Sofa Mesh, 暂时未开源，相关选型介绍可见 <a href="https://skyao.io/publication/service-mesh-explore/">Sofa Mesh</a></p>
</blockquote>
<h2 id="一、-Service-Mesh-概念与定义"><a href="#一、-Service-Mesh-概念与定义" class="headerlink" title="一、 Service Mesh 概念与定义"></a>一、 Service Mesh 概念与定义</h2><p>这个概念首先由 Linkerd 的团队提出，其官方定义是:</p>
<blockquote>
<p>A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.</p>
</blockquote>
<p>总结就是：</p>
<ol>
<li>服务网格是一个基础设施层</li>
<li>实现服务间请求的可靠传递、轻量级的网络代理</li>
<li>对应用与开发者透明</li>
</ol>
<p>故事的开始是微服务的出现与普及，很多大型单个应用程序可能由数百个服务组成，且每项服务可能有数千个实例，这些实例都是不断变化的。一旦实例状态变化，如 offline 变成 online 等，调度程序都需要进行动态调度。运行期间，这些服务之间的通信非常复杂，但这些通信却是每个应用的普遍需要的基础部分。因此将该部分抽象出来，形成服务网格，从而提供服务间可靠与高性能的通信服务。</p>
<h2 id="二、-Service-Mesh-解决的问题"><a href="#二、-Service-Mesh-解决的问题" class="headerlink" title="二、 Service Mesh 解决的问题"></a>二、 Service Mesh 解决的问题</h2><p>一个应用被拆分成了多个微服务，每个微服务又进行分布式部署，人工手动部署的话肯定是没人愿意的。因此 Docker 和 Kubernetes 等工具就出现了，实现了方便快捷将一个微服务应用成功部署。这些工具实现了整个部署过程的标准化。<br>一个服务产生价值的过程是在其运行期间与其他服务配合完成的，那么这个配合过程是否也能标准化呢？正如前文所述，运行期间，服务的状态与能力都是会变化的，为了能让应用稳定运行，这就需要每个服务都具备负载均衡、检测、通信可靠、安全、日志等能力。显然这些功能可以被抽成库，实现复用，比如谷歌的 Stubby、Netflix 的 HYstrix、Twitter 的 Finagle 等，提供了在运行期间服务之间的统一操作。其实这些库就是 service mesh。<br>库方式的 service mesh 存在许多缺点，如以下几点：</p>
<ul>
<li>与服务耦合，主要会有代码入侵和升级难的问题。 首先，代码入侵。开发者需要了解如何使用这些 SDK 并完成相应的非业务代码。 其次，升级难。库的更新会要求服务也更新，但出于对应用稳定性的考虑，或重新部署比较麻烦，开发者更新都比较谨慎，库的兼容性问题就出现了。</li>
<li>依赖冲突。比如两个库都用到了 fastjson，但由于依赖版本的不同，maven 最近原则选择了其中一个版本，那就可能导致另一个库在执行时出现 NoSuchMethod 等错误，就需要手动解决冲突。</li>
<li>无法跨语言。如果多语言支持代价很大，甚至可能需要重新开发一套。</li>
<li>应用开发和服务运维界线不清。故障时，应用开发者往往需要自行定位问题，无法由库的开发者统一对库进行监控与运维，等等。</li>
<li>另外一个办法就是代理，用另一个标准化服务代理当前服务就完美的解决了上述问题。这个代理服务分布式部署在每个服务所在的机子上，对原来形态各样服务的监控和负载均衡等操作，现在全部可通过对统一的代理服务的特定接口进行操作。</li>
</ul>
<p>由上，service mesh 实现了服务之间操作的标准化，实现了运行期的服务治理，让服务开发者回归业务开发与维护。</p>
<h2 id="三、-Service-mesh-的出现过程"><a href="#三、-Service-mesh-的出现过程" class="headerlink" title="三、 Service mesh 的出现过程"></a>三、 Service mesh 的出现过程</h2><p>如图所示，服务与服务直接交互转变成了 service mesh 代理。<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112385-fc700969-b005-425d-aae3-0b2ceb00bb76.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7e36bab6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=541&originWidth=1403&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=253614&status=done&style=none&taskId=ua5d4ae73-de0e-4c51-83e1-02938969425&title=" alt="image.png"><br>这个过程中，还经历了如下几个阶段：</p>
<ol>
<li>主机之间直接相连<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112203-d17b8f25-e7db-4d72-af1e-45ef950f40eb.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uc5118911&margin=%5Bobject%20Object%5D&name=image.png&originHeight=209&originWidth=575&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=15468&status=done&style=none&taskId=u30594fea-0893-4d9b-9fce-b0d32ef7a34&title=" alt="image.png"></li>
<li>网络层实现通信控制，解决数据包顺序等问题<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112212-a312154f-8cb3-4a2f-9f23-0f08fa845050.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua9da18a4&margin=%5Bobject%20Object%5D&name=image.png&originHeight=357&originWidth=589&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=30427&status=done&style=none&taskId=u9cae802b-c0c1-458b-bcd6-f6c594c3f8a&title=" alt="image.png"></li>
<li>集成到应用程序内部的流量控制<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112236-9e23ea34-94c7-4501-a6ea-142d9036c19a.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1e57ed0e&margin=%5Bobject%20Object%5D&name=image.png&originHeight=345&originWidth=569&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=36040&status=done&style=none&taskId=ue6caaa64-bef6-4731-ab58-04387e41c17&title=" alt="image.png"></li>
<li>解耦到应用程序外部的流量控制<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112249-e8e36f33-5386-4f84-9005-b018bc2cc82c.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ucca8000b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=555&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=34428&status=done&style=none&taskId=u5da3ddef-224d-4187-977f-dd811e6dba7&title=" alt="image.png"></li>
<li>应用程序的中集成服务发现和断路器<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595112968-a0087002-9923-49f4-aa64-4198e3a2bb4b.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u73746e35&margin=%5Bobject%20Object%5D&name=image.png&originHeight=408&originWidth=513&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=40501&status=done&style=none&taskId=ua94ad967-0e6e-4587-8517-f01ff678ed4&title=" alt="image.png"></li>
<li>专门用于服务发现和断路器的软件包&#x2F;库。缺点是与服务耦合<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595113042-10cbfc0f-f816-47c6-b524-705641f61670.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7baa58b6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=401&originWidth=505&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=36493&status=done&style=none&taskId=uc7f88b83-5b91-46bc-8f64-21a9bb3673c&title=" alt="image.png"></li>
<li>服务发现和断路器开源软件，如 Netflix OSS、Spring Cloud 等<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595114038-06a4204c-1583-4aaa-9d4e-2d0ddb02ae59.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u764a9bda&margin=%5Bobject%20Object%5D&name=image.png&originHeight=409&originWidth=515&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=41853&status=done&style=none&taskId=ud39898ce-b77c-4b4d-b497-4b8dc8eab0d&title=" alt="image.png"></li>
<li>微服务代理 service mesh 出现，图中 sidecar 的中文是边车，就是吃鸡里面三个轮子的那种摩托车。这里就是一个代理服务。<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595114050-de1524ef-9150-48a8-af87-94d21a39c0a2.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua3296fc0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=418&originWidth=655&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=58365&status=done&style=none&taskId=ud1beeab8-5000-47a6-8ae6-d8079110607&title=" alt="image.png"></li>
</ol>
<p>每个阶段详细解释可阅读 <a href="http://philcalcado.com/2017/08/03/pattern_service_mesh.html">Pattern: Service Mesh</a>这篇文章。</p>
<h2 id="四、-Service-mesh-代表产品"><a href="#四、-Service-mesh-代表产品" class="headerlink" title="四、 Service mesh 代表产品"></a>四、 Service mesh 代表产品</h2><p>Service Mesh 的代表产品主要有 Linkerd、Envoy、 Istio 和 Conduit。<br>Buoyant 公司给出了 service mesh 的定义，并发布第一个产品化的 Service Mesh Linkerd。2016 年 1 月 15 号，发布 0.0.7 版本，2017 年 4 月发布 1.0 版本，并加入了 CNCF。现在已经到 1.4.3 版本。 2016 年 9 月 Lyft 发布 service mesh 产品 Envoy。</p>
<p>按理 Linkerd 可能会是该领域的领头羊，只是在 2017 年 5 月，Google 和 IBM 等大佬公司们联合开发了 Istio，0.1 版本 release。目前最新版本是 0.8.0。其中，Istio 将 Lyft 开发的 Envoy 作为其数据面板部分。三大巨头合作后，相比 Linkerd 新增了服务控制相关的控制面板，功能强大。Isotio 发展迅速。而 Linkerd 却发展趋势急剧下降。2017 年 11 月 Linkerd 就提出了和 Istio 集成，作为数据面板替换掉 Envoy。不过 Envoy 稳定发展，并没有受影响。</p>
<p>2017 年 12 月，Buoyant 提出了最新产品 Conduit，对标 Istio。但目前看来，好像还是 Istio 发展更好。下面就概述下 Istio 的架构。</p>
<h2 id="五、Istio-架构"><a href="#五、Istio-架构" class="headerlink" title="五、Istio 架构"></a>五、Istio 架构</h2><p>Service mesh 的主要目的是实现服务运行时的标准化治理。Istio 将服务的管理分为了两大部分：数据面板和控制面板。<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595114906-0c124cfe-1679-481e-bd1f-27860196480c.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u5aaba33f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=881&originWidth=1729&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=917093&status=done&style=none&taskId=uba3b778d-168f-4910-bc84-0d556eab7ea&title=" alt="image.png"><br>数据面板：就是上文中的 sidecar 部分，代理了服务的所有通信。 控制面板：运行期间的服务控制，如流量控制和配置管理等。</p>
<p>Istio 中，数据面板由 Envoy 实现。控制面板包括 Pilot,Mixer,Istio-Auth 三部分。 Envoy 的功能包括：HTTP／1.1、HTTP&#x2F;2、gRPC 和 TCP 通信；请求过滤；服务健康检查；加密与认证；日志服务；Distribution Trace 等。 Pilot：服务发现；路由；负载均衡；故障处理；规则配置。官方描述为收集与验证配置，并传递给 Istio 的其他组件。 Mixer：为了减少 envoy 与服务的耦合而存在，让服务开发者仅关系业务本身，而验证规则、服务监控规则等则分离出来放到 Mixer 中，由运维人员负责。Mixer 的功能包括：前提条件检查，比如请求的合法性验证；配额管理，如限速；监测报告，上传服务日志等。 Istio-Auth：用于保证服务与服务之间的通信安全。包括：身份认证，密钥管理，请求审核等。<img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649595114403-59448ce3-e1cd-41bd-b26e-126c99bc6aac.png#clientId=u2b29b9ab-bb64-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=328&id=u938d86b8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=655&originWidth=1024&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=160621&status=done&style=none&taskId=ue14aefa1-024d-4ed2-b74f-2d07f3f2125&title=&width=512" alt="image.png"></p>
<h2 id="六、-总结"><a href="#六、-总结" class="headerlink" title="六、 总结"></a>六、 总结</h2><p>service mesh 还是个相对较新的技术，不过已经被认为是下一代的微服务，可见该技术对于微服务的必要性。Service mesh 的最大功能在于将运行期的微服务通信，微服务管理进行标准化管理，从而简化了微服务的开发与运维。</p>
]]></content>
      <categories>
        <category>cncf</category>
      </categories>
      <tags>
        <tag>CNCF</tag>
        <tag>ServiceMesh</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell常用命令</title>
    <url>/article/shell/shell-command/</url>
    <content><![CDATA[<h3 id="find-xargs"><a href="#find-xargs" class="headerlink" title="find + xargs"></a>find + xargs</h3><p>将当前目录下.bak 的文件，移动到临时&#x2F;tmp 下面</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">find . -name &quot;*.bak&quot; | xargs -I &#39;&#123;&#125;&#39; mv &#123;&#125; &#x2F;tmp</code></pre>

<p>移动到&#x2F;tmp 临时目录下，不要使用 rm -rf 命令防止误删，其中-I ‘{}’标识占位符</p>
<h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><p>分隔字符串，排序</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">grep charles &#x2F;home&#x2F;zhangcheng.log | awk &#39;&#123;split($0,a,&quot;,&quot;);if (index(a[11],&quot;5000000000013&quot;) &gt; 0 || index(a[11],&quot;5000000000059&quot;) &gt; 0) print substr(a[8],9,16),substr(a[11],18,13)&#125;&#39; | sort | uniq</code></pre>

<p>区分奇数行和偶数行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">awk &#39;&#123;if (NR%2&#x3D;&#x3D;1) &#123;printf(&quot;%s\t&quot;,$0);&#125; else &#123;printf(&quot;%s\n&quot;,$0);&#125;&#125;&#39; diagnostic.txt</code></pre>

<h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p>sed 删除不是以^ 开始的行，并且将正则匹配的^[ ]*替换为空</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">## hmaster
  hmaster-test
##&#x2F; hmaster

xx 为上面的3行数据，输出hmaster

cat xx | sed -e &#39;&#x2F;^## &#x2F;!d&#39; | sed -e &#39;s&#x2F;^##[ ]*&#x2F;&#x2F;g&#39;

删除不带loc的行，替换[ \t]*&lt;loc&gt;为空，&lt;&#x2F;loc&gt;为空
cat sitemap.xml | sed -e &#39;&#x2F;loc&#x2F;!d;s&#x2F;[ \t]*&lt;loc&gt;&#x2F;&#x2F;g;s&#x2F;&lt;\&#x2F;loc&gt;&#x2F;&#x2F;g&#39;</code></pre>

<h3 id="nc"><a href="#nc" class="headerlink" title="nc"></a>nc</h3><p>判断段是否开启</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">nc -vuz 192.168.99.100 2818

found 0 associations
found 1 connections:
1:	flags&#x3D;82&lt;CONNECTED,PREFERRED&gt;
	outif (null)
	src 192.168.99.1 port 53888
	dst 192.168.99.100 port 2818
	rank info not available

Connection to 192.168.99.100 port 2818 [udp&#x2F;rmlnk] succeeded!</code></pre>

<p>连接某个端口，类似 telnet，nc 127.0.0.1 12201</p>
<p>查找 java maven 版本差异<br><a href="https://www.alicharles.com/article/jar-diff/">https://www.alicharles.com/article/jar-diff/</a></p>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis（五）线程模型</title>
    <url>/article/redis/redis-thread-model/</url>
    <content><![CDATA[<h1 id="一、Redis-有多快？"><a href="#一、Redis-有多快？" class="headerlink" title="一、Redis 有多快？"></a>一、Redis 有多快？</h1><p>Redis 是基于内存运行的高性能 K-V 数据库，官方提供的测试报告是单机可以支持约 10w&#x2F;s 的 QPS<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780707278-e20636e0-ebfa-40c3-8f71-64535ead4337.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=453&id=ufd62af17&margin=%5Bobject%20Object%5D&name=image.png&originHeight=453&originWidth=754&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=80647&status=done&style=none&taskId=ud8e8b5e1-4735-4254-b416-c9d4c4bb91f&title=&width=754" alt="image.png"></p>
<h1 id="二、Redis-为什么这么快？"><a href="#二、Redis-为什么这么快？" class="headerlink" title="二、Redis 为什么这么快？"></a>二、Redis 为什么这么快？</h1><p>（1）完全基于内存，数据存在内存中，绝大部分请求是纯粹的内存操作，非常快速，跟传统的磁盘文件数据存储相比，避免了通过磁盘 IO 读取到内存这部分的开销。<br>（2）数据结构简单，对数据操作也简单。Redis 中的数据结构是专门进行设计的，每种数据结构都有一种或多种数据结构来支持。Redis 正是依赖这些灵活的数据结构，来提升读取和写入的性能。<br>（3）采用单线程，省去了很多上下文切换的时间以及 CPU 消耗，不存在竞争条件，不用去考虑各种锁的问题，不存在加锁释放锁操作，也不会出现死锁而导致的性能消耗。<br>（4）使用基于 IO 多路复用机制的线程模型，可以处理并发的链接。<br>Redis 基于 Reactor 模式开发了自己的网络事件处理器，这个处理器被称为文件事件处理器 file event handler。由于这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型，但是它采用 IO 多路复用机制同时监听多个 Socket，并根据 Socket 上的事件来选择对应的事件处理器进行处理。文件事件处理器的结构包含 4 个部分，线程模型如下图：</p>
<blockquote>
<p>多个 Socket<br>IO 多路复用程序<br>文件事件分派器<br>事件处理器（命令请求处理器、命令回复处理器、连接应答处理器）</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780718941-c3cd8bfa-de3a-45a8-a964-0d0d76db7078.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=728&id=u2a474487&margin=%5Bobject%20Object%5D&name=image.png&originHeight=728&originWidth=1200&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=262381&status=done&style=none&taskId=u7ef7b622-16d1-4dbb-9ca7-a01e5b79759&title=&width=1200" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780739146-4ee96535-2123-4803-a72b-836ce89e31b1.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=581&id=ude40546d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=581&originWidth=1497&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=332800&status=done&style=none&taskId=u29caaf54-2bb2-4536-b04f-8bebbb6439b&title=&width=1497" alt="image.png"><br>多个 Socket 可能会产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。<br>Redis 客户端对服务端的每次调用都经历了发送命令，执行命令，返回结果三个过程。其中执行命令阶段，由于 Redis 是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个队列中，然后逐个被执行。并且多个客户端发送的命令的执行顺序是不确定的。但是可以确定的是不会有两条命令被同时执行，不会产生并发问题，这就是 Redis 的单线程基本模型。</p>
<blockquote>
<p>多路 I&#x2F;O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I&#x2F;O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I&#x2F;O 事件时，就从阻塞态中唤醒，然后程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且依次顺序<typo id="typo-1053" data-origin="的" ignoretag="true">的</typo>处理就绪的流，这种做法就避免了大量的无用操作。<br>这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I&#x2F;O 复用技术可以让单个线程高效的处理多个客户端的网络 IO 连接请求（尽量减少网络 IO 的时间消耗）</p>
</blockquote>
<p>（5）Redis 直接自己构建了 VM 机制 ，避免调用系统函数的时候，浪费时间去移动和请求</p>
<h1 id="三、为什么-Redis-是单线程？"><a href="#三、为什么-Redis-是单线程？" class="headerlink" title="三、为什么 Redis 是单线程？"></a>三、为什么 Redis 是单线程？</h1><p>这里我们强调的单线程，指的是网络请求模块使用一个线程来处理，即一个线程处理所有网络请求，其他模块仍用了多个线程。<br>那为什么使用单线程呢？官方答案是：因为 CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。<br>但是，我们使用单线程的方式是无法发挥多核 CPU 性能，不过我们可以通过在单机开多个 Redis 实例来解决这个问题</p>
<h1 id="四、Redis6-0-的多线程？"><a href="#四、Redis6-0-的多线程？" class="headerlink" title="四、Redis6.0 的多线程？"></a>四、Redis6.0 的多线程？</h1><p>1、Redis6.0 之前为什么一直不使用多线程？<br>Redis 使用单线程的可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。<br>2、Redis6.0 为什么要引入多线程呢？<br>因为 Redis 的瓶颈不在内存，而是在网络 I&#x2F;O 模块带来 CPU 的耗时，所以 Redis6.0 的多线程是用来处理网络 I&#x2F;O 这部分，充分利用 CPU 资源，减少网络 I&#x2F;O 阻塞带来的性能损耗。<br>3、Redis6.0 如何开启多线程？<br>默认情况下 Redis 是关闭多线程的，可以在 conf 文件进行配置开启：<br>io-threads-do-reads yes<br>io-threads 线程数<br>“##”官方建议的线程数设置：4 核的机器建议设置为 2 或 3 个线程，8 核的建议设置为 6 个线程，线程数一定要小于机器核数，尽量不超过 8 个。<br><strong>4、多线程模式下，是否<typo id="typo-1890" data-origin="存在" ignoretag="true">存在</typo>线程并发安全问题？</strong><br>如图，一次 redis 请求，要建立连接，然后获取操作的命令，然后执行命令，最后将响应的结果写到 socket 上。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780790005-7feadbae-0815-49ce-82e5-652dde050548.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=312&id=u457be10d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=312&originWidth=646&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=76699&status=done&style=none&taskId=u3cfd9d4b-b573-440e-9586-facf1e78153&title=&width=646" alt="image.png"><br>在 redis 的多线程模式下，获取、解析命令，以及输出结果<typo id="typo-1988" data-origin="着" ignoretag="true">着</typo>两个过程，可以配置成多线程执行的，因为它毕竟是我们定位到的主要耗时点，但是命令的执行，也就是内存操作，依然是单线程运行的。所以，Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行，也就不存在并发安全问题。</p>
<h3 id="Redis-为什么用单线程"><a href="#Redis-为什么用单线程" class="headerlink" title="Redis 为什么用单线程"></a>Redis 为什么用单线程</h3><h4 id="Redis-单线程指的什么"><a href="#Redis-单线程指的什么" class="headerlink" title="Redis 单线程指的什么"></a>Redis 单线程指的什么</h4><p>Redis 是单线程，主要是指 <strong>Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程</strong>。 但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执 行的。</p>
<h4 id="多线程提高系统吞吐率"><a href="#多线程提高系统吞吐率" class="headerlink" title="多线程提高系统吞吐率"></a>多线程提高系统吞吐率</h4><p>日常写程序时，我们经常会听到一种说法：“<strong>使用多线程，可以增加系统吞吐率，或是可 以增加系统扩展性</strong>。”的确，对于一个多线程的系统来说，在有合理的资源分配的情况 下，可以增加系统中处理请求操作的资源实体，进而提升系统能够同时处理的请求数，即 吞吐率。下面的左图是我们采用多线程时所期待的结果。<br>但是，请你注意，通常情况下，<strong>在我们采用多线程后，如果没有良好的系统设计，实际得 到的结果，其实是右图所展示的那样。我们刚开始增加线程数时，系统吞吐率会增加，但 是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780858223-46203b98-d9af-429f-a64c-624e63499ea5.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=458&id=u80f98f2a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=458&originWidth=1100&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=102025&status=done&style=none&taskId=u8d644773-1c56-48fb-8946-3700895ff40&title=&width=1100" alt="image.png"></p>
<h4 id="多线程共享资源"><a href="#多线程共享资源" class="headerlink" title="多线程共享资源"></a>多线程共享资源</h4><p>为什么会出现这种情况呢？一个关键的瓶颈在于,系统中通常会存在被多线程同时访问的 共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共 享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开 销。</p>
<h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p>拿 Redis 来说，Redis 有 List 的数据类型，并提供出队（LPOP） 和入队（LPUSH）操作。假设 Redis 采用多线程设计，如下图所示，现在有两个线程 A 和 B，线程 A 对一个 List 做 LPUSH 操作，并对队列长度加 1。同时，线程 B 对该 List 执行 LPOP 操作，并对队列长度减 1。为了保证队列长度的正确性，Redis 需要让线程 A 和 B 的 LPUSH 和 LPOP 串行执行，这样一来，Redis 可以无误地记录它们对 List 长度的修 改。否则，我们可能就会得到错误的长度结果。这就是多线程编程模式面临的共享资源的 并发访问控制问题。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648780868651-b8a7673b-5b94-4382-ab1f-cc726493e5d1.png#clientId=u6b789c17-dfc4-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=725&id=ue4264bb6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=725&originWidth=1064&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=124110&status=done&style=none&taskId=u84165546-44e8-493f-920f-78d94a38511&title=&width=1064" alt="image.png"><br>并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，比如说，<strong>只是 简单地采用一个粗粒度互斥锁，就会出现不理想的结果：即使增加了线程，大部分线程也 在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增 加。甚至减少，因为多线程会存在多线程频繁切换开销</strong><br>采用<strong>多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统 代码的易调试性和可维护性</strong>。为了避免这些问题，Redis 直接采用了单线程模式。</p>
<h4 id="Redis-使用单线程小结"><a href="#Redis-使用单线程小结" class="headerlink" title="Redis 使用单线程小结"></a>Redis 使用单线程小结</h4><ul>
<li>使用多线程，可以增加系统吞吐率，如果没有良好的系统设计，实际得 到的结果我们刚开始增加线程数时，系统吞吐率会增加，但 是，再进一步增加线程时，系统吞吐率就增长迟缓了，有时甚至还会出现下降的情况</li>
<li>出现上述情况的原因是 redis 在使用多线程时同样会存在多线程同时访问的 共享资源的问题，为了保证共 享资源的正确性，就需要有额外的机制进行保证。</li>
<li>在没有良好的系统设计，这个额外的机制，就会带来额外的开 销。这种开销有时不但无法增加系统吞吐率，反而会降低系统吞吐率</li>
<li>多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统 代码的易调试性和可维护性</li>
</ul>
<h3 id="单线程-Redis-为什么快"><a href="#单线程-Redis-为什么快" class="headerlink" title="单线程 Redis 为什么快"></a>单线程 Redis 为什么快</h3><h4 id="多路复用-IO"><a href="#多路复用-IO" class="headerlink" title="多路复用 IO"></a>多路复用 IO</h4>]]></content>
      <categories>
        <category>cache</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell（二）分支和主干jar差异</title>
    <url>/article/shell/jar-diff/</url>
    <content><![CDATA[<h2 id="分支和主干-jar-差异"><a href="#分支和主干-jar-差异" class="headerlink" title="分支和主干 jar 差异"></a>分支和主干 jar 差异</h2><p>脚本文件见附件，可以快速了解本次分支修改，便于发布前比对当前的开发分支和主干 jar 差异情况。 将 jar-diff.sh 放在根目录文件下面。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">#!&#x2F;bin&#x2F;bash

# 获取当前git分支
CURRENT_BRANCH&#x3D;&#96;sh -c &#39;git branch --no-color 2&gt;&#x2F;dev&#x2F;null&#39; | sed -e &#39;&#x2F;^[^*]&#x2F;d&#39; -e &#39;s&#x2F;* \(.*\)&#x2F;\1&#x2F;&#39;&#96;

if [ -n &quot;$CURRENT_BRANCH&quot; ]; then
# 当前分支不为空
APP_NAME&#x3D;&#96;cat .git&#x2F;config | grep url | sed &#39;s&#x2F;.*\&#x2F;\(.*\)\.git&#x2F;\1&#x2F;g&#39;&#96;
echo &quot;app name : &quot;$&#123;APP_NAME&#125;
GIT_PATH&#x3D;&#96;cat .git&#x2F;config | grep url | sed &#39;s&#x2F;.*\url &#x3D; \(.*\)&#x2F;\1&#x2F;g&#39;&#96;
echo &quot;git path : &quot;$&#123;GIT_PATH&#125;
echo &quot;current branch : &quot;$&#123;CURRENT_BRANCH&#125;&quot;\n&quot;

if [ &quot;$CURRENT_BRANCH&quot;x &#x3D; &quot;master&quot;x ]; then
echo &quot;please change branch to diff jar. &quot;
exit -1
fi

# 比较当前分支和master分支的jar的差异
MASTER_FILE_NAME&#x3D;&quot;&#x2F;tmp&#x2F;&quot;$&#123;APP_NAME&#125;&quot;_master&quot;
BRANCH_FILE_NAME&#x3D;&quot;&#x2F;tmp&#x2F;&quot;$&#123;APP_NAME&#125;&quot;_&quot;&#96;echo $&#123;CURRENT_BRANCH&#125; | sed -e &#39;s&#x2F;\&#x2F;&#x2F;\_&#x2F;g&#39;&#96;
# 未清洗的临时文件
MASTER_FILE_TMP&#x3D;$&#123;MASTER_FILE_NAME&#125;&quot;_tmp&quot;
BRANCH_FILE_TMP&#x3D;$&#123;BRANCH_FILE_NAME&#125;&quot;_tmp&quot;

# 编译生成工程依赖的jar列表
git pull
mvn clean install -Dmaven.test.skip &gt; &#x2F;dev&#x2F;null
mvn dependency:list&gt;$&#123;BRANCH_FILE_TMP&#125;

# 校验分支编译是否成功
if cat $&#123;BRANCH_FILE_TMP&#125; | grep &quot;BUILD SUCCESS&quot;&gt;&#x2F;dev&#x2F;null
then
echo $&#123;CURRENT_BRANCH&#125; &quot; build success&quot;
# 清洗jar列表数据
cat $&#123;BRANCH_FILE_TMP&#125; | grep &quot;\[INFO\]    &quot; | grep compile | sed &#39;s&#x2F;\[INFO\]    &#x2F;&#x2F;g&#39; | \
sed &#39;s&#x2F;:compile&#x2F;&#x2F;g&#39; | sort | uniq &gt; $&#123;BRANCH_FILE_NAME&#125;
else
echo $&#123;CURRENT_BRANCH&#125; &quot;build failure\n&quot;
exit -1;
fi

# 切换到主干分支
sleep 2s
git checkout master
git pull
mvn clean install -Dmaven.test.skip &gt; &#x2F;dev&#x2F;null
mvn dependency:list&gt;$&#123;MASTER_FILE_TMP&#125;

# 校验主干编译是否成功
if cat $&#123;MASTER_FILE_TMP&#125; | grep &quot;BUILD SUCCESS&quot;&gt;&#x2F;dev&#x2F;null
then
echo &quot;master build success\n&quot;
# 清洗jar列表数据
cat $&#123;MASTER_FILE_TMP&#125; | grep &quot;\[INFO\]    &quot; | grep compile | sed &#39;s&#x2F;\[INFO\]    &#x2F;&#x2F;g&#39; | \
sed &#39;s&#x2F;:compile&#x2F;&#x2F;g&#39; | sort | uniq &gt; $&#123;MASTER_FILE_NAME&#125;

# 输出分支的差异(不输出公共行)
# 去掉--suppress-common-lines，可显示所有依赖的jar列表
diff -y -W 150 --suppress-common-lines $&#123;BRANCH_FILE_NAME&#125; $&#123;MASTER_FILE_NAME&#125; | tee diff.txt
echo &quot;\n&quot;

else
echo &quot;master build failure\n&quot;
exit -1;
fi

# 切换回原来的分支
sleep 2s
git checkout $&#123;CURRENT_BRANCH&#125;
else
echo &quot;not a git repository. &quot;
fi</code></pre>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Spock 基于BDD测试</title>
    <url>/article/spock/</url>
    <content><![CDATA[<blockquote>
<p>Spock 测试框架基于 Groovy 并吸收了 Junit、TestNG、Mockito 等测试框架的优点。 Spock 编写的单元测试层次清晰，代码量少，可读性好，Groovy 最终会编译为 class 文件，支持各种集成开发环境（eclipse，Intellij Ieda）， 尤其是 Intellij idea 已经集成支持 Groovy 的插件，也支持 maven-surefire-plugin、jacoco 等 maven 插件。</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649583018000-a421eec4-e140-4dc7-b441-18d73fd6dee8.png#clientId=u8bb98b5c-a46d-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua18a10b6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=338&originWidth=694&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=33048&status=done&style=none&taskId=u04c672d8-be2e-4f25-909f-4cd0c0965e0&title=" alt="image.png"><br><a href="http://spockframework.org/">Spock 官网</a>，必读书籍《Java Testing with Spock》, 如要速成只需要阅读以下两篇文章</p>
<ul>
<li><a href="https://learnxinyminutes.com/docs/groovy/">5 分钟入门 Groovy</a></li>
<li><a href="https://semaphoreci.com/community/tutorials/stubbing-and-mocking-in-java-with-the-spock-testing-framework">一篇非常详尽的介绍 Spock 的英文教程</a></li>
</ul>
<h2 id="Spock-实例"><a href="#Spock-实例" class="headerlink" title="Spock 实例"></a>Spock 实例</h2><p>大多数遵循 TDD 的 Java 开发者均会使用 mockito 或 powermock，但 mockito 和 powermock 均包含了许多样本代码，导致测试代码变得冗长而难以维护。 在测试中引入 Groovy&#x2F;Spock 后，我完全被它们吸引，并转向使用 Groovy&#x2F;Spock 来替代原有的测试框架。</p>
<h3 id="定义-Domain，DAO，Service"><a href="#定义-Domain，DAO，Service" class="headerlink" title="定义 Domain，DAO，Service"></a>定义 Domain，DAO，Service</h3><p>下面将围绕一个简单例子来讲解 Groovy&#x2F;Spock，例子中将包含一个 service 类，负责处理 domain 对象，以及一个数据访问层。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class User &#123;
    private int id;
    private String name;
    private int age;
    &#x2F;&#x2F; Accessors omitted
&#125;

public interface UserDao &#123;
    public User get(int id);
&#125;

public class UserService &#123;
    private UserDao userDao;

    public UserService(UserDao userDao) &#123;
        this.userDao &#x3D; userDao;
    &#125;

    public User findUser(int id)&#123;
        return userDao.get(id);;
    &#125;
&#125;</code></pre>

<h3 id="采用-Groovy-x2F-Spock-针对-UserService-编写测试"><a href="#采用-Groovy-x2F-Spock-针对-UserService-编写测试" class="headerlink" title="采用 Groovy&#x2F;Spock 针对 UserService 编写测试"></a>采用 Groovy&#x2F;Spock 针对 UserService 编写测试</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">class UserTest extends Specification &#123;
    UserDao dao &#x3D; Mock(UserDao)
    UserService service &#x3D; new UserService(dao)

    def &quot;it gets a user by id&quot;() &#123;
        given:
        1 * dao.get(id) &gt;&gt; new User(id: id, name: name, age: age)

        when:
        def result &#x3D; service.findUser(id)

        then:
        result.id &#x3D;&#x3D; userId
        result.name &#x3D;&#x3D; userName
        result.age &#x3D;&#x3D; userAge

        where:
        id | name      | age || userId | userName  | userAge
        1  | &quot;zhang&quot;   | 18  || 1      | &quot;zhang&quot;   | 18
        2  | &quot;charles&quot; | 28  || 2      | &quot;charles&quot; | 28
    &#125;
&#125;</code></pre>

<p>在 Spock 中创建 mock 对象非常容易，只需要使用 Mock(Class)这样的语句即可。如上所述，mock 后的 DAO 对象被传入 userService 中。 Setup 方法会在每个测试方法运行前被执行。<br>Spock 是一个 BDD 测试框架，因此对于 Spock 中涉及的 given，when，then 样式最简单的理解就是：</p>
<ul>
<li>given 给定一些条件</li>
<li>when 当执行一些操作时</li>
<li>then 期望得到某个结果</li>
<li>where 多套测试数据的检测和验证<table><thead><tr>
<th><strong>分块</strong></th>
<th><strong>替换</strong></th>
<th><strong>功能</strong></th>
<th><strong>限制</strong></th>
</tr>
</thead><tbody><tr>
<td>given</td>
<td>setup</td>
<td>初始化函数，mock</td>
<td>非必要</td>
</tr>
<tr>
<td>when</td>
<td>expect</td>
<td>执行待测试的函数</td>
<td>when 和 then 必须对成出现</td>
</tr>
<tr>
<td>then</td>
<td>expect</td>
<td>验证函数结果</td>
<td>when 和 then 可以被 expect 替换</td>
</tr>
<tr>
<td>where</td>
<td></td>
<td>多套测试数据的检测</td>
<td>spock 的特性功能</td>
</tr>
<tr>
<td>and</td>
<td></td>
<td>对其余块进行分隔说明</td>
<td>非必要</td>
</tr>
</tbody></table></li>
</ul>
<p>如上述测试方法中 Given，给定 id&#x3D;1，即测试的变量；而在 When 中则是被测试方法，如在上述代码中调用 findUser()； Then 中则是断言，即检查被测试方法的输出结果。<br>上述 Then 中的第一句语句虽然看上去可怕，但实际上却非常容易理解：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">1 * dao.get(id) &gt;&gt; new User(id:id, name:&quot;James&quot;, age:27)</code></pre>

<p>该行表示了对于 mock 对象 dao 的期望值，即期望调用 dao.get()方法 1 次，而“&gt;&gt;”是 spock 的特色，表示“then return”含义。 因此该句翻译过来的意思是：期望调用 1 次 dao.get()方法，当执行该方法后，请返回一个新的 User 对象。 此外在构造方法中使用具名参数也是 groovy 的另一特点。Then 中剩余的代码对 result 对象进行检查。<br>由此测试代码驱动产生的产品代码非常简单，如下所示：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public class UserService &#123;
    private UserDao userDao;

    public UserService(UserDao userDao) &#123;
        this.userDao &#x3D; userDao;
    &#125;

    public User findUser(int id)&#123;
        return userDao.get(id);
    &#125;
&#125;</code></pre>

<p>接下来实现创建用户功能，在 UserService 中添加如下代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void createUser(User user) &#123;
    &#x2F;&#x2F; check name
    &#x2F;&#x2F; if exists, throw exception
    &#x2F;&#x2F; if !exists, create user
&#125;</code></pre>

<p>在 UserDao 中添加如下方法：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public User findByName(String name);
public void createUser(User user);</code></pre>

<p>相应的测试方法如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">def &quot;it saves a new user&quot;() &#123;
    given:
        def user &#x3D; new User(id: 1, name: &#39;James&#39;, age:27)

    when:
        service.createUser(user)

    then:
        1 * dao.findByName(user.name) &gt;&gt; null

    then:
        1 * dao.createUser(user)
&#125;</code></pre>

<p>在上述代码中出现了两处 Then，这是因为当所有断言放在一个 then 块中，Spock 会认为这些断言是同时发生的。 如果期望断言按顺序执行，则需要将断言分割到多个 then 块中，spock 会按顺序执行断言。 如上述所示，首先需要判断用户是否存在，然后再去创建用户。产品代码实现如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void createUser(User user)&#123;
    User existing &#x3D; userDao.findByName(user.getName());

    if(existing &#x3D;&#x3D; null)&#123;
        userDao.createUser(user);
    &#125;
&#125;</code></pre>

<p>上述代码针对用户不存在场景，而对于用户存在的场景，测试代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">def &quot;it fails to create a user because one already exists with that name&quot;() &#123;
    given:
        def user &#x3D; new User(id: 1, name: &#39;James&#39;, age:27)

    when:
        service.createUser(user)

    then:
        1 * dao.findByName(user.name) &gt;&gt; user

    then:
        0 * dao.createUser(user)

    then:
        def exception &#x3D; thrown(RuntimeException)
        exception.message &#x3D;&#x3D; &quot;User with name $&#123;user.name&#125; already exists!&quot;
&#125;</code></pre>

<p>上述代码当调用 findByName 时，返回一个存在的用户，然后不调用 createUser()，第三个 Then 块捕获方法抛出的异常。 注意 groovy 拥有一个称之为 GStrings 的特征，该特征可以在引用的字符串中插入参数，如${user.name}。相应产品代码如下：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public void createUser(User user)&#123;
    User existing &#x3D; userDao.findByName(user.getName());

    if(existing &#x3D;&#x3D; null)&#123;
        userDao.createUser(user);
    &#125; else&#123;
        throw new RuntimeException(String.format(&quot;User with name %s already exists!&quot;, user.getName()));
    &#125;
&#125;</code></pre>

<h3 id="结合-PowerMock-mock-静态方法"><a href="#结合-PowerMock-mock-静态方法" class="headerlink" title="结合 PowerMock mock 静态方法"></a>结合 PowerMock mock 静态方法</h3><pre class="line-numbers language-java" data-language="java"><code class="language-java">@RunWith(PowerMockRunner)
@PowerMockRunnerDelegate(Sputnik)
@PowerMockIgnore(&#123;
        &quot;javax.net.ssl.*&quot;,
        &quot;javax.management.*&quot;,
        &quot;com.sun.crypto.*&quot;,
        &quot;javax.crypto.*&quot;&#125;)
@PrepareForTest([BizEngine.class])
class BaseSimpleTest extends Specification &#123;
    def &quot;test engine&quot;() &#123;
        setup:
        BizEngine mockStatic &#x3D; PowerMockito.mock(BizEngine.class)
        Whitebox.setInternalState(BizEngine.class, &quot;bizEngine&quot;, mockStatic)

        when:
        Mockito.when(mockStatic.getPoint(Point.class, null, null)).thenReturn(new LocationPoint())

        then:
        println &quot;test engine end&quot;
    &#125;
&#125;</code></pre>

<h2 id="其他提示"><a href="#其他提示" class="headerlink" title="其他提示"></a>其他提示</h2><ul>
<li>最重要也是最容易被遗忘的提示，阅读 spock 文档</li>
<li>可以命名 spock 块，例如将 given 命名为“Some variables”，有助于开发者在测试代码中更加清楚的表达含义</li>
<li>当对 mock 对象方法调用次数不关心时，可以使用_ * mock.method()</li>
<li>在 then 块中可使用下划线来通配方法及类，例如，0 _ mock._ 表示期望 mock 对象的任何方法都未被调用，或 0 _ . 表示期望任何对象的任何方法都未被调用</li>
<li>通常按 given，when，then 编写测试，但实际上从 when 开始编写测试会更加容易发现测试需要的 given 和测试的输出结果(then)</li>
<li>expect 块对于测试不需要对 mock 对象进行断言的简单方法更加有效</li>
<li>当对于传递给 mock 对象的参数不关注时，可以使用通配符参数</li>
<li>拥抱 groovy 闭包 Embrace groovy closures! They can be you’re best friend in assertions!</li>
<li>当希望在整个测试类中只运行一次，可以复写 setupSpec 和 cleanupSpec</li>
</ul>
]]></content>
      <categories>
        <category>spock</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spock</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell（一）常用命令</title>
    <url>/article/shell/shell-command/</url>
    <content><![CDATA[<h3 id="find-xargs"><a href="#find-xargs" class="headerlink" title="find + xargs"></a>find + xargs</h3><p>将当前目录下.bak 的文件，移动到临时&#x2F;tmp 下面</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">find . -name &quot;*.bak&quot; | xargs -I &#39;&#123;&#125;&#39; mv &#123;&#125; &#x2F;tmp</code></pre>

<p>移动到&#x2F;tmp 临时目录下，不要使用 rm -rf 命令防止误删，其中-I ‘{}’标识占位符</p>
<h3 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h3><p>分隔字符串，排序</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">grep charles &#x2F;home&#x2F;zhangcheng.log | awk &#39;&#123;split($0,a,&quot;,&quot;);if (index(a[11],&quot;5000000000013&quot;) &gt; 0 || index(a[11],&quot;5000000000059&quot;) &gt; 0) print substr(a[8],9,16),substr(a[11],18,13)&#125;&#39; | sort | uniq</code></pre>

<p>区分奇数行和偶数行</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">awk &#39;&#123;if (NR%2&#x3D;&#x3D;1) &#123;printf(&quot;%s\t&quot;,$0);&#125; else &#123;printf(&quot;%s\n&quot;,$0);&#125;&#125;&#39; diagnostic.txt</code></pre>

<h3 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h3><p>sed 删除不是以^ 开始的行，并且将正则匹配的^[ ]*替换为空</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">## hmaster
  hmaster-test
##&#x2F; hmaster

xx 为上面的3行数据，输出hmaster

cat xx | sed -e &#39;&#x2F;^## &#x2F;!d&#39; | sed -e &#39;s&#x2F;^##[ ]*&#x2F;&#x2F;g&#39;

删除不带loc的行，替换[ \t]*&lt;loc&gt;为空，&lt;&#x2F;loc&gt;为空
cat sitemap.xml | sed -e &#39;&#x2F;loc&#x2F;!d;s&#x2F;[ \t]*&lt;loc&gt;&#x2F;&#x2F;g;s&#x2F;&lt;\&#x2F;loc&gt;&#x2F;&#x2F;g&#39;</code></pre>

<h3 id="nc"><a href="#nc" class="headerlink" title="nc"></a>nc</h3><p>判断段是否开启</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">nc -vuz 192.168.99.100 2818

found 0 associations
found 1 connections:
1:	flags&#x3D;82&lt;CONNECTED,PREFERRED&gt;
	outif (null)
	src 192.168.99.1 port 53888
	dst 192.168.99.100 port 2818
	rank info not available

Connection to 192.168.99.100 port 2818 [udp&#x2F;rmlnk] succeeded!</code></pre>

<p>连接某个端口，类似 telnet，nc 127.0.0.1 12201</p>
<p>查找 java maven 版本差异<br><a href="https://www.alicharles.com/article/jar-diff/">https://www.alicharles.com/article/jar-diff/</a></p>
]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Bean的生命周期</title>
    <url>/article/spring/spring-bean-lifecycle/</url>
    <content><![CDATA[<p>要彻底搞清楚 Spring 的生命周期，首先要把这四个阶段牢牢记住。实例化和属性赋值对应<strong>构造方法</strong>和<strong>setter 方法</strong>的注入，初始化和销毁是用户能自定义扩展的两个阶段。</p>
<ol>
<li>实例化-&gt;Instantiation</li>
<li>属性赋值-&gt;Populate</li>
<li>初始化-&gt;Initialization</li>
<li>销毁-&gt;Destruction</li>
</ol>
<p>实例化 -&gt; 属性赋值 -&gt; 初始化 -&gt; 销毁</p>
<h2 id="1、影响多个-Bean-的接口"><a href="#1、影响多个-Bean-的接口" class="headerlink" title="1、影响多个 Bean 的接口"></a>1、影响多个 Bean 的接口</h2><p>实现了这些接口的 Bean 会切入到多个 Bean 的生命周期中。正因为如此，这些接口的功能非常强大，Spring 内部扩展也经常使用这些接口，例如自动注入以及 AOP 的实现都和他们有关。</p>
<ul>
<li>InstantiationAwareBeanPostProcessor</li>
<li>BeanPostProcessor</li>
</ul>
<p>这两兄弟可能是 Spring 扩展中最重要的两个接口！InstantiationAwareBeanPostProcessor 作用于实例化阶段的前后，BeanPostProcessor 作用于初始化阶段的前后。如图：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1649521466271-63972c73-03ba-4d2e-a4a0-69cdd8a179c6.png#clientId=u437c72b1-3eed-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=354&id=u714da385&margin=%5Bobject%20Object%5D&name=image.png&originHeight=472&originWidth=562&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=47256&status=done&style=none&taskId=uef4c9713-7b08-483d-860f-b78efc2a756&title=&width=422" alt="image.png"><br><strong>其中 InstantiationAwareBeanPostProcessor 继承自 BeanPostProcessor 是 Spring 非常重要的拓展接口</strong><br>1、postProcessBeforeInstantiation 调用时机为 bean 实例化(Instantiation)之前 如果返回了 bean 实例, 则会替代原来正常通过 target bean 生成的 bean 的流程. 典型的例如 aop 返回 proxy 对象. 此时 bean 的执行流程将会缩短, 只会执行 BeanPostProcessor#postProcessAfterInitialization 接口完成初始化。<br>2、postProcessAfterInstantiation 调用时机为 bean 实例化(Instantiation)之后和任何初始化(Initialization)之前。<br>3、postProcessProperties 调用时机为 postProcessAfterInstantiation 执行之后并返回 true, 返回的 PropertyValues 将作用于给定 bean 属性赋值。Spring 5.1 之后出现以替换@Deprecated 标注的 postProcessPropertyValues<br>4、postProcessPropertyValues 已经被标注@Deprecated，后续将会被 postProcessProperties 取代。<br>进入执行流程<br>步骤 1 ：InstantiationAwareBeanPostProcessor 的触发入口 AbstractAutowireCapableBeanFactory #createBean 开始。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
* Central method of this class: creates a bean instance,
* populates the bean instance, applies post-processors, etc.
*
* @see #doCreateBean
*&#x2F;
@Override
protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args)
    throws BeanCreationException &#123;

    &#x2F;&#x2F; 省略......
    try &#123;
        &#x2F;**
        * 注释1. InstantiationAwareBeanPostProcessor#postProcessorsBeforeInstantiation触发入口
        *&#x2F;
        Object bean &#x3D; resolveBeforeInstantiation(beanName, mbdToUse);
        if (bean !&#x3D; null) &#123;
            return bean;
        &#125;
    &#125; catch (Throwable ex) &#123;
        throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName,
                                        &quot;BeanPostProcessor before instantiation of bean failed&quot;, ex);
    &#125;
    &#x2F;&#x2F; 省略......
    try &#123;
        &#x2F;**
        * 注释2. postProcessAfterInstantiation、postProcessProperties 触发入口
        * 主要逻辑都在doCreateBean()方法中，
        * 方法中包含了实例化、属性赋值、初始化过程。逻辑很清晰
        * 这三个方法与三个生命周期阶段一一对应，非常重要
        *&#x2F;
        Object beanInstance &#x3D; doCreateBean(beanName, mbdToUse, args);
        if (logger.isTraceEnabled()) &#123;
            logger.trace(&quot;Finished creating instance of bean &#39;&quot; + beanName + &quot;&#39;&quot;);
        &#125;
        return beanInstance;
    &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123;
        &#x2F;&#x2F; A previously detected exception with proper bean creation context already,
        &#x2F;&#x2F; or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry.
        throw ex;
    &#125; catch (Throwable ex) &#123;
        throw new BeanCreationException(
            mbdToUse.getResourceDescription(), beanName, &quot;Unexpected exception during bean creation&quot;, ex);
    &#125;
&#125;</code></pre>

<p>步骤 2：注释 1 中，跟进 AbstractAutowireCapableBeanFactory#resolveBeforeInstantiation， 分析 postProcessorsBeforeInstantiation 执行时机 ：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** 注释1 代码进入后执行InstantiationAwareBeanPostProcessor#ostProcessBeforeInstantiation方法*&#x2F;
@Nullable
protected Object resolveBeforeInstantiation(String beanName, RootBeanDefinition mbd) &#123;
    Object bean &#x3D; null;
    if (!Boolean.FALSE.equals(mbd.beforeInstantiationResolved)) &#123;
        &#x2F;&#x2F; Make sure bean class is actually resolved at this point.
        if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;
            Class&lt;?&gt; targetType &#x3D; determineTargetType(beanName, mbd);
            if (targetType !&#x3D; null) &#123;
                &#x2F;**
                * 注释3：回调beanPostProcessorsBeforeInstantiation实例化，如果返回bean非null则直接执行
                * 不为空null就直接返回了而不执行doCreateBean()方法了，而该方法是创建Bean对象的方法
                * beanPostProcessorsAfterInitialization进行实例初始化
                *&#x2F;
                bean &#x3D; applyBeanPostProcessorsBeforeInstantiation(targetType, beanName);
                if (bean !&#x3D; null) &#123;
                    &#x2F;** 注释4 *&#x2F;
                    bean &#x3D; applyBeanPostProcessorsAfterInitialization(bean, beanName);
                &#125;
            &#125;
        &#125;
        mbd.beforeInstantiationResolved &#x3D; (bean !&#x3D; null);
    &#125;
    return bean;
&#125;

&#x2F;**注释3 代码跟进*&#x2F;
@Nullable
protected Object applyBeanPostProcessorsBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) &#123;
    for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;
        if (bp instanceof InstantiationAwareBeanPostProcessor) &#123;
            &#x2F;**
            * 注释5：只要其中一个postProcessBeforeInstantiation返回实例bean即结束回调，
            * 这个bean将会直接返回给bean容器管理
            *&#x2F;
            InstantiationAwareBeanPostProcessor ibp &#x3D; (InstantiationAwareBeanPostProcessor) bp;
            Object result &#x3D; ibp.postProcessBeforeInstantiation(beanClass, beanName);
            if (result !&#x3D; null) &#123;
                return result;
            &#125;
        &#125;
    &#125;
    return null;
&#125;

&#x2F;** 注释4 代码跟进*&#x2F;
@Override
public Object applyBeanPostProcessorsAfterInitialization(Object existingBean, String beanName)
    throws BeansException &#123;
    Object result &#x3D; existingBean;
    for (BeanPostProcessor processor : getBeanPostProcessors()) &#123;
        &#x2F;**注释6 *&#x2F;
        Object current &#x3D; processor.postProcessAfterInitialization(result, beanName);
        if (current &#x3D;&#x3D; null) &#123;
            return result;
        &#125;
        result &#x3D; current;
    &#125;
    return result;
&#125;</code></pre>

<p>可以看到，postProcessBeforeInstantiation 在 doCreateBean 之前调用，也就是在 bean 实例化之前调用的，英文源码注释解释道该方法的返回值会替换原本的 Bean 作为代理，这也是 Aop 等功能实现的关键点。</p>
<blockquote>
<p>代码说明：</p>
</blockquote>
<ol>
<li>注释 5 中，如果 postProcessBeforeInstantiation 方法返回了 Object 是 null;那么就直接返回，调用 doCreateBean 方法();</li>
<li>注释 5 中，如果 postProcessBeforeInstantiation 返回不为 null;说明修改了 bean 对象;然后这个时候就立马执行 postProcessAfterInitialization 方法(注意这个是初始化之后的方法,也就是通过这个方法实例化了之后，直接执行初始化之后的方法;中间的实例化之后 和 初始化之前都不执行);</li>
<li>注释 6 中，在调用 postProcessAfterInitialization 方法时候如果返回 null;那么就直接返回，调用 doCreateBean 方法();(初始化之后的方法返回了 null,那就需要调用 doCreateBean 生成对象了)</li>
<li>在调用 postProcessAfterInitialization 时返回不为 null;那这个 bean 就直接返回给 ioc 容器了初始化之后的操作是这里面最后一个方法了；</li>
</ol>
<p>步骤 2：跟进 AbstractAutowireCapableBeanFactory#doCreateBean， 分析 postProcessAfterInstantiation、postProcessProperties 执行时机 ：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args)
    throws BeanCreationException &#123;

    BeanWrapper instanceWrapper &#x3D; null;
    if (mbd.isSingleton()) &#123;
        instanceWrapper &#x3D; this.factoryBeanInstanceCache.remove(beanName);
    &#125;
    if (instanceWrapper &#x3D;&#x3D; null) &#123;
        &#x2F;**  注释7 实例化阶段！ *&#x2F;
        instanceWrapper &#x3D; createBeanInstance(beanName, mbd, args);
    &#125;
    &#x2F;&#x2F; 省略......
    &#x2F;&#x2F; Initialize the bean instance.
    Object exposedObject &#x3D; bean;
    try &#123;
        &#x2F;** 注释8 依据bean definition 完成bean属性赋值 *&#x2F;
        populateBean(beanName, mbd, instanceWrapper);
        &#x2F;** 注释9 执行bean初始化 *&#x2F;
        exposedObject &#x3D; initializeBean(beanName, exposedObject, mbd);
    &#125; catch (Throwable ex) &#123;
        if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123;
            throw (BeanCreationException) ex;
        &#125; else &#123;
            throw new BeanCreationException(
                mbd.getResourceDescription(), beanName, &quot;Initialization of bean failed&quot;, ex);
        &#125;
    &#125;
    &#x2F;&#x2F; 省略......
    return exposedObject;
&#125;</code></pre>

<blockquote>
<p>这三个方法与三个生命周期阶段一一对应，非常重要</p>
<ol>
<li>createBeanInstance() -&gt; 实例化（注释 7）</li>
<li>populateBean() -&gt; 属性赋值（注释 8）</li>
<li>initializeBean() -&gt; 初始化（注释 9）</li>
</ol>
</blockquote>
<p>注释 8 中，继续跟进 AbstractAutowireCapableBeanFactory#populateBean</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123;

    &#x2F;&#x2F; Give any InstantiationAwareBeanPostProcessors the opportunity to modify the
    &#x2F;&#x2F; state of the bean before properties are set. This can be used, for example,
    &#x2F;&#x2F; to support styles of field injection.
    boolean continueWithPropertyPopulation &#x3D; true;
    &#x2F;&#x2F; InstantiationAwareBeanPostProcessor#postProcessAfterInstantiation()
    &#x2F;**
    * 注释10：满足两个要求：
    * 1、BeanDefinition为应用程序bean，而非基础框架bean信息。
    * 2、注册过InstantiationAwareBeanPostProcessor类型接口，上文有提到这个标志位。
    * 3、注册了多个接口时，只要其中一个postProcessAfterInstantiation返回false，即停止后续执行。
    *&#x2F;
    if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123;
        for (BeanPostProcessor bp : getBeanPostProcessors()) &#123;
            if (bp instanceof InstantiationAwareBeanPostProcessor) &#123;
                InstantiationAwareBeanPostProcessor ibp &#x3D; (InstantiationAwareBeanPostProcessor) bp;
                if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123;
                    continueWithPropertyPopulation &#x3D; false;
                    break;
                &#125;
            &#125;
        &#125;
    &#125;

    &#x2F;&#x2F; 忽略后续的属性赋值操作代码
&#125;</code></pre>

<p>可以看到该方法在属性赋值方法内，但是在真正执行赋值操作之前。其返回值为 boolean，返回 false 时可以阻断属性赋值阶段（continueWithPropertyPopulation &#x3D; false;）<br>关于 BeanPostProcessor 执行阶段的源码穿插在下文 Aware 接口的调用时机分析中，因为部分 Aware 功能的就是通过他实现的!只需要先记住 BeanPostProcessor 在初始化前后调用就可以了。</p>
<h2 id="2、只调用一次的接口"><a href="#2、只调用一次的接口" class="headerlink" title="2、只调用一次的接口"></a>2、只调用一次的接口</h2><p>这一大类接口的特点是功能丰富，常用于用户自定义扩展。<br>第二大类中又可以分为两类：</p>
<ol>
<li>Aware 类型的接口</li>
<li>生命周期接口</li>
</ol>
<p>Aware 类型的接口的作用就是让我们能够拿到 Spring 容器中的一些资源。基本都能够见名知意，Aware 之前的名字就是可以拿到什么资源，例如 BeanNameAware 可以拿到 BeanName，以此类推。调用时机需要注意：所有的 Aware 方法都是在初始化阶段之前调用的！<br>Aware 接口众多，这里同样通过分类的方式帮助大家记忆。<br>Aware 接口具体可以分为两组，至于为什么这么分，详见下面的源码分析。如下排列顺序同样也是 Aware 接口的执行顺序，能够见名知意的接口不再解释。<br><strong>Aware Group1</strong></p>
<ol>
<li>BeanNameAware</li>
<li>BeanClassLoaderAware</li>
<li>BeanFactoryAware</li>
</ol>
<p><strong>Aware Group2</strong></p>
<ol>
<li>EnvironmentAware</li>
<li>EmbeddedValueResolverAware (这个知道的人可能不多，实现该接口能够获取 Spring EL 解析器，用户的自定义注解需要支持 spel 表达式的时候可以使用，非常方便。)</li>
<li>ApplicationContextAware(ResourceLoaderAware\ApplicationEventPublisherAware\MessageSourceAware) 这几个接口可能让人有点懵，实际上这几个接口可以一起记，其返回值实质上都是当前的 ApplicationContext 对象，因为 ApplicationContext 是一个复合接口，如下：</li>
</ol>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123;
&#125;</code></pre>

<p>这里涉及常问的问题，<strong>ApplicationContext 和 BeanFactory 的区别</strong>，可以从 ApplicationContext 继承的这几个接口入手，除去 BeanFactory 相关的两个接口（ListableBeanFactory, HierarchicalBeanFactory）就是 ApplicationContext 独有的功能，这里不详细说明。</p>
<h3 id="Aware-调用时机源码分析"><a href="#Aware-调用时机源码分析" class="headerlink" title="Aware 调用时机源码分析"></a>Aware 调用时机源码分析</h3><p>详情如下，忽略了部分无关代码。代码位置就是我们上文提到的 initializeBean 方法详情，这也说明了 Aware 都是在初始化阶段之前调用的！</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 注释9 代码进入 调用初始化阶段
protected Object initializeBean(final String beanName, final Object bean, @Nullable RootBeanDefinition mbd) &#123;

    &#x2F;&#x2F; 注释11 这里调用的是Group1中的三个Bean开头的Aware
    invokeAwareMethods(beanName, bean);

    Object wrappedBean &#x3D; bean;

    &#x2F;**
    * 这里调用的是Group2中的几个Aware，
    * 而实质上这里就是前面所说的BeanPostProcessor的调用点！
    * 也就是说与Group1中的Aware不同，这里是通过BeanPostProcessor（ApplicationContextAwareProcessor）实现的。
    *&#x2F;
    &#x2F;** 注释12 *&#x2F;
    wrappedBean &#x3D; applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);
    &#x2F;** 注释13 下文即将介绍的InitializingBean调用点 *&#x2F;
    invokeInitMethods(beanName, wrappedBean, mbd);
    &#x2F;** 注释14 BeanPostProcessor的另一个调用点*&#x2F;
    wrappedBean &#x3D; applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);

    return wrappedBean;
&#125;

&#x2F;**注释11 代码进入 *&#x2F;
private void invokeAwareMethods(final String beanName, final Object bean) &#123;
    if (bean instanceof Aware) &#123;
        if (bean instanceof BeanNameAware) &#123;
            ((BeanNameAware) bean).setBeanName(beanName);
        &#125;
        if (bean instanceof BeanClassLoaderAware) &#123;
            ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader());
        &#125;
        if (bean instanceof BeanFactoryAware) &#123;
            ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this);
        &#125;
    &#125;
&#125;</code></pre>

<p>注释 11 代码进入后，可以看到并不是所有的 Aware 接口都使用同样的方式调用。Bean××Aware 都是在代码中直接调用的。<br>而 ApplicationContext 相关的 Aware 都是通过 applyBeanPostProcessorsBeforeInitialization 来调用 BeanPostProcessor#postProcessBeforeInitialization()实现的。感兴趣的可以自己看一下 ApplicationContextAwareProcessor 这个类的源码，就是判断当前创建的 Bean 是否实现了相关的 Aware 方法，如果实现了会调用回调方法将资源传递给 Bean。<br>至于 Spring 为什么这么实现，应该没什么特殊的考量。也许和 Spring 的版本升级有关。基于对修改关闭，对扩展开放的原则，Spring 对一些新的 Aware 采用了扩展的方式添加。<br>BeanPostProcessor 的调用时机也能在这里体现，包围住 invokeInitMethods 方法，也就说明了在初始化阶段的前后执行。<br>关于 Aware 接口的执行顺序，其实只需要记住第一组在第二组执行之前就行了。每组中各个 Aware 方法的调用顺序其实没有必要记，有需要的时候点进源码一看便知。</p>
<h3 id="简单的两个生命周期接口"><a href="#简单的两个生命周期接口" class="headerlink" title="简单的两个生命周期接口"></a>简单的两个生命周期接口</h3><p>至于剩下的两个生命周期接口就很简单了，实例化和属性赋值都是 Spring 帮助我们做的，能够自己实现的有初始化和销毁两个生命周期阶段。</p>
<ol>
<li>InitializingBean 对应生命周期的初始化阶段，在上面源码的 invokeInitMethods(beanName, wrappedBean, mbd);方法中调用。<br>有一点需要注意，因为 Aware 方法都是执行在初始化方法之前，所以可以在初始化方法中放心大胆的使用 Aware 接口获取的资源，这也是我们自定义扩展 Spring 的常用方式。<br>除了实现 InitializingBean 接口之外还能通过注解或者 xml 配置的方式指定初始化方法，至于这几种定义方式的调用顺序其实没有必要记。因为这几个方法对应的都是同一个生命周期，只是实现方式不同，我们一般只采用其中一种方式。</li>
<li>DisposableBean 类似于 InitializingBean，对应生命周期的销毁阶段，以 ConfigurableApplicationContext#close()方法作为入口，实现是通过循环取所有实现了 DisposableBean 接口的 Bean 然后调用其 destroy()方法 。感兴趣的可以自行跟一下源码。</li>
</ol>
<p>扩展阅读: BeanPostProcessor 注册时机与执行顺序</p>
<h3 id="注册时机"><a href="#注册时机" class="headerlink" title="注册时机"></a>注册时机</h3><p>我们知道 BeanPostProcessor 也会注册为 Bean，那么 Spring 是如何保证 BeanPostProcessor 在我们的业务 Bean 之前初始化完成呢？请看我们熟悉的 refresh()方法的源码，省略部分无关代码：</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">@Override
public void refresh() throws BeansException, IllegalStateException &#123;
    synchronized (this.startupShutdownMonitor) &#123;

        try &#123;
            &#x2F;&#x2F; Allows post-processing of the bean factory in context subclasses.
            postProcessBeanFactory(beanFactory);

            &#x2F;&#x2F; Invoke factory processors registered as beans in the context.
            invokeBeanFactoryPostProcessors(beanFactory);

            &#x2F;&#x2F; Register bean processors that intercept bean creation.
            &#x2F;&#x2F; 所有BeanPostProcesser初始化的调用点
            registerBeanPostProcessors(beanFactory);

            &#x2F;&#x2F; Initialize message source for this context.
            initMessageSource();

            &#x2F;&#x2F; Initialize event multicaster for this context.
            initApplicationEventMulticaster();

            &#x2F;&#x2F; Initialize other special beans in specific context subclasses.
            onRefresh();

            &#x2F;&#x2F; Check for listener beans and register them.
            registerListeners();

            &#x2F;&#x2F; Instantiate all remaining (non-lazy-init) singletons.
            &#x2F;&#x2F; 所有单例非懒加载Bean的调用点
            finishBeanFactoryInitialization(beanFactory);

            &#x2F;&#x2F; Last step: publish corresponding event.
            finishRefresh();
        &#125;

&#125;</code></pre>

<p>可以看出，Spring 是先执行 registerBeanPostProcessors()进行 BeanPostProcessors 的注册，然后再执行 finishBeanFactoryInitialization 初始化我们的单例非懒加载的 Bean。</p>
<h3 id="执行顺序"><a href="#执行顺序" class="headerlink" title="执行顺序"></a>执行顺序</h3><p>BeanPostProcessor 有很多个，而且每个 BeanPostProcessor 都影响多个 Bean，其执行顺序至关重要，必须能够控制其执行顺序才行。关于执行顺序这里需要引入两个排序相关的接口：PriorityOrdered、Ordered</p>
<ul>
<li>PriorityOrdered 是一等公民，首先被执行，PriorityOrdered 公民之间通过接口返回值排序</li>
<li>Ordered 是二等公民，然后执行，Ordered 公民之间通过接口返回值排序</li>
<li>都没有实现是三等公民，最后执行</li>
</ul>
<p>在以下源码中，可以很清晰的看到 Spring 注册各种类型 BeanPostProcessor 的逻辑，根据实现不同排序接口进行分组。优先级高的先加入，优先级低的后加入。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.
&#x2F;&#x2F; 首先，加入实现了PriorityOrdered接口的BeanPostProcessors，顺便根据PriorityOrdered排了序
String[] postProcessorNames &#x3D;
    beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
for (String ppName : postProcessorNames) &#123;
    if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;
        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
        processedBeans.add(ppName);
    &#125;
&#125;
sortPostProcessors(currentRegistryProcessors, beanFactory);
registryProcessors.addAll(currentRegistryProcessors);
invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
currentRegistryProcessors.clear();

&#x2F;&#x2F; Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.
&#x2F;&#x2F; 然后，加入实现了Ordered接口的BeanPostProcessors，顺便根据Ordered排了序
postProcessorNames &#x3D; beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
for (String ppName : postProcessorNames) &#123;
    if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;
        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
        processedBeans.add(ppName);
    &#125;
&#125;
sortPostProcessors(currentRegistryProcessors, beanFactory);
registryProcessors.addAll(currentRegistryProcessors);
invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
currentRegistryProcessors.clear();

&#x2F;&#x2F; Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.
&#x2F;&#x2F; 最后加入其他常规的BeanPostProcessors
boolean reiterate &#x3D; true;
while (reiterate) &#123;
    reiterate &#x3D; false;
    postProcessorNames &#x3D; beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
    for (String ppName : postProcessorNames) &#123;
        if (!processedBeans.contains(ppName)) &#123;
            currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
            processedBeans.add(ppName);
            reiterate &#x3D; true;
        &#125;
    &#125;
    sortPostProcessors(currentRegistryProcessors, beanFactory);
    registryProcessors.addAll(currentRegistryProcessors);
    invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
    currentRegistryProcessors.clear();
&#125;&#x2F;&#x2F; First, invoke the BeanDefinitionRegistryPostProcessors that implement PriorityOrdered.
&#x2F;&#x2F; 首先，加入实现了PriorityOrdered接口的BeanPostProcessors，顺便根据PriorityOrdered排了序
String[] postProcessorNames &#x3D;
    beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
for (String ppName : postProcessorNames) &#123;
    if (beanFactory.isTypeMatch(ppName, PriorityOrdered.class)) &#123;
        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
        processedBeans.add(ppName);
    &#125;
&#125;
sortPostProcessors(currentRegistryProcessors, beanFactory);
registryProcessors.addAll(currentRegistryProcessors);
invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
currentRegistryProcessors.clear();

&#x2F;&#x2F; Next, invoke the BeanDefinitionRegistryPostProcessors that implement Ordered.
&#x2F;&#x2F; 然后，加入实现了Ordered接口的BeanPostProcessors，顺便根据Ordered排了序
postProcessorNames &#x3D; beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
for (String ppName : postProcessorNames) &#123;
    if (!processedBeans.contains(ppName) &amp;&amp; beanFactory.isTypeMatch(ppName, Ordered.class)) &#123;
        currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
        processedBeans.add(ppName);
    &#125;
&#125;
sortPostProcessors(currentRegistryProcessors, beanFactory);
registryProcessors.addAll(currentRegistryProcessors);
invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
currentRegistryProcessors.clear();

&#x2F;&#x2F; Finally, invoke all other BeanDefinitionRegistryPostProcessors until no further ones appear.
&#x2F;&#x2F; 最后加入其他常规的BeanPostProcessors
boolean reiterate &#x3D; true;
while (reiterate) &#123;
    reiterate &#x3D; false;
    postProcessorNames &#x3D; beanFactory.getBeanNamesForType(BeanDefinitionRegistryPostProcessor.class, true, false);
    for (String ppName : postProcessorNames) &#123;
        if (!processedBeans.contains(ppName)) &#123;
            currentRegistryProcessors.add(beanFactory.getBean(ppName, BeanDefinitionRegistryPostProcessor.class));
            processedBeans.add(ppName);
            reiterate &#x3D; true;
        &#125;
    &#125;
    sortPostProcessors(currentRegistryProcessors, beanFactory);
    registryProcessors.addAll(currentRegistryProcessors);
    invokeBeanDefinitionRegistryPostProcessors(currentRegistryProcessors, registry);
    currentRegistryProcessors.clear();
&#125;</code></pre>

<p>根据排序接口返回值排序，默认升序排序，返回值越低优先级越高。</p>
<pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;**
* Useful constant for the highest precedence value.
* @see java.lang.Integer#MIN_VALUE
*&#x2F;
int HIGHEST_PRECEDENCE &#x3D; Integer.MIN_VALUE;

&#x2F;**
* Useful constant for the lowest precedence value.
* @see java.lang.Integer#MAX_VALUE
*&#x2F;
int LOWEST_PRECEDENCE &#x3D; Integer.MAX_VALUE;&#125;</code></pre>

<p>PriorityOrdered、Ordered 接口作为 Spring 整个框架通用的排序接口，在 Spring 中应用广泛，也是非常重要的接口。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Spring Bean 的生命周期分为四个阶段和多个扩展点。扩展点又可以分为影响多个 Bean 和影响单个 Bean。整理如下：</p>
<blockquote>
<p><strong>四个阶段</strong></p>
<ul>
<li>实例化 Instantiation</li>
<li>属性赋值 Populate</li>
<li>初始化 Initialization</li>
<li>销毁 Destruction</li>
</ul>
</blockquote>
<blockquote>
<p><strong>多个扩展点</strong></p>
<ul>
<li>影响多个 Bean<ul>
<li>BeanPostProcessor</li>
<li>InstantiationAwareBeanPostProcessor</li>
</ul>
</li>
<li>影响单个 Bean<ul>
<li>Aware<ul>
<li>Aware Group1<ul>
<li>BeanNameAware</li>
<li>BeanClassLoaderAware</li>
<li>BeanFactoryAware</li>
</ul>
</li>
<li>Aware Group2<ul>
<li>EnvironmentAware</li>
<li>EmbeddedValueResolverAware</li>
<li>ApplicationContextAware(ResourceLoaderAware\ApplicationEventPublisherAware\MessageSourceAware)</li>
</ul>
</li>
</ul>
</li>
<li>生命周期<ul>
<li>InitializingBean</li>
<li>DisposableBean</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
<blockquote>
<ol>
<li>如果实现了 BeanFactoryPostProcessor 接口，那么在容器启动的时候，该接口中的 postProcessBeanFactory 方法可以修改 Bean 中元数据中的信息。该方法是在实例化对象之前执行</li>
<li>如果实现了 InstantiationAwareBeanPostProcessor 接口，那么在实例化 Bean 对象之前会调用<strong>postProcessBeforeInstantiation</strong>方法，该方法如果返回的不为 null 则会直接调用 postProcessAfterInitialization 方法，而跳过了 Bean 实例化后及初始化前的相关方法，如果返回 null 则正常流程，<strong>postProcessAfterInstantiation</strong>在实例化成功后执行，这个时候对象已经被实例化，但是该实例的属性还未被设置，都是 null。因为它的返回值是决定要不要调用 postProcessPropertyValues 方法的其中一个因素，因为还有一个因素是 mbd.getDependencyCheck()；如果该方法返回 false,并且不需要 check，那么 postProcessPropertyValues 就会被忽略不执行；如果返回 true, postProcessPropertyValues 就会被执行,<strong>postProcessPropertyValues</strong>用来修改属性，在初始化方法之前执行。</li>
<li>如果实现了 Aware 相关的结果，那么相关的 set 方法会在初始化之前执行。</li>
<li>如果实现了 BeanPostProcessor 接口，那么该接口的方法会在实例化后的初始化方法前后执行。</li>
<li>如果实现了 InitializingBean 接口则在初始化的时候执行 afterPropertiesSet</li>
<li>如果指定了 init-method 属性则在初始化的时候会执行指定的方法。</li>
<li>如果指定了@PostConstruct 则在初始化的时候会执行标注的方法。</li>
<li>到此对象创建完成</li>
<li>当对象需要销毁的时候。</li>
<li>如果实现了 DisposableBean 接口会执行 destroy 方法</li>
<li>如果指定了 destroy-method 属性则会执行指定的方法</li>
<li>如果指定了@PreDestroy 注解则会执行标注的方法</li>
</ol>
</blockquote>
<p>至此，Spring Bean 的生命周期介绍完毕。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cnblogs.com/zrtqsk/p/3735273.html">Spring Bean 的生命周期（详细）</a><br><a href="https://blog.csdn.net/qq_20021569/article/details/109178816">Spring Bean 的生命周期（Spring5）</a><br><a href="https://blog.csdn.net/riemann_/article/details/118500805">一文读懂 Spring Bean 的生命周期</a></p>
]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>常用架构分析</title>
    <url>/article/architecture/architecture/</url>
    <content><![CDATA[<h2 id="常用架构分析"><a href="#常用架构分析" class="headerlink" title="常用架构分析"></a>常用架构分析</h2><p>常用经典架构分析，了解设计思路和注意问题<br>1、<a href="https://www.alicharles.com/article/architecture/architecture-skill/">架构师技能和微服务架构图谱</a><br>2、<a href="https://www.alicharles.com/article/architecture/architecture-miaosha/">秒杀架构设计</a></p>
]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>发号器</title>
    <url>/article/id-generator/id-generator/</url>
    <content><![CDATA[<h2 id="为什么需要一个发号器"><a href="#为什么需要一个发号器" class="headerlink" title="为什么需要一个发号器"></a>为什么需要一个发号器</h2><p>在使用数据库时，表的主键经常会使用数据库的自增（auto_increment）来产生。这当然很方便也很高效。但是使用自增也会带来一些麻烦。如果从一个数据库以外的地方，也就是发号器来产生全局唯一 ID，这些问题就可以得到解决，生活就可以更美好。</p>
<ul>
<li>难以适应分片场景在采用数据库分片时，如果使用数据库自增 ID，不同分片上会产生相同的 ID。单靠 ID 无法唯一标示一个对象，还需要额外加上分片字段才行。如果需要将 ID 用于其他对象的关联时，会麻烦很多。而采用发号器生成的是全局唯一的 ID，单靠 ID 就能实现关联。同时，这也使得采用 ID 作为分片字段成为可能。</li>
<li>主备切换时数据冲突在 MySQL 集群发生主备切换时，异步复制无法确保主从完全同步。在备库开放写入后，备库上产生的自增 ID 会和尚未同步的主库上的数据冲突。这样一来，即使原来的主库恢复了，也无法重新加入集群。数据修复也变成了一件非常困难的事情。引入发号器以后，备库上插入的 ID 和原来主库上的 ID 是不会重复的。因此，未复制的新增数据和对这些新增数据的修改就不会在备库发生冲突。</li>
<li>网络异常时无法判断插入是否成功当插入记录时，如果使用数据库自增 ID，在完成插入后，才能得到产生的 ID。如果在执行语句时发生网络中断，客户端无法知道事务是否成功，即使成功，也无法再获得产生的 ID。如果使用发号器，就可以在插入之前预先产生 ID。如果碰到网络中断，可以用已经获得的 ID 去尝试查询来判断之前的插入是否成功。</li>
</ul>
<p>此外，一些业务 ID 会需要一个全局唯一的整数作为它的组成部分。其他的分布式系统可以用全局单调的唯一 ID 作为事务号。有一个现成的服务就不用各自实现了。</p>
<h2 id="发号器的必要特性"><a href="#发号器的必要特性" class="headerlink" title="发号器的必要特性"></a>发号器的必要特性</h2><p>既然叫发号器，首先就得保证 ID 的全局唯一。就是说保证无论什么情况下都不会发出重复的 ID。这看起来很简单，但是事实上，很多实现却上并没有做到这点。要真正做到全局唯一，发号器必须要实现 crash safe，并不受外部环境变化影响。</p>
<ul>
<li>crash safe 首先是 crash safe。即得保证在服务崩溃重新恢复后，不会产生已经发过的 ID。在服务彻底完蛋时，也要能够在其他地方恢复出一个一定能用的。有的实现定期保存或者异步保存已经发过的 ID。如果发生崩溃，如果直接用保存过的 ID 继续发，就会发出已经发过的号。有的实现采用 MySQL 或 Redis 来产生 ID。由于 MySQL 和 Redis 的复制本身难以保证强一致，在发生主备切换时，备机尚未完全同步的话，还是会发出重复的 ID 来。有的实现没有使用副本，单纯靠分片来实现负载均衡和高可用，这时如果某个实例完蛋了，想要重新恢复一个就没法了。</li>
<li>不受外部环境变化影响很多发号器实现是基于时间戳的。但是有些实现直接采用了机器上的时间戳作为 ID 的一部分。如果机器时间发生回跳（不要认为这不可能），就会造成 ID 重复。使用时间戳同时也对机器时间的精度有了依赖。</li>
</ul>
<p>要让发号器能真正有用，还得实现高可用，并能支撑足够大的吞吐量。不然发号器本身也会成为一个单点或瓶颈。</p>
<h2 id="如何设计发号器"><a href="#如何设计发号器" class="headerlink" title="如何设计发号器"></a>如何设计发号器</h2><p>有赞同样有对发号器的需求。经过对现有实现的考察后，我们还是打算实现一个自己的发号器，我给它起了个名字：March。我们的发号器同样要解决这些问题。</p>
<h3 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h3><p>要满足真正的全局唯一，持久化是必须的。而且持久化还必须是不会丢失的，强一致的。<br>如果发号器实现是分散在各个应用服务器上的，由于应用服务器的持久化能力是难以保证的，可靠性就会受影响。而且这样一来，每个应用服务器也要有一个终身及死后也全局唯一的 ID 作为产生的 ID 的一部分，来满足全局唯一，这就大大提高了部署和运维的门槛。所以，我们认为发号器最好还是集中式的。<br>在采用集中式的前提下，持久化的副本也是不可少的。要自己实现这样的一个持久化系统是很难的。所以，在持久化方案上，我们选择了现成的 etcd。etcd 能满足不会丢失的，多副本，强一致的全部需求。持久化就可以全部放到 etcd 中，发号器本身就可以是无状态的，这样一来，高可用的实现也会容易一些。</p>
<h3 id="是否全局单调（线上版本使用多机房，全局不再保证单调性）"><a href="#是否全局单调（线上版本使用多机房，全局不再保证单调性）" class="headerlink" title="是否全局单调（线上版本使用多机房，全局不再保证单调性）"></a>是否全局单调（线上版本使用多机房，全局不再保证单调性）</h3><p>是否全局单调其实是个权衡。在确定要高可用的前提下，全局单调和负载均衡是不可兼得的（可以想想为什么）。我们最终还是选择实现全局单调。全局单调的 ID 有额外的好处。作为主键时，可以直接代替时间字段排序。由于 MySQL 二级索引是指向主键的，使用主键排序通常可以避免排序操作，直接利用索引就能完成。另外，如果要实现一些分布式一致性系统，一个全局单调的 ID 生成器也是一个必备的组件。</p>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>由于采用了全局单调，高可用方案就只能是主备的。一个集群内，同时只能有一个实例对外提供服务。这时候就要考虑怎么实现选主和故障切换。既然我们用了 etcd，实现高可用的时候也正好可以用上它的 TTL、Watch 这些特性。然后也要能让客户端知道哪个实例才是主实例，可以自动切换访问路径。</p>
<h3 id="ID-的形式"><a href="#ID-的形式" class="headerlink" title="ID 的形式"></a>ID 的形式</h3><p>发号器产生的 ID 一般都是 64 位整数，这样对数据库比较友好，容量也能满足业务需求，不会哪天爆了。通常产生的 ID 可以分成两大类。一类是单纯的 Sequence，即一个不断递增的整数。另一类是基于 Timestamp 的，由于机器时间的精度限制，通常都会额外再加一段 Sequence。为了分布式，还经常会加上各种不同的标示实例的位。不同的实现无非就是这些东西的组合以及各段的长短的变化。有赞之前已经有了几个实现。新的发号器要落地，也得兼容现有的。所以不同的 ID 的形式还是都得支持。但是具体实现细节上，可以比原有的更进一步。</p>
<h3 id="认证和权限控制"><a href="#认证和权限控制" class="headerlink" title="认证和权限控制"></a>认证和权限控制</h3><p>使用发号器的业务方会有很多。为了信息安全，和避免相互干扰，认证和权限控制功能也有了需求。March 可以设置多个用户，为每个用户分配访问不同的发号器的权限，以及其他的创建，管理类权限。用户信息同样不能丢，所以也持久化在 etcd 中。</p>
<h3 id="通信协议"><a href="#通信协议" class="headerlink" title="通信协议"></a>通信协议</h3><p>作为一个服务，就会有和客户端交互。有交互，就要有一个协议。我们希望尽量能采用一个现成的协议。这样对实现不同语言的客户端会方便很多。同时这个协议要足够轻量高效，也能具备扩展性。我们最后选择了 Redis 协议。Redis 协议很简单，协议本身的负担小。由于是个广泛使用的东西，各种语言都有它的库。这样在实现客户端 SDK 的时候，就有了个很好的起点。现成的一些命令，如 INCR，INCRBY，GET 等本身也很适合用于发号器。在需要一些特殊的功能时，也可以自己添加新命令。高可用方面，Redis Cluster 的协议也可以用上。这样客户端的自动切换就不用自己实现了。对于服务端，好几个语言也都有现成的库。</p>
<h2 id="发号器的实现"><a href="#发号器的实现" class="headerlink" title="发号器的实现"></a>发号器的实现</h2><p>有赞的发号器 March 是用 Go 语言实现的。语言选择上其实没太大讲究。不过对于这类项目，Go 在开发效率，部署简便，和倾向低延迟的 gc 优化还是有一些优势。</p>
<h3 id="ID-生成"><a href="#ID-生成" class="headerlink" title="ID 生成"></a>ID 生成</h3><p>前面说过，发号器产生的 ID 可以分成两大类。一类是 Sequence，一类是基于 Timestamp 的。这两类有各自的实现。</p>
<ul>
<li>Sequence</li>
</ul>
<p>March 在启动时会从 etcd 中载入之前持久化的已经发过的 id 作为起点。然后执行一次持久化，将起始 id + batch 保存下来。 [ id, id + batch ) 的区间就是缓存。客户端请求时，下发的 id 都是从这个缓存中取的。同时启动一个 goroutine 来做持久化。在这个缓存的容量低于水位线（默认是 50%）时，会异步通知这个持久化 goroutine 进行持久化，将 id + batch _ 2 保存下来。此时，缓存的上界就扩容到了 id + batch _ 2，以此类推。由于持久化是异步的，所以一般情况下，并不会阻塞请求，造成请求延迟增大。但是有突发的并发时，在持久化没进行完，缓存就已经耗尽的情况下，为了保证正确性，才会发生阻塞，等待持久化完成。所以，对于高并发的应用，配置一个大的缓存区间可以获取更高的性能。比如将 batch 设为 10000，平均发出 10000 个号才需要持久化一次。备机平时是不提供服务的，在发生主备切换时，备机才会从持久化中重新载入配置。所以备机提升为主机以后，也可以保证不会发重，只是从客户端看来，会跳空一段 id。不过这也算不上什么问题。</p>
<ul>
<li>Timestamp</li>
</ul>
<p>Timestamp 类型的 ID 分成 3 段：node，timestamp，sequence。通过配置各个段的长度和偏移，以及时间戳的精度，就可以兼容各种已有的基于时间戳的发号器实现。多个请求到来时，如果 timestamp 相同，会增长 sequence。timestamp 改变时，就清零 sequence。有一点特别的地方是，我们允许 sequence 段溢出。 溢出的部分会加到 timestamp 段上去。这样即使在时间戳精度范围内 sequence 耗尽了，也不用阻塞请求。Timestamp 类型持久化的是时间，保存的是当前的 timestamp + 提前量。这里的 timestamp 是包含 sequence 溢出的部分。Timestamp 类型的持久化是定时进行的。由于已持久化的时间戳总是大于当前时间的，因此等待持久化而造成的阻塞基本上是不会发生的。March 启动时，如果获取的当前时间大于保存的时间，就使用当前时间作为起点，否则就使用已保存的时间作为起点。每次请求获取时间时也是类似。如果发现获取的时间小于已经发过的 timestamp，就继续使用当前 timestamp。这样就确保了即使机器时间跳变时，发出的 id 也是单调增长的，绝对不会重复。同时由于允许溢出，也不会因为时间回跳而阻塞。当然这种方式带来的一个影响是，如果从获取的 id 里解析出时间，可能并不是准确的时间。由于切换或溢出，看到的时间可能会提前。不过本来也不应该依赖这些细节不是么。</p>
<h3 id="高可用-1"><a href="#高可用-1" class="headerlink" title="高可用"></a>高可用</h3><p>March 的高可用是利用 etcd 的 ttl 和 watch 实现的。启动时，先尝试创建一个新的带 ttl 的 Node。如果成功，就成为了主节点；如果由于已存在而失败，就成为了备节点。</p>
<ul>
<li>主节点定时用前一次请求返回的 index 刷新 Node 的 ttl，保持自己的主节点角色。发现刷新失败时，说明主节点角色已经被抢走，从抢主节点过程重新开始。与此同时，还会等待 demote 请求。收到 demote 请求时，会等待新的主节点信息，然后将自己置为备节点。</li>
<li>备节点先查询主节点的信息。在备节点收到发号请求时，会按 Redis Cluster 协议重定向到主节点。之后就开始 Watch Node 的变化。检测到变化后，也开始抢主节点过程。</li>
</ul>
<p>这样，可以做到在主节点发生故障时，最多等待一个 ttl 就能检测到，并完成切换。而在主动切换时，结合客户端，可以做到完全无损，只有毫秒级的阻塞 s。<br>此外，每个节点都会存保存各自的带 ttl 的节点信息，同时定时刷新，用于返回给客户端集群信息。每个发号器在每次持久化时，也会携带上上一次持久化获得的 index。一旦不匹配出错，也会将自身重置为备节点。这可以避免网络堵塞或进程僵死造成原主失效而自身却不知道。在发生非预期错误时，HA goroutine 会等待 2 * ttl，以免不断出错造成死循环。此外，备节点也需要能够完成用户认证。但因为认证是不能重定向的，所以还需要检测 etcd 上的用户信息变化，重新同步用户数据。</p>
<h3 id="多机房"><a href="#多机房" class="headerlink" title="多机房"></a>多机房</h3><p>发号器多机房功能详见：发号器拆分方案</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>发号器看起来简单，但是要实现一个靠谱的，易用的，要考虑到的地方还是很多的。其实很多东西都是这样。我们还做了更多。为了更容易接入落地，我们在数据库中间件中也做了集成。配置后，执行 insert 时，会自动代入配置的自增字段和 id 值，让业务方完全无痛。</p>
]]></content>
      <categories>
        <category>id-generator</category>
      </categories>
      <tags>
        <tag>IdGenerator</tag>
      </tags>
  </entry>
  <entry>
    <title>架构（一）架构师技能和微服务架构图谱</title>
    <url>/article/architecture/architecture-skill/</url>
    <content><![CDATA[<h2 id="架构师技能图谱"><a href="#架构师技能图谱" class="headerlink" title="架构师技能图谱"></a>架构师技能图谱</h2><p>平时学习的知识比较零散，没有做系统的归类和整理，通过下面的图，可以系统的学习。 补充不太熟悉知识，做到查漏补缺。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648980331589-0ee55daa-5a4c-4388-9801-5bbf7ef036e8.png#clientId=uf38a9b84-2418-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=3031&id=u060428fd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=6061&originWidth=4127&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=1800478&status=done&style=none&taskId=u6932b75d-4b06-4d81-8172-5e9663baa00&title=&width=2063.5" alt="image.png"></p>
<h2 id="微服务架构图谱"><a href="#微服务架构图谱" class="headerlink" title="微服务架构图谱"></a>微服务架构图谱</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648980274280-d137083a-256a-407e-8636-6641f3e2c87d.png#clientId=u5affc02a-88fc-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u821406e5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=719&originWidth=1280&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=429091&status=done&style=none&taskId=uac98a620-4396-4fd8-a4fc-7a6fe7d07ab&title=" alt="image.png"></p>
]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>架构（二）秒杀架构设计</title>
    <url>/article/architecture/architecture-miaosha/</url>
    <content><![CDATA[<h2 id="秒杀业务与难点"><a href="#秒杀业务与难点" class="headerlink" title="秒杀业务与难点"></a>秒杀业务与难点</h2><p>秒杀业务在各业务中已然非常流行，这里我将互联网行业中的秒杀定义为： 在非常短的时间内，将一件商品分成多份进行购买的行为。微信抢红包、一元夺宝、双 11 大促抢购等业务本质上都可视作秒杀业务。而最近大热的抢红包的难度在于这是和钱打交道的秒杀场景，对于事务的要求性更高。 秒杀业务优化的难点或者说痛点在于： 同一件商品在同一时间段内有非常多的用户去进行抢夺，从而造成服务器资源的紧张。<br>非秒杀情况下，比如非大促的时候，用户购买的体验都是非常不错的。但是在秒杀场景下，这时意味着多个用户在同时抢一件商品，也就是并发很高，但集中在同一商品上，造成实质为串行操作。因为在数据库这层本质执行的是对同一件商品扣库存。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648980457917-053f8895-79ab-415f-9308-188a7a3903ef.png#clientId=ue66a0a2f-77e9-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=5141&id=ubd9150e7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=10282&originWidth=2278&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=2363971&status=done&style=none&taskId=u4cc2d65e-8c97-43ae-bef8-709a905f9a7&title=&width=1139" alt="image.png"></p>
]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>Architecture</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解Disruptor</title>
    <url>/article/disruptor/understanding-disruptor/</url>
    <content><![CDATA[<blockquote>
<p>Disruptor 是 LMAX 公司开源的一个高效的内存无锁队列，一个高性能的异步处理框架，或者可以认为是最快的消息框架(轻量的 JMS)，也可以认为是一个观察者模式实现，或者事件-监听模式的实现，直接称 disruptor 模式。disruptor 最大特点是高性能，其 LMAX 架构可以获得每秒 6 百万订单，用 1 微秒的延迟获得吞吐量为 100K+。理解 Disruptor 的原理，可以帮助我们更好的理解内存无锁，CAS，volatile，缓冲行等并发原理。</p>
</blockquote>
<p>本文主要从以下方面介绍 disruptor：<br>1、<a href="https://www.alicharles.com/article/disruptor/disruptor-ringbuffer/">Disruptor 概念和 RingBuffer 数据结构</a><br>2、<a href="https://www.alicharles.com/article/disruptor/disruptor-ringbuffer-read/">RingBuffer 读取</a><br>3、<a href="https://www.alicharles.com/article/disruptor/disruptor-ringbuffer-single-write/">RingBuffer 单生产者写入</a><br>4、<a href="https://www.alicharles.com/article/disruptor/disruptor-ringbuffer-muti-write/">RingBuffer 多生产者写入</a><br>5、<a href="https://www.alicharles.com/article/disruptor/disruptor-practise/">Disruptor 的 DSL 实践</a><br>6、相关的性能比较</p>
]]></content>
      <categories>
        <category>disruptor</category>
      </categories>
      <tags>
        <tag>Disruptor</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>短链生成</title>
    <url>/article/url/short-url/</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>当前短地址发号使用 hbase 的 increament 指令, 每个转短请求都会做一次操作, 当 qps 超过 1k 时, 会造成 hbase 机器报警, 需要减少 hbase 的 increament 指令调用</p>
<h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><p>修改为每个请求在本地取号, 当本地无号可取时请求 hbase 发号, 每次在 hbase 中调用 increament 时取 100 个号, 回到本地</p>
<h2 id="具体代码流程"><a href="#具体代码流程" class="headerlink" title="具体代码流程"></a>具体代码流程</h2><ul>
<li>加全局锁, 所有转短请求在取号前通过全局锁串行</li>
<li>尝试本地取号, 如果不成功, 去 hbase 取号 100 个, 放入本地缓存</li>
<li>解锁, 并继续原有转短流程</li>
</ul>
<p>待确认的点，全局锁是否需要公平 公平锁的性能是否满足需求</p>
<h2 id="修改背景"><a href="#修改背景" class="headerlink" title="修改背景"></a>修改背景</h2><p>商家有需求需要定制自己的域名不使用有赞的默认域名。<br>定制的过程涉及到一个 VIP 域名的发布，这个发布涉及到前端，后端，运维的一个 VIP 域名的维护，现在是 iron，node，后端，运维都维护了一个 VIP 名单，存储的位置也是各自维护的，之前发布过程每次发布都会有白名单不同步问题导致 VIP 商户的功能挂掉。<br>上午讨论的结果同步：<br>上午和前端，后端，运维的同事讨论了下，使用 apollo 统一维护一份域名，每次更改这份配置将自动同步到其他不同的端，保证数据的维护的一致性。</p>
<ul>
<li>短地址修改方案</li>
</ul>
<p>短地址白名单修改为由动态白名单和静态白名单合并得到，动态白名单从 apollo 中获取，静态白名单在启动时配置。<br>apollo 配置格式为 json 格式，数据结构为 map，key 为 kdtid，value 为对应域名</p>
<ul>
<li>可能影响的场景<ul>
<li>静态白名单的有效性<ul>
<li>静态白名单中配置的域名应该始终可以成功进行转短链</li>
</ul>
</li>
<li>动态白名单的有效性<ul>
<li>动态白名单中配置的域名应该可以成功转短链</li>
<li>当 apollo 中配置的动态白名单添加域名后，新增加的域名应该可以成功转短链</li>
<li>当 apollo 中配置的动态白名单减少部分域名后，如减少的域名不在静态白名单中，则该域名应该转短链失败</li>
<li>当 apollo 中配置的动态白名单减少部分域名后，如减少的域名在静态白名单中，则该域名应该可以成功转短链</li>
<li>当 apollo 中白名单配置为空时，应该只有静态白名单中的域名可以成功转短链</li>
</ul>
</li>
<li>动态白名单无法获取或是失效场景<ul>
<li>当 apollo 中配置的动态白名单不符合 json 的 map 格式时，视为动态白名单配空，与 2.e 场景一致</li>
<li>当 apollo 无法正常读取到白名单配置项时，将最后一次成功读取的值视为动态白名单的值，该值保存在 apollo-config.json 文件中</li>
</ul>
</li>
<li>短转长的场景<ul>
<li>经产品确认，该场景不受白名单限制，无论域名是否还在白名单中，短转长都应该正常进行</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="主要的方案有两种"><a href="#主要的方案有两种" class="headerlink" title="主要的方案有两种"></a>主要的方案有两种</h2><ol>
<li>hash 算法: hash 长地址得到一个短地址</li>
<li>发号器：通过发号器得到一个整数，再转为 62 进制</li>
</ol>
<h2 id="两种方案的优缺点"><a href="#两种方案的优缺点" class="headerlink" title="两种方案的优缺点"></a>两种方案的优缺点</h2><ol>
<li><p>hash 方案的优点: 生成的短链不可遍历</p>
</li>
<li><p>hash 方案的缺点：位数较短时，生成的短链容易冲突，碰撞的概率可由如下公式得出：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646818360387-c606b10f-0666-4543-a76d-19919097f615.png#clientId=ubd7c2cee-e4f0-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=44&id=u6e000831&margin=%5Bobject%20Object%5D&name=image.png&originHeight=44&originWidth=541&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=9956&status=done&style=none&taskId=u07c03a37-7e88-4869-af19-704523d54b4&title=&width=541" alt="image.png"><br>当生成的短链为 8 位，且为 62 进制时，在 hash 了 3kw 次时，碰撞的概率为 1&#x2F;2, 我们要求生成的短链接为 6 位，且目前每日的增长量为 200w，显然不符合我们的要求</p>
</li>
<li><p>发号器的优点：生成的短链必定不会碰撞</p>
</li>
<li><p>发号器的缺点：同一个 url 分两次不同的时间，生成结果不一致，且 url 容易被遍历</p>
</li>
</ol>
<h2 id="最终采取的方案"><a href="#最终采取的方案" class="headerlink" title="最终采取的方案"></a>最终采取的方案</h2><p>选择发号器，且做了一些方案上的优化解决了发号器的缺点：</p>
<ol>
<li>预先生成一亿个短链接，并随机打乱插入到 mysql，这样通过发号器拿到的 id 去更新数据库的对应主键短链，解决了短链容易被遍历，且为将来的横向扩展做了准备，当数据量即将一亿时，再重新准备插入一亿的纪录到新的 mysql 实例</li>
<li>用 redis 缓存了最近一天的长链，每次生成短链先去 redis 查，这样同一个长链接在一天内反复生成的短链相同，并且每次查询成功时，更新 key 的过期时间，所以热门的短链很大可能上生成的都是同一个短链。</li>
</ol>
<h2 id="短地址店铺隔离改造"><a href="#短地址店铺隔离改造" class="headerlink" title="短地址店铺隔离改造"></a>短地址店铺隔离改造</h2><ul>
<li>改造背景：为规避腾讯风控，短地址改为不同商家使用不同的域名访问，同时增加对不同调用方的接入管理</li>
<li>改造方案：<ul>
<li>长转短：<ul>
<li>接口输入参数为 长地址，访问限制域名，调用方 app_name，版本号</li>
<li>按照原有方案生成短地址，将短地址和长地址以及对应域名的关系存入 hbase，以供短转长时校验</li>
</ul>
</li>
<li>短转长：<ul>
<li>接口输入参数为短地址，调用方 app_name， 版本号</li>
<li>hbase 中查询到长地址和访问限制域名，校验 hbase 中的访问限制域名与参数中短地址访问的域名是否一致，如一致，按原流程返回，否则报错</li>
</ul>
</li>
<li>接入管理：<ul>
<li>前期先通过人工接入，后续改造接入 ops</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="短地址监控"><a href="#短地址监控" class="headerlink" title="短地址监控"></a>短地址监控</h2><p>监控接口 curl -H “Host: <a href="http://kdt.im/">kdt.im</a>“ “<a href="http://127.0.0.1/shorturl_status">http://127.0.0.1/shorturl_status</a><br>监控分四个维度:</p>
<ul>
<li>redis<br>a. hit: 缓存的命中次数<br>b. miss：缓存的 miss 次数，当 miss 上升时需引起注意<br>c. error：error 次数，任何非正常情况下的错误，当 error 上升时，需要立刻查看日志排查问题</li>
<li>mysql<br>a. update: 短链的更新次数<br>b. select: 缓存失效，数据库查询的次数，当次数上升时需关注<br>c. error: error 次数，任何非正常情况下的错误，当 error 上升时，需要立刻查看日志排查问题</li>
<li>lock<br>a. get: 缓存失效时，获取的锁，当次数上升时需关注<br>b. error: 任何非正常情况下的错误，当 error 上升时，需要立刻查看日志排查问题</li>
<li>发号器<br>a. current: 发号器当前的号，当发号即将达到预设的一亿、二亿时，需要进行扩容<br>b. error: 任何非正常情况下的错误，当 error 上升时，需要立刻查看日志排查问题</li>
</ul>
<h2 id="短地址部署容量"><a href="#短地址部署容量" class="headerlink" title="短地址部署容量"></a>短地址部署容量</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646818507763-fd691c4a-0b77-4895-9286-20aa70fbe593.png#clientId=ubd7c2cee-e4f0-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=267&id=ue2bfc6fe&margin=%5Bobject%20Object%5D&name=image.png&originHeight=267&originWidth=297&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=21991&status=done&style=none&taskId=uab6c0ba0-3092-49fb-acc0-a061e2ea13a&title=&width=297" alt="image.png"><br>nginx 的 qps 单机过万，umem 的 qps 单机过万，只有 udb 的 tps 单机只有 800， 目前整个系统的瓶颈在 udb</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"># &#x2F;opt&#x2F;wrk&#x2F;bin&#x2F;wrk -t 4 -c 4 -d 3600s --script get.lua http:&#x2F;&#x2F;127.0.0.1
Running 60m test @ http:&#x2F;&#x2F;127.0.0.1
4 threads and 4 connections
Thread Stats   Avg      Stdev     Max   +&#x2F;- Stdev
Latency    19.86ms   62.22ms   1.00s    93.87%
Req&#x2F;Sec   198.29     59.82   474.00     84.81%
2714028 requests in 60.00m, 832.96MB read
Requests&#x2F;sec:    753.88
Transfer&#x2F;sec:    236.93KB</code></pre>

<p>&#x2F;data&#x2F;shorturl&#x2F;src&#x2F;config.lua<br>因为没有配置解析器，不要配置有域名，直接换成 ip，tengine 要换成 openresty</p>
<p>短链链接使用 6 位字符，62^6 &#x3D; 568 亿，a-zA-Z0-9 这 62 位取 6 位组合,可产生 500 多亿个组合数量。把数字和字符组合做一定的映射，就可以产生唯一的字符串，如第 62 个组合就是 aaaaa9，第 63 个组合就是 aaaaba，再利用洗牌算法，把原字符串打乱后保存，那么对应位置的组合字符串就会是无序的组合。</p>
<p>把长网址存入数据库，取返回的 id，找出对应的字符串，例如返回 ID 为 1，那么对应上面的字符串组合就是 bbb，同理 ID 为 2 时，字符串组合为 bba，依次类推，直至到达 64 种组合后才会出现重复的可能，所以如果用上面的 62 个字符，任意取 6 个字符组合成字符串的话，你的数据存量达到 500 多亿后才会出现重复的可能。</p>
]]></content>
      <categories>
        <category>short-url</category>
      </categories>
      <tags>
        <tag>ShortUrl</tag>
      </tags>
  </entry>
  <entry>
    <title>限流熔断降级区别</title>
    <url>/article/stability/stability-diff/</url>
    <content><![CDATA[<p>熔断、限流、降级都是保持系统稳定运行的策略，但针对的场景有所不同，常用框架有 hystrix 和 sentinel</p>
<h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><p>限流是指<strong>上游服务</strong>对本服务请求 QPS 超过阙值时，通过一定的策略(如延迟处理、拒绝处理)对上游服务的请求量进行限制，以保证本服务不被压垮，从而持续提供稳定服务。常见的限流算法有滑动窗口、令牌桶、漏桶等<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1641271491145-c50a4550-6ace-4652-bd90-1a7b7304c3c6.png#clientId=u78b04063-6e1d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=232&id=u9bed191c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=232&originWidth=252&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=12424&status=done&style=none&taskId=uf6e0b014-01bf-479c-8ff3-996b9f01526&title=&width=252" alt="image.png"><br>如上图，当 服务 B 对 服务 D 请求过多时，<strong>服务 D 可以放弃一部分请求</strong>，保证自身服务的稳定</p>
<p>常见限流算法<br><a href="https://www.cnblogs.com/taromilk/p/11751211.html">https://www.cnblogs.com/taromilk/p/11751211.html</a></p>
<p>限流规则参数说明：<br>限流类型：分为 HSF 限流和 HTTP 限流。请根据应用的访问类型，选择具体的限流类型。<br>需要限流的接口：列出了应用中所有的接口。请根据实际情况选择需要限流的接口。<br>需要限流的方法：针对选择的接口，自动加载接口内所有的方法。可以根据实际情况选择某个方法进行限流，也可以选择对全部方法都进行限流。<br>被限流的应用：此时列表中将加载除当前应用以外的所有应用，因为每一个应用都可能会访问当前应用。请根据实际情况，选择被限流的应用。<br>限流粒度：主要分为 QPS 限流和 Thread 限流。<br>QPS 限流表示对请求中每秒请求次数的限制；<br>Thread 限流是对线程数的限制。<br>一般来讲线程越大则 QPS 越大，但是一个线程的 QPS 一般都会 &gt;1，因为一个线程会持续发请求，请求的响应时间一般就几十毫秒。<br>限流阈值：高于阈值时将触发限流动作。</p>
<h2 id="熔断"><a href="#熔断" class="headerlink" title="熔断"></a>熔断</h2><p>服务熔断的作用类似于我们家用的保险丝，当<strong>下游某服务出现不可用或响应超时</strong>的情况时，为了防止整个系统出现雪崩，<strong>暂时停止</strong>对该服务的调用<br>上面的解释中有两个很关键的词，一个是暂时，一个是停止。<br>停止是说，当前服务一旦对下游服务进行熔断，当请求到达时，当前服务不再对下游服务进行调用，而是<strong>使用设定好的策略(如构建默认值)直接返回</strong><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1641271468202-f451e8ba-cef9-46e5-b7e5-06d4be4c112b.png#clientId=u78b04063-6e1d-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=232&id=u0ee24bd0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=232&originWidth=252&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=11093&status=done&style=none&taskId=u9c8a0d0c-51cc-4480-888b-e79283f9fbd&title=&width=252" alt="image.png"></p>
<p>暂时是说，<strong>熔断后，并不会一直不再调用下游服务，而是以一定的策略(如每分钟调用 10 次，若均返回成功，则增大调用量)试探调用下游服务，当下游服务恢复可用时，自动停止熔断</strong>。<br>如上图，当 服务 D 不可用时，服务 B 应对 服务 D 进行熔断。</p>
<p>熔断器的设计思路<br>Closed：初始状态，熔断器关闭，正常提供服务<br>Open: 失败次数，失败百分比达到一定的阈值之后，熔断器打开，停止访问服务<br>Half-Open：熔断一定时间之后，小流量尝试调用服务，如果成功则恢复，熔断器变为 Closed 状态</p>
<p>熔断机制<br><a href="https://www.cnblogs.com/yawen/p/6655352.html">https://www.cnblogs.com/yawen/p/6655352.html</a></p>
<h2 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h2><p>降级是指当自身服务压力增大时，采取一些手段，增强自身服务的处理能力，以保障服务的持续可用。比如，<strong>下线非核心服务以保证核心服务的稳定、降低实时性、降低数据一致性</strong></p>
<p>常见降级策略<br><strong>业务降级，是指牺牲非核心的业务功能，保证核心功能的稳定运行</strong>。<br>简单来说，要实现优雅的业务降级，需要将功能实现拆分到相对独立的不同代码单元，分优先级进行隔离。在后台通过开关控制，降级部分非主流程的业务功能，减轻系统依赖和性能损耗，从而提升集群的整体吞吐率。<br><strong>降级的重点是：业务之间有优先级之分</strong>。降级的典型应用是：电商活动期间。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr>
<th><strong>措施</strong></th>
<th><strong>产生原因</strong></th>
<th>** 针对服务**</th>
</tr>
</thead><tbody><tr>
<td>限流</td>
<td>上游服务请求增多</td>
<td>上游服务</td>
</tr>
<tr>
<td>熔断</td>
<td>下游服务不可用</td>
<td>下游服务</td>
</tr>
<tr>
<td>降级</td>
<td>自身服务的处理能力不够</td>
<td>自身服务</td>
</tr>
</tbody></table><p>降级熔断相似点</p>
<ul>
<li>目的一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段</li>
<li>最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用</li>
<li>粒度一般都是服务级别</li>
<li>自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段</li>
</ul>
<p>降级熔断区别</p>
<ul>
<li>触发原因不一样，服务熔断一般是某个服务（下游服务）故障引起，</li>
<li>服务降级一般是从整体负荷考虑</li>
<li>自愈能力要求不一样，服务熔断在发生后有自愈能力，而服务降级没有该职责</li>
</ul>
<p>其他内容可参考 <a href="https://www.cnblogs.com/DengGao/p/rateLimit.html">https://www.cnblogs.com/DengGao/p/rateLimit.html</a></p>
]]></content>
      <categories>
        <category>stability</category>
      </categories>
      <tags>
        <tag>Stability</tag>
        <tag>Limit</tag>
        <tag>Fuse</tag>
        <tag>Degradation</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式一致性Raft算法</title>
    <url>/article/raft/</url>
    <content><![CDATA[<blockquote>
<p>本文是转载的<a href="https://raft.github.io/raft.pdf">论文翻译</a>，Raft 算法是可以用来替代 Paxos 算法的分布式一致性算法， 而且 raft 算法比 Paxos 算法更易懂且更容易实现。本文对 raft 论文进行翻译，希望能有助于读者更方便地理解 raft 的思想。</p>
</blockquote>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Raft 是用来管理复制日志（replicated log）的一致性协议。它跟 multi-Paxos 作用相同，效率也相当，但是它的组织结构跟 Paxos 不同。 这使得 Raft 比 Paxos 更容易理解并且更容易在工程实践中实现。为了使 Raft 协议更易懂，Raft 将一致性的关键元素分开， 如 leader 选举、日志复制和安全性，并且它实施更强的一致性以减少必须考虑的状态的数量。用户研究的结果表明，Raft 比 Paxos 更容易学习。 Raft 还包括一个用于变更集群成员的新机制，它使用重叠的大多数（overlapping majorities）来保证安全性。</p>
<h2 id="1、介绍"><a href="#1、介绍" class="headerlink" title="1、介绍"></a>1、介绍</h2><p>一致性算法允许多台机器作为一个集群协同工作，并且在其中的某几台机器出故障时集群仍然能正常工作。 正因为如此，一致性算法 在建立可靠的大规模软件系统方面发挥了关键作用。 在过去十年中，Paxos [15,16] 主导了关于一致性算法的讨论： 大多数一致性的实现都是基于 Paxos 或受其影响，Paxos 已成为用于教授学生一致性相关知识的主要工具。<br>不幸的是，Paxos 实在是太难以理解，尽管许多人一直在努力尝试使其更易懂。 此外，其架构需要复杂的改变来支持实际系统。 结果是，系统开发者和学生都在与 Paxos 斗争。<br>在我们自己与 Paxos 斗争之后，我们开始着手寻找一个新的一致性算法，可以为系统开发和教学提供更好的基础。 我们的方法是不寻常的， 因为我们的主要目标是可理解性：我们可以为实际系统定义一个一致性算法，并以比 Paxos 更容易学习的方式描述它吗？在该算法的设计过程中， 重要的不仅是如何让该算法起作用，还有清晰地知道该算法为什么会起作用。<br>这项工作的结果是一个称为 Raft 的一致性算法。 在设计 Raft 时，我们使用了特定的技术来提高可理解性，包括分解 （Raft 分离 leader 选举，日志复制和安全）和状态空间减少（相对于 Paxos ，Raft 减少了不确定性程度和服务器之间彼此不一致的方式 ）。 一项针对两个大学的 43 名学生的用户研究表明，Raft 比 Paxos 更容易理解：在学习两种算法后，其中 33 名学生能够更好地回答关于 Raft 的问题。<br>Raft 在许多方面类似于现有的一致性算法（尤其是 Oki 和 Liskov 的 Viewstamped Replication [29,22]），但它有几个新特性：</p>
<ul>
<li>Strong leader：在 Raft 中，日志条目（log entries）只从 leader 流向其他服务器。 这简化了复制日志的管理，使得 raft 更容易理解。</li>
<li>Leader 选举：Raft 使用随机计时器进行 leader 选举。 这只需在任何一致性算法都需要的心跳（heartbeats）上增加少量机制，同时能够简单快速地解决冲突。</li>
<li>成员变更：Raft 使用了一种新的联合一致性方法，其中两个不同配置的大多数在过渡期间重叠。 这允许集群在配置更改期间继续正常运行。</li>
</ul>
<p>我们认为，Raft 优于 Paxos 和其他一致性算法，不仅在教学方面，在工程实现方面也是。 它比其他算法更简单且更易于理解; 它被描述得十分详细足以满足实际系统的需要; 它有多个开源实现，并被多家公司使用; 它的安全性已被正式规定和验证; 它的效率与其他算法相当。<br>本文的剩余部分介绍了复制状态机问题（第 2 节），讨论了 Paxos 的优点和缺点（第 3 节），描述了我们实现易理解性的方法（第 4 节）， 提出了 Raft 一致性算法（第 5-8 节），评估 Raft（第 9 节），并讨论了相关工作（第 10 节）。</p>
<h2 id="2、复制状态机"><a href="#2、复制状态机" class="headerlink" title="2、复制状态机"></a>2、复制状态机</h2><p>一致性算法是在复制状态机[37]的背景下产生的。 在这种方法中，一组服务器上的状态机计算相同状态的相同副本，并且即使某些服务器宕机，也可以继续运行。<br>复制状态机用于解决分布式系统中的各种容错问题。 例如，具有单个 leader 的大规模系统，如 GFS [8]，HDFS [38] 和 RAMCloud [33] ， 通常使用单独的复制状态机来进行 leader 选举和存储 leader 崩溃后重新选举需要的配置信息。Chubby [2] 和 ZooKeeper [11] 都是复制状态机。<br>复制状态机通常使用复制日志实现，如图 1 所示。每个服务器存储一个包含一系列命令的日志，其状态机按顺序执行日志中的命令。 每个日志中命令都相同并且顺序也一样，因此每个状态机处理相同的命令序列。 这样就能得到相同的状态和相同的输出序列。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979938303-98693306-bf71-40ac-a51a-c01cfd213652.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1bb16401&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1140&originWidth=1992&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=252836&status=done&style=none&taskId=u37e1a885-3cb4-4391-a5aa-f6450ec26bb&title=" alt="image.png"><br>一致性算法的工作就是保证复制日志的一致性。 每台服务器上的一致性模块接收来自客户端的命令，并将它们添加到其日志中。 它与其他服务器上的一致性模块通信，以确保每个日志最终以相同的顺序包含相同的命令，即使有一些服务器失败。 一旦命令被正确复制， 每个服务器上的状态机按日志顺序处理它们，并将输出返回给客户端。 这样就形成了高可用的复制状态机。<br>实际系统中的一致性算法通常具有以下属性：</p>
<ul>
<li>它们确保在所有非拜占庭条件下（包括网络延迟，分区和数据包丢失，重复和乱序）的安全性（不会返回不正确的结果）。</li>
<li>只要任何大多数（过半）服务器都可以运行，并且可以相互通信和与客户通信，一致性算法就可用。 因此，五台服务器的典型集群可以容忍任何两台服务器的故障。 假设服务器突然宕机，它们可以稍后从状态恢复并重新加入群集。</li>
<li>它们不依赖于时序来确保日志的一致性：错误的时钟和极端消息延迟在最坏的情况下会导致可用性问题（译者注：言外之意是可以保证一致性）。</li>
<li>在通常情况下，只要集群的大部分（过半服务器）已经响应了单轮远程过程调用，命令就可以完成; 少数（一半以下）慢服务器不会影响整个系统性能。</li>
</ul>
<h2 id="3、Paxos-存在的问题"><a href="#3、Paxos-存在的问题" class="headerlink" title="3、Paxos 存在的问题"></a>3、Paxos 存在的问题</h2><p>在过去十年里，Leslie Lamport 的 Paxos 协议[15]几乎成为一致性的同义词：它是课堂上教授最多的一致性协议，并且大多数一致性的实现也以它为起点。 Paxos 首先定义了能够在单个决策（例如单个复制日志条目）上达成一致的协议。 我们将这个子集称为 single-decree Paxos。 然后 Paxos 组合该协议的多个实例以促进一系列决策，例如日志（multi-Paxos）。 Paxos 能够确保安全性和活性，并且支持集群成员的变更。 它的正确性已被证明，并且在正常情况下是高效的。<br>不幸的是，Paxos 有两个显著的缺点。 第一个缺点是 Paxos 非常难以理解。 Paxos 的描述晦涩难懂，臭名昭著（译者注：《The Part-time Parliament》 比较晦涩难懂，但是《Paxos Made Simple》就比较容易理解）; 很少有人成功地理解它，即使能理解也必须付出巨大的努力。 因此，已有几个尝试用更简单的方式来描述 Paxos [16,20,21] 。 这些描述集中在 single-degree Paxos ，但它们仍然具有挑战性。 在对 NSDI 2012 参会者的非正式调查中，我们发现很少有人喜欢 Paxos ，即使是经验丰富的研究人员。 我们自己也跟 Paxos 进行了艰苦的斗争; 我们也无法完全理解整个协议，直到阅读了几个更简单的描述和自己设计替代 Paxos 的协议，整个过程花了将近一年。<br>Paxos 晦涩难懂的原因是作者选择了 single-degree Paxos 作为基础。Single-decree Paxos 分成两个阶段，这两个阶段没有简单直观的说明， 并且不能被单独理解。因此，很难理解为什么该算法能起作用。Multi-Paxos 的合成规则又增加了许多复杂性。我们相信，对多个决定 （日志而不是单个日志条目）达成一致的总体问题可以用其他更直接和更明显的方式进行分解。<br>Paxos 的第二个问题是它不能为构建实际的实现提供良好的基础。 一个原因是没有针对 multi-Paxos 的广泛同意的算法。 Lamport 的描述主要是关于 single-decree Paxos; 他描述了 multi-Paxos 的可能方法，但缺少许多细节。 已经有几个尝试来具体化和优化 Paxos ，例如[26]，[39]和[13]， 但这些彼此各不相同并且跟 Lamport 描述的也不同。 像 Chubby [4] 这样的系统已经实现了类 Paxos（Paxos-like）算法，但大多数情况下，它们的细节并没有公布。<br>此外，Paxos 的架构对于构建实际系统来说是一个糟糕的设计，这是 single-decree 分解的另一个结果。 例如，独立地选择日志条目集合， 然后再将它们合并到顺序日志中几乎没有任何好处，这只会增加复杂性。 围绕日志设计系统是更简单和有效的方法，新日志条目按照约束顺序地添加到日志中。 Paxos 的做法适用于只需要做一次决策的情况，如果需要做一系列决策，更简单和快速的方法是先选择一个 leader ，然后让该 leader 协调这些决策。<br>因此，实际的系统跟 Paxos 相差很大。几乎所有的实现都是从 Paxos 开始，然后发现很多实现上的难题，接着就开发了一种和 Paxos 完全不一样的架构。 这样既费时又容易出错，而且 Paxos 本身晦涩难懂使得该问题更加严重。Paxos 的公式可能可以很好地证明它的正确性，但是现实的系统 和 Paxos 差别是如此之大，以至于这些证明并没有什么太大的价值。下面来自 Chubby 作者的评论非常典型：<br>在 Paxos 算法描述和实现现实系统之间有着巨大的鸿沟。最终的系统往往建立在一个还未被证明的协议之上。<br>由于以上问题，我们得出的结论是 Paxos 算法没有为系统实践和教学提供一个良好的基础。考虑到一致性问题在大规模软件系统中的重要性， 我们决定尝试设计一个能够替代 Paxos 并且具有更好特性的一致性算法。Raft 算法就是这次实验的结果。</p>
<h2 id="4、为可理解性而设计"><a href="#4、为可理解性而设计" class="headerlink" title="4、为可理解性而设计"></a>4、为可理解性而设计</h2><p>在设计 Raft 算法过程中我们有几个目标：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下 都是安全的并且在典型的应用条件下是可用的；并且在正常情况下是高效的。但是我们最重要的目标也是最大的挑战是可理解性。它必须保证能够 被大多数人容易地理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行扩展。<br>在设计 Raft 算法的时候，很多情况下我们需要在多个备选方案中进行选择。在这种情况下，我们基于可理解性来评估备选方案： 解释各个备选方案的难道有多大（例如，Raft 的状态空间有多复杂，是否有微妙的含义）？对于一个读者而言，完全理解这个方案和含义是否容易？<br>我们意识到这样的分析具有高度的主观性；但是我们使用了两种通用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能， 我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成 leader 选举，日志复制，安全性和成员变更几个部分。<br>我们使用的第二个方法是通过减少状态的数量来简化状态空间，使得系统更加连贯并且尽可能消除不确定性。特别的，所有的日志是不允许有空洞的， 并且 Raft 限制了使日志之间不一致的方式。尽管在大多数情况下我们都试图去消除不确定性，但是在某些情况下不确定性可以提高可理解性。 特别是，随机化方法虽然引入了不确定性，但是他们往往能够通过使用相近的方法处理可能的选择来减少状态空间。我们使用随机化来简化 Raft 中的 leader 选举算法。</p>
<h2 id="5、Raft-一致性算法"><a href="#5、Raft-一致性算法" class="headerlink" title="5、Raft 一致性算法"></a>5、Raft 一致性算法</h2><p>Raft 是一种用来管理第 2 节中描述的复制日志的算法。图 2 是该算法的浓缩，可用作参考，图 3 列举了该算法的一些关键特性。 图中的这些内容将在剩下的章节中逐一介绍。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979943304-c07abf2e-2606-4c82-9f82-675faf63c020.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6466d5c3&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1530&originWidth=1280&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=656051&status=done&style=none&taskId=u76420fdd-6029-4425-9de8-d227b718224&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979939271-fb94cf3f-fd66-4c3d-b257-e35c521003ac.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2722944f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=952&originWidth=1304&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=227027&status=done&style=none&taskId=u542ab733-c7db-4186-be74-e9b0a149cb8&title=" alt="image.png"><br>Raft 通过首先选举一个 distinguished leader，然后让它全权负责管理复制日志来实现一致性。Leader 从客户端接收日志条目， 把日志条目复制到其他服务器上，并且在保证安全性的时候通知其他服务器将日志条目应用到他们的状态机中。拥有一个 leader 大大简化了对 复制日志的管理。例如，leader 可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都是从 leader 流向其他服务器。 leader 可能宕机，也可能和其他服务器断开连接，这时一个新的 leader 会被选举出来。<br>通过选举一个 leader 的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题将会在接下来的子章节中进行讨论：<br>Leader 选举：当前的 leader 宕机时，一个新的 leader 必须被选举出来。（5.2 节） 日志复制：Leader 必须从客户端接收日志条目然后复制到集群中的其他节点，并且强制要求其他节点的日志和自己的保持一致。 安全性：Raft 中安全性的关键是图 3 中状态机的安全性：如果有任何的服务器节点已经应用了一个特定的日志条目到它的状态机中， 那么其他服务器节点不能在同一个日志索引位置应用一条不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的； 该解决方案在选举机制（5.2 节）上增加了额外的限制。 在展示一致性算法之后，本章节将讨论可用性的一些问题以及时序在系统中的作用。</p>
<h3 id="5-1-Raft-基础"><a href="#5-1-Raft-基础" class="headerlink" title="5.1 Raft 基础"></a>5.1 Raft 基础</h3><p>一个 Raft 集群包含若干个服务器节点；通常是 5 个，这样的系统可以容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于 这三个状态之一：leader、follower 或者 candidate 。在正常情况下，集群中只有一个 leader 并且其他的节点全部都是 follower 。 Follower 都是被动的：他们不会发送任何请求，只是简单的响应来自 leader 和 candidate 的请求。Leader 处理所有的客户端请求 （如果一个客户端和 follower 通信，follower 会将请求重定向给 leader）。第三种状态，candidate ， 是用来选举一个新的 leader（章节 5.2）。图 4 展示了这些状态和他们之间的转换关系；这些转换关系在接下来会进行讨论。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979939236-ffb4644b-08d1-43ed-b257-e55039699374.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9c94ba13&margin=%5Bobject%20Object%5D&name=image.png&originHeight=766&originWidth=1864&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=203315&status=done&style=none&taskId=u7b8c49e7-4dbd-4f24-9470-70cc2237f28&title=" alt="image.png"><br>Raft 把时间分割成任意长度的任期（term），如图 5 所示。任期用连续的整数标记。每一段任期从一次选举开始，一个或者多个 candidate 尝试成为 leader 。如果一个 candidate 赢得选举，然后他就在该任期剩下的时间里充当 leader 。在某些情况下，一次选举无法选出 leader 。 在这种情况下，这一任期会以没有 leader 结束；一个新的任期（包含一次新的选举）会很快重新开始。Raft 保证了在任意一个任期内，最多只有一个 leader 。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979939113-ab13a018-fd3e-408a-a482-ba3d95b8de7b.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u573ed813&margin=%5Bobject%20Object%5D&name=image.png&originHeight=736&originWidth=2094&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=115547&status=done&style=none&taskId=u5f1f2faf-f32f-4505-919a-c246cdea007&title=" alt="image.png"><br>不同的服务器节点观察到的任期转换的次数可能不同，在某些情况下，一个服务器节点可能没有看到 leader 选举过程或者甚至整个任期全程。 任期在 Raft 算法中充当逻辑时钟的作用，这使得服务器节点可以发现一些过期的信息比如过时的 leader 。每一个服务器节点存储一个当前任期号， 该编号随着时间单调递增。服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他的小，该服务器会将自己的任期号 更新为较大的那个值。如果一个 candidate 或者 leader 发现自己的任期号过期了，它会立即回到 follower 状态。 如果一个节点接收到一个包含过期的任期号的请求，它会直接拒绝这个请求。<br>Raft 算法中服务器节点之间使用 RPC 进行通信，并且基本的一致性算法只需要两种类型的 RPC。请求投票（RequestVote） RPC 由 candidate 在选举期间发起（章节 5.2），追加条目（AppendEntries）RPC 由 leader 发起， 用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时， 会进行重试， 并且他们能够并行的发起 RPC 来获得最佳的性能。</p>
<h3 id="5-2-Leader-选举"><a href="#5-2-Leader-选举" class="headerlink" title="5.2 Leader 选举"></a>5.2 Leader 选举</h3><p>Raft 使用一种心跳机制来触发 leader 选举。当服务器程序启动时，他们都是 follower 。一个服务器节点只要能从 leader 或 candidate 处接收到有效的 RPC 就一直保持 follower 状态。Leader 周期性地向所有 follower 发送心跳（不包含日志条目的 AppendEntries RPC） 来维持自己的地位。如果一个 follower 在一段选举超时时间内没有接收到任何消息，它就假设系统中没有可用的 leader ，然后开始进行选举以选出新的 leader 。<br>要开始一次选举过程，follower 先增加自己的当前任期号并且转换到 candidate 状态。然后投票给自己并且并行地向集群中的其他服务器节点发送 RequestVote RPC（让其他服务器节点投票给它）。Candidate 会一直保持当前状态直到以下三件事情之一发生：(a) 它自己赢得了这次的选举 （收到过半的投票），(b) 其他的服务器节点成为 leader ，(c) 一段时间之后没有任何获胜者。这些结果会在下面的章节里分别讨论。<br>当一个 candidate 获得集群中过半服务器节点针对同一个任期的投票，它就赢得了这次选举并成为 leader 。对于同一个任期， 每个服务器节点只会投给一个 candidate ，按照先来先服务（first-come-first-served）的原则（注意：5.4 节在投票上增加了额外的限制）。 要求获得过半投票的规则确保了最多只有一个 candidate 赢得此次选举（图 3 中的选举安全性）。一旦 candidate 赢得选举，就立即成为 leader 。 然后它会向其他的服务器节点发送心跳消息来确定自己的地位并阻止新的选举。<br>在等待投票期间，candidate 可能会收到另一个声称自己是 leader 的服务器节点发来的 AppendEntries RPC 。如果这个 leader 的任期号（包含在 RPC 中）不小于 candidate 当前的任期号，那么 candidate 会承认该 leader 的合法地位并回到 follower 状态。 如果 RPC 中的任期号比自己的小，那么 candidate 就会拒绝这次的 RPC 并且继续保持 candidate 状态。<br>第三种可能的结果是 candidate 既没有赢得选举也没有输：如果有多个 follower 同时成为 candidate ，那么选票可能会被瓜分以至于没有 candidate 赢得过半的投票。当这种情况发生时，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而， 如果没有其他机制的话，该情况可能会无限重复。<br>Raft 算法使用随机选举超时时间的方法来确保很少发生选票瓜分的情况，就算发生也能很快地解决。为了阻止选票一开始就被瓜分， 选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时； 然后该服务器赢得选举并在其他服务器超时之前发送心跳。同样的机制被用来解决选票被瓜分的情况。每个 candidate 在开始一次选举的时候 会重置一个随机的选举超时时间，然后一直等待直到选举超时；这样减小了在新的选举中再次发生选票瓜分情况的可能性。 9.3 节展示了该方案能够快速地选出一个 leader 。<br>选举的例子可以很好地展示可理解性是如何指导我们选择设计方案的。起初我们打算使用一种等级系统（ranking system）： 每一个 candidate 都被赋予一个唯一的等级（rank），等级用来在竞争的 candidate 之间进行选择。如果一个 candidate 发现另一个 candidate 拥有更高的等级，它就会回到 follower 状态，这样高等级的 candidate 能够更加容易地赢得下一次选举。 但是我们发现这种方法在可用性方面会有一下小问题。我们对该算法进行了多次调整，但是每次调整之后都会有新的小问题。 最终我们认为随机重试的方法更加显然且易于理解。</p>
<h3 id="5-3-日志复制"><a href="#5-3-日志复制" class="headerlink" title="5.3 日志复制"></a>5.3 日志复制</h3><p>Leader 一旦被选举出来，就开始为客户端请求提供服务。客户端的每一个请求都包含一条将被复制状态机执行的指令。 Leader 把该指令作为一个新的条目追加到日志中去，然后并行的发起 AppendEntries RPC 给其他的服务器，让它们复制该条目。 当该条目被安全地复制（下面会介绍），leader 会应用该条目到它的状态机中（状态机执行该指令）然后把执行的结果返回给客户端。 如果 follower 崩溃或者运行缓慢，或者网络丢包，leader 会不断地重试 AppendEntries RPC（即使已经回复了客户端） 直到所有的 follower 最终都存储了所有的日志条目。<br>日志以图 6 展示的方式组织。每个日志条目存储一条状态机指令和 leader 收到该指令时的任期号。任期号用来检测多个日志副本之间的不一致情况， 同时也用来保证图 3 中的某些性质。每个日志条目都有一个整数索引值来表明它在日志中的位置。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979939510-f6c2224b-6357-47e8-a0ce-b421b5f16685.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uce6744cc&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1306&originWidth=1706&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=235162&status=done&style=none&taskId=u3e2ca745-1229-404d-b076-927c6b64e17&title=" alt="image.png"><br>Leader 决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为已提交的。Raft 算法保证所有已提交的日志条目都是持久化的 并且最终会被所有可用的状态机执行。一旦创建该日志条目的 leader 将它复制到过半的服务器上，该日志条目就会被提交（例如在图 6 中的条目 7）。 同时，leader 日志中该日志条目之前的所有日志条目也都会被提交，包括由其他 leader 创建的条目。5.4 节讨论在 leader 变更之后应用 该规则的一些细节，并且证明了这种提交的规则是安全的。Leader 追踪将会被提交的日志条目的最大索引，未来的所有 AppendEntries RPC 都会包含该索引，这样其他的服务器才能最终知道哪些日志条目需要被提交。Follower 一旦知道某个日志条目已经被提交就会将该日志条目 应用到自己的本地状态机中（按照日志的顺序）。<br>我们设计了 Raft 日志机制来维持不同服务器之间日志高层次的一致性。这么做不仅简化了系统的行为也使得系统行为更加可预测， 同时该机制也是保证安全性的重要组成部分。Raft 维护着以下特性，这些同时也构成了图 3 中的日志匹配特性：<br>如果不同日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。 如果不同日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也都相同。 Leader 在特定的任期号内的一个日志索引处最多创建一个日志条目，同时日志条目在日志中的位置也从来不会改变。 该点保证了上面的第一条特性。第二个特性是由 AppendEntries RPC 执行一个简单的一致性检查所保证的。 在发送 AppendEntries RPC 的时候，leader 会将前一个日志条目的索引位置和任期号包含在里面。如果 follower 在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝该新的日志条目。一致性检查就像一个归纳步骤： 一开始空的日志状态肯定是满足 Log Matching Property（日志匹配特性） 的，然后一致性检查保证了日志扩展时的日志匹配特性。 因此，每当 AppendEntries RPC 返回成功时，leader 就知道 follower 的日志一定和自己相同（从第一个日志条目到最新条目）。<br>正常操作期间，leader 和 follower 的日志保持一致，所以 AppendEntries RPC 的一致性检查从来不会失败。然而，leader 崩溃的情况会使日志处于不一致的状态（老的 leader 可能还没有完全复制它日志里的所有条目）。这种不一致会在一系列的 leader 和 follower 崩溃的情况下加剧。图 7 展示了在什么情况下 follower 的日志可能和新的 leader 的日志不同。Follower 可能缺少一些在新 leader 中有的日志条目，也可能拥有一些新 leader 没有的日志条目，或者同时发生。缺失或多出日志条目的情况可能会涉及到多个任期。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979943156-d809e298-94d6-49cd-ac33-93eea25bf8fd.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uaa1ed6ad&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1064&originWidth=1622&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=191156&status=done&style=none&taskId=uc455610d-85a6-4221-b418-101971a2ecb&title=" alt="image.png"><br>图 7：当一个 leader 成功当选时（最上面那条日志），follower 可能是（a-f）中的任何情况。每一个盒子表示一个日志条目； 里面的数字表示任期号。Follower 可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。 例如，场景 f 可能这样发生，f 对应的服务器在任期 2 的时候是 leader ，追加了一些日志条目到自己的日志中， 一条都还没提交（commit）就崩溃了；该服务器很快重启，在任期 3 重新被选为 leader，又追加了一些日志条目到自己的日志中； 在这些任期 2 和任期 3 中的日志都还没被提交之前，该服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。<br>在 Raft 算法中，leader 通过强制 follower 复制它的日志来解决不一致的问题。这意味着 follower 中跟 leader 冲突的日志条目 会被 leader 的日志条目覆盖。5.4 节会证明通过增加一个限制可以保证安全性。<br>要使得 follower 的日志跟自己一致，leader 必须找到两者达成一致的最大的日志条目（索引最大），删除 follower 日志中 从那个点之后的所有日志条目，并且将自己从那个点之后的所有日志条目发送给 follower 。所有的这些操作都发生在对 AppendEntries RPCs 中一致性检查的回复中。Leader 针对每一个 follower 都维护了一个 nextIndex ， 表示 leader 要发送给 follower 的下一个日志条目的索引。当选出一个新 leader 时，该 leader 将所有 nextIndex 的值都 初始化为自己最后一个日志条目的 index 加 1（图 7 中的 11）。如果 follower 的日志和 leader 的不一致， 那么下一次 AppendEntries RPC 中的一致性检查就会失败。在被 follower 拒绝之后，leaer 就会减小 nextIndex 值 并重试 AppendEntries RPC 。最终 nextIndex 会在某个位置使得 leader 和 follower 的日志达成一致。 此时，AppendEntries RPC 就会成功，将 follower 中跟 leader 冲突的日志条目全部删除然后追加 leader 中的日志条目 （如果有需要追加的日志条目的话）。一旦 AppendEntries RPC 成功，follower 的日志就和 leader 一致，并且在该任期接下来的时间里保持一致。<br>如果想要的话，该协议可以被优化来减少被拒绝的 AppendEntries RPC 的个数。例如，当拒绝一个 AppendEntries RPC 的请求的时候， follower 可以包含冲突条目的任期号和自己存储的那个任期的第一个 index 。借助这些信息，leader 可以跳过那个任期内 所有冲突的日志条目来减小 nextIndex；这样就变成每个有冲突日志条目的任期需要一个 AppendEntries RPC 而不是每个条目一次。 在实践中，我们认为这种优化是没有必要的，因为失败不经常发生并且也不可能有很多不一致的日志条目。<br>通过这种机制，leader 在当权之后就不需要任何特殊的操作来使日志恢复到一致状态。Leader 只需要进行正常的操作， 然后日志就能在回复 AppendEntries 一致性检查失败的时候自动趋于一致。Leader 从来不会覆盖或者删除自己的日志条目 （图 3 的 Leader Append-Only 属性）。<br>这样的日志复制机制展示了第 2 节中描述的一致性特性：只要过半的服务器能正常运行，Raft 就能够接受，复制并应用新的日志条目； 在正常情况下，新的日志条目可以在一个 RPC 来回中被复制给集群中的过半机器；并且单个运行慢的 follower 不会影响整体的性能。</p>
<h3 id="5-4-安全性"><a href="#5-4-安全性" class="headerlink" title="5.4 安全性"></a>5.4 安全性</h3><p>前面的章节里描述了 Raft 算法是如何进行 leader 选举和日志复制的。然而，到目前为止描述的机制并不能充分地保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个 follower 可能会进入不可用状态，在此期间，leader 可能提交了若干的日志条目，然后这个 follower 可能会被选举为 leader 并且用新的日志条目覆盖这些日志条目；结果，不同的状态机可能会执行不同的指令序列。<br>这节通过对 leader 选举增加一个限制来完善 Raft 算法。这一限制保证了对于给定的任意任期号， leader 都包含了之前各个任期 所有被提交的日志条目（图 3 中的 Leader Completeness 性质）。有了这一 leader 选举的限制，我们也使得提交规则更加清晰。 最后，我们展示了对于 Leader Completeness 性质的简要证明并且说明该性质是如何领导复制状态机执行正确的行为的。</p>
<h4 id="5-4-1-选举限制"><a href="#5-4-1-选举限制" class="headerlink" title="5.4.1 选举限制"></a>5.4.1 选举限制</h4><p>在任何基于 leader 的一致性算法中，leader 最终都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication[22]， 一开始并没有包含所有已经提交的日志条目的服务器也可能被选为 leader 。这种算法包含一些额外的机制来识别丢失的日志条目并将它们传送给新的 leader ， 要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法， 它可以保证新 leader 在当选时就包含了之前所有任期号中已经提交的日志条目，不需要再传送这些日志条目给新 leader 。 这意味着日志条目的传送是单向的，只从 leader 到 follower，并且 leader 从不会覆盖本地日志中已经存在的条目。<br>Raft 使用投票的方式来阻止 candidate 赢得选举除非该 candidate 包含了所有已经提交的日志条目。候选人为了赢得选举必须与集群中的过半节点通信， 这意味着至少其中一个服务器节点包含了所有已提交的日志条目。如果 candidate 的日志至少和过半的服务器节点一样新（接下来会精确地定义“新”）， 那么他一定包含了所有已经提交的日志条目。RequestVote RPC 执行了这样的限制： RPC 中包含了 candidate 的日志信息， 如果投票者自己的日志比 candidate 的还新，它会拒绝掉该投票请求。<br>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号来定义谁的日志比较新。如果两份日志最后条目的任期号不同，那么任期号大的日志更新。 如果两份日志最后条目的任期号相同，那么日志较长的那个更新。</p>
<h4 id="5-4-2-提交之前任期内的日志条目"><a href="#5-4-2-提交之前任期内的日志条目" class="headerlink" title="5.4.2 提交之前任期内的日志条目"></a>5.4.2 提交之前任期内的日志条目</h4><p>如同 5.3 节描述的那样，一旦当前任期内的某个日志条目已经存储到过半的服务器节点上，leader 就知道该日志条目已经被提交了。 如果某个 leader 在提交某个日志条目之前崩溃了，以后的 leader 会试图完成该日志条目的复制。然而，如果是之前任期内的某个日志条目 已经存储到过半的服务器节点上，leader 也无法立即断定该日志条目已经被提交了。图 8 展示了一种情况，一个已经被存储到过半节点上的老日志条目， 仍然有可能会被未来的 leader 覆盖掉。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979940459-741bc4db-ed14-4c23-b2ed-a8947245665b.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ufa0379b2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=824&originWidth=1778&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=177337&status=done&style=none&taskId=u0f1ca11c-cc3e-43d8-8bdc-be878a4feef&title=" alt="image.png"><br>图 8：如图的时间序列展示了为什么 leader 无法判断老的任期号内的日志是否已经被提交。在 (a) 中，S1 是 leader ，部分地复制了索引位置 2 的日志条目。 在 (b) 中，S1 崩溃了，然后 S5 在任期 3 中通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。 然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，继续复制日志。此时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上， 但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。 但是，在崩溃之前，如果 S1 在自己的任期里复制了日志条目到大多数机器上，如 (e) 中，然后这个条目就会被提交（S5 就不可能选举成功）。 在这种情况下，之前的所有日志也被提交了。<br>为了消除图 8 中描述的问题，Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目。只有 leader 当前任期内的日志条目才通过 计算副本数目的方式来提交；一旦当前任期的某个日志条目以这种方式被提交，那么由于日志匹配特性，之前的所有日志条目也都会被间接地提交。 在某些情况下，领导人可以安全地断定一个老的日志条目已经被提交（例如，如果该条目已经存储到所有服务器上），但是 Raft 为了简化问题使用了一种更加保守的方法。<br>Raft 会在提交规则上增加额外的复杂性是因为当 leader 复制之前任期内的日志条目时，这些日志条目都保留原来的任期号。在其他的一致性算法中， 如果一个新的 leader 要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 的做法使得更加容易推导出（reason about）日志条目， 因为他们自始至终都使用同一个任期号。另外，和其他的算法相比，Raft 中的新 leader 只需要发送更少的日志条目（其他算法中必须在它们被提交之前 发送更多的冗余日志条目来给它们重新编号）。</p>
<h4 id="5-4-3-安全性论证"><a href="#5-4-3-安全性论证" class="headerlink" title="5.4.3 安全性论证"></a>5.4.3 安全性论证</h4><p>在给出了完整的 Raft 算法之后，我们现在可以更加精确的讨论 leader 完整性特性（Leader Completeness Property）（这一讨论基于 9.2 节的安全性证明）。 我们假设 leader 完整性特性是不满足的，然后我们推出矛盾来。假设任期 T 的 leader（leader T）在任期内提交了一个日志条目，但是该日志条目 没有被存储到未来某些任期的 leader 中。假设 U 是大于 T 的没有存储该日志条目的最小任期号。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979941054-e3404669-ebb2-4b31-8595-11584a6e6b6c.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u854aac64&margin=%5Bobject%20Object%5D&name=image.png&originHeight=814&originWidth=1514&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=149298&status=done&style=none&taskId=u674c58d0-9489-4962-8763-6fdfcf1cfed&title=" alt="image.png"><br>图 9：如果 S1 （任期 T 的 leader）在它的任期里提交了一个新的日志条目，然后 S5 在之后的任期 U 里被选举为 leader ， 那么肯定至少会有一个节点，如 S3，既接收了来自 S1 的日志条目，也给 S5 投票了。<br>U 一定在刚成为 leader 的时候就没有那条被提交的日志条目了（leader 从不会删除或者覆盖任何条目）。<br>Leader T 复制该日志条目给集群中的过半节点，同时，leader U 从集群中的过半节点赢得了选票。因此，至少有一个节点（投票者） 同时接受了来自 leader T 的日志条目和给 leader U 投票了，如图 9。该投票者是产生矛盾的关键。<br>该投票者必须在给 leader U 投票之前先接受了从 leader T 发来的已经被提交的日志条目；否则它就会拒绝来自 leader T 的 AppendEntries 请求（因为此时它的任期号会比 T 大）。<br>该投票者在给 leader U 投票时依然保有这该日志条目，因为任何 U 、T 之间的 leader 都包含该日志条目（根据上述的假设）， leader 从不会删除条目，并且 follower 只有跟 leader 冲突的时候才会删除条目。<br>该投票者把自己选票投给 leader U 时，leader U 的日志必须至少和投票者的一样新。这就导致了以下两个矛盾之一。<br>首先，如果该投票者和 leader U 的最后一个日志条目的任期号相同，那么 leader U 的日志至少和该投票者的一样长， 所以 leader U 的日志一定包含该投票者日志中的所有日志条目。这是一个矛盾，因为该投票者包含了该已被提交的日志条目， 但是在上述的假设里，leader U 是不包含的。<br>否则，leader U 的最后一个日志条目的任期号就必须比该投票者的大了。此外，该任期号也比 T 大，因为该投票者的最后一个 日志条目的任期号至少和 T 一样大（它包含了来自任期 T 的已提交的日志）。创建了 leader U 最后一个日志条目的之前的 leader 一定已经包含了该已被提交的日志条目（根据上述假设，leader U 是第一个不包含该日志条目的 leader）。所以，根据日志匹配特性， leader U 一定也包含该已被提交的日志条目，这里产生了矛盾。<br>因此，所有比 T 大的任期的 leader 一定都包含了任期 T 中提交的所有日志条目。<br>日志匹配特性保证了未来的 leader 也会包含被间接提交的日志条目，例如图 8 (d) 中的索引 2。<br>通过 Leader 完整性特性，我们就能证明图 3 中的状态机安全特性，即如果某个服务器已经将某个给定的索引处的日志条目应用到自己的状态机里了， 那么其他的服务器就不会在相同的索引处应用一个不同的日志条目。在一个服务器应用一个日志条目到自己的状态机中时，它的日志和 leader 的日志从开始到该日志条目都相同，并且该日志条目必须被提交。现在考虑如下最小任期号：某服务器在该任期号中某个特定的索引处 应用了一个日志条目；日志完整性特性保证拥有更高任期号的 leader 会存储相同的日志条目，所以之后任期里服务器应用该索引处的日志条目也会是相同的值。 因此，状态机安全特性是成立的。<br>最后，Raft 要求服务器按照日志索引顺序应用日志条目。再加上状态机安全特性，这就意味着所有的服务器都会按照相同的顺序应用相同的日志条目到自己的状态机中。</p>
<h3 id="5-5-Follower-和-candidate-崩溃"><a href="#5-5-Follower-和-candidate-崩溃" class="headerlink" title="5.5 Follower 和 candidate 崩溃"></a>5.5 Follower 和 candidate 崩溃</h3><p>到目前为止，我们只关注了 leader 崩溃的情况。Follower 和 candidate 崩溃后的处理方式比 leader 崩溃要简单的多，并且两者的处理方式是相同的。 如果 follower 或者 candidate 崩溃了，那么后续发送给他们的 RequestVote 和 AppendEntries RPCs 都会失败。Raft 通过无限的重试来处理这种失败； 如果崩溃的机器重启了，那么这些 RPC 就会成功地完成。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了， 那么在它重启之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样的重试不会造成任何伤害。例如，一个 follower 如果收到 AppendEntries 请求但是它的日志中已经包含了这些日志条目，它就会直接忽略这个新的请求中的这些日志条目。</p>
<h3 id="5-6-定时（timing）和可用性"><a href="#5-6-定时（timing）和可用性" class="headerlink" title="5.6 定时（timing）和可用性"></a>5.6 定时（timing）和可用性</h3><p>Raft 的要求之一就是安全性不能依赖定时：整个系统不能因为某些事件运行得比预期快一点或者慢一点就产生错误的结果。但是，可用性 （系统能够及时响应客户端）不可避免的要依赖于定时。例如，当有服务器崩溃时，消息交换的时间就会比正常情况下长，candidate 将不会等待太长的时间来赢得选举；没有一个稳定的 leader ，Raft 将无法工作。<br>Leader 选举是 Raft 中定时最为关键的方面。 只要整个系统满足下面的时间要求，Raft 就可以选举出并维持一个稳定的 leader：<br>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）<br>在这个不等式中，广播时间指的是一个服务器并行地发送 RPCs 给集群中所有的其他服务器并接收到响应的平均时间；选举超时时间就是在 5.2 节中 介绍的选举超时时间；平均故障间隔时间就是对于一台服务器而言，两次故障间隔时间的平均值。广播时间必须比选举超时时间小一个量级， 这样 leader 才能够可靠地发送心跳消息来阻止 follower 开始进入选举状态；再加上随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况 变得不可能。选举超时时间需要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定地运行。当 leader 崩溃后， 整个系统会有大约选举超时时间不可用；我们希望该情况在整个时间里只占一小部分。<br>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化地保存到稳定存储中去， 所以广播时间大约是 0.5 毫秒到 20 毫秒之间，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。 大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的要求。</p>
<h2 id="6、集群成员变更"><a href="#6、集群成员变更" class="headerlink" title="6、集群成员变更"></a>6、集群成员变更</h2><p>到目前为止，我们都假设集群的配置（参与一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔会改变集群的配置的，例如替换那些宕机的机器 或者改变复制程度。尽管可以通过使整个集群下线，更新所有配置，然后重启整个集群的方式来实现，但是在更改期间集群会不可用。另外， 如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定将配置变更自动化并将其纳入到 Raft 一致性算法中来。<br>为了使配置变更机制能够安全，在转换的过程中不能够存在任何时间点使得同一个任期里可能选出两个 leader 。不幸的是，任何服务器直接 从旧的配置转换到新的配置的方案都是不安全的。一次性自动地转换所有服务器是不可能的，所以在转换期间整个集群可能划分成两个独立的大多数（见图 10）。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979941270-f491933f-1d8d-4a1e-bb60-da1a5d0c3b93.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2e6c27ac&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1048&originWidth=1448&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=114639&status=done&style=none&taskId=u141e27c4-1e70-4ec8-a854-5da3a2261aa&title=" alt="image.png"><br>图 10：直接从一种配置转到另一种配置是不安全的，因为各个机器会在不同的时候进行转换。在这个例子中，集群从 3 台机器变成了 5 台。不幸的是， 存在这样的一个时间点，同一个任期里两个不同的 leader 会被选出。一个获得旧配置里过半机器的投票，一个获得新配置里过半机器的投票。<br>为了保证安全性，配置变更必须采用一种两阶段方法。目前有很多种两阶段的实现。例如，有些系统（比如，[22]）在第一阶段停掉旧的配置所以 不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为联合一致（joint consensus）； 一旦联合一致已经被提交了，那么系统就切换到新的配置上。联合一致结合了老配置和新配置：<br>日志条目被复制给集群中新、老配置的所有服务器。 新、旧配置的服务器都可以成为 leader 。 达成一致（针对选举和提交）需要分别在两种配置上获得过半的支持。 联合一致允许独立的服务器在不妥协安全性的前提下，在不同的时刻进行配置转换过程。此外，联合一致允许集群在配置变更期间依然响应客户端请求。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979942003-a5914296-38a1-412d-9eaa-b8fa6ff41596.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u9d1339ba&margin=%5Bobject%20Object%5D&name=image.png&originHeight=880&originWidth=1862&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=150693&status=done&style=none&taskId=u31a21db5-648b-40c9-a713-023e2a188c3&title=" alt="image.png"><br>集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置变更过程。当一个 leader 接收到一个改变配置从 C-old 到 C-new 的请求， 它就为联合一致将该配置（图中的 C-old,new）存储为一个日志条目，并以前面描述的方式复制该条目。一旦某个服务器将该新配置日志条目 增加到自己的日志中，它就会用该配置来做出未来所有的决策（服务器总是使用它日志中最新的配置，无论该配置日志是否已经被提交）。 这就意味着 leader 会使用 C-old,new 的规则来决定 C-old,new 的日志条目是什么时候被提交的。如果 leader 崩溃了， 新 leader 可能是在 C-old 配置也可能是在 C-old,new 配置下选出来的，这取决于赢得选举的 candidate 是否已经接收到了 C-old,new 配置。 在任何情况下， C-new 在这一时期都不能做出单方面决定。<br>一旦 C-old,new 被提交，那么 C-old 和 C-new 都不能在没有得到对方认可的情况下做出决定，并且 leader 完整性特性保证了只有拥有 C-old, new 日志条目的服务器才能被选举为 leader 。现在 leader 创建一个描述 C-new 配置的日志条目并复制到集群其他节点就是安全的了。 此外，新的配置被服务器收到后就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新配置的服务器就可以被关闭了。 如图 11 所示，任何时刻 C-old 和 C-new 都不能单方面做出决定；这保证了安全性。<br>在关于配置变更还有三个问题需要解决。第一个问题是，新的服务器开始时可能没有存储任何的日志条目。当这些服务器以这种状态加入到集群中， 它们需要一段时间来更新来赶上其他服务器，这段它们无法提交新的日志条目。为了避免因此而造成的系统短时间的不可用， Raft 在配置变更前引入了一个额外的阶段，在该阶段，新的服务器以没有投票权身份加入到集群中来（leader 也复制日志给它们， 但是考虑过半的时候不用考虑它们）。一旦该新的服务器追赶上了集群中的其他机器，配置变更就可以按上面描述的方式进行。<br>第二个问题是，集群的 leader 可能不是新配置中的一员。在这种情况下，leader 一旦提交了 C-new 日志条目就会退位（回到 follower 状态）。 这意味着有这样的一段时间（leader 提交 C-new 期间），leader 管理着一个不包括自己的集群；它复制着日志但不把自己算在过半里面。 Leader 转换发生在 C-new 被提交的时候，因为这是新配置可以独立运转的最早时刻（将总是能够在 C-new 配置下选出新的领导人）。 在此之前，可能只能从 C-old 中选出领导人。<br>第三个问题是，那些被移除的服务器（不在 C-new 中）可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时， 它们就会进行新的选举过程。它们会发送带有新任期号的 RequestVote RPCs ，这样会导致当前的 leader 回到 follower 状态。 新的 leader 最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致系统可用性很差。<br>为了防止这种问题，当服务器认为当前 leader 存在时，服务器会忽略 RequestVote RPCs 。特别的，当服务器在最小选举超时时间内 收到一个 RequestVote RPC，它不会更新任期号或者投票。这不会影响正常的选举，每个服务器在开始一次选举之前， 至少等待最小选举超时时间。相反，这有利于避免被移除的服务器的扰乱：如果 leader 能够发送心跳给集群，那它就不会被更大的任期号废黜。</p>
<h2 id="7、日志压缩"><a href="#7、日志压缩" class="headerlink" title="7、日志压缩"></a>7、日志压缩</h2><p>Raft 的日志在正常操作中随着包含更多的客户端请求不断地增长，但是在实际的系统中，日志不能无限制地增长。随着日志越来越长， 它会占用越来越多的空间，并且需要花更多的时间来回放。如果没有一定的机制来清除日志中积累的过期的信息，最终就会带来可用性问题。<br>快照技术是日志压缩最简单的方法。在快照技术中，整个当前系统的状态都以快照的形式持久化到稳定的存储中，该时间点之前的日志全部丢弃。 快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。<br>增量压缩方法，例如日志清理或者日志结构合并树（log-structured merge trees，LSM 树），都是可行的。这些方法每次只对一小部分数据 进行操作，这样就分散了压缩的负载压力。首先，它们先选择一个积累了大量已经被删除或者被覆盖的对象的数据区域，然后重写该区域还活着的对象， 之后释放该区域。和快照技术相比，它们需要大量额外的机制和复杂性，快照技术通过操作整个数据集来简化该问题。状态机可以用和快照技术 相同的接口来实现 LSM 树，但是日志清除方法就需要修改 Raft 了。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979943010-32487d62-f3ff-4121-a759-8b5c86d99e38.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1b049bac&margin=%5Bobject%20Object%5D&name=image.png&originHeight=904&originWidth=1396&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=150346&status=done&style=none&taskId=uaa5cf193-8c3f-4bae-8aa2-9300b500968&title=" alt="image.png"><br>一台服务器用一个新快照替代了它日志中已经提交了的条目（索引 1 到 5），该快照只存储了当前的状态（变量 x 和 y 的值）。 快照的 last included index 和 last included term 被保存来定位日志中条目 6 之前的快照<br>图 12 展示了 Raft 中快照的基本思想。每个服务器独立地创建快照，快照只包括自己日志中已经被提交的条目。 主要的工作是状态机将自己的状态写入快照中。Raft 快照中也包含了少量的元数据：the last included index 指的是最后一个被快照取代的日志条目的索引值（状态机最后应用的日志条目），the last included term 是该条目的任期号。 保留这些元数据是为了支持快照后第一个条目的 AppendEntries 一致性检查，因为该条目需要之前的索引值和任期号。 为了支持集群成员变更（第 6 节），快照中也包括日志中最新的配置作为 last included index 。一旦服务器完成写快照， 他就可以删除 last included index 之前的所有日志条目，包括之前的快照。<br>尽管通常服务器都是独立地创建快照，但是 leader 必须偶尔发送快照给一些落后的跟随者。这通常发生在 leader 已经丢弃了 需要发送给 follower 的下一条日志条目的时候。幸运的是这种情况在常规操作中是不可能的：一个与 leader 保持同步的 follower 通常都会有该日志条目。然而一个例外的运行缓慢的 follower 或者新加入集群的服务器（第 6 节）将不会有这个条目。 这时让该 follower 更新到最新的状态的方式就是通过网络把快照发送给它。<br>Leader 使用 InstallSnapshot RPC 来发送快照给太落后的 follower ；见图 13。当 follower 收到带有这种 RPC 的快照时， 它必须决定如何处理已经存在的日志条目。通常该快照会包含接收者日志中没有的信息。在这种情况下，follower 丢弃它所有的日志； 这些会被该快照所取代，并且可能一些没有提交的条目会和该快照产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误）， 那么被快照包含的条目将会被全部删除，但是快照之后的条目仍然有用并保留。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1648979943194-43eb1404-66d9-4683-8940-302ac550b9a3.png#clientId=uc4f99d0c-aa86-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u09343306&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1552&originWidth=1152&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=317733&status=done&style=none&taskId=u75c2ce70-a374-4126-9555-e0105901890&title=" alt="image.png"><br>这种快照的方式违反了 Raft 的 strong leader 原则，因为 follower 可以在不知道 leader 状态的情况下创建快照。 但是我们认为这种违背是合乎情理的。Leader 的存在，是为了防止在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成， 因此没有决策会冲突。数据依然只能从 leader 流到 follower ，只是 follower 可以重新组织它们的数据了。<br>我们考虑过一种可替代的基于 leader 的快照方案，在该方案中，只有 leader 会创建快照，然后 leader 会发送它的快照给所有的 follower 。 但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照过程。每个 follower 都已经拥有了创建自己的快照所需要的信息， 而且很显然，follower 从本地的状态中创建快照远比通过网络接收别人发来的要来得经济。第二，leader 的实现会更加复杂。例如，leader 发送快照给 follower 的同时也要并行地将新的日志条目发送给它们，这样才不会阻塞新的客户端请求。<br>还有两个问题会影响快照的性能。首先，服务器必须决定什么时候创建快照。如果快照创建过于频繁，那么就会浪费大量的磁盘带宽和其他资源； 如果创建快照频率太低，就要承担耗尽存储容量的风险，同时也增加了重启时日志回放的时间。一个简单的策略就是当日志大小达到一个固定大小的时候 就创建一次快照。如果这个阈值设置得显著大于期望的快照的大小，那么快照的磁盘带宽负载就会很小。<br>第二个性能问题就是写入快照需要花费一段时间，并且我们不希望它影响到正常的操作。解决方案是通过写时复制的技术，这样新的更新就可以 在不影响正在写的快照的情况下被接收。例如，具有泛函数据结构的状态机天然支持这样的功能。另外，操作系统对写时复制技术的支持 （如 Linux 上的 fork）可以被用来创建整个状态机的内存快照（我们的实现用的就是这种方法）。</p>
<h2 id="8、客户端交互"><a href="#8、客户端交互" class="headerlink" title="8、客户端交互"></a>8、客户端交互</h2><p>本节介绍客户端如何和 Raft 进行交互，包括客户端如何找到 leader 和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在， 并且 Raft 的解决方案和其他的也差不多。<br>Raft 的客户端发送所有的请求给 leader 。当客户端第一次启动的时候，它会随机挑选一个服务器进行通信。如果客户端第一次挑选的 服务器不是 leader ，那么该服务器会拒绝客户端的请求并且提供关于它最近接收到的领导人的信息（AppendEntries 请求包含了 leader 的网络地址）。 如果 leader 已经崩溃了，客户端请求就会超时；客户端之后会再次随机挑选服务器进行重试。<br>我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在它的调用和回复之间）。但是，如上述，Raft 可能执行同一条命令多次： 例如，如果 leader 在提交了该日志条目之后，响应客户端之前崩溃了，那么客户端会和新的 leader 重试这条指令，导致这条命令被再次执行。 解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每个客户端已经处理的最新的序列号以及相关联的回复。 如果接收到一条指令，该指令的序列号已经被执行过了，就立即返回结果，而不重新执行该请求。<br>只读的操作可以直接处理而不需要记录日志。但是，如果不采取任何其他措施，这么做可能会有返回过时数据（stale data）的风险， 因为 leader 响应客户端请求时可能已经被新的 leader 替代了，但是它还不知道自己已经不是最新的 leader 了。 线性化的读操作肯定不会返回过时数据，Raft 需要使用两个额外的预防措施来在不使用日志的情况下保证这一点。 首先，leader 必须有关于哪些日志条目被提交了的最新信息。Leader 完整性特性保证了 leader 一定拥有所有已经被提交的日志条目， 但是在它任期开始的时候，它可能不知道哪些是已经被提交的。为了知道这些信息，它需要在它的任期里提交一个日志条目。 Raft 通过让 leader 在任期开始的时候提交一个空的没有任何操作的日志条目到日志中来处理该问题。 第二，leader 在处理只读请求之前必须检查自己是否已经被替代了（如果一个更新的 leader 被选举出来了，它的信息就是过时的了）。 Raft 通过让 leader 在响应只读请求之前，先和集群中的过半节点交换一次心跳信息来处理该问题。另一种可选的方案， leader 可以依赖心跳机制来实现一种租约的形式，但是这种方法依赖 timing 来保证安全性（假设时间误差是有界的）</p>
]]></content>
      <categories>
        <category>raft</category>
      </categories>
      <tags>
        <tag>Raft</tag>
      </tags>
  </entry>
  <entry>
    <title>TMC多级缓存</title>
    <url>/article/cache/tmc/</url>
    <content><![CDATA[<blockquote>
<p>TMC (Transparent Multilevel Cache) 在通用“分布式缓存解决方案（如 CodisProxy + Redis ）”基础上，增加了以下功能：</p>
<ul>
<li>应用层热点探测</li>
<li>应用层本地缓存</li>
<li>应用层缓存命中统计</li>
</ul>
<p>以帮助应用层解决缓存使用过程中出现的热点访问问题</p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646820802045-a323118a-557c-437b-b9be-a088dbe54746.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=375&id=u40be1be5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=375&originWidth=529&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=43922&status=done&style=none&taskId=ua6df5020-2746-48b0-b0d7-c884974a4c5&title=&width=529" alt="image.png"></p>
<p>使用有赞服务的电商商家数量和类型很多， 商家会不定期做一些“商品秒杀”、“商品推广”活动， 导致“营销活动”、“商品详情”、“交易下单”等链路应用出现 缓存热点访问 的情况：</p>
<ul>
<li>活动时间、活动类型、活动商品之类的信息不可预期，导致 缓存热点访问 情况不可提前预知;</li>
<li>缓存热点访问 出现期间，应用层少数热点访问 key 产生大量缓存访问请求:冲击分布式缓存系统，大量 占据内网带宽，最终影响应用层系统稳定性;</li>
</ul>
<p>为了应对以上问题，需要一个能够 自动发现热点 并将 热点缓存访问请求前置在应用层本地缓存 的解决方案， 这就是 TMC 产生的原因。</p>
<h2 id="TMC-架构"><a href="#TMC-架构" class="headerlink" title="TMC 架构"></a>TMC 架构</h2><h3 id="业务定位"><a href="#业务定位" class="headerlink" title="业务定位"></a>业务定位</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646821796846-9a991b6c-34c8-444c-a836-a36d0a25ec5b.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=704&id=u48b2c098&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1408&originWidth=1948&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=824381&status=done&style=none&taskId=u335a67a8-16fe-4046-abdf-35aaec6946d&title=&width=974" alt="image.png"></p>
<h3 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h3><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823138502-b2037837-e4d9-49eb-a1f7-fa9ede195b43.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=773&id=ufc255c34&margin=%5Bobject%20Object%5D&name=image.png&originHeight=773&originWidth=1233&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=328621&status=done&style=none&taskId=u503f2fcc-6797-42f7-b817-b57efea6c9b&title=&width=1233" alt="image.png"></p>
<h4 id="老的上报链路"><a href="#老的上报链路" class="headerlink" title="老的上报链路"></a>老的上报链路</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823300463-ff6d428d-cac3-4fe8-8ef3-584ba8451831.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=337&id=ucfda2623&margin=%5Bobject%20Object%5D&name=image.png&originHeight=337&originWidth=1097&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=118996&status=done&style=none&taskId=u38ed54a1-a4c7-4353-b314-b765cce3b8e&title=&width=1097" alt="image.png"><br>旧架构强依赖 etcd 和 kafka</p>
<ul>
<li>etcd write 1w&#x2F;s， 击穿时 tmc 产生的 变更事件远超这个量级；</li>
<li>kafka 链路长，延迟较高且潜在风险较高。</li>
</ul>
<h4 id="新的上报通道"><a href="#新的上报通道" class="headerlink" title="新的上报通道"></a>新的上报通道</h4><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823329955-979a8907-e143-448a-a563-ed3f61d15085.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=303&id=uc8b73849&margin=%5Bobject%20Object%5D&name=image.png&originHeight=303&originWidth=1089&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=81534&status=done&style=none&taskId=u953b6a30-7332-4636-a1b2-93febeb25be&title=&width=1089" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646821907075-e77eaf88-f968-48e5-bb9d-3a545df7607d.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=894&id=Gag7f&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1788&originWidth=2466&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=523892&status=done&style=none&taskId=uc20faab3-42cc-4aa2-a04e-e7c683ce7bb&title=&width=1233" alt="image.png"><br>主要功能：热点上报、缓存失效广播、热点下发、服务依赖<br>主要接接口</p>
<ul>
<li>NotifierService#Report 供 sdk 上报新的热 key</li>
<li>NotifierService#ExpireHotKeys 供 sdk 推送 key 过期通知</li>
<li>NotifierService#Publish， 供 volcano publish 热 key</li>
</ul>
<pre class="line-numbers language-pascal" data-language="pascal"><code class="language-pascal">syntax&#x3D;&quot;proto3&quot;;

package&#x3D;v1;

service NotifierService &#123;
    rpc ExpireHotKeys (ExpireHotKeysRequest) returns (ExpireHotKeysResponse) &#123;
    &#125;

    rpc Report (ReportRequest) returns (ReportResponse) &#123;
    &#125;

    rpc Publish (PublishRequest) returns (PublishResponse) &#123;
    &#125;
&#125;

message ExpireHotKeysRequest &#123;
  repeated string appNames&#x3D;1;
  repeated bytes hotKeys&#x3D;2;
  string groupName&#x3D;3;
&#125;

message ExpireHotKeysResponse &#123;
  int32 code&#x3D;1;
  string msg&#x3D;2;
&#125;

message ReportRequest &#123;
    repeated ReportData reportData &#x3D; 1;
    string groupName &#x3D; 2;
&#125;

message ReportData &#123;
    string appName &#x3D; 1;
    string key &#x3D; 2;
    int32 accessTimes &#x3D; 3;
    int32 redisHitTimes &#x3D; 4;
    int32 localCacheHitTimes &#x3D; 5;
    int32 localCacheLossTimes &#x3D; 6;
    int32 version &#x3D; 7;
    int64 sendTime &#x3D; 8;
&#125;

message ReportResponse &#123;
    int32 code &#x3D; 1;
    string msg &#x3D; 2;
&#125;

message PublishRequest &#123;
    string groupName &#x3D; 1;
    repeated string appNames &#x3D; 2;
    repeated HotKeyChangeModel changeModels &#x3D; 3;
    int64 findAt &#x3D; 4;
    enum EventType &#123;
        NULL &#x3D; 0;
        DELETE &#x3D; 1;
        UPDATE &#x3D; 2;
        EXPIRE &#x3D; 3;
        FIND &#x3D; 4;
    &#125;
    EventType eventType &#x3D; 5;
&#125;

message HotKeyChangeModel &#123;
    string hotKey &#x3D; 1;
    int64 expireTime &#x3D; 2;
&#125;

message PublishResponse &#123;
    int32 code &#x3D; 1;
    string msg &#x3D; 2;
&#125;

&#x2F;&#x2F; code 0: 正确
&#x2F;&#x2F; code 400: 参数不对</code></pre>

<ul>
<li>按 group+key 维度聚合</li>
<li>跨注册中心的需求，采用 notifier 互调实现</li>
<li>对于 kvproxy 的 hotkey error，触发立即下发热点 key 的逻辑</li>
</ul>
<p>notifier 可能会存在内存泄露问题<br>1、双缓冲队列：通过覆盖写的方式，只能解决突发流量洪峰，丢弃 limit 以外的流量；<br>2、下游 sweep（Tether 广播或者上报 volcano-server）性能受限时，内存中的 message 会产生积压，造成泄漏；<br>使用 LRU 缓存来替换抖动的数据映射来解决</p>
<h2 id="热点计算"><a href="#热点计算" class="headerlink" title="热点计算"></a>热点计算</h2><p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823769927-04919d8e-a674-458c-9747-74815d47ef3e.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=89&id=uab9b841c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=89&originWidth=757&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=40862&status=done&style=none&taskId=ueb90a1de-ff6b-4442-af25-83381c6f784&title=&width=757" alt="image.png"></p>
<ul>
<li><strong>数据收集</strong>: 收集 Volcano-SDK 上报的 key 访问事件;</li>
<li><strong>热度滑窗</strong>: 对 App 的每个 Key ，维护一个时间轮，记录基于当前时刻滑窗的访问热度;</li>
<li><strong>热度汇聚</strong>: 对 App 的所有 Key ，以&lt;key， 热度&gt;的形式进行 热度排序汇总;</li>
<li><strong>热点探测</strong>: 对 App ，从 热 Key 排序汇总 结果中选出 TopN 的热点 Key ，推送给 volcano-SDK;</li>
</ul>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823827946-0b66c565-0753-4a82-b219-5cfa14cf0ff6.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=891&id=u3bfdcd68&margin=%5Bobject%20Object%5D&name=image.png&originHeight=891&originWidth=1893&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=463441&status=done&style=none&taskId=ub6a503d8-388c-4bb0-b5e4-7e1c20e345d&title=&width=1893" alt="image.png"></p>
<p><strong>volcano-sdk</strong><br>对于 redis 的 Jedis 客户端中封装已有的 get、set、expire、delete 操作，做热点的发现统计，以及本地缓存变更通知。<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823662468-ff5848c6-0a20-4ddc-b578-06b89099f5ce.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=1970&id=u04c4c881&margin=%5Bobject%20Object%5D&name=image.png&originHeight=1970&originWidth=2832&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=2136422&status=done&style=none&taskId=ud56b3858-b3e0-4ad2-b1e5-0de0f081211&title=&width=2832" alt="image.png"><br><strong>volcano-server</strong><br>对于收集的数据，进行滑动窗口计算，汇总，热点推送到各机器上<br><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1646823710525-c6631258-d680-43b8-954d-131d9ae6d86e.png#clientId=udf52bffe-ad73-4&crop=0&crop=0&crop=1&crop=1&from=paste&height=2232&id=u543813a8&margin=%5Bobject%20Object%5D&name=image.png&originHeight=2232&originWidth=1634&originalType=binary%E2%88%B6=1&rotation=0&showTitle=false&size=540021&status=done&style=none&taskId=ub6fb5c79-1778-47c4-ad67-cb30480bf3f&title=&width=1634" alt="image.png"></p>
<h2 id="关于缓存击穿的处理"><a href="#关于缓存击穿的处理" class="headerlink" title="关于缓存击穿的处理"></a>关于缓存击穿的处理</h2><p>如果没有处理好并发问题， 业务方很容易出现， 在缓存数据过期时， 大量相同的请求回源到底层的 DB 读取数据， 导致大量无效回源请求， 增加 DB 的压力， 在大流量的情况下可能会导致 DB 崩溃， 从而导致雪崩。 对于这种情况， 我们在 redis-zan 框架中封装了一个简易接口来避免这种情况。<br>使用 redis-zan 的业务方， 可以通过封装的接口完成缓存击穿的简化处理， 缓存失效自动 DB 回源更新缓存的使用示例:</p>
<pre class="line-numbers language-protobuf" data-language="protobuf"><code class="language-protobuf">public void testStringGet() throws ExecutionException &#123;
   String key &#x3D; &quot;youzan:test:db_callback&quot;;
   Supplier&lt;String&gt; supplier &#x3D; () -&gt; &#123;
    &#x2F;&#x2F; 处理读取db的数据, 返回对应db的值
     return ret;
   &#125;;

   &#x2F;&#x2F; 此方法会从kv读取key的值, 如果不存在, 调用supplier回调函数从db中回源, 然后自动更新到kv, 并设置指定的ttl过期时间.
   &#x2F;&#x2F; 此方法会自动处理缓存失效时多个并发回源问题, 保证只有第一个线程的调用会回源db并更新kv. 后面的线程会排队等待第一个线程返回.

   String value &#x3D; redisClient.opsForString().get(key, 5, supplier);
 &#125;</code></pre>

<p>注意， 此方式可以单独使用， 不需要开启 TMC 本地缓存功能也可以使用。<br>类似的， 对于读取业务本身就不存在的数据， 出现的缓存穿透情况， 业务可以设置一个业务认为不存在的标记， 来避免不存在的数据一直请求 DB。</p>
<h2 id="KV-增强本地缓存-LRUs"><a href="#KV-增强本地缓存-LRUs" class="headerlink" title="KV 增强本地缓存 LRUs"></a>KV 增强本地缓存 LRUs</h2><p>默认的热点缓存一般只用于少量的热点数据缓存(几百以内的 key)， tmc-kv 新功能新增支持本地 LRU 能力， 可以近实时的拦截热点(理论上可以立即缓存热点读请求)， 也可以缓存更多的数据到本地(几十万 key)， 并且通过淘汰算法自动驱逐非热点数据， 不过由于缓存的 key 更多了， 因此有可能会扩大数据不一致的影响范围(开启更新通知广播可以通过更新广播减少不一致窗口)， 适合数据修改不频繁的业务场景， 需要的业务方可以联系开发手动开启本地 LRU 增强功能。</p>
<h2 id="RPC-缓存"><a href="#RPC-缓存" class="headerlink" title="RPC 缓存"></a>RPC 缓存</h2><p>最近新增了一项 RPC 缓存功能， 来提供更加快捷的本地缓存使用方式， 可以直接缓存 RPC 的响应结果， 业务方不需要关注缓存细节。 通过 RPC 缓存，业务可以：</p>
<ul>
<li>提升请求的处理速度，提升业务的吞吐量。从本地缓存中获取响应结果，性能远高于向后端发起 RPC 请求。</li>
<li>降低后端应用负载，节省成本。本地缓存可以有效的降低后端应用处理的 RPC 请求量(RPS，requests per second)，进而降低后端应用的负载，节省成本。</li>
<li>流量削峰，提升应用稳定性。缓存命中率在秒杀等瞬间洪水流量场景下会显著提升，从而避免洪水流量瞬间冲击后端服务。</li>
</ul>
<p>通过开启缓存配置，即可零开发零成本的享受到 RPC 缓存带来的收益。对于不需要针对 kv 具体缓存数据做读取操作的应用，或者需要 kv 之外数据缓存的业务， 可以使用 RPC 缓存更加简单的提升性能。</p>
]]></content>
      <categories>
        <category>cache</category>
      </categories>
      <tags>
        <tag>Cache</tag>
        <tag>TMC</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式与GO</title>
    <url>/article/design-pattern/go-design-pattern/</url>
    <content><![CDATA[<blockquote>
<p>原文链接：<a href="https://refactoringguru.cn/design-patterns/go">https://refactoringguru.cn/design-patterns/go</a><br>代码可见：<a href="https://github.com/charles0212/design-patterns">https://github.com/charles0212/design-patterns</a></p>
</blockquote>
<p><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849120-8c935106-b50d-43e2-b077-2a346ba4ea36.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u7026b96a&margin=%5Bobject%20Object%5D&name=image.png&originHeight=600&originWidth=960&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=220800&status=done&style=none&taskId=u23e06ec8-c91e-41c5-8e49-2a209dab84c&title=" alt="image.png"></p>
<h2 id="创建型模式"><a href="#创建型模式" class="headerlink" title="创建型模式"></a>创建型模式</h2><table><colgroup><col width="20"></col><col width="80"></col></colgroup><thead><tr>
<th><strong>创建型模式</strong></th>
<th><strong>模式描述</strong></th>
</tr>
</thead><tbody>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849095-626a3435-1374-4508-ab81-9b2109b83745.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uba777813&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3905&status=done&style=none&taskId=uf226d5b6-e539-49c0-aec5-95610636e66&title=" alt="image.png"></td>
<td><strong>抽象工厂 Abstract Factory</strong>，让你能创建一系列相关的对象， 而无需指定其具体类。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849054-7304f282-6d0d-4db6-a776-27e27b6ea17d.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u4dd0d6a1&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=6475&status=done&style=none&taskId=ub6be7df0-5818-4fbc-a0ef-a326ba15135&title=" alt="image.png"></td>
<td><strong>生成器 Builder</strong>，使你能够分步骤创建复杂对象。 该模式允许你使用相同的创建代码生成不同类型和形式的对象。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849067-c3d1d6c6-8743-4b7e-af85-dcb3a2b7cae4.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ub641ba7c&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=2625&status=done&style=none&taskId=u4f78fd44-c2fd-4cc7-9b3e-90113b8a4d7&title=" alt="image.png"></td>
<td><strong>工厂方法 Factory Method</strong>，在父类中提供一个创建对象的接口以允许子类决定实例化对象的类型。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849070-e2b0651a-bf98-439d-b77e-acd81280af6c.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u86f89380&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=14041&status=done&style=none&taskId=u3ba94088-fe3a-4dc9-b98e-e424fd9d967&title=" alt="image.png"></td>
<td><strong>原型 Prototype</strong>，让你能够复制已有对象， 而又无需使代码依赖它们所属的类。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849617-3ffd03b7-59ba-493d-b9ce-a50d8e84e5c0.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u570258e5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=2128&status=done&style=none&taskId=u542f8ff7-efad-4752-b538-2b8bcbe6ef9&title=" alt="image.png"></td>
<td><strong>单例 Singleton</strong>，让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。</td>
</tr>
</tbody></table><h2 id="结构型模式"><a href="#结构型模式" class="headerlink" title="结构型模式"></a>结构型模式</h2><table><colgroup><col width="20"></col><col width="80"></col></colgroup><thead><tr>
<th><strong>结构性模式</strong></th>
<th><strong>模式描述</strong></th>
</tr>
</thead><tbody>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849754-e74d572b-1040-4330-ac23-b8258c30af2a.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2ee328c2&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=2971&status=done&style=none&taskId=u277352f6-4f8f-4352-9a49-807a6e2b43e&title=" alt="image.png"></td>
<td><strong>适配器 Adapter</strong>，让接口不兼容的对象能够相互合作。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849811-f2cbc725-8b43-47ac-b973-3df5e5ce6b30.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6c885612&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=4018&status=done&style=none&taskId=u997fd844-d4fb-4d98-8ebb-9ea19905ebe&title=" alt="image.png"></td>
<td><strong>桥接 Bridge</strong>，可将一个大类或一系列紧密相关的类拆分为抽象和实现两个独立的层次结构， 从而能在开发时分别使用。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419849824-6006c823-2710-4cce-b04b-66d052334c0f.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u2cccdb85&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3542&status=done&style=none&taskId=uc7184567-7724-4113-8d62-c4a103eb683&title=" alt="image.png"></td>
<td><strong>组合 Composite</strong>，你可以使用它将对象组合成树状结构， 并且能像使用独立对象一样使用它们。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850270-8f4560cc-e2ff-4d65-bff4-e8646e63c89d.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u0ce9d493&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=10561&status=done&style=none&taskId=u2534127f-0ba4-4ef7-9cdf-e3f8b9320da&title=" alt="image.png"></td>
<td><strong>装饰 Decorator</strong>，允许你通过将对象放入包含行为的特殊封装对象中来为原对象绑定新的行为。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850383-6f6c9195-ec0f-40e8-af0f-aab3744ef1c3.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u8fb6593d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=2784&status=done&style=none&taskId=u20bdf3c8-e29f-441e-9774-3b6dbcc2e8f&title=" alt="image.png"></td>
<td><strong>外观 Facade</strong>，能为程序库、 框架或其他复杂类提供一个简单的接口。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850393-128ff22a-0cc7-4c42-be52-ca5fcc7d4677.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u079e11fd&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3333&status=done&style=none&taskId=u5eae9f5d-d2f8-440b-b97a-643edeed936&title=" alt="image.png"></td>
<td><strong>享元 Flyweight</strong>，摒弃了在每个对象中保存所有数据的方式， 通过共享多个对象所共有的相同状态， 让你能在有限的内存容量中载入更多对象。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850546-92b8d448-1ee1-4841-9ecb-d4846da08198.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1f0338d0&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=1645&status=done&style=none&taskId=u6c6ebcbc-4063-4dd8-a702-905aab82c20&title=" alt="image.png"></td>
<td><strong>代理 Proxy</strong>，让你能够提供对象的替代品或其占位符。 代理控制着对于原对象的访问， 并允许在将请求提交给对象前后进行一些处理。</td>
</tr>
</tbody></table><h2 id="行为型模式"><a href="#行为型模式" class="headerlink" title="行为型模式"></a>行为型模式</h2><table><colgroup><col width="20"></col><col width="80"></col></colgroup><thead><tr>
<th><strong>行为性模式</strong></th>
<th><strong>模式描述</strong></th>
</tr>
</thead><tbody>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850774-43741606-2215-4297-9049-b41440f13ae3.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ua4922a46&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=4034&status=done&style=none&taskId=u0da1875d-f5b9-4f57-b97c-6de189e0cf9&title=" alt="image.png"></td>
<td><strong>责任链 Chain of Responsibility</strong>，允许你将请求沿着处理者链进行发送。 收到请求后， 每个处理者均可对请求进行处理， 或将其传递给链上的下个处理者。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850803-ce8a391b-ce80-4b21-9048-3e6fb3df91f5.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uce7c51c7&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3065&status=done&style=none&taskId=u2ee77d86-85d4-44f9-9e85-1f45d07f452&title=" alt="image.png"></td>
<td><strong>命令 Command</strong>，它可将请求转换为一个包含与请求相关的所有信息的独立对象。 该转换让你能根据不同的请求将方法参数化、 延迟请求执行或将其放入队列中， 且能实现可撤销操作。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419850856-045ccfd2-fa99-4123-810f-0be5779e9871.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u103fd17b&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=6061&status=done&style=none&taskId=u9c2c6e91-e2a6-4523-98bf-7c80a3e0914&title=" alt="image.png"></td>
<td><strong>迭代器 Iterator</strong>，让你能在不暴露集合底层表现形式 （列表、 栈和树等） 的情况下遍历集合中所有的元素。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851330-f2b8af3a-0f5b-4e54-88d4-29a7d99f8304.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u95977239&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=2038&status=done&style=none&taskId=uf6eb2c39-a29e-45c2-823d-bd5a210b3bb&title=" alt="image.png"></td>
<td><strong>中介者 Mediator</strong>，能让你减少对象之间混乱无序的依赖关系。 该模式会限制对象之间的直接交互， 迫使它们通过一个中介者对象进行合作。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851420-3d37f88e-a223-40ee-b78d-a03be8a303aa.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u768009d6&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3274&status=done&style=none&taskId=u0fb6fc6d-96a3-486a-aa57-6453e1252c6&title=" alt="image.png"></td>
<td><strong>备忘录 Memento</strong>，允许在不暴露对象实现细节的情况下保存和恢复对象之前的状态。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851452-91b361c0-b965-4671-ad50-b27d33fd4079.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u1957d769&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=8155&status=done&style=none&taskId=u4a972d76-d3c7-47e3-b467-e830209e43a&title=" alt="image.png"></td>
<td><strong>观察者 Observer</strong>，允许你定义一种订阅机制， 可在对象事件发生时通知多个 “观察” 该对象的其他对象。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851562-6be2e45f-ed63-4ce3-9d64-e11f31088452.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u53a0ee5d&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=4930&status=done&style=none&taskId=u041f7417-5e63-46aa-9c95-76178e05921&title=" alt="image.png"></td>
<td><strong>状态 State</strong>，让你能在一个对象的内部状态变化时改变其行为， 使其看上去就像改变了自身所属的类一样。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851853-78b38f09-76cb-4f59-a8e0-07c80d3ec98f.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u80f965ba&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=5693&status=done&style=none&taskId=u2c83b195-9a8c-454c-85d0-f2a12aa9d65&title=" alt="image.png"></td>
<td><strong>策略 Strategy</strong>，能让你定义一系列算法， 并将每种算法分别放入独立的类中， 以使算法的对象能够相互替换。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851960-16f0f3ad-4ec5-4c93-8964-4aca78b0fcbe.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=ue6914357&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=1585&status=done&style=none&taskId=u5ac64deb-7c04-449d-bd31-098bfb4e3c1&title=" alt="image.png"></td>
<td><strong>模板方法 Template Method</strong>，在超类中定义一个算法的框架， 允许子类在不修改结构的情况下重写算法的特定步骤。</td>
</tr>
<tr>
<td><img src="https://cdn.nlark.com/yuque/0/2022/png/104130/1651419851999-1a7d7935-a1c0-4794-8f0a-c0d61ef0cb83.png#clientId=ub9cf0ad6-367a-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=u6ee1c241&margin=%5Bobject%20Object%5D&name=image.png&originHeight=100&originWidth=140&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=3891&status=done&style=none&taskId=u55e7de19-52ec-49f9-9dbb-657aefd2004&title=" alt="image.png"></td>
<td><strong>访问者 Visitor</strong>，将算法与其所作用的对象隔离开来。</td>
</tr>
</tbody></table>]]></content>
      <categories>
        <category>design-pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>深入理解jvm虚拟机</title>
    <url>/article/jvm/understanding-jvm/</url>
    <content><![CDATA[<blockquote>
<p>每个 Java 开发者都知道 Java 字节码是执行在 JRE(（Java Runtime Environment Java 运行时环境）上的。JRE 中最重要的部分是 Java 虚拟机（JVM），JVM 负责分析和执行 Java 字节码。Java 开发人员并不需要去关心 JVM 是如何运行的。在没有深入理解 JVM 的情况下，许多开发者已经开发出了非常多的优秀的应用以及 Java 类库。不过，如果你了解 JVM 的话，你会更加了解 Java 的，并且你会轻松解决那些看似简单但是无从下手的问题。</p>
</blockquote>
<p>本系列主要从以下几个方面进行分析<br>1、<a href="https://www.alicharles.com/article/jvm/java-oom/">Java 内存区域与内存溢出</a><br>2、<a href="https://www.alicharles.com/article/jvm/jvm-gc/">垃圾收集算法以及垃圾收集器</a><br>3、<a href="https://www.alicharles.com/article/jvm/jvm-gc-allocation/">内存分配与回收策略</a><br>4、<a href="https://www.alicharles.com/article/jvm/jvm-class/">类文件结构</a><br>5、<a href="https://www.alicharles.com/article/jvm/jvm-classloader/">虚拟机类加载机制</a><br>6、<a href="https://www.alicharles.com/article/jvm/jvm-classloader-delegate/">虚拟机类加载委派模型</a><br>7、<a href="https://www.alicharles.com/article/jvm/java-memory-model/">JVM 内存模型</a><br>8、虚拟机字节码执行引擎</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
</search>
