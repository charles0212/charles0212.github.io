{"title":"Hive文件格式","slug":"yuque/Hive文件格式","date":"2021-06-19T16:00:00.000Z","updated":"2022-05-15T04:19:28.000Z","comments":true,"path":"api/articles/hive/hive-file-format.json","excerpt":"一、文件定义ORC File，它的全名是Optimized RowColumnar (ORC)file，其实就是对 RCFile做了一些优化。据官方文档介绍，这种文件格式可以提供一种高效的方法来存储Hive 数据。它的设计目标是来克服Hive 其他格式的缺陷。运用 ORC File 可以提高Hive 的读、写以及处理数据的性能。和 RCFile 格式相比，ORCFile 格式有以下优点：1、每个 task只输出单个文件，这样可以减少NameNode 的负载；2、支持各种复杂的数据类型，比如：datetime, decimal,以及一些复杂类型 struct","covers":["https://cdn.nlark.com/yuque/0/2022/png/104130/1647844523024-2b5c70d6-ad6d-4c2d-b9b3-7574e6b90e5f.png#clientId=u33b0a1c0-a42f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uedd4c4f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=601&originWidth=439&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=161175&status=done&style=none&taskId=ucae6d17b-cb33-424e-94d1-c8bfe888641&title="],"content":"<h2 id=\"一、文件定义\"><a href=\"#一、文件定义\" class=\"headerlink\" title=\"一、文件定义\"></a>一、文件定义</h2><p>ORC File，它的全名是 Optimized Row Columnar (ORC) file，其实就是对 RCFile 做了一些优化。<br>据官方文档介绍，这种文件格式可以提供一种高效的方法来存储 Hive 数据。它的设计目标是来克服 Hive 其他格式的缺陷。<br>运用 ORC File 可以提高 Hive 的读、写以及处理数据的性能。<br>和 RCFile 格式相比，ORC File 格式有以下优点：<br>1、每个 task 只输出单个文件，这样可以减少 NameNode 的负载；<br>2、支持各种复杂的数据类型，比如： datetime, decimal, 以及一些复杂类型 struct, list, map, and union；<br>3、在文件中存储了一些轻量级的索引数据；<br>4、基于数据类型的块模式压缩：<br>a、integer 类型的列用行程长度编码 run-length encoding;<br>b、String 类型的列用字典编码 dictionary encoding；<br>5、用多个互相独立的 RecordReaders 并行读相同的文件；<br>6、无需扫描 markers 就可以分割文件；<br>7、绑定读写所需要的内存；<br>8、metadata 的存储是用 Protocol Buffers 的，所以它支持添加和删除一些列。</p>\n<h2 id=\"二、文件结构\"><a href=\"#二、文件结构\" class=\"headerlink\" title=\"二、文件结构\"></a>二、文件结构</h2><p>ORC File 包含一组组的行数据，称为 stripes，除此之外，ORC File 的 file footer 还包含一些额外的辅助信息。<br>在 ORC File 文件的最后，有一个被称为 postscript 的区，它主要是用来存储压缩参数及压缩页脚的大小。<br>在默认情况下，一个 stripe 的大小为 250MB。大尺寸的 stripes 使得从 HDFS 读数据更高效。<br>在 file footer 里面包含了该 ORC File 文件中 stripes 的信息，每个 stripe 中有多少行，以及每列的数据类型。<br>当然，它里面还包含了列级别的一些聚合的结果，比如：count, min, max, and sum。<br>下图显示出可 ORC File 文件结构：<br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/104130/1647844523024-2b5c70d6-ad6d-4c2d-b9b3-7574e6b90e5f.png#clientId=u33b0a1c0-a42f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uedd4c4f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=601&originWidth=439&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=161175&status=done&style=none&taskId=ucae6d17b-cb33-424e-94d1-c8bfe888641&title=\" alt=\"image.png\"></p>\n<h2 id=\"三、Stripe-结构\"><a href=\"#三、Stripe-结构\" class=\"headerlink\" title=\"三、Stripe 结构\"></a>三、Stripe 结构</h2><p>从上图我们可以看出，每个 Stripe 都包含 index data、row data 以及 stripe footer。Stripe footer 包含流位置的目录；Row data 在表扫描的时候会用到。<br>Index data 包含每列的最大和最小值以及每列所在的行。<br>行索引里面提供了偏移量，它可以跳到正确的压缩块位置。具有相对频繁的行索引，使得在 stripe 中快速读取的过程中可以跳过很多行，尽管这个 stripe 的大小很大。<br>在默认情况下，最大可以跳过 10000 行。拥有通过过滤谓词而跳过大量的行的能力，你可以在表的 secondary keys 进行排序，从而可以大幅减少执行时间。<br>比如你的表的主分区是交易日期，那么你可以对次分区（state、zip code 以及 last name）进行排序。</p>\n<h2 id=\"四、Hive-里面如何用-ORCFile\"><a href=\"#四、Hive-里面如何用-ORCFile\" class=\"headerlink\" title=\"四、Hive 里面如何用 ORCFile\"></a>四、Hive 里面如何用 ORCFile</h2><p>在建 Hive 表的时候我们就应该指定文件的存储格式。所以你可以在 Hive QL 语句里面指定用 ORCFile 这种文件格式，如下：</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">CREATE TABLE ... STORED AS ORC\nALTER TABLE ... [PARTITION partition_spec] SET FILEFORMAT ORC\nSET hive.default.fileformat&#x3D;Orc</code></pre>\n\n<p>所有关于 ORCFile 的参数都是在 Hive QL 语句的 TBLPROPERTIES 字段里面出现，他们是：</p>\n<table><thead><tr>\n<th>Key</th>\n<th>Default</th>\n<th>Notes</th>\n</tr>\n</thead><tbody><tr>\n<td>orc.compress</td>\n<td>ZLIB</td>\n<td>high level compression (one of NONE, ZLIB, SNAPPY)</td>\n</tr>\n<tr>\n<td>orc.compress.size</td>\n<td>262,144</td>\n<td>number of bytes in each compression chunk</td>\n</tr>\n<tr>\n<td>orc.stripe.size</td>\n<td>268435456</td>\n<td>number of bytes in each stripe</td>\n</tr>\n<tr>\n<td>orc.row.index.stride</td>\n<td>10,000</td>\n<td>number of rows between index entries (must be &gt;&#x3D; 1000)</td>\n</tr>\n<tr>\n<td>orc.create.index</td>\n<td>true</td>\n<td>whether to create row indexes</td>\n</tr>\n</tbody></table><p>下面的例子是建立一个没有启用压缩的 ORCFile 的表</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">create table Addresses (\n  name string,\n  street string,\n  city string,\n  state string,\n  zip int\n) stored as orc tblproperties (&quot;orc.compress&quot;&#x3D;&quot;NONE&quot;);</code></pre>\n\n<h2 id=\"五、序列化和压缩\"><a href=\"#五、序列化和压缩\" class=\"headerlink\" title=\"五、序列化和压缩\"></a>五、序列化和压缩</h2><p>对 ORCFile 文件中的列进行压缩是基于这列的数据类型是 integer 或者 string。具体什么序列化我就不涉及了。<br>想深入了解的可以看看下面的英文：<br>Integer Column Serialization<br>Integer columns are serialized in two streams.<br>1、present bit stream: is the value non-null?<br>2、data stream: a stream of integers<br>Integer data is serialized in a way that takes advantage of the common distribution of numbers:<br>1、Integers are encoded using a variable-width encoding that has fewer bytes for small integers.<br>2、Repeated values are run-length encoded.<br>3、Values that differ by a constant in the range (-128 to 127) are run-length encoded.<br>The variable-width encoding is based on Google’s protocol buffers and uses the high bit to represent whether this byte is not the last and the lower 7 bits to encode data. To encode negative numbers, a zigzag encoding is used where 0, -1, 1, -2, and 2 map into 0, 1, 2, 3, 4, and 5 respectively.</p>\n<p>Each set of numbers is encoded this way:<br>1、If the first byte (b0) is negative:<br>-b0 variable-length integers follow.<br>2、If the first byte (b0) is positive:<br>it represents b0 + 3 repeated integers<br>the second byte (-128 to +127) is added between each repetition<br>1 variable-length integer.<br>In run-length encoding, the first byte specifies run length and whether the values are literals or duplicates. Duplicates can step by -128 to +128. Run-length encoding uses protobuf style variable-length integers.</p>\n<p>String Column Serialization<br>Serialization of string columns uses a dictionary to form unique column values The dictionary is sorted to speed up predicate filtering and improve compression ratios.<br>String columns are serialized in four streams.<br>1、present bit stream: is the value non-null?<br>2、dictionary data: the bytes for the strings<br>3、dictionary length: the length of each entry<br>4、row data: the row values<br>Both the dictionary length and the row values are run length encoded streams of integers.</p>\n","more":"<h2 id=\"一、文件定义\"><a href=\"#一、文件定义\" class=\"headerlink\" title=\"一、文件定义\"></a>一、文件定义</h2><p>ORC File，它的全名是 Optimized Row Columnar (ORC) file，其实就是对 RCFile 做了一些优化。<br>据官方文档介绍，这种文件格式可以提供一种高效的方法来存储 Hive 数据。它的设计目标是来克服 Hive 其他格式的缺陷。<br>运用 ORC File 可以提高 Hive 的读、写以及处理数据的性能。<br>和 RCFile 格式相比，ORC File 格式有以下优点：<br>1、每个 task 只输出单个文件，这样可以减少 NameNode 的负载；<br>2、支持各种复杂的数据类型，比如： datetime, decimal, 以及一些复杂类型 struct, list, map, and union；<br>3、在文件中存储了一些轻量级的索引数据；<br>4、基于数据类型的块模式压缩：<br>a、integer 类型的列用行程长度编码 run-length encoding;<br>b、String 类型的列用字典编码 dictionary encoding；<br>5、用多个互相独立的 RecordReaders 并行读相同的文件；<br>6、无需扫描 markers 就可以分割文件；<br>7、绑定读写所需要的内存；<br>8、metadata 的存储是用 Protocol Buffers 的，所以它支持添加和删除一些列。</p>\n<h2 id=\"二、文件结构\"><a href=\"#二、文件结构\" class=\"headerlink\" title=\"二、文件结构\"></a>二、文件结构</h2><p>ORC File 包含一组组的行数据，称为 stripes，除此之外，ORC File 的 file footer 还包含一些额外的辅助信息。<br>在 ORC File 文件的最后，有一个被称为 postscript 的区，它主要是用来存储压缩参数及压缩页脚的大小。<br>在默认情况下，一个 stripe 的大小为 250MB。大尺寸的 stripes 使得从 HDFS 读数据更高效。<br>在 file footer 里面包含了该 ORC File 文件中 stripes 的信息，每个 stripe 中有多少行，以及每列的数据类型。<br>当然，它里面还包含了列级别的一些聚合的结果，比如：count, min, max, and sum。<br>下图显示出可 ORC File 文件结构：<br><img src=\"https://cdn.nlark.com/yuque/0/2022/png/104130/1647844523024-2b5c70d6-ad6d-4c2d-b9b3-7574e6b90e5f.png#clientId=u33b0a1c0-a42f-4&crop=0&crop=0&crop=1&crop=1&from=paste&id=uedd4c4f5&margin=%5Bobject%20Object%5D&name=image.png&originHeight=601&originWidth=439&originalType=url%E2%88%B6=1&rotation=0&showTitle=false&size=161175&status=done&style=none&taskId=ucae6d17b-cb33-424e-94d1-c8bfe888641&title=\" alt=\"image.png\"></p>\n<h2 id=\"三、Stripe-结构\"><a href=\"#三、Stripe-结构\" class=\"headerlink\" title=\"三、Stripe 结构\"></a>三、Stripe 结构</h2><p>从上图我们可以看出，每个 Stripe 都包含 index data、row data 以及 stripe footer。Stripe footer 包含流位置的目录；Row data 在表扫描的时候会用到。<br>Index data 包含每列的最大和最小值以及每列所在的行。<br>行索引里面提供了偏移量，它可以跳到正确的压缩块位置。具有相对频繁的行索引，使得在 stripe 中快速读取的过程中可以跳过很多行，尽管这个 stripe 的大小很大。<br>在默认情况下，最大可以跳过 10000 行。拥有通过过滤谓词而跳过大量的行的能力，你可以在表的 secondary keys 进行排序，从而可以大幅减少执行时间。<br>比如你的表的主分区是交易日期，那么你可以对次分区（state、zip code 以及 last name）进行排序。</p>\n<h2 id=\"四、Hive-里面如何用-ORCFile\"><a href=\"#四、Hive-里面如何用-ORCFile\" class=\"headerlink\" title=\"四、Hive 里面如何用 ORCFile\"></a>四、Hive 里面如何用 ORCFile</h2><p>在建 Hive 表的时候我们就应该指定文件的存储格式。所以你可以在 Hive QL 语句里面指定用 ORCFile 这种文件格式，如下：</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">CREATE TABLE ... STORED AS ORC\nALTER TABLE ... [PARTITION partition_spec] SET FILEFORMAT ORC\nSET hive.default.fileformat&#x3D;Orc</code></pre>\n\n<p>所有关于 ORCFile 的参数都是在 Hive QL 语句的 TBLPROPERTIES 字段里面出现，他们是：</p>\n<table><thead><tr>\n<th>Key</th>\n<th>Default</th>\n<th>Notes</th>\n</tr>\n</thead><tbody><tr>\n<td>orc.compress</td>\n<td>ZLIB</td>\n<td>high level compression (one of NONE, ZLIB, SNAPPY)</td>\n</tr>\n<tr>\n<td>orc.compress.size</td>\n<td>262,144</td>\n<td>number of bytes in each compression chunk</td>\n</tr>\n<tr>\n<td>orc.stripe.size</td>\n<td>268435456</td>\n<td>number of bytes in each stripe</td>\n</tr>\n<tr>\n<td>orc.row.index.stride</td>\n<td>10,000</td>\n<td>number of rows between index entries (must be &gt;&#x3D; 1000)</td>\n</tr>\n<tr>\n<td>orc.create.index</td>\n<td>true</td>\n<td>whether to create row indexes</td>\n</tr>\n</tbody></table><p>下面的例子是建立一个没有启用压缩的 ORCFile 的表</p>\n<pre class=\"line-numbers language-sql\" data-language=\"sql\"><code class=\"language-sql\">create table Addresses (\n  name string,\n  street string,\n  city string,\n  state string,\n  zip int\n) stored as orc tblproperties (&quot;orc.compress&quot;&#x3D;&quot;NONE&quot;);</code></pre>\n\n<h2 id=\"五、序列化和压缩\"><a href=\"#五、序列化和压缩\" class=\"headerlink\" title=\"五、序列化和压缩\"></a>五、序列化和压缩</h2><p>对 ORCFile 文件中的列进行压缩是基于这列的数据类型是 integer 或者 string。具体什么序列化我就不涉及了。<br>想深入了解的可以看看下面的英文：<br>Integer Column Serialization<br>Integer columns are serialized in two streams.<br>1、present bit stream: is the value non-null?<br>2、data stream: a stream of integers<br>Integer data is serialized in a way that takes advantage of the common distribution of numbers:<br>1、Integers are encoded using a variable-width encoding that has fewer bytes for small integers.<br>2、Repeated values are run-length encoded.<br>3、Values that differ by a constant in the range (-128 to 127) are run-length encoded.<br>The variable-width encoding is based on Google’s protocol buffers and uses the high bit to represent whether this byte is not the last and the lower 7 bits to encode data. To encode negative numbers, a zigzag encoding is used where 0, -1, 1, -2, and 2 map into 0, 1, 2, 3, 4, and 5 respectively.</p>\n<p>Each set of numbers is encoded this way:<br>1、If the first byte (b0) is negative:<br>-b0 variable-length integers follow.<br>2、If the first byte (b0) is positive:<br>it represents b0 + 3 repeated integers<br>the second byte (-128 to +127) is added between each repetition<br>1 variable-length integer.<br>In run-length encoding, the first byte specifies run length and whether the values are literals or duplicates. Duplicates can step by -128 to +128. Run-length encoding uses protobuf style variable-length integers.</p>\n<p>String Column Serialization<br>Serialization of string columns uses a dictionary to form unique column values The dictionary is sorted to speed up predicate filtering and improve compression ratios.<br>String columns are serialized in four streams.<br>1、present bit stream: is the value non-null?<br>2、dictionary data: the bytes for the strings<br>3、dictionary length: the length of each entry<br>4、row data: the row values<br>Both the dictionary length and the row values are run length encoded streams of integers.</p>\n","categories":[{"name":"hive","path":"api/categories/hive.json"}],"tags":[{"name":"Hive","path":"api/tags/Hive.json"}]}